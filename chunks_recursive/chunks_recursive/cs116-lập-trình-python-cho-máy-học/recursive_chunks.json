[
  {
    "page_content": "rồi và tương tự như vậy cho cái việc là chúng ta làm trên cái chỉ mục dạng boolean. Chỉ mục dạng boolean thì thường được sử dụng để lọc ra những cái phần tử thỏa mãn một cái tính chất nào đó, các cái phần tử thỏa mãn tính chất nào đó. Ví dụ ở trong đây A là gồm, là một cái ma trận gồm là các phần tử là 1 2 3 4 5 6 và chúng ta sẽ có một cái boolean Index là a lớn hơn 2. Thì lúc này boolean Index của mình nó sẽ là gì? False False. Hai cái phần tử đầu tiên là False False. Tại vì 1 của mình nó đều",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:43"
    }
  },
  {
    "page_content": "đầu tiên là False False. Tại vì 1 của mình nó đều nhỏ, nó không có lớn hơn 2 nên nó sẽ là bằng False. Nhưng mà hai cái hàng tiếp theo là 3 4 5 6 thì đều là lớn hơn 2. Do đó nó sẽ trở là True True. Boolean Index của mình sẽ là cái ma trận như thế này. Và khi chúng ta truyền `a[boolean Index]` thì nó cũng tương đương với cái việc là chúng ta có thể ghi gọn lại là `a[a > 2]`. Nó sẽ ra cái kết quả như sau, đó là một cái array là một cái vector các cái phần tử trong cái ma trận A này có giá trị lớn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 1,
      "start_timestamp": "0:00:38",
      "end_timestamp": "0:01:19"
    }
  },
  {
    "page_content": "phần tử trong cái ma trận A này có giá trị lớn hơn 2, đó là 3 4 5 6. Thì đây là hai cách. Thì mình thích viết cái cách ở dưới hơn, đó nó gọn hơn. `a > 2` nó sẽ trả về một cái boolean dạng như là Index như thế này, và chúng ta đóng thêm một, đưa nó vào bên trong cái dấu ngoặc vuông này, thì hàm ý đó là chúng ta sẽ lấy ra những cái phần tử có giá trị lớn. Và chúng ta sẽ có các cái phương thức khác nữa cũng được sử dụng rất là phổ biến: `argmax` sẽ là trả về phần tử lớn nhất thì `argmax` sẽ trả về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 2,
      "start_timestamp": "0:01:14",
      "end_timestamp": "0:01:51"
    }
  },
  {
    "page_content": "là trả về phần tử lớn nhất thì `argmax` sẽ trả về cái chỉ số của phần tử lớn nhất. `argmin` sẽ là trả về cái chỉ số của phần tử nhỏ nhất. `argsort` là chúng ta thay vì chúng ta `sort` và in ra các giá trị theo thứ tự giảm dần hoặc tăng dần thì `argsort` nó sẽ trả về các cái chỉ số của các phần tử sau khi đã `sort` xong. `where` là để lấy những chỉ số thỏa mãn một phần tử nào, thỏa mãn một điều kiện nào đó. Rồi thì chúng ta thấy cái array ở đây. `argmax` của A. Thì `np.max(A)` nó là số 9 đúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 3,
      "start_timestamp": "0:01:46",
      "end_timestamp": "0:02:30"
    }
  },
  {
    "page_content": "`argmax` của A. Thì `np.max(A)` nó là số 9 đúng không? Thì số 9 ở đây nó sẽ có hai giá trị, số 9 là 9 ở đây và 9 ở đây. Thì `argmax` nó sẽ trả về cái phần tử đầu tiên, đó chính là phần tử này. Chỉ số của nó sẽ là 0 1 2, tức là phần tử 2 ở đây. Rồi `argmin` thì ở đây giá trị nhỏ nhất của mình sẽ là -3 và cái chỉ số của mình sẽ là 0 1 2 3, tức là chỉ số 3. Như vậy là phần tử thứ ba sẽ cho giá trị là nhỏ nhất. `argsort` thì nó sẽ sắp xếp theo thứ tự giảm dần à, xin lỗi, sắp xếp theo thứ tự tăng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 4,
      "start_timestamp": "0:02:21",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "tự giảm dần à, xin lỗi, sắp xếp theo thứ tự tăng dần, và cái giá trị mà mình trả về của cái hàm `argsort` này chính là các chỉ số của các phần tử được sắp xếp theo thứ tự tăng dần. Tương tự như vậy ha, cho các cái ví dụ dưới. `np.where` rồi, `np.where(a >= np.max(a))` Tức là ở đây cái ý của cái câu lệnh này đó là hãy chỉ ra những cái vị trí, những cái chỉ mục nào mà của các phần tử đạt được cái giá trị là lớn nhất. Thì ở đây có hai phần tử là tại vị trí số 2 và số 7. Vị trí số 2 là đây và vị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 5,
      "start_timestamp": "0:03:00",
      "end_timestamp": "0:03:45"
    }
  },
  {
    "page_content": "tại vị trí số 2 và số 7. Vị trí số 2 là đây và vị trí số 7 là đây. Rồi, cái số 3, cái mục phần thứ ba đó chính là chúng ta có thể tạo ra được rất nhiều những cái kiểu dữ liệu khác nhau, chứ không phải là những số dạng số nguyên như ở trên đây. Chúng ta có hỗ trợ những cái số như là số thực nè, rồi thậm chí là số nguyên nhưng mà có cái số lượng phần tử, xin lỗi, có cái khả năng biểu diễn lớn, tức là có kích thước lớn. Ví dụ như là `int64`. Đó thì ở đây chúng ta chạy thử ha. Kiểu dữ liệu của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 6,
      "start_timestamp": "0:03:40",
      "end_timestamp": "0:04:22"
    }
  },
  {
    "page_content": "ở đây chúng ta chạy thử ha. Kiểu dữ liệu của mình là kiểu `int64` nè, `float64` nè, và số thực à số nguyên `int64`. Rồi array mà, tức là array có hỗ trợ các cái thao tác tính toán, có hỗ trợ các thao tác số học. Thì ở đây chúng ta có một cái lưu ý quan trọng. Nếu như cái NumPy array của mình nó có các cái hàm nào mà đã được cài đặt sẵn rồi thì chúng ta ưu tiên sử dụng những hàm đó thay vì chúng ta cài đặt lại. Ở đây chúng ta thấy là cái hàm tính tổng tất cả các phần tử trong array A có 100",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 7,
      "start_timestamp": "0:04:17",
      "end_timestamp": "0:05:00"
    }
  },
  {
    "page_content": "tính tổng tất cả các phần tử trong array A có 100 triệu phần tử, có 100 triệu phần tử thì nếu như chúng ta thực hiện cái lệnh này nó chỉ tốn của chúng ta có 76 ms. Trong khi đó nếu như chúng ta thực hiện với cái vòng lặp for duyệt các phần tử từ đầu cho đến cuối và chúng ta cộng dồn thì cái tốc độ nó cực kỳ chậm. Thì cái ví dụ này cho chúng ta thấy đó là thay vì chúng ta cài đặt lại thì đừng nên như vậy, mà hãy sử dụng tận dụng tối đa những cái hàm có sẵn của NumPy thì tốc độ nó sẽ nhanh hơn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 8,
      "start_timestamp": "0:04:51",
      "end_timestamp": "0:05:30"
    }
  },
  {
    "page_content": "hàm có sẵn của NumPy thì tốc độ nó sẽ nhanh hơn rất nhiều. Thì ở đây chúng ta thấy nè, cũng là hàm tính tổng nhưng mà ở đây nó sẽ tốn hết 20 giây, trong khi ở đây chưa tới 1 giây, chưa tới 0.1 giây. Tốc độ rất là nhanh. Thì chúng ta sẽ cố gắng đó là sử dụng những cái hàm có sẵn ha. Ngoài ra thì chúng ta cũng cố gắng sử dụng những cái phương pháp dạng vector hóa. Ví dụ ở đây chúng ta cộng hai cái vector này là `[1, 2]` cộng với 1 thì thay vì chúng ta viết vòng for cộng 1 với 1 cộng 2 với 1 thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 9,
      "start_timestamp": "0:05:24",
      "end_timestamp": "0:06:14"
    }
  },
  {
    "page_content": "ta viết vòng for cộng 1 với 1 cộng 2 với 1 thì chúng ta có thể dùng trực tiếp là `data` cộng 1, tức là chúng ta sẽ lấy hai cái vector cộng trực tiếp với nhau thì tốc độ nó sẽ nhanh hơn rất nhiều so với việc chúng ta viết vòng for. Thì toán tử cộng này nó cũng tương đương với lại cái hàm là hàm `np.add`. Rồi, tương tự như vậy cho phép trừ. Và đối với phép nhân thì chúng ta sẽ có cái phép là `x * y`, tức là đây là nhân theo từng phần tử hay còn gọi là Element- wise. Đó, thì cái cách là `x * y`",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 10,
      "start_timestamp": "0:06:07",
      "end_timestamp": "0:06:46"
    }
  },
  {
    "page_content": "gọi là Element- wise. Đó, thì cái cách là `x * y` với lại `np.multiply(x, y)` nó cũng tương đương nhau và cho kết quả giống nhau. Thì đây là nhân Element-wise, tức là nhân Element-wise. Tức là nhân theo từng phần tử. Thì số phần tử của X và số phần tử của Y nó phải giống nhau. Tương tự như vậy cho phép chia, tính căn. Để mà chúng ta muốn thực hiện cái phép nhân mà nhân dạng nhân ma trận trong đại số tuyến tính. Trong đại số tuyến tính thì hai ma trận A và B nhân nhau (A nhân với B) thì số cột",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 11,
      "start_timestamp": "0:06:41",
      "end_timestamp": "0:07:37"
    }
  },
  {
    "page_content": "trận A và B nhân nhau (A nhân với B) thì số cột của A phải trùng với số dòng của B. Thì ở đây chúng ta thấy có ba cột và ở đây phải có ba dòng thì mới có thể nhân được với nhau. Thì để thực hiện được cái phép nhân ma trận này, chúng ta sẽ phải sử dụng cái hàm đó là hàm `dot`. Hàm `dot` là `v.dot(w)` và `np.dot(v, w)`. Thì hai cái cách này hoàn toàn tương tự nhau ha, `v.dot(w)` hoặc là `np.dot(v, w)`. Chúng ta sẽ truyền V và W. Còn một cái toán tử khác đó chính là toán tử `@` nó cũng là nhân ma",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 12,
      "start_timestamp": "0:07:33",
      "end_timestamp": "0:08:12"
    }
  },
  {
    "page_content": "khác đó chính là toán tử `@` nó cũng là nhân ma trận. Đó thì cái kết quả của mình nó ra giống nhau. Rồi đây ba cách. Rồi ngoài các cái hàm `argmin`, `argmax` thì ở đây chúng ta thấy là NumPy có hỗ trợ rất nhiều những cái hàm phổ thông. Ví dụ như hàm `max`, hàm `min`, hàm `sum` và thậm chí là hàm tính trung bình. Rồi hàm tính trung bình tất cả các phần tử. Rồi ở đây chúng ta sẽ thêm một cái một cái cách thức nữa, đó là nếu như chúng ta không muốn tìm giá trị lớn nhất cho tất cả các phần tử của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 13,
      "start_timestamp": "0:08:08",
      "end_timestamp": "0:08:47"
    }
  },
  {
    "page_content": "tìm giá trị lớn nhất cho tất cả các phần tử của X, hoặc là tìm giá trị nhỏ nhất trên tất cả phần tử của X, mà chúng ta đang muốn tìm theo những cái phần tử lớn nhất theo từng dòng hoặc là phần tử lớn nhất theo từng cột, thì chúng ta sẽ truyền vào cái `axis` của mình đây. `axis` bằng 0 tức là chúng ta đang làm trên cột. `axis` bằng 0 chúng ta làm trên cột. Ví dụ ở đây chúng ta có `data` là ma trận [[1, 2], [5, 3], [4, 6]]. Theo cột đầu tiên giá trị lớn nhất sẽ là 5. Theo cột tiếp theo giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 14,
      "start_timestamp": "0:08:41",
      "end_timestamp": "0:09:32"
    }
  },
  {
    "page_content": "trị lớn nhất sẽ là 5. Theo cột tiếp theo giá trị lớn nhất sẽ là 6. Thì cái hàm này nó sẽ trả về hai phần tử là 5 và 6. Nếu chúng ta cho `axis` là bằng 1 thì chúng ta sẽ đang làm theo từng hàng. Thì hàng đầu tiên giá trị lớn nhất của mình sẽ là 2. Hàng tiếp theo giá trị lớn nhất sẽ là 5. Hàng tiếp theo giá trị lớn nhất sẽ là 6. Như vậy chúng ta sẽ có 2, 5, 6. Còn `axis` bằng 0 tức là 5 và 6 thôi. Thì chi tiết các cái hàm khác chúng ta có thể tham khảo thêm trong cái nguồn tài liệu ở đây.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 15,
      "start_timestamp": "0:09:25",
      "end_timestamp": "0:10:09"
    }
  },
  {
    "page_content": "tham khảo thêm trong cái nguồn tài liệu ở đây. Mathematical functions. Rồi ngoài ra thì trong NumPy sẽ có hỗ trợ thao tác `transpose` (hay còn gọi là chuyển vị) là chuyển một cái ma trận từ dạng như thế này [[1, 2, 3], [4, 5, 6]] lật ngược nó lại thành [[1, 4], [2, 5], [3, 6]]. Và thì đây cũng là một trong những thao tác dùng rất là phổ biến trong đại số tuyến tính. Rồi, ví dụ array 1D [1,2,3] thì transpose vẫn là [1,2,3]. Rồi hàm `reshape` tức là hàm này giúp cho chúng ta định hình lại cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 16,
      "start_timestamp": "00:10:03",
      "end_timestamp": "0:10:51"
    }
  },
  {
    "page_content": "là hàm này giúp cho chúng ta định hình lại cái kích thước của dữ liệu của mình. Ví dụ ở bên trái chúng ta có cái data là 1 2 3 4 5 6, tức là một cái vector. Chúng ta muốn biến nó thành một cái ma trận kích thước là 2 x 3 thì chúng ta sẽ dùng hàm là `data.reshape(2,3)`. Nó sẽ tạo ra là [[1, 2, 3]], số dòng [[4, 5, 6]]. Tương tự như vậy cho `data.reshape(3,2)`. Thì ở đây nó sẽ tạo ra một cái ma trận kích thước là ba dòng và hai cột là [[1,2]], xuống dòng [[3,4]], rồi [[5,6]]. Rồi thì khi chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 17,
      "start_timestamp": "0:10:44",
      "end_timestamp": "0:11:34"
    }
  },
  {
    "page_content": "dòng [[3,4]], rồi [[5,6]]. Rồi thì khi chúng ta `reshape` thì nếu như chúng ta truyền vào một cái giá trị đó là -1 thì hàm ý đó là thư viện NumPy của mình sẽ tính xem cái số phần tử của mình nó sẽ là bao nhiêu. Đó ví dụ ở đây `w` ban đầu của mình á là gồm có các cái là một array (hoặc vector) gồm ba phần tử, ví dụ như [1, 2, 3]. Thì khi chúng ta `reshape(-1)` vector và nó không cần phải chỉ ra cái số phần tử của mình là bao nhiêu. Chúng ta chỉ cần truyền vào -1 thì NumPy nó sẽ tự biết là à, ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 18,
      "start_timestamp": "0:11:28",
      "end_timestamp": "0:12:13"
    }
  },
  {
    "page_content": "cần truyền vào -1 thì NumPy nó sẽ tự biết là à, ở đây có ba phần tử nên kết quả của mình nó sẽ là 3. Tương tự như vậy cho hàm `squeeze`. Rồi nếu như chúng ta muốn chuyển cái hàm này về trở lại cái ma trận đúng không, thì chúng ta sẽ truyền vào một cái `tuple` và chúng ta cho nó biết là à cái số cột của mình là 1, số cột của mình nó sẽ là 1, còn số hàng của mình là bao nhiêu thì tự NumPy nó sẽ tính. Tự NumPy nó sẽ tính là bao nhiêu. Thì ở đây `y` của mình nó có ba phần tử, nên nếu chỉ có một cột",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 19,
      "start_timestamp": "0:12:07",
      "end_timestamp": "0:13:26"
    }
  },
  {
    "page_content": "của mình nó có ba phần tử, nên nếu chỉ có một cột thì số hàng. Và cuối cùng đó chính là cơ chế `broadcasting`. Đây là một trong những cơ chế rất là hiệu quả giúp cho chúng ta đơn giản hóa cái công thức của mình. Thì ở đây chúng ta sẽ có các cái ví dụ nếu như cái array của mình, khi chúng ta thực hiện cái phép cộng hoặc là phép nhân hoặc các cái phép tính mà kích thước của các cái phần tử nó không giống nhau. Ví dụ bên trái là một cái vector ba phần tử. Nhưng B bên phải nó là một giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 20,
      "start_timestamp": "0:13:20",
      "end_timestamp": "0:13:39"
    }
  },
  {
    "page_content": "ba phần tử. Nhưng B bên phải nó là một giá trị `scalar` thì tự động nó sẽ chuyển cái giá trị `scalar` này thành một cái vector là `[1,1,1]`. Và khi đó chúng ta sẽ cộng lại. Ở đây thì chúng ta sẽ thấy là array của mình bên trái sẽ là một cái array hai chiều, trong đó thì có hai hàng Nếu hai array có số chiều khác nhau. Ví dụ ở đây ha, array A có `shape` là (3,) (tức là một chiều), khác số chiều so với array B (có hai chiều). Thì kích thước của array với số chiều ít hơn sẽ được chèn thêm một về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "với số chiều ít hơn sẽ được chèn thêm một về phía đầu bên tay trái. Tức là `shape` (3,) đúng không? `Tuple` ở đây chỉ có một phần tử là 3 thì nó sẽ chèn thêm số 1 ở trước số 3 này, tức là nó sẽ chuyển về cái `shape` là (1,3). Như vậy số chiều của array A lúc này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ozeUUS9DzQ",
      "filename": "0ozeUUS9DzQ",
      "title": "[CS116 - Buổi 2] Part 4 (tt)",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tiếp theo một cái thành phần cũng rất là quan trọng trong lập trình Python và nó cũng liên quan đến khá là nhiều đến môn học này đó chính là Lập trình hướng đối tượng thì ở đây chúng ta sẽ có một cái hình ảnh minh họa đó là một cái thực thể trong đời sống đúng không Thì nó sẽ biểu diễn trong máy tính là thông qua các cái công cụ đó là class hoặc là object hoặc Ví dụ như cái người sinh viên này là có email và có số điện thoại rồi có các cái phương thức ví dụ như là gửi email hoặc là gọi điện thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:01:08"
    }
  },
  {
    "page_content": "thức ví dụ như là gửi email hoặc là gọi điện thì đây là một cái hình ảnh minh họa tượng trưng cho cái việc là chúng ta sẽ mô phỏng một cái thực thể ở ngoài đời thực bằng các cái lớp đối tượng ở bên trong ngôn ngữ lập trình thì các tính chất của một cái hướng lập trình đối tượng thì nó sẽ bao gồm tính chất đó là trừu tượng hóa trừu tượng hóa rồi tính encapsulation tức là tính đóng gói các cái dữ liệu và phương thức inheritance rất là tính kế thừa tức là chúng ta có thể tái sử dụng lại code của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 1,
      "start_timestamp": "00:01:02",
      "end_timestamp": "0:01:42"
    }
  },
  {
    "page_content": "tức là chúng ta có thể tái sử dụng lại code của lớp cha mà không cần phải cài đặt lại ở các cái lớp mà kế thừa là nó còn kế thừa rồi tính đa hình thì đây là 4 cái tính chất cơ bản của Lập trình hướng đối tượng thì đầu tiên chúng ta tiên đó là object là một cái dữ liệu trừu tượng nó sẽ bao gồm những cái dữ liệu nội bộ dữ liệu nội bộ và được truy xuất thông qua cái thuộc tính của dữ liệu cái thứ hai đó chính là cái giao diện interface để tương tác với object thông qua các cái phương thức và hay",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 2,
      "start_timestamp": "00:01:36",
      "end_timestamp": "0:02:20"
    }
  },
  {
    "page_content": "với object thông qua các cái phương thức và hay còn gọi là hàm thủ tục thì chút nữa thì chúng ta sẽ nói chi tiết hơn là làm sao chúng ta có thể tạo ra một cái lớp đối tượng thông qua việc là tạo một cái class với cái tên class các định nghĩa các cái thuộc tính và các phương thức thì hiểu một cách nôm Na tên class cho một nhóm đối tượng Ví dụ như ở trong trường hợp thì chúng đặc trưng cho cái đối tượng của mình cho cái lớp đối tượng của mình và lưu ý là cái thuộc tính này thì mỗi một cái thực",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 3,
      "start_timestamp": "00:02:15",
      "end_timestamp": "0:03:28"
    }
  },
  {
    "page_content": "lưu ý là cái thuộc tính này thì mỗi một cái thực thể một cái đối tượng sẽ có chứa những giá trị khác nhau Ví dụ như một bạn sinh viên tên là Nguyễn Văn A tuổi là 20 tuổi những cái trường thuộc tính để đại đó phương thức này nó giống hành động Ví dụ như sinh viên thì sẽ có các cái tạo một cái thực thể mới cho cái class đó Lưu ý class nó giống như là một tập hợp nó giống như là một cái tập hợp đại là một cái một cái phần tử trong cái tập hợp này và để thực hiện được các phép toán tử và phải các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 4,
      "start_timestamp": "00:03:25",
      "end_timestamp": "0:05:10"
    }
  },
  {
    "page_content": "và để thực hiện được các phép toán tử và phải các phương thức trên các instance vừa tạo được ví dụ như chúng ta có thể truy xuất vào thuộc tính đó chúng nghĩa các cái phương thức ở bên sau cái dấu hai chấm này rồi thì ví dụ như trong trong hướng đối tượng Lập trình hướng đối tượng của Python thì nó có một cái phương thức đặc biệt đó chính là __init__ lưu ý các bạn ở đây lưu ý đó là ở đây là hai cái dấu gạch dưới tức là hai cái dấu cái phương thức __init__ này nó sẽ giống như thì ở đây chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 5,
      "start_timestamp": "00:05:03",
      "end_timestamp": "0:09:07"
    }
  },
  {
    "page_content": "__init__ này nó sẽ giống như thì ở đây chúng ta sẽ có cái ghi chú nè và chúng ta sẽ truyền cái tên của cái của C và origin. tiếp theo đó chính là phương thức phương của một cái class nó là các cái hàm mà chúng ta sẽ lấy một cái ví dụ là chúng ta khởi tạo một cái class tên là Coord Và đây là một lớp rất là chung cái lớp này rất là chung và lưu ý là cái này là mặc định nha Cái này là không phải mặc định mà là tùy biến chúng ta không có không không có truyền cái cái lớp cha này vô cũng được không",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 6,
      "start_timestamp": "000:9:02",
      "end_timestamp": "0:09:39"
    }
  },
  {
    "page_content": "có truyền cái cái lớp cha này vô cũng được không sao cả rồi Đây là cái constructor thì đã đề cập ở trước và chúng ta sẽ tạo một cái phương thức chúng ta sẽ tạo một cái phương thức một cái method tên là distance nó giống như là một cái hành động vậy đó một cái hành động tính cái khoảng cách và chúng ta như đã đề cập ở đây nè là nó phải là một cái tham số phải có một cái tham số đầu tiên đó chính là tham số self sử dụng self để tham chiếu đến các instance và ngoài ra thì nó phải tính khoảng cách",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 7,
      "start_timestamp": "000:9:33",
      "end_timestamp": "0:10:16"
    }
  },
  {
    "page_content": "instance và ngoài ra thì nó phải tính khoảng cách đến đâu đúng không bản thân cái tọa độ này nó chỉ là một điểm và nó sẽ tính distance đến đâu nó sẽ distance đến một cái tham số lên đến một cái tọa độ khác và ở đây thì bản chất nó chỉ là cái công thức độ đo Euclidean của mình đây -x tất cả bình phương y - y² Rồi lấy hai thằng này tính tổng và lấy căn thì đây chính là cái công thức tính khoảng cách",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=0ycFt1_Ph58",
      "filename": "0ycFt1_Ph58",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.1: Lập trình Python - Hướng đối tượng (P1)",
      "chunk_id": 8,
      "start_timestamp": "00:10:11",
      "end_timestamp": "0:10:16"
    }
  },
  {
    "page_content": "đầu tiên khi ôn tập về Python thì chúng ta sẽ tìm hiểu về kiểu dữ liệu thì cũng tương tự như các cái ngôn ngữ lập trình khác như là C++ và các ngôn ngữ nó cũng có những cái kiểu dữ liệu cơ bản ví dụ như là kiểu số nguyên kiểu số thực kiểu số phức kiểu boolean hay kiểu luận lý và kiểu chuỗi và tương ứng ở đây thì chúng ta sẽ có các cái ví dụ về các cái loại kiểu dữ liệu này thì cái này là rất là cơ bản rồi và để xác định xem một cái biến của mình nó có cái kiểu dữ liệu gì thì chúng ta sẽ dùng cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:43"
    }
  },
  {
    "page_content": "có cái kiểu dữ liệu gì thì chúng ta sẽ dùng cái hàm type và chúng ta sẽ truyền cái biến vào đây để kiểm tra rồi và trong Python cái tính uyển chuyển nó được thể hiện đó là chúng ta hoàn toàn có thể ép kiểu dữ liệu kiểu biến Ví dụ như chúng ta ép kiểu thì chúng ta sẽ để cái tên kiểu và để mở ngoặc rồi đưa cái biến vào tên kiểu để kiểm tra thì bây giờ chúng ta sẽ tiến hành thử nghiệm trên các cái ví dụ này ha Đây chính là cái giao diện của Colab và để mà sử dụng được cái Google Colab này thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:35",
      "end_timestamp": "0:01:34"
    }
  },
  {
    "page_content": "và để mà sử dụng được cái Google Colab này thì chúng ta sẽ phải kết nối Nhấn vào cái nút Connect Thì tại thời điểm này là cái tài khoản của chúng ta đang kết nối vào server của Google và từ đó là giúp cho chúng ta khởi tạo cái một cái con server thì như chúng ta thấy là cái con Server này nó sẽ có 12,68 GB và 100gb ổ cứng rất là dư giả để cho chúng ta có thể làm được thí nghiệm và lưu ý là cái con Server này thì chỉ được lưu trữ tạm thời trong vòng vài tiếng đồng hồ để cho chúng ta có sử dụng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:29",
      "end_timestamp": "0:02:11"
    }
  },
  {
    "page_content": "vòng vài tiếng đồng hồ để cho chúng ta có sử dụng và nó sẽ ngắt và đâu đó khoảng 12 tiếng nếu như chúng ta không sử dụng để tạo ra một biến thì chúng ta sẽ gán là x = 3 rồi sau đó thì chúng ta sẽ in ra Ví dụ như X và chúng ta sẽ chạy để chạy thì chúng ta có thể nhấn Ctrl enter hoặc là nhấn vào cái nút ở đây thì chúng ta thấy biến x của mình là bằng 3 Tuy nhiên 3 ở đây nó có thể là kiểu Số nguyên có thể là kiểu số thực hay là kiểu chuỗi mình không biết do đó thì mình sẽ ép kiểu Anh xin lỗi mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:05",
      "end_timestamp": "0:02:54"
    }
  },
  {
    "page_content": "biết do đó thì mình sẽ ép kiểu Anh xin lỗi mình sẽ dùng cái hàm type và truyền vào cái biến để xem cái kiểu dữ liệu của nó là gì thì ở đây 3 mặc định nó sẽ hiểu là int để ép cái số 3 này về cái kiểu số thực thì chúng ta có thể để cái tên của cái kiểu và ép kiểu và truyền cái biến chúng ta muốn ép rồi sau đó gán ngược trở lại vào chính biến x lưu ý là chúng ta phải có một cái bước gán ngược trở lại vì nếu không cái lệnh ép X thì nó sẽ tạo ra một cái biến số thực nhưng mà nó không được gán vào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 4,
      "start_timestamp": "0:02:47",
      "end_timestamp": "0:03:27"
    }
  },
  {
    "page_content": "cái biến số thực nhưng mà nó không được gán vào bất cứ cái biến nào khác do đó x của mình nó vẫn sẽ giữ nguyên X sẽ giữ nguyên cái kiểu gốc ban đầu là kiểu số nguyên do đó để đổi kiểu của X thì chúng ta sẽ phải gán liền trở lại vào X rồi và bây giờ thì chúng ta sẽ in ra cái kiểu của X của x Xem coi nó sẽ là kiểu gì thì chúng sẽ ghi ra là kiểu dữ liệu mới rồi kiểu dữ liệu mới của chúng ta chính là float trong khi trước đây nó là số nguyên như vậy thì đây là một cái ví dụ để minh họa cho cái việc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 5,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:23"
    }
  },
  {
    "page_content": "thì đây là một cái ví dụ để minh họa cho cái việc ép kiểu dữ liệu trong Python thì các cái toán tử cũng tương tự như là các cái toán tử của các cái ngôn ngữ lập trình khác nó sẽ có các phép toán tử như là cộng trừ nhân chia và có một kế toán tử mà mình cũng rất thích sử dụng trong Python đó là toán tử sau sao thì ý nghĩa của nó đó chính là cái phép mũ hay là phép lũy thừa thì ở đây ta ví dụ như là x sao sao 3 thì nó sẽ tương đương với lại là x lũy thừa 3 Ngoài ra thì Python cũng có hỗ trợ các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 6,
      "start_timestamp": "0:04:19",
      "end_timestamp": "0:05:14"
    }
  },
  {
    "page_content": "lũy thừa 3 Ngoài ra thì Python cũng có hỗ trợ các thao tác So sánh bé so sánh lớn so sánh bằng So sánh khác và kết quả của các toán tử của các toán tử này nó sẽ là các giá trị luận lý Ngoài ra thì trong Python cũng có hỗ trợ các kế toán tử trên cái kiểu dữ liệu luận lý Ví dụ như ở đây chúng ta sẽ có cái toán tử là AND, OR thì ở đây chúng ta sẽ có một cái ví dụ để minh họa cho cái việc sử dụng các cái toán tử này ví dụ như ở đây chúng ta khởi tạo X là bằng 4.0 và chúng ta sẽ in ra kế toán tử in",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 7,
      "start_timestamp": "0:05:08",
      "end_timestamp": "0:06:48"
    }
  },
  {
    "page_content": "X là bằng 4.0 và chúng ta sẽ in ra kế toán tử in ra kết quả của Toán tử là x sao sao ví dụ như là bình phương Tức là sao Sao 2 rồi thì 4 Bình Phương nó sẽ ra là 16 Ngoài ra thì một trong những cái kiểu dữ liệu khác mà Python mình cũng rất hay sử dụng đó chính là kiểu string là Hello Và nếu như chúng ta thực hiện tiếp theo thì chúng ta sẽ cùng qua cái nội dung về các cái cấu trúc dữ liệu phổ biến trên ngôn ngữ lập trình Python thì trong Python có 4 cái cấu trúc dữ liệu rất là phổ biến đó chính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 8,
      "start_timestamp": "0:06:43",
      "end_timestamp": "0:07:24"
    }
  },
  {
    "page_content": "4 cái cấu trúc dữ liệu rất là phổ biến đó chính là list Tuple, set và dictionary đối với list thì đây là một trong những cái cấu trúc dữ liệu mà mình sử dụng nhiều nhất và nó để lưu trữ các đối tượng khác nhau lưu trữ các đối tượng khác nhau và có thể thêm bớt thay đổi giá trị và các cái giá trị của các đối tượng này có thể trùng nhau ví dụ như là list có thể chứa các cái phần tử là có cùng một giá trị thì ở đây chúng ta sẽ lấy một cái cú pháp minh họa cho một cái cú pháp thì trong Python chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:18",
      "end_timestamp": "0:07:58"
    }
  },
  {
    "page_content": "họa cho một cái cú pháp thì trong Python chúng ta sẽ sử dụng cái dấu mở ngoặc vuông và đóng ngoặc vuông để bao các cái dữ liệu mà mình muốn khởi tạo Ví dụ như ở đây chúng ta muốn khởi tạo ra một cái list bao gồm các cái số là 3.0 5 và hello thì chúng ta có thể thấy là ba cái giá trị này nó sẽ có 3 cái kiểu dữ liệu khác nhau đó là 3.0 là số thực 5 là số nguyên và hello là kiểu string thì đây chính là cái tính uyển chuyển của cái cấu trúc dữ liệu list và Chính điều đó khiến cho cái việc lập trình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 10,
      "start_timestamp": "0:07:53",
      "end_timestamp": "0:08:41"
    }
  },
  {
    "page_content": "và Chính điều đó khiến cho cái việc lập trình nó sẽ tiện lợi hơn và ở đây chúng ta sẽ ví dụ là chúng ta sẽ khai báo một list các cái số tự nhiên từ 1 cho đến 10 và chúng ta sẽ lấy ra một cái phần tử ở vị trí thứ 5 lưu ý là ở vị trí thứ năm của cái list này và chúng ta sẽ lọc lấy 5 phần tử đầu tiên của list thì đây là mình sẽ lập trình thử cho các bạn cùng theo dõi Ví dụ như chúng ta sẽ có list là bằng mở ngoặc vuông và nếu như chúng ta tạo một cái list gồm có 10 cái phần tử này thì cái cách đơn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 11,
      "start_timestamp": "0:08:36",
      "end_timestamp": "0:09:17"
    }
  },
  {
    "page_content": "list gồm có 10 cái phần tử này thì cái cách đơn giản nhất mà mình có thể làm đó chính là gõ ra từng phần tử như thế này tuy nhiên cái việc này thì sau này chúng ta sẽ rất là bất tiện Nếu như mà cái số phần tử của mình nó rất là lớn lên đến hàng trăm hoặc là hàng ngàn phần tử thì lúc đó chúng ta sẽ có những cái cách thức để khởi tạo riêng sử dụng NumPy Tuy nhiên ở trong các trường hợp này chúng ta sẽ minh họa đó là khai báo tường minh tất cả các phần tử ở bên trong các danh sách và chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 12,
      "start_timestamp": "0:09:10",
      "end_timestamp": "0:09:50"
    }
  },
  {
    "page_content": "phần tử ở bên trong các danh sách và chúng ta sẽ in ra cái list này thì đây là tất cả các phần tử và bây giờ mình sẽ in ra phần tử ở vị trí thứ 5 thì lưu ý là chúng ta có thể có hai cái cách hiểu cái khái niệm đầu tiên đó là vị trí thứ vị trí thứ năm như vậy thì nếu như chúng ta đánh cái chỉ mục của mình là bắt đầu từ vị trí thứ nhất vị trí thứ hai vị trí thứ ba vị trí thứ tư vị trí thứ năm thì để lấy ra cái vị trí thứ năm thì chúng ta lưu ý chúng ta sẽ không dùng cái chỉ số gọi là 5 đó chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 13,
      "start_timestamp": "0:09:39",
      "end_timestamp": "0:10:25"
    }
  },
  {
    "page_content": "ta sẽ không dùng cái chỉ số gọi là 5 đó chúng ta sẽ để mở ngoặc vuông là 5 như thế này các bạn có thể đoán được nó ra kết quả là bao nhiêu hay không nó sẽ ra là 6 Tức là nó sẽ ra kết quả là 6 Tại vì sao tại vì trong Python cái chỉ mục của mình cái chỉ mục Tức là cái con số mà mình sẽ truyền vào cái dấu mở ngoặc vuông đóng ngoặc vuông này nè Để lấy cái phần tử đó ra thì nó bắt đầu từ 0 chứ nó không phải bắt đầu từ 1 do đó nếu cái phần tử đầu tiên này nó sẽ là chỉ số là 0 chỉ số 1 2 3 4 5 và do",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 14,
      "start_timestamp": "0:10:21",
      "end_timestamp": "0:11:14"
    }
  },
  {
    "page_content": "này nó sẽ là chỉ số là 0 chỉ số 1 2 3 4 5 và do đó thì tại cái chỉ số 5 thì tương ứng nó sẽ lấy ra cái giá trị là 6 do đó thì muốn lấy cái phần tử tại cái vị trí thứ 5 thì chúng ta sẽ truyền vô đó là chỉ số thứ tư thì nó sẽ lấy ra cái giá trị của cái số thứ Năm rồi bây giờ chúng ta muốn thực hiện in ra ở 5 cái phần tử đầu tiên thì chúng ta sẽ thực hiện cái câu lệnh đó là print list thực hiện một cách tường minh để cái chỉ số một cách tường minh đó là print list[0:5] Tức là nó sẽ chạy từ phần tử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 15,
      "start_timestamp": "0:11:10",
      "end_timestamp": "0:11:52"
    }
  },
  {
    "page_content": "là print list[0:5] Tức là nó sẽ chạy từ phần tử đầu tiên là 0 rồi cho đến phần tử trước khi con số 5 này tức là 4 0 1 2 3 4 tức là có 5 cái phần tử thì đây là cái cách khai báo tường minh là 0:5 chúng ta sẽ lấy ra 5 phần tử đầu tiên còn một cái cách khác viết tắt hơn đó chính là chúng ta không để cái chỉ số 0 mà chúng ta sẽ để là :5 Ví dụ như :5 tức là lấy ra 5 phần tử đầu tiên rồi các bạn sẽ nói là vậy thì cái ý nghĩa của cái chỉ số này cái con số 5 này nó là gì Và nó có gọi là không có tự",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 16,
      "start_timestamp": "0:11:46",
      "end_timestamp": "0:11:56"
    }
  },
  {
    "page_content": "con số 5 này nó là gì Và nó có gọi là không có tự nhiên trong cái cách mình suy luận đúng không Tuy nhiên thì ở đây nó cũng thuộc về cái phạm trù gọi là quy ước ví dụ như là :5 thì chúng ta sẽ hiểu ý Đó là chúng ta sẽ chạy từ cái chỉ số đầu tiên cho đến trước trước thì chỉ số mà nó có thông số ghi ở đây tức là trước cái chỉ số 5 chỉ số 4 từ 0 cho đến 4 thì nó sẽ có tất cả là 5 phần tử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1a7AxTRLrlQ",
      "filename": "1a7AxTRLrlQ",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.2: Lập trình Python - Biến và kiểu dữ liệu (P2)",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Kỹ thuật ensemble model nâng cao. Kỹ thuật như stacking, blending, bagging, boosting. Đối với stacking, chúng ta tiến hành chồng lớp các mô hình với nhau. Sau đó, chúng ta huấn luyện tiếp một mô hình để học dựa trên kết quả dự đoán đó. Blending là việc trộn dữ liệu gốc với kết quả dự đoán của từng mô hình sau đó xây dựng một mô hình, huấn luyện với mô hình mới để học trên dữ liệu mà đã trộn. Bagging là cơ chế học các mô hình thực hiện một cách gọi là song song. Boosting là học các mô hình theo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:01:00"
    }
  },
  {
    "page_content": "là song song. Boosting là học các mô hình theo trình tự tuần tự. Tức là những mô hình sau sẽ được học dựa trên kết quả của mô hình trước. Để khắc phục những điểm yếu của các mô hình trước. Sau đây chúng ta sẽ đi đến chi tiết hơn cho từng thuật toán. Kỹ thuật Stacking là kỹ thuật sử dụng kết quả dự đoán của tập Train như đặc trưng để huấn luyện. Kết quả dự đoán của tập Train làm đặc trưng để huấn luyện cho mô hình tổ hợp Meta-Learner. Với dữ liệu Train của mình, nó sẽ đưa qua n mô hình. Mỗi mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:01:49"
    }
  },
  {
    "page_content": "Train của mình, nó sẽ đưa qua n mô hình. Mỗi mô hình này có thể là những mô hình rất khác nhau. Sau khi đã Train xong, chúng ta sẽ đưa ra dự đoán trên dữ liệu Train này. Mỗi mô hình sẽ có một kết quả dự đoán và tất cả các giá trị dự đoán sẽ chồng lên nhau. sau đó toàn bộ các giá trị đã chồng lên, chúng ta sẽ xem nó như là một input feature để chúng ta huấn luyện cho Meta-Learner, tức là một mô hình máy học khác, một mô hình máy học tổng hợp ở tầng thứ 2. Còn các mô hình số 1, số 2, số 3 cho đến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 2,
      "start_timestamp": "0:01:38",
      "end_timestamp": "0:03:00"
    }
  },
  {
    "page_content": "thứ 2. Còn các mô hình số 1, số 2, số 3 cho đến n ở đây đó là những mô hình ở tầng thứ 1. Còn tầng thứ 2 chúng ta sẽ gọi là Meta-Learner. Và với Meta-Learner này, nó học dựa trên các đặc trưng đã được dự đoán từ các mô hình ở tầng thứ 1. Rồi nó sẽ đưa ra được kết quả dự đoán cuối cùng. Như vậy thì có thể nói, Meta-Learner giống như là một người lớp trưởng nó sẽ thực hiện huấn luyện và khai thác được những cái giá trị dự đoán của từng thành viên trong lớp để từ đó nó sẽ đưa ra cái quyết định",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 3,
      "start_timestamp": "0:02:55",
      "end_timestamp": "0:03:42"
    }
  },
  {
    "page_content": "trong lớp để từ đó nó sẽ đưa ra cái quyết định cuối cùng. Thì ở đây chính là cái ý tưởng của kỹ thuật stacking. Tiếp theo thì chúng ta sẽ đến với kỹ thuật blending. Kỹ thuật blending, blending có nghĩa là sự pha trộn. Đó là sự pha trộn của hai loại dữ liệu khác nhau. Cái loại dữ liệu đầu tiên chính là dữ liệu đặc trưng. Còn cái dữ liệu thứ hai đó là kết quả dự đoán. Và tất cả ở đây đều thực hiện trên tập validation. Đặc trưng này là đặc trưng từ tập validation. Kết quả dự đoán này cũng là kết",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 4,
      "start_timestamp": "0:03:36",
      "end_timestamp": "0:04:21"
    }
  },
  {
    "page_content": "tập validation. Kết quả dự đoán này cũng là kết quả dự đoán trên tập validation. Chúng ta kết hợp lại với nhau, chúng ta pha trộn với nhau. và hai cái này nó sẽ tạo ra thành một đặc trưng để huấn luyện cho mô hình tổng hợp. Thì ở đây chúng ta sẽ có bước số 1. Bước số 1, đó là chúng ta sẽ lấy dữ liệu Train. Vì vậy là toàn bộ data huấn luyện của mình sẽ chia nó ra làm 2 phần. Phần đầu tiên đó là Train và phần thứ 2 là Validation. Đối với tập dữ liệu Train, chúng ta sẽ đưa vào bên trong từ mô hình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 5,
      "start_timestamp": "0:04:18",
      "end_timestamp": "0:05:01"
    }
  },
  {
    "page_content": "Train, chúng ta sẽ đưa vào bên trong từ mô hình 1, 2 cho đến mô hình thứ n, chúng ta sẽ tiến hành huấn luyện để cho nó có thể giải quyết được trên tập dữ liệu Train này. Sau đó qua bước số 2, chúng ta sẽ tiến hành không sử dụng tập Train nữa và chúng ta chỉ sử dụng tập Validation thôi. và đưa vào các mô hình số 1, số 2, số 3 cho đến số n và ứng với mỗi mô hình thì chúng ta sẽ có kết quả tương ứng là thể hiện ở trong các dấu chấm ở đây và chúng ta sẽ kết hợp, chúng ta sẽ trộn lại toàn bộ Ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 6,
      "start_timestamp": "0:04:49",
      "end_timestamp": "0:05:53"
    }
  },
  {
    "page_content": "ta sẽ kết hợp, chúng ta sẽ trộn lại toàn bộ Ở đây là chúng ta sẽ trộn cái gì? Chúng ta sẽ trộn cái tập validation chính là cái tập này Với các mô hình này, chúng ta sẽ trộn thêm kết quả dự đoán của chúng. Với các giá trị dự đoán của mô hình, đó chính là các kết quả dự đoán này. Vì vậy, tổ hợp cả hai loại dữ liệu. Đây là dữ liệu gốc, đây là dữ liệu gốc. Còn đây là các dữ liệu của các mô hình có sự đóng góp vào dữ liệu gốc này. Tức là mỗi mô hình này sẽ thể hiện một quan điểm. Thì mô hình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 7,
      "start_timestamp": "0:05:39",
      "end_timestamp": "0:06:34"
    }
  },
  {
    "page_content": "hình này sẽ thể hiện một quan điểm. Thì mô hình Meta-Learner sẽ tiến hành huấn luyện trên dữ liệu tổng hợp này. Tức là thay vì trong mô hình stacking, Meta-Learner chỉ có thể khai thác được các kết quả dự đoán của từng mô hình. Tức là các giá trị này thôi. và nó sẽ bị một cái vấn đề đó là lan truyền lỗi, tức là nếu như model số 1, số 2, số 3, cho đến số n, và các cái model này nó bị lỗi, nó sẽ khiến cho Meta-Learner cũng sẽ bị ảnh hưởng theo. Cái việc mà chúng ta đưa cái dữ liệu gốc tập",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 8,
      "start_timestamp": "0:06:30",
      "end_timestamp": "0:07:13"
    }
  },
  {
    "page_content": "Cái việc mà chúng ta đưa cái dữ liệu gốc tập validation vào bên trong này, nó sẽ giúp cho chúng ta truyền được cái thông tin nguyên bản đến trong Meta-Learner để Meta-Learner có thể học được cả dữ liệu gốc cũng như khai thác được quan điểm, điểm mạnh của từng mô hình này. Vì vậy thì rõ ràng là Meta-Learner sẽ giúp cho chúng ta học toàn diện hơn. Tại vì nó có thể học được dữ liệu gốc ban đầu và đồng thời cũng có thể khai thác được điểm mạnh những cái quan điểm của từng mô hình thành phần ở cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 9,
      "start_timestamp": "0:07:10",
      "end_timestamp": "0:07:33"
    }
  },
  {
    "page_content": "cái quan điểm của từng mô hình thành phần ở cái tầng thứ nhất. Và cuối cùng thì Meta-Learner sẽ đưa ra cái quyết định cuối cùng là dự đoán xem cái giá trị output của mình sẽ là gì. Thì đây chính là cái ý tưởng của thuật toán của cái kỹ thuật là blending.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=1XtVmBf5vGA",
      "filename": "1XtVmBf5vGA",
      "title": "[CS116 - Buổi 13] Part 3_0",
      "chunk_id": 10,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tiếp theo thì chúng ta sẽ tiến hành triển khai cái ứng dụng của mình dưới dạng là một cái dịch vụ hay còn gọi là cái api và cái tình huống sử dụng của mình trong trường hợp này đó là chúng ta đang muốn tạo ra một cái dịch vụ web cho bên thứ ba có thể khai thác được và bên thứ ba này thì có thể là đối tác của mình hoặc là cho cái team nội bộ về phát triển phần mềm của bên mình thì mô hình của mình cái cái cái dịch vụ web này của mình sẽ tải được nhiều có thể tái sử dụng được cho nhiều cái ứng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:36"
    }
  },
  {
    "page_content": "nhiều có thể tái sử dụng được cho nhiều cái ứng dụng khác nhau tức là có thể dùng cho nội bộ có thể dùng cho các cái đối tác rồi Thậm chí là cũng có thể sử dụng được cho cả cái thậm chí là có thể sử dụng được cho chính cái người dùng cũi của mình thì nhắc lại ha thì đây chính là cái sơ đồ triển khai của mình và chúng ta sẽ phải viết Cái api chúng ta sẽ phải viết Cái api này và có rất nhiều cái công cụ nhưng mà có hai cái công cụ được sử dụng phổ biến cành đây nổi tiếng nhất và kinh điện nhất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:00:32",
      "end_timestamp": "0:01:17"
    }
  },
  {
    "page_content": "biến cành đây nổi tiếng nhất và kinh điện nhất chính là flash nhưng mà gần đây thì sẽ có fast api thì như cái tên gọi fast api thì đây là một cái thư viện Giúp cho chúng ta tạo ra các cái dịch vụ với cái tốc độ thực thi rất là cao có thể đồng bộ hóa và phục vụ được rất nhiều những cái lược truy cập trong cùng một cái thời điểm thì sau đây chúng ta sẽ sử dụng cái công cụ chat gpt như đã đề cập ở trong phần trước để mà nhờ nó viết dùng một cái fast api thì viết cái api sử dụng fast Tức là mình sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:01:09",
      "end_timestamp": "0:01:57"
    }
  },
  {
    "page_content": "api thì viết cái api sử dụng fast Tức là mình sẽ cung mình nói cho nó biết mình muốn cái gì đó là mình muốn viết một cái api Nhưng mà phải viết bằng công cụ gì thì đó là fast api trong đó dữ liệu đầu vào trong đó input của cái dịch vụ của cái service sẽ là thông tin về size và quay và giá trị trả ra là Price sẽ được tính toán từ một mô hình à huấn luyện huấn luyện trước đó và lưu ý đó là mô hình này đã được lưu ở dạng file có tên là best Tre chp rồi đầu tiên thì nó cũng sẽ yêu cầu chúng ta cài",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:01:52",
      "end_timestamp": "0:03:25"
    }
  },
  {
    "page_content": "rồi đầu tiên thì nó cũng sẽ yêu cầu chúng ta cài đặt các cái thư viện này đúng không thử và chúng ta lưu ý là chúng ta sẽ chừa cái ccet lên ra để có thể cài được cái ccet lên theo đúng cái phiên bản của mình rồi sau đó Ờ để tạo ra cái file này thì ở đây là best picle này thì người ta đang hướng dẫn cái cách mình tạo ra một cái mẫu dữ liệu rồi huấn luyện Tuy nhiên cái công việc này chúng ta đã thực hiện ở trong cái file colap này rồi do đó cái bước số hai này chúng ta không cần thiết phải thực",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:03:18",
      "end_timestamp": "0:03:58"
    }
  },
  {
    "page_content": "số hai này chúng ta không cần thiết phải thực hiện nữa và ở bước số ba thì chúng ta sẽ tiến hành tạo cái cái api cho mình rồi Thế thì chúng ta sẽ tiến hành đầu tiên đó là cài đặt các cái thư biệt đúng không Thì là p install cái này do đó thì chúng ta sẽ tư tự như trong cái bài trước rồi chúng ta sẽ tạo một cái môi trường mới đó là cona create thì ở đây chúng ta sẽ dùng là first sẽ đặt tên cho cái environment này đó là api và thư viện Python ngôn ngữ Python 3.9 và ở đây chúng ta sẽ không dùng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:03:54",
      "end_timestamp": "0:04:48"
    }
  },
  {
    "page_content": "ngữ Python 3.9 và ở đây chúng ta sẽ không dùng stream list mà chúng ta sẽ cài là fast api và uvic rồi chop list thì mình không rõ cái chop list này nó dùng để à chop list này thì nó cũng giống giống như là picle do đó ở đây thì chúng ta sẽ không cần thiết phải cài cái này nữa fast api và uvic rồi sau khi chúng ta đã cài xong thì chúng ta sẽ cona activate api đó thì ở đây chúng ta đã tạo ra một cái environment có tên là api và chúng ta sẽ tiếp tục cài cái escal là p inst escal bằng bằng 1.3.2",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:04:41",
      "end_timestamp": "0:06:07"
    }
  },
  {
    "page_content": "tục cài cái escal là p inst escal bằng bằng 1.3.2 thì đây chính là cái phiên bản để mà cái mô hình của mình có thể thực thi được đúng như cái kết quả ở đây rồi sau khi chúng ta cài đặt xong thì chúng ta sẽ tiến hành triển khai cái file api này chúng ta sẽ tạo ra một cái file mới pyon file chúng ta sẽ sẽ tiến hành lưu cái file này lại thì mình sẽ để là Python và tên file sẽ là Model api Model as api thì chúng ta lưu ý là ở đây chúng ta sử dụng cái thư viện trong cái code mà chat gpt nó tạo ra là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:06:01",
      "end_timestamp": "0:06:56"
    }
  },
  {
    "page_content": "thư viện trong cái code mà chat gpt nó tạo ra là dùng chli Nhưng mà mình đang sử dụng cái thư viện là Pixel do đó ở đây mình sẽ phải sửa lại chúng ta sẽ copy cái đoạn code clad cái model lên từ file của Pixel rồi và chúng ta sẽ thay thế cái đoạn code đó ở đây tiếp theo đó là chúng ta sẽ activate cái môi trường mà chúng ta đã cài đặt ha con activate api rồi thì như vậy chúng ta đã tiến hành cài xong và CD chúng ta sẽ vào thư mục là doc pro rồi thì để run cái này chúng ta sẽ chạy cái lệnh đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:06:51",
      "end_timestamp": "0:07:53"
    }
  },
  {
    "page_content": "để run cái này chúng ta sẽ chạy cái lệnh đó là uvic Script name app Tức là trong đó Script name chính là cái đường dẫn đến cái file Python của mình thì cái đường dẫn của mình đó chính là Model as api là Model as api và app chính là cái tên biến của mình cái đối tượng mà mình đã tạo ra với fast api ở đây đó là F rồi giờ mình sẽ run cái này ha rồi thì nó báo là nó đã run với cái port là 12 27 port là 8000 và để test thử cái này thì chúng ta sẽ phải dùng cái giao thức là giao thức post Tuy nhiên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:07:48",
      "end_timestamp": "0:08:39"
    }
  },
  {
    "page_content": "dùng cái giao thức là giao thức post Tuy nhiên để test với giao thức post thì nó sẽ hơi phức tạp hơn một chút đó là chúng ta sẽ phải cài một cái phần mềm đó là postman đó thì nó sẽ hơi mất thời gian do đó thì chúng ta có thể sửa cái này một chút xíu đó là chúng ta sẽ dùng giao tích là get rồi và ở đây thay vì chúng ta truyền cái đối tượng là item base Model thì ở đây chúng ta sẽ truyền vào trực tiếp hai cái tham số đó là size kiểu float và way kiểu float thì ở đây chúng ta sẽ truyền vô là siz",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:08:36",
      "end_timestamp": "0:09:38"
    }
  },
  {
    "page_content": "kiểu float thì ở đây chúng ta sẽ truyền vô là siz và way rồi phương thức ở đây sẽ là phương thức get sau khi lưu xong thì ở bên đây nó sẽ tự động reload lại cái file Model as api cho mình và để test thì chúng ta sẽ Ờ vào cái cửa sổ chat xin lỗi vào cái cửa sổ của của Browser và để là local host 2 ch port là 8000 rồi not file đúng không thì chúng ta sẽ truyền vào là ừ chúng ta sẽ xem lại cái đường dẫn của mình là predict predict rồi tham số thì chúng ta sẽ để size là bằng ví dụ như hồi nãy chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:09:31",
      "end_timestamp": "0:10:30"
    }
  },
  {
    "page_content": "ta sẽ để size là bằng ví dụ như hồi nãy chúng ta để là 110 rồi and w thì sẽ là bằng 120 đó thì khi chúng ta truyền cái tham số này vào thì chúng ta sẽ thấy là nó trả ra một cái đình dạng là jas trong đó có cái trường là Price dự đoán là 500 9.90 tức là khớp với cái con số hồi nãy n lịch khoảng 9000 so với lại cái tập dataset huấn luyện của mình thì đây là cái cách thức để mà chúng ta tạo ra một cái api với cái dịch vụ web của Fast api và một cách tương tự nếu như chúng ta muốn sửa cái local",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:10:23",
      "end_timestamp": "0:10:42"
    }
  },
  {
    "page_content": "cách tương tự nếu như chúng ta muốn sửa cái local host 8000 này thành cái đường dẫn cái domain của mình thì chúng ta sẽ phải Cấu hình lại cái mzx để cho nó nhận cái p 8000 nhận cái port 8000 này tương ứng với lại cái dịch vụ là su predit thì chúng ta sẽ phải cấu hình tương tự như trong cái phần tạo một cái dịch vụ web",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=2AfXTKxyUd8",
      "filename": "2AfXTKxyUd8",
      "title": "[CS116 - Buổi 14] Part 4",
      "chunk_id": 13,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cuối cùng đó là chúng ta sẽ cùng tìm hiểu về một số cái mô hình để giảm chiều dữ liệu trong học không giám sát. Thế thì giảm chiều dữ liệu là gì thì đó là một cái quá trình mà chúng ta chuyển đổi dữ liệu từ cái không gian đa chiều sang cái không gian ít chiều hơn. Ví dụ cái không gian ban đầu của mình đó là n chiều, sau khi chúng ta giảm xong thì nó sẽ đưa về là cái không gian ít chiều hơn là n'. Và cái n' này thì nó sẽ nhỏ hơn so với cái N lớn. Tức là giảm chiều thì cái số chiều sau khi chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:39"
    }
  },
  {
    "page_content": "Tức là giảm chiều thì cái số chiều sau khi chúng ta đã biến đổi thì nó phải ít hơn. Và không phải chỉ là biểu diễn ít chiều hơn là đủ mà nó phải thỏa mãn một số tính chất nữa đó, đó là cái biểu diễn trong cái không gian ít chiều hơn nhưng nó vẫn phải đảm bảo được là vẫn giữ được một số cái tính chất có ý nghĩa trong cái dữ liệu gốc, cái tính chất có ý nghĩa chứ nó không phải là tạo ra một cái vectơ ít chiều hơn nhưng mà đó là những cái vectơ ngẫu nhiên và nó không có một cái sự liên hệ gì đến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:34",
      "end_timestamp": "0:01:14"
    }
  },
  {
    "page_content": "nhiên và nó không có một cái sự liên hệ gì đến dữ liệu gốc thì khi đó thuật toán của mình cũng không có thực sự hiệu quả. Tại vì các cái đặc trưng ở trong cái không gian ít chiều hơn này nó không giúp cho mình mang những cái thông tin gốc ban đầu và nó sẽ không giúp cho mình giải quyết được những cái bài toán phân loại hoặc là các bài toán hồi quy về sau. Thì hình ở bên đây chúng ta đang minh họa cho một cái không gian đặc trưng mà giảm số chiều bởi PCA. Giả sử như ở đây chúng ta có cái Ờ điểm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:09",
      "end_timestamp": "0:01:53"
    }
  },
  {
    "page_content": "bởi PCA. Giả sử như ở đây chúng ta có cái Ờ điểm nằm trong không gian là hai chiều là E1 và E2 và chúng ta biến đổi nó về cái không gian U1 và U2 đó. Thì đây là cái thuật toán PCA ha, và nó sẽ tìm cách đó là nó loại bỏ đi, nó loại bỏ đi cái trục U1 này. Nó chỉ cần duy nhất một cái trục đó là, xin lỗi, nó loại bỏ đi cái trục U2 và nó chỉ chừa lại cái trục U1 này thôi. Thì khi đó là cái số chiều của mình đang từ hai chiều gốc ban đầu là E1, E2 bây giờ chúng ta chỉ còn duy nhất là một chiều là U1.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:01:47",
      "end_timestamp": "0:02:25"
    }
  },
  {
    "page_content": "giờ chúng ta chỉ còn duy nhất là một chiều là U1. Nhưng mà cái căn cứ tại sao chúng ta lại có thể bỏ được cái trục U1 này thì chút nữa chúng ta sẽ xem cái ví dụ và để cho chúng ta có thể cảm quan, cảm nhận được tại sao chúng ta có thể bỏ được. Và đây là một cái trực quan hóa cho cái thuật toán PCA. Thì chi tiết của cái PCA chúng ta sẽ tìm hiểu trong những cái phần sau. Nhưng mà ý tưởng của nó đó là nó sẽ đưa về một cái không gian mới và trong cái không gian mới này thì những cái điểm, những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:20",
      "end_timestamp": "0:03:02"
    }
  },
  {
    "page_content": "không gian mới này thì những cái điểm, những cái trục không gian nào mà nó ít thông tin hơn thì chúng ta sẽ loại bỏ đi. Còn những cái trục không gian nào mà nó Ờ có nhiều thông tin thì chúng ta sẽ giữ lại. Và đó chính là cái ý tưởng của PCA. Thế thì giảm chiều dữ liệu nó có rất nhiều những cái hướng tiếp cận. Thì trong đó ở đây chúng ta sẽ tiếp cận bằng hai cái mô hình chính. Mô hình đầu tiên đó là phân tích thành phần chính là Principal Component Analysis. Thì đây là cái mô hình mà chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:02:55",
      "end_timestamp": "0:03:36"
    }
  },
  {
    "page_content": "Analysis. Thì đây là cái mô hình mà chúng ta vừa mới đề cập lúc nãy khi đề cập trong cái trực quan hóa hồi nãy. Chi tiết của PCA chúng ta sẽ thảo luận ở trong cái slide tiếp theo. Và phương pháp thứ hai cũng rất là nổi tiếng đó chính là t-SNE. Thì đây chính là cái phương pháp dùng để mà giảm chiều với cái dữ liệu của mình có mối quan hệ phi tuyến tính. Và cái công dụng chính, công dụng mà được sử dụng nhiều nhất của t-SNE chính là để trực quan hóa dữ liệu. Tại sao có thể trực quan hóa dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:03:30",
      "end_timestamp": "0:04:13"
    }
  },
  {
    "page_content": "hóa dữ liệu. Tại sao có thể trực quan hóa dữ liệu được? Đó là vì khi chúng ta ở trong không gian N chiều, N này có thể là không gian lớn hơn 3 chiều. Ví dụ trong không gian 3 chiều thì chúng ta còn có thể trực quan hóa được. Nhưng mà không gian có thể là 4, 5, 6 chiều thì khi đó cái việc trực quan hóa nó rất là khó. Chúng ta sẽ đưa nó về cái không gian là 2D hoặc là 3D. Và khi đó thì chúng ta có thể dễ dàng vẽ dưới dạng là các cái trong cái không gian mà XY hoặc là XYZ. Trong cái không gian ba",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:04:08",
      "end_timestamp": "0:04:53"
    }
  },
  {
    "page_content": "gian mà XY hoặc là XYZ. Trong cái không gian ba chiều XYZ. Thì khi chúng ta đưa về trong cái không gian hai chiều và ba chiều nó vẫn phải giữ được những cái tính chất, nó vẫn phải giữ được cái tính chất nào đó, tính chất nhất định của cái không gian gốc thì khi đó cái việc trực quan này nó mới có ý nghĩa. Chứ còn nếu chúng ta đưa về không gian hai chiều ba chiều nhưng mà ngẫu nhiên, tức là chúng ta lấy đại những cái giá trị hai chiều hoặc là ba chiều để đại diện cho các cái đặc trưng thì rõ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:04:49",
      "end_timestamp": "0:05:25"
    }
  },
  {
    "page_content": "ba chiều để đại diện cho các cái đặc trưng thì rõ ràng là nó không có thể hiện được cái tính chất của cái dữ liệu ban đầu. Thì mỗi phương, tương tự như vậy, mỗi phương pháp PCA hoặc là t-SNE nó cũng sẽ có những đặc điểm và những cái vai trò về ứng dụng riêng. Do đó thì tùy vào bộ dữ liệu cũng như là mục tiêu mà mình sẽ sử dụng cái thuật toán cho hoặc là cái phương pháp cho nó phù hợp. Hồi nãy chúng ta có đề cập đến cái việc đó là chúng ta có hai trục không gian U1 và U2 và tại sao chúng ta lại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:05:19",
      "end_timestamp": "0:06:00"
    }
  },
  {
    "page_content": "trục không gian U1 và U2 và tại sao chúng ta lại giữ U1 và chúng ta lại bỏ U2. Thì bây giờ chúng ta sẽ cùng đến với một cái ví dụ rất là đơn giản và dễ hiểu như sau. Giả sử như chúng ta có một cái bảng điểm dữ liệu của một cái lớp học. Và các cái bạn có nhận ra rằng cái cột điểm Văn này nó có cái tính chất gì hay không? Nếu như các cái trục không gian khác, ví dụ như họ tên chúng ta thấy là họ tên, ờ họ tên một, họ tên hai, họ tên 3 cho đến họ tên 5 thì đây là các cái giá trị rất là khác nhau.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 10,
      "start_timestamp": "0:05:54",
      "end_timestamp": "0:06:37"
    }
  },
  {
    "page_content": "5 thì đây là các cái giá trị rất là khác nhau. Giới tính thì chúng ta sẽ thấy là các giá trị cũng rất là khác nhau: nam nữ, nam nữ, nam nữ, tỉ lệ của nó cũng rất là đồng đều. Điểm Toán thì cái điểm của mình nó cũng trải từ những cái giá trị rất là thấp như là 6,5 cho đến những cái điểm rất là cao ví dụ như là 9,5, nó trải đều. Nhưng mà riêng cái điểm Văn thì nó lại có một tính chất đó là tất cả đều bằng 7 và độ lệch của mình trong trường hợp này là bằng 0. Độ lệch trong trường hợp này bằng 0.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 11,
      "start_timestamp": "0:06:29",
      "end_timestamp": "0:07:18"
    }
  },
  {
    "page_content": "là bằng 0. Độ lệch trong trường hợp này bằng 0. Như vậy thì chúng ta sẽ có cái ý tưởng gì? Đó là chúng ta sẽ thay vì lưu hết mỗi bạn là một cái điểm Văn là 7 điểm thì để tiết kiệm chúng ta chỉ cần lưu đúng một cái số 7 thôi. Chúng ta chỉ cần lưu một cái điểm chung đó là số 7. Và khi đó chúng ta loại bỏ đi cái cột điểm Văn này. Và khi đó thì cái thuật toán này của mình nó đã giúp cho mình giảm được một cột trên bốn cột. Ở đây là chúng ta có bốn cột đúng không? Và bỏ được cái cột Văn này tức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 12,
      "start_timestamp": "0:07:10",
      "end_timestamp": "0:07:48"
    }
  },
  {
    "page_content": "cột đúng không? Và bỏ được cái cột Văn này tức là nó đã giúp cho chúng ta giảm được 1/4 tức là 25% dữ liệu. Tại sao ở đây là mình dùng cái dấu xấp xỉ? Tại vì chúng ta vẫn phải tốn thêm một cái bộ nhớ nữa để lưu cái con số 7 này. Nhưng thực sự mà nói cái con số 7 này nó quá ít so với lại tất cả các cái mẫu dữ liệu này nên mình để cái dấu là xấp xỉ, xấp xỉ là 1/4. Và chúng ta sẽ đến một cái ví dụ khác khi cái điểm Văn của mình là 7 điểm hết thì rõ ràng đó là tình huống thi thực tế đúng không? Thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 13,
      "start_timestamp": "0:07:44",
      "end_timestamp": "0:08:28"
    }
  },
  {
    "page_content": "ràng đó là tình huống thi thực tế đúng không? Thì chúng ta sẽ xem đến một cái tình huống nó khác hơn một chút đó là điểm Văn của mình có cái sự dao động. Cái điểm Văn của mình có cái sự dao động. Ví dụ như điểm Văn ở đây là 7 điểm, 6,5 điểm, 7 điểm, 7,5 điểm. Thì cái độ lệch của các cái điểm này lúc này nó đã tăng lên thay vì là nó bằng 0 thì nó tiến lên là cỡ 0.32. Thì nhìn chung cái 0.32 này nó vẫn là một cái con số bé hơn cái con số 0.5 tức là cái điểm nhỏ nhất, cái bước nhảy điểm nhỏ nhất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 14,
      "start_timestamp": "0:08:22",
      "end_timestamp": "0:09:07"
    }
  },
  {
    "page_content": "là cái điểm nhỏ nhất, cái bước nhảy điểm nhỏ nhất trong cái chương trình phổ thông của mình. Như vậy thì đây là một cái độ lệch nhỏ và chấp nhận được. Do đó thì chúng ta vẫn sẽ chỉ cần lưu, chỉ lưu những cái điểm trung bình là 7 điểm. Thay vì chúng ta lưu cái giá trị gốc thì chúng ta sẽ lưu cái điểm trung bình là 7 điểm. Thì khi này cái hiệu quả trong cái việc là giảm chiều bộ nhớ, giảm chiều dữ liệu của mình á là nó vẫn đạt được tương đương đó là chúng ta giảm được khoảng 1/4 tức là 25% dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 15,
      "start_timestamp": "0:09:02",
      "end_timestamp": "0:09:44"
    }
  },
  {
    "page_content": "đó là chúng ta giảm được khoảng 1/4 tức là 25% dữ liệu. Chuyện này không đổi so với cái ví dụ trước. Nhưng cái điểm khác đó là khi khôi phục, à thì cái dữ liệu của chúng ta không thể nào khôi phục được về cái dữ liệu gốc. Thì cái điểm ở đây chúng ta đang muốn bàn đến đó là khi chúng ta giảm chiều dữ liệu chúng ta có đánh đổi cái việc đó là chúng ta có khả năng khôi phục lại với lại dữ liệu gốc hay không? Thì đối với cái thuật toán PCA mà chúng ta sẽ thảo luận sắp tới thì nó nằm trong cái nhóm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 16,
      "start_timestamp": "0:09:35",
      "end_timestamp": "0:10:36"
    }
  },
  {
    "page_content": "ta sẽ thảo luận sắp tới thì nó nằm trong cái nhóm tiếp cận đó là nó sẽ không thể khôi phục lại 100% so với lại dữ liệu gốc. Do đó chúng ta chỉ chọn những cái chiều nào mà có cái độ lệch thấp thì chúng ta sẽ loại bỏ nó đi. Còn ví dụ như cái cột Toán hoặc là cái cột giới tính, họ tên, chúng ta thấy có cái độ biến động cao từ 6 lên 6,5, từ 6 lên 9,5, từ 6 lên 9 rồi từ 6,5 lên 7,5 vân vân, thì cái độ biến động của nó thấp thì khi đó là chúng ta sẽ giữ nguyên biến động thấp. Xin lỗi, đây là biến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 17,
      "start_timestamp": "0:10:30",
      "end_timestamp": "0:11:04"
    }
  },
  {
    "page_content": "giữ nguyên biến động thấp. Xin lỗi, đây là biến động cao. Rồi đây là độ biến động cao thì khi đó là nó sẽ có nhiều thông tin. Mà có nhiều thông tin thì khi đó chúng ta không nên, không nên loại bỏ cái cột này, chúng ta không nên bỏ cái cột này đó. Còn cái cột Văn thì mặc dù có cái sự thay đổi về điểm nhưng mà chúng ta thấy là cái độ lệch của nó, cái độ biến động của nó, độ dao động của nó thấp. Do đó mình không nhất thiết mình có thể cần phải lưu lại. Mình cần phải khôi phục lại nguyên với dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 18,
      "start_timestamp": "0:11:00",
      "end_timestamp": "0:11:46"
    }
  },
  {
    "page_content": "lại. Mình cần phải khôi phục lại nguyên với dữ liệu ban đầu. Trong nhiều tình huống thì chúng ta chỉ cần khôi phục lại một phần thôi. Có cái sự sai số nhất định mà vẫn có thể giải quyết được một số cái bài toán thì khi đó PCA là một trong những cái giải pháp mà luôn luôn là ưu tiên để chọn. Như vậy thì chiều của dữ liệu nào mà ít biến động, chúng ta có cái kết luận là chiều của dữ liệu nào mà ít biến động thì khi đó chúng ta có thể loại bỏ. Và đây chính là cái ý tưởng lớn nhất của thuật toán",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 19,
      "start_timestamp": "0:11:41",
      "end_timestamp": "0:12:27"
    }
  },
  {
    "page_content": "đây chính là cái ý tưởng lớn nhất của thuật toán PCA. PCA là nó sẽ tìm ra một cái không gian con tuyến tính mới. Nó là một cái không gian con C và không gian con này nó vẫn đảm bảo được cái tính chất là tuyến tính, nó khác so với lại cái không gian ban đầu. Và dữ liệu này thì nó được biểu diễn một cách hiệu quả nhất. Thì ví dụ như đây là cái không gian ban đầu nè. Đây là không gian ban đầu. Nó sẽ thực hiện cái thao tác đó là trừ cho cái giá trị mean. Thì rõ ràng mean của các cái điểm dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 20,
      "start_timestamp": "0:12:21",
      "end_timestamp": "0:13:02"
    }
  },
  {
    "page_content": "mean. Thì rõ ràng mean của các cái điểm dữ liệu của mình nó nằm ở đây. Khi chúng ta trừ cho mean tức là chúng ta đang làm một thao tác dịch chuyển tịnh tiến cái không gian của mình đúng cái trục hệ trục tọa độ của mình về cái giá trị mean ở đây sẽ dịch chuyển vào đây. Sau đó Bước số ba và bước số 4 là nó đi tìm ra một cái không gian con C, nó đi tìm cái không gian C sao cho nó biểu diễn hiệu quả. Thì cái không gian con C này á đó chính là cái không gian của vectơ U1 và U2. U1 là cái trục nét",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 21,
      "start_timestamp": "0:12:56",
      "end_timestamp": "0:13:40"
    }
  },
  {
    "page_content": "không gian của vectơ U1 và U2. U1 là cái trục nét đứt như thế này và U2 là cái trục như thế này. Thì để thực hiện được cái việc mà tìm cái hệ trục U1 và U2 thì chúng ta sẽ tính S là bằng trung bình cộng của cái giá trị mà đã được trừ đi cái mean ở bước số 2 nhân với chuyển vị của nó. Thì thực ra đây chính là cái thao tác mà tính cái độ lệch đúng không? Cái covariance. Đây là cái covariance, cái ma trận tính cái ma trận covariance của mình. Và với cái việc mà tính cái ma trận covariance, sau đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 22,
      "start_timestamp": "0:13:36",
      "end_timestamp": "0:14:17"
    }
  },
  {
    "page_content": "cái việc mà tính cái ma trận covariance, sau đó chúng ta sẽ phân tích các cái giá trị eigenvalue tức là các cái trị riêng và các cái vector riêng (eigen) vector đó của cái ma trận S này thì chúng ta sẽ ra được các cái giá trị trị riêng lambda 1, lambda 2, lambda và vectơ riêng đó là U1, U2, U3. Thì chúng ta sẽ có một cái lưu ý đó là các cái lambda 1, lambda 2 nó sẽ được sắp xếp lại theo một cái trình tự là giảm dần hoặc là tăng dần. Thì với cái giá trị trị riêng này nó sẽ giúp cho chúng ta biết",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 23,
      "start_timestamp": "0:14:12",
      "end_timestamp": "0:15:17"
    }
  },
  {
    "page_content": "trị trị riêng này nó sẽ giúp cho chúng ta biết rằng là cái hàm lượng thông tin của mình ứng với lại cái trục U của mình là nhiều hay ít. Thì chúng ta lấy một cái ví dụ ở đây. Chúng khi chúng ta tách cái dữ liệu ở đây, chúng ta phân tích cái dữ liệu ở đây thì chúng ta sẽ có hai cái giá trị là lambda 1, U1 tương ứng nó sẽ là cái vectơ U1 và lambda 2, U2. Và chúng ta thấy là cái lambda tương ứng cho cái U1 này nè thì nó sẽ lớn hơn là lambda 2. Tức là chúng ta đang sắp xếp tăng dần từ trái sang",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 24,
      "start_timestamp": "0:15:11",
      "end_timestamp": "0:15:47"
    }
  },
  {
    "page_content": "là chúng ta đang sắp xếp tăng dần từ trái sang phải. Thì cái lambda 1 tương ứng với lại cái trục U1 này á thì nó sẽ cho chúng ta biết rằng là cái thông tin khi chúng ta chiếu các cái điểm gốc này nè xuống dưới cái hệ trục U1 thì nó sẽ cho thông tin nó nhiều hơn hay là cái độ động nhiều hơn. Còn ở đây thì là cái độ biến động ít hơn. Như vậy thì với cái lambda 2 và tương ứng với U2 thì chúng ta thấy cái trục U1, à Xin lỗi, cái trục U2 nó sẽ ít thông tin hơn do đó có thể chúng ta có thể loại bỏ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 25,
      "start_timestamp": "0:15:43",
      "end_timestamp": "0:16:26"
    }
  },
  {
    "page_content": "tin hơn do đó có thể chúng ta có thể loại bỏ đó. Và khi này cái U2 của chúng ta thay vì chúng ta lưu các cái giá trị trên cái trục U2 như thế này, lưu cái giá trị đó, thì chúng ta chỉ cần lưu duy nhất một giá trị đó là số 0. Tại vì chúng ta đã bỏ đi cái trục U2 này rồi. Thì đây chúng ta liên tưởng đến cái ví dụ trước đây. Thay vì chúng ta lưu cái điểm gốc, cái giá trị gốc đúng không, thì chúng ta chỉ cần lưu cái giá trị trung bình ở đây thôi. Và trong trường hợp bên đây thì cái giá trị trung",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 26,
      "start_timestamp": "0:16:19",
      "end_timestamp": "0:16:36"
    }
  },
  {
    "page_content": "Và trong trường hợp bên đây thì cái giá trị trung bình của mình trong trường hợp này chính là 0. Tại vì chúng ta đã thực hiện cái thao tác là trừ cho cái giá trị mean rồi nên trung bình của mình trong trường hợp này nó sẽ là bằng 0. Rồi và sau khi chúng ta loại bỏ được cái trục U2 này rồi thì chúng ta sẽ chiếu. Ở đây chúng ta thấy cái ký hiệu nè. Chúng ta sẽ chiếu các cái data point này lên trên cái trục U1. Và cái giá trị của cái thao tác chiếu này chính là cái đặc trưng mới mà chúng ta sẽ lưu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "này chính là cái đặc trưng mới mà chúng ta sẽ lưu trữ. Và như vậy thì thay vì chúng ta lưu hai chiều chúng ta chỉ cần lưu các cái giá trị là hình chiếu là giá trị của cái phép chiếu của cái điểm gốc lên trên cái U1 này thôi. Như vậy là chúng ta chỉ cần lưu một chiều. Như vậy là chúng ta đã tiết kiệm được 50% dữ liệu đó. Thì chúng ta sẽ obtain N projected Point in low dimension. Tức là chúng ta chỉ cần lưu các cái điểm màu đỏ là những cái điểm hình chiếu trong một cái không gian ít chiều hơn đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chiếu trong một cái không gian ít chiều hơn đó là không gian của U1.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=5Hr7WDN8QKI",
      "filename": "5Hr7WDN8QKI",
      "title": "[CS116 - Buổi 6] Part 3",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tiếp theo thì chúng ta sẽ cùng đến với hai cái khái niệm đó là bias và variance đây là hai cái khái niệm để giúp cho chúng ta hiểu về cái tính chất của cái mô hình của mình sau khi đã huấn luyện xong nó liên quan đến các cái khái niệm ví dụ như là overfitting tức là quá khớp với dữ liệu hoặc là underfitting tức là chưa khớp với cái dữ liệu của mình nó bị dưới cái mức có thể khớp với dữ liệu của mình thì bias đó là một cái sai số là một cái sai số, sai số có thể hiểu đó là cái hiệu số ha, hiệu số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:46"
    }
  },
  {
    "page_content": "sai số có thể hiểu đó là cái hiệu số ha, hiệu số thể hiện bởi phép trừ ở đây nè, giữa cái trung bình hay cái kỳ vọng của mô hình dự đoán nếu như với cái dữ liệu, với một cái mẫu dữ liệu chúng ta ước lượng ra được một cái tham số Beta là cái tham số cho cái mô hình của mình thì chúng ta sẽ có rất nhiều những cái mẫu dữ liệu khác nhau đúng không? Tại vì dữ liệu huấn luyện bản chất nó chỉ là cái quá trình chúng ta lấy mẫu và với những cái lần lấy mẫu khác nhau thì chúng ta sẽ có một cái bộ tham số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:40",
      "end_timestamp": "0:01:21"
    }
  },
  {
    "page_content": "khác nhau thì chúng ta sẽ có một cái bộ tham số beta khác nhau và khi chúng ta lấy mẫu nhiều lần hay lấy mẫu huấn luyện nhiều lần thì kỳ vọng của các cái giá trị beta này hay là trung bình của các beta này thì chúng ta sẽ ký hiệu là bằng E của beta mũ thì đây chính là cái đại lượng trung bình hoặc là kỳ vọng của mô hình mình dự đoán so với so với cái mô hình thực tế thì trong cái slide trước, trong slide trước chúng ta đã tìm hiểu về cái khái niệm gọi là mô hình thực tế và mô hình thực tế ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:16",
      "end_timestamp": "0:01:58"
    }
  },
  {
    "page_content": "gọi là mô hình thực tế và mô hình thực tế ở đây thì được biểu hiện bởi cái tham số là beta, beta không có mũ và chúng ta luôn mong muốn là cái mô hình dự đoán của mình cái kỳ vọng của nó nó phải khớp, nó phải chính xác với lại cái mô hình thực tế nhất thì cái bias nó sẽ thể hiện cái sai số này đó là E beta mũ trừ cho Beta và bias thấp thì điều đó thể hiện kiện gì? Bias thấp thể hiện là mô hình đã học được, đã thực sự học được cái mối quan hệ của cái dữ liệu huấn luyện. Tức là cái sai số giữa",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:01:52",
      "end_timestamp": "0:02:37"
    }
  },
  {
    "page_content": "cái dữ liệu huấn luyện. Tức là cái sai số giữa trung bình beta mũ và Beta là nhỏ. Tức là hàm của mình đã tìm ra được cái mối quan hệ, đã tìm ra được cái mối quan hệ giữa dữ liệu đầu vào và cái giá trị dự đoán đầu ra. Và trong trường hợp mà bias mà cao thì thể hiện là mô hình nó không học được mối quan hệ của cái dữ liệu huấn luyện. Sau đây thì chúng ta sẽ qua cái khái niệm về variance. Variance nó thể hiện cái sai số trung bình của mô hình dự đoán, sai số trung bình của mô hình dự đoán so với",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:30",
      "end_timestamp": "0:03:18"
    }
  },
  {
    "page_content": "sai số trung bình của mô hình dự đoán so với cái kỳ vọng trung bình của mô hình được huấn luyện trên toàn bộ cái dữ liệu thực. Nghĩa là sao? Tại một cái mẫu dữ liệu, một cái dataset i đúng không? Thì chúng ta huấn luyện mô hình D là cái ký hiệu của chữ dataset ha. Dataset chúng ta huấn luyện ra được một cái mô hình là beta mũ và chúng ta kỳ vọng gì? Chúng ta kỳ vọng là cái beta mũ này nó xấp xỉ với lại cái beta tức là cái mô hình thực tế. Nhưng điều gì xảy ra nếu như cái sự thay đổi của cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:03:14",
      "end_timestamp": "0:04:03"
    }
  },
  {
    "page_content": "điều gì xảy ra nếu như cái sự thay đổi của cái dataset này nó cũng làm cho cái beta mũ này dao động? À, nó dao động có thể là nhỏ xuống hoặc là lên tăng lên. Thì khi cái dao động này nó quá lớn, nó thể hiện cái sự không ổn định, không ổn định của mô hình. Thì cái kỳ vọng của beta mũ đó chính là cái cái giá trị trung bình của các cái beta mũ ha và trừ cho beta. Sau đó chúng ta bình phương thì đây chính là cái phương sai, đây chính là cái phương sai. Đây chính là phương sai của các cái mô hình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:03:56",
      "end_timestamp": "0:04:41"
    }
  },
  {
    "page_content": "sai. Đây chính là phương sai của các cái mô hình của mình khi dự đoán trên những cái bộ dữ liệu khác nhau và trung bình của nó thì nó sẽ là cái sai số trên toàn bộ cái dữ liệu thực của mình. Thì nếu variance thấp nó thể hiện cái gì? Cái variance thấp tức là cái sai số này là thấp. Tức là mô hình của mình nó có cái tính tổng quát cao. Tại sao nó gọi là tổng quát cao? Tại vì khi chúng ta huấn luyện trên cái tập dữ liệu thứ i, chúng ta ra được một cái giá trị là beta. Khi chúng ta huấn luyện trên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:04:35",
      "end_timestamp": "0:05:14"
    }
  },
  {
    "page_content": "cái giá trị là beta. Khi chúng ta huấn luyện trên cái tập dữ liệu là thứ J, J khác i ha, thì chúng ta tạo ra được một cái tham số là beta J. Và hai cái beta và beta J này không có sự thay đổi nhiều, không có sự thay đổi nhiều. Tức là khi chúng ta thay đổi cái tập dữ liệu, cái dataset thì beta và beta J này nó xem xem nhau. Nó nó có thay đổi nhưng mà rất ít. Tức là mô hình của mình nó tổng quát hay nói cách khác đó là nó không có cái sự dao động. Như vậy là cái variance thấp nó sẽ thể hiện cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:05:10",
      "end_timestamp": "0:05:48"
    }
  },
  {
    "page_content": "Như vậy là cái variance thấp nó sẽ thể hiện cái tính tổng quát của mô hình, cái tính tổng quát của mình nó rất là cao. Dù có huấn luyện trên cái một cái tập con thì nó vẫn đúng trên những cái dữ liệu mà nó chưa thấy. Tức là trên cái tập test. Và ngược lại nếu variance mà thấp, xin lỗi. Ngược lại nếu variance mà cao tức là mô hình của mình nó sẽ không có đoán tốt trên những cái dữ liệu chưa gặp hay nói cách khác đó là nó chưa có đủ tổng quát. Nghĩa là khi chúng ta với cái mẫu dataset thứ i chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:05:43",
      "end_timestamp": "0:06:26"
    }
  },
  {
    "page_content": "là khi chúng ta với cái mẫu dataset thứ i chúng ta tạo ra được cái tham số là beta mũ i nhưng khi chúng ta đổi một cái dataset khác thì tự nhiên cái beta của mình nó lại ra một cái giá trị beta J rất khác so với lại giá trị beta i này. Tức là có cái sự dao động, có cái sự thay đổi rất là đột ngột khi thay đổi dữ liệu đó thì chứng tỏ là mô hình của mình không có ổn định hoặc là không đủ tổng quát. Và gần gũi hơn đó chính là nó không có đoán tốt trên những cái dữ liệu mà nó chưa từng thấy. Tại vì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:06:21",
      "end_timestamp": "0:07:04"
    }
  },
  {
    "page_content": "những cái dữ liệu mà nó chưa từng thấy. Tại vì khi chúng ta huấn luyện trên cái tập D_i thì lúc đó D của mình nó chính là cái dữ liệu mà chúng ta chưa thấy hay còn gọi là dữ liệu trong tập test. Và dưới đây là một cái sự so sánh về cái sự cân bằng của bias và variance khi xây dựng cái mô hình huấn luyện. Và huấn luyện trên cái tập dữ liệu thì chúng ta cần phải lưu ý đó là đảm bảo cho cả bias và variance nó đều thấp. Thì ở trong trường hợp đầu tiên đó là bias thấp và variance thấp tức là mô hình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:06:59",
      "end_timestamp": "0:07:39"
    }
  },
  {
    "page_content": "đó là bias thấp và variance thấp tức là mô hình của mình nó rất khớp với cái dữ liệu. Cái variance của nó, cái hồng tâm này chính là thể hiện cái sự cái bias của mình. Còn cái độ dao động giữa cái vòng tròn này với cái vòng tròn kia đó chính là thể hiện cái bias, thể hiện cái variance, cái mức độ dao động của cái dự đoán của mình, cái beta mũ của mình. Và bias mà thấp mà variance cao đúng không? Thì tương ứng đó là trường hợp overfitting. Overfitting tức là nó đã quá khớp, nó quá khớp so với",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:07:35",
      "end_timestamp": "0:08:11"
    }
  },
  {
    "page_content": "tức là nó đã quá khớp, nó quá khớp so với lại một cái tập dữ liệu nào đó nhưng mà đôi khi chúng ta thay đổi trên một cái tập dữ liệu khác thì nó có cái sự dao động. Thì đó là overfitting. Và tương tự như vậy nó sẽ có cái tình huống gọi là underfitting khi cái bias của mình nó cao, bias của mình nó cao và cho dù cái variance của mình nó thấp hay cao thì nó cũng đều là cái tình huống nó gọi là underfitting tức là chưa khớp với cái dữ liệu. Như vậy thì khi huấn luyện chúng ta luôn mong muốn tiến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 13,
      "start_timestamp": "0:08:06",
      "end_timestamp": "0:08:46"
    }
  },
  {
    "page_content": "thì khi huấn luyện chúng ta luôn mong muốn tiến đến cái tình huống này. Chúng ta luôn mong muốn tiến đến cái tình huống này. Còn cái tình huống này thì nó sẽ thể hiện cái mô hình của mình không có cái sự tổng quát hoặc là có cái sự bất ổn định, nó quá phụ thuộc vô cái dữ liệu train và khi test thì nó tạo ra một cái khác hoàn toàn, cái dữ liệu dự đoán có cái sai số, có cái sự sai lệch rất là lớn. Và để trực quan hơn với cái ví dụ mẫu của hiện tượng bias, variance và các cái hiện tượng liên quan",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 14,
      "start_timestamp": "0:08:42",
      "end_timestamp": "0:09:27"
    }
  },
  {
    "page_content": "bias, variance và các cái hiện tượng liên quan đến overfitting và underfitting thì chúng ta sẽ lấy cái ví dụ cho bài toán phân lớp mặc dù chúng ta đang làm với bài toán hồi quy ha, nhưng mà chúng ta lấy cái tình huống là là bài toán phân lớp để hiểu nó rõ hơn. Thì giả sử như chúng ta đang phân hai cái tập này ra làm hai cái phần là hình tròn và dấu X thì cái hiện tượng overfitting đó chính là cái hiện tượng này. Nghĩa là sao? Cái đường mà phân chia của mình nó sẽ đi zích zắc, đi zích zắc và đi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 15,
      "start_timestamp": "0:09:21",
      "end_timestamp": "0:09:56"
    }
  },
  {
    "page_content": "của mình nó sẽ đi zích zắc, đi zích zắc và đi xuyên qua các cái điểm nhiễu. Các cái dấu X này chính là các điểm nhiễu. Tại vì nó nằm nằm bên trong hoàn toàn cái đường hình tròn nhưng mà nó vẫn bị gọi là đánh giá nhãn đó là là X. Thì cái đường mô hình của mình nó sẽ tìm cách để cố học những cái điểm dữ liệu mà bị nhiễu này. Và khi đó thì chúng ta thấy là cái hiệu quả khi trên cái mô hình này thì nó vẫn rất là tốt cho cái trường hợp là tập train. Nhưng mà sau này khi chúng ta tiến hành trên những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 16,
      "start_timestamp": "0:09:52",
      "end_timestamp": "0:10:25"
    }
  },
  {
    "page_content": "mà sau này khi chúng ta tiến hành trên những cái tập dữ liệu test thì rõ ràng là cái mô hình phức tạp này nó sẽ khiến cho chúng ta không đạt được cái mức độ gọi là độ tin cậy cao. Và để tránh cái hiện tượng overfitting thì chúng ta sẽ có hai cái giải pháp. Giải pháp đầu tiên đó chính là chúng ta giảm bớt cái sự phức tạp của mô hình đi. Chúng ta thấy là cái mô hình này nó có cái đường đi rất là phức tạp do đó để tránh cái hiện tượng nó cố học những cái điểm nhiễu này thì chúng ta sẽ giảm bớt cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 17,
      "start_timestamp": "0:10:23",
      "end_timestamp": "0:11:05"
    }
  },
  {
    "page_content": "cái điểm nhiễu này thì chúng ta sẽ giảm bớt cái tham số của mô hình hay là giảm bớt cái sự phức tạp của mô hình đi. Và chúng ta sẽ lấy mẫu thêm, chúng ta sẽ lấy mẫu thêm hay là lấy thêm cái dữ liệu hay còn gọi là tăng cường dữ liệu á. Thì khi chúng ta tăng cường thêm dữ liệu thì cái mô hình của mình nó sẽ giảm bớt được cái hiện tượng overfitting. Và trường hợp underfitting thì thì nguyên nhân đó là xảy ra khi cái mô hình của mình nó quá đơn giản. Nó thuộc cái tình huống này. Tức là lẽ ra cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 18,
      "start_timestamp": "0:10:59",
      "end_timestamp": "0:11:35"
    }
  },
  {
    "page_content": "Nó thuộc cái tình huống này. Tức là lẽ ra cái đường mà tối ưu tốt nó phải là ra một cái đường cong như thế này thì cái hàm mô hình của mình nó lại quá đơn giản, nó chỉ là một cái đường thẳng như thế này thôi. Và so với cái tính chất phức tạp của dữ liệu đó thì lúc đó là hoặc là dữ liệu của mình nó không đủ tổng quát thì khi đó là nguyên nhân gây ra cái hiện tượng underfitting này. Và để chống cái hiện tượng underfitting này thì chúng ta có hai cách luôn. Cách đầu tiên đó là chúng ta sẽ chuyển",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 19,
      "start_timestamp": "0:11:30",
      "end_timestamp": "0:12:03"
    }
  },
  {
    "page_content": "cách luôn. Cách đầu tiên đó là chúng ta sẽ chuyển từ một cái mô hình đơn giản sang một cái mô hình phức tạp hơn, chúng ta sẽ thay cái hàm mô hình của mình. Và cách thứ hai, cách này thì luôn luôn là luôn luôn đúng. Tức là trong trường hợp mà underfitting hay overfitting chúng ta đều có thể làm được đó là tăng cường cái tập dữ liệu huấn luyện lên. Thì khi tăng cường cái tập dữ liệu lên thì lúc đó cái dữ liệu của mình, cái dữ liệu D_i của mình nó sẽ tiệm cận với lại cái tập dữ liệu D. Tức là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 20,
      "start_timestamp": "0:11:58",
      "end_timestamp": "0:12:08"
    }
  },
  {
    "page_content": "sẽ tiệm cận với lại cái tập dữ liệu D. Tức là cái dữ liệu trong thực tế, đây là cái dữ liệu thực. Thì khi chúng ta tăng cái số lượng mẫu dữ liệu của D_i. Tức là cái quá trình train của mình lên. Trong cái quá trình train mà train nhiều lần thì cái D_i này nó sẽ tiệm cận về cái D này. Tức là nó sẽ tiệm cận đến cái dữ liệu thực tế. Đó thì khi chúng ta tiệm cận được dữ liệu thực tế tức là dữ liệu của mình nó đã đạt được cái độ tổng quát cao. Khi dữ liệu tổng quát cao thì lúc đó cái mô hình của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "dữ liệu tổng quát cao thì lúc đó cái mô hình của mình nó học được những cái tình huống đó thì nó cũng sẽ tránh được cái hiện tượng underfitting.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=73-FbhDr_Po",
      "filename": "73-FbhDr_Po",
      "title": "[CS116 - Buổi 7] Part 2",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với cái bước thực hiện đầu tiên và là cũng là một trong những cái bước quan trọng trong cái machine learning pipeline đó chính là phân tích dữ liệu phân tích dữ liệu đó là chúng ta sẽ thực hiện các cái công việc liên quan đến hiểu dữ liệu và chúng ta à đánh giá được cái vai trò của từng cái trường trong cái dữ liệu của mình vai trò của cái dữ liệu rồi chúng ta sẽ hiểu về cái phân bố của dữ liệu hoặc là tính chất của dữ liệu rồi đồng thời là chúng ta có thể phát hiện những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:56"
    }
  },
  {
    "page_content": "rồi đồng thời là chúng ta có thể phát hiện những cái vấn đề phát hiện những cái vấn đề trong cái dữ liệu của mình thì những cái vấn đề này có thể bao gồm đó là cái dữ liệu của mình nó bị thiếu hoặc là cái dữ liệu của mình nó bị nhiễu thì chúng ta sẽ phải xử lý như thế nào đó Thì đó chính là những cái công việc mà chúng ta cần phải thực hiện với lại cái bước đầu tiên đó là edi thì tại sao chúng ta cần phải phân tích dữ liệu thì cái việc phân tích dữ liệu nó sẽ giúp cho chúng ta hiểu rõ về cái dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:49",
      "end_timestamp": "0:01:40"
    }
  },
  {
    "page_content": "dữ liệu nó sẽ giúp cho chúng ta hiểu rõ về cái dữ liệu của mình hơn rõ ràng là khi chúng ta làm với machine learning Mặc dù là cái mô hình máy học nó sẽ tiến hành huấn luyện trên cái đặc Trư huấn luyện trên cái cái dữ liệu đầu vào của mình và nó được thực hiện một cách tự động nhưng nếu chúng ta không hiểu về những cái tính chất của dữ liệu thì dẫn đến là chúng ta sẽ thiết kế cái mô hình máy học nó không phù hợp do đó thì cái lý do tại sao đầu tiên chúng ta cần phải phân tích dữ liệu đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:33",
      "end_timestamp": "0:02:08"
    }
  },
  {
    "page_content": "tiên chúng ta cần phải phân tích dữ liệu đó là chúng ta hiểu rõ dữ liệu và thế nào gọi là hiểu rõ dữ liệu chúng ta sẽ biết được là à trong cái dữ liệu của mình nó sẽ có bao nhiêu cái đặc trưng đầu vào số mẫu dữ liệu của mình là nhiều hay ít tùy vào cái số mẫu dữ liệu của mình là nhiều hay ít thì khi đó chúng ta sẽ biết là chúng ta sẽ phải chọn lựa những mô hình nào cho phù hợp rồi Cái loại đặc trưng của mình đó là đặc trưng kiểu gì đó là đặc trưng dạng số hay đó là đặc trưng dạng phân loại hoặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:02:04",
      "end_timestamp": "0:02:49"
    }
  },
  {
    "page_content": "dạng số hay đó là đặc trưng dạng phân loại hoặc là danh mục rồi cái phân bố dữ liệu của mình đó là giải giá trị của mình là kéo dài từ giá trị nào đến giá trị nào đồng thời là mình sẽ xem coi các cái giá trị ở vùng biên này nè Nó có phải là những cái giá trị ngoại lệ hay không Hoặc là có phải là giá trị nhiễu hay không đó rồi mối quan hệ và cái xu hướng của dữ liệu của mình là gì trong các cái đặc trưng thì các cái Đặc trưng nào là có mối quan hệ mật thiết với nhau hoặc là đối với cái giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:43",
      "end_timestamp": "0:03:25"
    }
  },
  {
    "page_content": "hệ mật thiết với nhau hoặc là đối với cái giá trị mà mình cần phải dự đoán thì nó có mối quan hệ mang tính chất xu hướng với cái dữ liệu đặc trưng đầu vào hay không thì đó chính là chúng ta hiểu rõ về cái dữ liệu của mình những cái câu hỏi mà chúng ta cần phải trả lời Bước tiếp theo đó là cái tiền đề để chúng ta có thể làm sạch dữ liệu về sau tại vì khi chúng ta phân tích dữ liệu thì nó sẽ xác định được những cái vấn đề mà dữ liệu của mình đang còn tồn tại ví dụ thiếu dữ liệu có những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:03:20",
      "end_timestamp": "0:03:57"
    }
  },
  {
    "page_content": "đang còn tồn tại ví dụ thiếu dữ liệu có những cái trường thuộc tính trong dữ liệu nó bị chứa giá trị rỗng hoặc là chứa một cái giá trị là không xác định hoặc là trong cái dữ liệu của mình nó bị trùng lập có những cái phần tử gọi là hai hàng giống y chang nhau thì khi hai hàng giống y chang nhau này thì sẽ gây ra cho mình đó là dữ liệu của mình thừa và nếu như cái tình trạng mà trùng lắp dữ liệu này á mà quá nhiều ví dụ như có những cái trường hợp mà nó lặp lại đến chếm đến 10 ph cái dữ liệu của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:03:51",
      "end_timestamp": "0:04:27"
    }
  },
  {
    "page_content": "mà nó lặp lại đến chếm đến 10 ph cái dữ liệu của mình thì nó sẽ gây ra cho cái mô hình máy học nó một cái hiện tượng nó gọi là bias tức là mô hình máy học của mình sẽ tìm cách để học thuộc cái tình huống mà trùng lắp dữ liệu này gây ra cái việc là cái mô hình của mình nó không có cái tính chất nó sẽ không có tính nó gọi là không có tổng quát cái ba hiện tượng bas nó lớn thì nó sẽ làm cho mô hình của mình nó không tổng quát sau này khi chúng ta làm việc trên những cái mẫu dữ liệu mà mới chưa",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:04:23",
      "end_timestamp": "0:05:08"
    }
  },
  {
    "page_content": "làm việc trên những cái mẫu dữ liệu mà mới chưa từng thấy thì nó sẽ cho cái độ chính xác Nó không cao vì cái mô hình nó cứ tìm cách nó học thuộc trên những cái mẫu dữ liệu mà có sẵn và đặc biệt là những cái mẫu dữ liệu mà xuất hiện nhiều rồi và xác định xem là cái dữ liệu của mình Nó có nhiễu hay không Tức là các cái giá trị ở đây là có nằm ngoài cái phạm vi mà trong thực tế thường xuyên xuất hiện hay không Ví dụ độ tuổi mà chúng ta thấy là có độ tuổi là -1 thì liệu là Đây có phải là một giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:05:03",
      "end_timestamp": "0:05:37"
    }
  },
  {
    "page_content": "độ tuổi là -1 thì liệu là Đây có phải là một giá trị nhiễu hay không hay nó mang một cái ý nghĩa khác thì lúc đó chúng ta sẽ phải xử lý riêng cho các cái tình huống ghê nhiễu này dữ liệu của mình nó có lỗi hoặc là có cái tính không nhất quán hay không Cái tính không nhất quán ví dụ như là cũng là cái đối tượng đó nhưng mà ở phía trên thì nó lại là nhận cái giá trị nhưng mà phía dưới nó lại nhận là giá trị khác ví dụ như ở phía trên thì cái người đó cái tên của công ty đó là viết dạng đầy đủ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:05:32",
      "end_timestamp": "0:06:15"
    }
  },
  {
    "page_content": "đó cái tên của công ty đó là viết dạng đầy đủ nhưng mà phía dưới thì nó lại viết dưới dạng là một cái tên khác thì các cùng một cái đối tượng nhưng mà viết những cái giá trị khác nhau thì đó là cái tính không nhất quán của dữ liệu và khi chúng ta phân tích và xác định được những vấn đề rồi thì nó sẽ làm tiền đề tiền đề để sau này chúng ta sẽ xóa Nhữ liệu điền khuyết hoặc là chúng ta giữ nguyên dữ liệu và đây cũng là cái phân tích dữ liệu nó cũng là cái tiền đề để sau này chúng ta chọn lựa đặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 10,
      "start_timestamp": "0:06:09",
      "end_timestamp": "0:06:45"
    }
  },
  {
    "page_content": "là cái tiền đề để sau này chúng ta chọn lựa đặc trưng khi chúng ta đã hiểu rõ về cái tính chất của dữ liệu rồi thì sau này chúng ta sẽ biết rằng là đặc trưng nào là những cái đặc trưng tốt để chúng ta lựa chọn đưa cho cái mô hình nó huấn luyện Và thậm chí là chúng ta biết được cái tính chất của cái đặc trưng rồi thì chúng ta sau này chúng ta sẽ chọn lượ cái mô hình phù hợp với cái đặc trưng đó rồi Thậm chí là chúng ta có thể tạo ra những cái đặc trưng tốt hơn tạo ra những cái đặc trưng nó giúp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 11,
      "start_timestamp": "0:06:40",
      "end_timestamp": "0:07:20"
    }
  },
  {
    "page_content": "trưng tốt hơn tạo ra những cái đặc trưng nó giúp cho mô hình có thể Dự đoán chính xác hơn rồi chúng ta có thể chuẩn hóa cái đặc trưng về những cái dạng mà mô hình máy học nó có thể thực hiện tốt Ví dụ như một số mô hình máy học nó đòi hỏi là cái dữ liệu đầu vào cái đặc trưng đầu vào của mình nó phải lợi dạng số thì các cái đặc Trưng các cái đặc trưng của mình Nó sẽ phải chuyển về cái dạng số hoặc là cái dữ liệu cái mô hình máy học của mình đầu vào nó yêu cầu là dữ liệu phải ở dạng được chuẩn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 12,
      "start_timestamp": "0:07:14",
      "end_timestamp": "0:07:56"
    }
  },
  {
    "page_content": "vào nó yêu cầu là dữ liệu phải ở dạng được chuẩn hóa theoo phân bố chuẩn thì chúng ta sẽ phải đưa các cái dữ liệu của mình về cái phân bố chuẩn cho phù hợp với lại cái vô hình máy học đó yêu cầu và chúng ta có thể lường trước một số cái tình huống của cái dữ liệu Ví dụ như dữ liệu bị mất cân bằng hoặc là dữ liệu bị Thiên lệch rồi vấn đề về rò rỉ thông tin và vi phạm các cái vấn đề về dữ liệu ví dụ như là chúng ta để cái tên người thật ở bên trong cái dữ liệu của mình có thể gây ra cái hiện",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 13,
      "start_timestamp": "0:07:52",
      "end_timestamp": "0:08:30"
    }
  },
  {
    "page_content": "trong cái dữ liệu của mình có thể gây ra cái hiện tượng là rò rỉ thông tin về sau hoặc là vi phạm các cái điều lọc về cái dữ liệu của mình thì đâu đó chúng ta sẽ phải nếu như chúng ta ở trong cái dữ liệu thô ban đầu của mình mà có chứa những cái dữ liệu bị vi phạm như vậy thì chúng ta sẽ phải làm một cái công đoạn thêm một cái công đoạn nữa đó là chúng ta sẽ anonymize chúng ta sẽ ẩn danh hóa cái thông tin này của mình đi Ví dụ thông tin về số tài khoản thì rõ ràng là nếu như cái số tài khoản",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 14,
      "start_timestamp": "0:08:19",
      "end_timestamp": "0:08:59"
    }
  },
  {
    "page_content": "tài khoản thì rõ ràng là nếu như cái số tài khoản này mà rò rỉ ra bên ngoài thì nó sẽ gây ra hệ luy rất là lớn do đó thì các cái thông tin tài khoản của mình Chúng ta sẽ phải mã hóa nó bằng một cái dạng thức khác cho phù hợp và đây là một cái công cụ truyền thông tại vì khi chúng ta phân tích dữ liệu thì nó sẽ giúp cho chúng ta trực quan hóa được dữ liệu và khi chúng ta trực quan hóa dữ liệu dưới dạng là các cái biểu đồ trực quan dễ hiểu dễ cảm nhận thì khi đó chúng ta sẽ dễ dàng giải thích cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 15,
      "start_timestamp": "0:08:55",
      "end_timestamp": "0:09:38"
    }
  },
  {
    "page_content": "thì khi đó chúng ta sẽ dễ dàng giải thích cái vấn đề của mình với cái người không có chuyên môn ví dụ như là những người đến từ K lĩnh vực không phải là về máy học Hoặc là những cái người đó là khách hàng của mình thì nó sẽ giúp cho chúng ta giải thích với họ là à dữ liệu của mình nó đang có những vấn đề gì chúng ta phải xử lý ra sao Và khi chúng ta Ờ xử lý xong rồi thì mình sẽ giải thích với họ là cái hiệu quả của nó như thế nào thì đó là tại sao chúng ta cần phải phân tích dữ liệu và các cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 16,
      "start_timestamp": "0:09:33",
      "end_timestamp": "0:10:24"
    }
  },
  {
    "page_content": "chúng ta cần phải phân tích dữ liệu và các cái công cụ để chúng ta có thể thực hiện được cái phân tích dữ liệu đó là chúng ta có thể sử dụng các cái công cụ trực Quang ví dụ như là chúng ta sử dụng các cái biểu đồ histogram hoặc là vẽ dưới dạng là các cái biểu đồ dưới dạng hộp box rồi ma trận tương quan và chúng ta cũng có thể sử dụng các cái công cụ về thống kê ví dụ như là sử dụng các cái chỉ số thống kê như là giá trị trung bình trung vị phương sai độ lịch chuẩn rồi các cái hệ số tương quan",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 17,
      "start_timestamp": "0:10:15",
      "end_timestamp": "0:10:59"
    }
  },
  {
    "page_content": "sai độ lịch chuẩn rồi các cái hệ số tương quan như là phân tích tương quan đơn biến Phân tích đa biến rồi một số cái mô hình một số cái công cụ hồi quy Tiến Tính hệ số Pon để phân tích cái dữ liệu của mình và có các cái kiểu phân tích dữ liệu đó là chúng ta sẽ phân tích dữ liệu đơn biến ví dụ đây là một cái bản dữ liệu của mình và ở đây chúng ta sẽ có x1 x2 x3 x4 là các cái đặc trưng đầu vào và y Tức là cái đặc trưng mà chúng ta cần phải dự đoán thì phân tích đơn biến đó là chúng ta sẽ phải xem",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 18,
      "start_timestamp": "0:10:54",
      "end_timestamp": "0:11:36"
    }
  },
  {
    "page_content": "thì phân tích đơn biến đó là chúng ta sẽ phải xem xét trên từng cái biến độc lập này và chúng ta sẽ không có cái sự tương tác giữa cái biến X1 với X2 hoặc là X1 với xy thì các biến được phân tích một cách độc lập với nhau phân tích hai biến đó là chúng ta sẽ đi theo phân tích theo cái sự tương quan của từng cặp dữ liệu X1 với X2 hoặc là X1 với lại xy nó sẽ được lấy ra từng cặp để chúng ta phân tích hoặc là Phân tích đa biến tức là chúng ta sẽ lấy ra một cái bộ các cái biến có thể là ba biến bốn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 19,
      "start_timestamp": "0:11:31",
      "end_timestamp": "0:12:12"
    }
  },
  {
    "page_content": "ra một cái bộ các cái biến có thể là ba biến bốn biến để mà Cùng phân tích một lúc thì đó là Phân tích đa biến và đối với phân tích đơn biến thì chúng ta chỉ cần quan tâm đến một đặc trưng và hoặc là một cột trong cái dữ liệu của mình Chúng ta có thể sử dụng các cái phương thức Ờ Bằng thống kê ví dụ như là chúng ta phân tích cái xu Hống tập trung dữ liệu hay còn gọi là Central dep à tendency Central tendency các cái tham số ước lượng như là giá trị trung bình giá trị trung vị hoặc là giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 20,
      "start_timestamp": "0:12:06",
      "end_timestamp": "0:12:54"
    }
  },
  {
    "page_content": "trị trung bình giá trị trung vị hoặc là giá trị Mode chúng ta có thể phân tích trên cái khoảng giá trị Ví dụ như là khoảng cách giữa các cái Giá trị tối đa và giá trị tối thiểu của mình v cái khoảng giá trị của đó sẽ là bao nhiêu chúng ta có thể phân tích cái Phương sii hoặc là độ lịch chuẩn thì toàn bộ tất cả những cái cái phân tích này đó là phân tích về mặt thống kê và tương tự như vậy thì khi mà chúng ta phân tích đơn biến và bằng thống kê thì trong cái thư viện của pandas chúng ta có cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 21,
      "start_timestamp": "0:12:46",
      "end_timestamp": "0:13:27"
    }
  },
  {
    "page_content": "thì trong cái thư viện của pandas chúng ta có cái hàm Đó là hàm describe hàm mô tả thì nó đã giúp cho chúng ta thực hiện cái thao tác thống kê Này Rồi ví dụ đối với những cái dữ liệu mà dạng số thì chúng ta thấy là nó sẽ đếm coi là có bao nhiêu cái dữ liệu nè rồi nó sẽ đếm xem là à giá trị trung bình của cái độ tuổi của mình là bao nhiêu nè Đây là chúng ta đang xem xét đến Tộ đổi n rồi độ lệch chuẩn rồi giá trị nhỏ nhất giá trị lớn nhất là bao nhiêu nè Rồi cái khoảng giá trị 25 ph 50 ph và 75",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 22,
      "start_timestamp": "0:13:23",
      "end_timestamp": "0:14:20"
    }
  },
  {
    "page_content": "nhiêu nè Rồi cái khoảng giá trị 25 ph 50 ph và 75 ph đó là bao nhiêu thì đây chính là cái à phân tích mà đơn biến sử dụng cái hàm describe của pandas rồi một cái kiểu nữa đó là chúng ta sẽ phân tích đơn biến mà bằng biểu đồ thì chúng ta có thể sử dụng cái biểu đồ histogram đây là cái biểu đồ trong đó là tần số của dữ liệu Được biểu thị bằng các cái Thanh hình chữ nhật và chúng ta có thể sử dụng một cái kiểu biểu diễn cho cái phân bố theo dưới dạng là ờ mật độ biểu đồ mật độ thì đây là một cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "là ờ mật độ biểu đồ mật độ thì đây là một cái phiên bản liên tục của biểu đồ histogram nếu như biểu đồ histogram chúng ta tạo ra các cái Thanh như thế này thì biểu độ mật độ là chúng ta sẽ tạo ra các cái giá trị liên tục thì đó chính là biểu đồ dữ dạng và mật độ và một cái kiểu nữa đơn giản hơn đó chính là box Plus box Plus thì chúng ta sẽ có các cái giá trị như là median rồi giá trị Q1 q3 và có thể là cái giá trị là min max thì ngoài ra thì khi những cái giá trị nào mà vượt qua cái giá trị min",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "những cái giá trị nào mà vượt qua cái giá trị min max này thì đâu đó nó có khả năng là những cái giá trị out layer hay là những cái giá trị nhiễu thì đây là cái cách phân tích về box box CL",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7bb6IFBgtfw",
      "filename": "7bb6IFBgtfw",
      "title": "[CS116 - Buổi 3] Part 3",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong bài trước thì chúng ta đã thử nghiệm mô hình Logistic với cái dữ liệu tuyến tính thì bây giờ tiếp theo chúng ta sẽ thử nghiệm với cái dữ liệu có quan hệ phi tuyến tính ở đây chúng ta sẽ thử nghiệm với hai cái điểm màu xanh và màu đỏ trong đó màu đỏ sẽ nằm bên trong một cái vòng tròn và màu xanh sẽ nằm bên ngoài một cái vòng tròn thì chúng ta thấy là cái trường hợp này chúng ta không thể chia tách ra hai cái tập màu xanh và màu đỏ này bởi một đường thẳng nhất đúng không Thì ở đây chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:37"
    }
  },
  {
    "page_content": "đường thẳng nhất đúng không Thì ở đây chúng ta sẽ gọi lại cái hàm Logistic Regression rồi chúng ta sẽ khai báo lại Logistic Regression và chúng ta sẽ truyền vào cái x và y tương ứng là các cái điểm xy ở bên đây đã khởi tạo bởi cái hàm make_circles của cái module là datasets và chúng ta cũng sẽ trực quan hóa cái dữ liệu này với cái hàm Ờ vẽ mô hình đã cài đặt ở trong phần trước rồi chúng ta copy cái nội dung của cái hàm này xuống và ở đây có một cái lưu ý đó là x của mình á là nó sẽ bắt đầu cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 1,
      "start_timestamp": "0:00:30",
      "end_timestamp": "0:01:23"
    }
  },
  {
    "page_content": "cái lưu ý đó là x của mình á là nó sẽ bắt đầu cái điểm bên trái của mình nó sẽ là X1 của mình sẽ là bằng -1 và X2 à Xin lỗi X1 bên tay phải á cái điểm bên phải này nè Nó sẽ là 1 X1 = -1 và X1 = 1 thì từ đó mình sẽ dự đoán với cái hàm mô hình của mình mình dự đoán xem cái điểm y X1 X2 tương ứng là bao nhiêu thì mình sẽ có cái hàm là calculate_X2 và khi chạy cái hàm này cái đoạn code này thì nó vẽ ra một cái đường thẳng chia cái tập điểm này ra làm hai phần như vậy thì chúng ta có thể thấy là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 2,
      "start_timestamp": "0:01:14",
      "end_timestamp": "0:02:00"
    }
  },
  {
    "page_content": "hai phần như vậy thì chúng ta có thể thấy là cái đường thẳng này nó không có tách hai cái điểm màu xanh và màu đỏ ra làm hai và cũng dễ hiểu nếu như cái độ chính xác accuracy của mình là thấp trong trường hợp này chúng ta thấy là accuracy của mình là bằng 0.505 tức là khoảng 50 phần trăm Tức là nó chỉ đúng cho một nửa thôi còn một nửa là bị sai Ví dụ ở đây nó sẽ đúng cho một nửa các cái điểm màu xanh và nó bị sai cho một nửa xin lỗi nó đúng cho một nửa cái điểm màu xanh ở bên đây và một nửa các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 3,
      "start_timestamp": "0:01:55",
      "end_timestamp": "0:02:32"
    }
  },
  {
    "page_content": "nửa cái điểm màu xanh ở bên đây và một nửa các điểm màu đỏ bên đây và nó bị sai bởi các cái điểm này và sai bởi các cái điểm này rồi và bây giờ chúng ta cũng tương tự như vậy chúng ta sẽ tiến hành feature engineering chúng ta sẽ tạo thêm các cái đặc trưng mới thì ở đây chúng ta có X1 và X2 chúng ta sẽ feature engineering thêm là nếu như X1 đúng không thì chúng ta sẽ tạo ra thêm là X1 mũ 2 rồi tương tự như vậy X2 chúng ta sẽ có là X2 mũ 2 và chúng ta cũng không nên quên chúng ta sẽ tạo ra thêm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 4,
      "start_timestamp": "0:02:27",
      "end_timestamp": "0:03:14"
    }
  },
  {
    "page_content": "ta cũng không nên quên chúng ta sẽ tạo ra thêm một cái đặc trưng nữa đó là X1 nhân với lại X2 thì để đảm bảo là có cái sự kết hợp giữa đặc trưng của X1 với X2 Như vậy thì cái hàm của mình nó mới phụ thuộc một cách bậc hai và X_new của mình chính là cái đặc trưng mới bao gồm X_cũ đúng không kèm theo nè Đây chính là X1 nè X[:,0] thì đây chính là X1 bình phương phương X[:,1] bình phương đây chính là X2 đây chính là cái X2 của mình và X2 của mình và X[:,0] nhân với lại X[:,1] đó chính là cái thành",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 5,
      "start_timestamp": "0:03:08",
      "end_timestamp": "0:04:05"
    }
  },
  {
    "page_content": "X[:,0] nhân với lại X[:,1] đó chính là cái thành phần X1 nhân với X2 thì chúng ta sẽ dùng horizontal stack ha và chúng ta sẽ có cái kích thước của cái X_new này chính là bằng 400x5 trong đó 5 ở đây bao gồm ở đây là 5 features là bao gồm là X1 nè X2 nè rồi X1 bình phương nè X2 bình phương nè và X1 nhân với lại X2 đó thì đây là năm cái features mới của mình và tương tự như vậy thì chúng ta sẽ cùng build cái model này lên để thử xem cái accuracy của mình trong trường hợp này là bao nhiêu rồi Ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 6,
      "start_timestamp": "0:03:58",
      "end_timestamp": "0:04:45"
    }
  },
  {
    "page_content": "mình trong trường hợp này là bao nhiêu rồi Ở đây thì mình sẽ fit predict cái X_new này X_new ở đây sẽ phải là X_new đó như vậy thì sau khi chúng ta đã thực hiện cái feature engineering engineering xong thì nó sẽ ra là độ chính xác là bằng 100 phần trăm thì rõ ràng với cái phương pháp feature engineering nó đã tạo ra được cái sự hiệu quả khi chúng ta dự đoán được à cái đặc trưng một cách đúng đắn tức là đây là một cái cái đường phân chia hai cái tập màu xanh và màu đỏ này á Nó là một cái dạng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 7,
      "start_timestamp": "0:04:39",
      "end_timestamp": "0:05:18"
    }
  },
  {
    "page_content": "tập màu xanh và màu đỏ này á Nó là một cái dạng bậc hai đó là một cái dạng bậc hai của hai cái đặc trưng đầu vào là X1, X2 tuy nhiên trong trường hợp mà chúng ta không biết được cái dữ liệu của mình nó quá nhiều chiều X này của chúng ta Nó không chỉ có hai chiều X1, X2 mà có thể lên đến hàng trăm chiều và chúng ta cũng không đủ cái tri thức để chúng ta biết được rằng là có những cái dạng mô hình nào để chúng ta feature engineering thì khi đó chúng ta sẽ sử dụng một cái công cụ đó chính là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 8,
      "start_timestamp": "0:05:14",
      "end_timestamp": "0:05:55"
    }
  },
  {
    "page_content": "chúng ta sẽ sử dụng một cái công cụ đó chính là Neural Network mạng neuron nhân tạo cho cái trường hợp dữ liệu phi tuyến thì ở đây chúng ta đã có một cái cách để mà cài đặt chúng ta đã có đoạn code để cài đặt sẵn Ờ Neural Network Nó là một cái tên gọi khác trong scikit-learn đó là Multi-layer Perceptron Multi-layer Perceptron Và Nó là một cái dạng classifier nó nằm trong cái lớp là scikit-learn Neural Network và ở đây thì mình sẽ có cái tham số cho cái model này của mình thì hidden layer ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 9,
      "start_timestamp": "0:05:48",
      "end_timestamp": "0:06:33"
    }
  },
  {
    "page_content": "cho cái model này của mình thì hidden layer ở đây đó là cho biết là cái mạng neural này sẽ sẽ bao gồm layer thì ở đây chúng ta sẽ tra cứu ha là Neural Network thì cái Neural Network của mình nó sẽ có nhiều layer nhưng mà trong trường hợp này chúng ta sẽ làm một cái mạng đơn giản là chỉ bao gồm duy nhất một layer là một cái lớp ẩn thôi một hidden layer thôi giống như trong cái hình ở đây là một lớp ẩn và lớp ẩn này thì trong cái hình ví dụ này thì nó sẽ có là 4 neuron nhưng mà chúng ta ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 10,
      "start_timestamp": "0:06:28",
      "end_timestamp": "0:07:07"
    }
  },
  {
    "page_content": "thì nó sẽ có là 4 neuron nhưng mà chúng ta ở đây chúng ta sẽ cho đến 10 neuron và hàm kích hoạt ở đây mặc định chúng ta sẽ sử dụng là hàm Logistic Regression và các cái solver Tức là cái thuật toán để tối ưu cái mạng neural Network này thì mặc định chúng ta cũng nên sử dụng Adam và một loạt các cái tham số khác và sau khi chúng ta khai báo xong thì chúng ta sẽ tiến hành fit trên cái data cũ tức là lưu ý ở đây chúng ta sẽ không sử dụng cái data X_new Tại vì X_new nó đã có chứa cái đặc trưng đã",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 11,
      "start_timestamp": "0:07:00",
      "end_timestamp": "0:07:40"
    }
  },
  {
    "page_content": "X_new Tại vì X_new nó đã có chứa cái đặc trưng đã được engineered là các cái đặc trưng mà chúng ta đã đã đã thêm vô đó thì ở đây chúng ta đang giả định rằng là chúng ta sử dụng cái dữ liệu thô raw data sử dụng dữ liệu thô Chúng ta không có cái tri thức gì về cái mô hình của mình thì chúng ta sẽ gọi cái hàm net.fit và sau đó thì chúng ta sẽ dùng cái hàm đánh giá thì với cái hàm đánh giá này chúng ta thấy độ chính xác là 100 phần trăm như vậy với Neural Network chúng ta không cần phải làm cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 12,
      "start_timestamp": "0:07:35",
      "end_timestamp": "0:08:25"
    }
  },
  {
    "page_content": "Neural Network chúng ta không cần phải làm cái bước feature engineering Và đây là các cái tham số của bias cũng như là à Xin lỗi đây là các cái tham số của bias và chúng ta sẽ còn một cái nữa là chấm score và coefficients rồi thì ở đây nó sẽ phức tạp hơn so với lại cái Logistic Regression một chút xíu ở đây là chúng ta sẽ có 10 ở đây chúng ta sẽ có 10 node 10 cái neuron thì tương ứng bias của mình nó cũng sẽ có 10 cái giá trị mình sẽ có 10 cái giá trị cho cái layer thứ ở giữa còn ở cái lớp đầu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 13,
      "start_timestamp": "0:08:22",
      "end_timestamp": "0:09:05"
    }
  },
  {
    "page_content": "trị cho cái layer thứ ở giữa còn ở cái lớp đầu tiên thì chúng ta chỉ có duy nhất một cái bias thôi trong lớp đầu tiên chúng ta sẽ có duy nhất một cái bias còn sang cái lớp tiếp theo thì chúng ta sẽ có đến 10 cái bias và tương tự như vậy thì cho cái hệ số thì chúng ta cũng sẽ có các cái layer mỗi layer chúng ta sẽ có các cái hệ số cho các cái trọng số của mạng neuron và ở đây thì chúng ta có sẵn một cái chương trình để giúp chúng ta trực quan hóa cái mạng các cái kết quả trọng số của cái mạng ha",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 14,
      "start_timestamp": "0:09:00",
      "end_timestamp": "0:09:33"
    }
  },
  {
    "page_content": "cái mạng các cái kết quả trọng số của cái mạng ha chúng ta thấy là với mỗi một cái neuron với mỗi một neuron nó bản chất chính là một cái Logistic Regression mà một cái Logistic Regression thì bản chất Nó là một cái lá cắt một cái đường phân lớp như vậy một cái neuron trong 10 cái neuron của mình nó sẽ là một cái đường thẳng như thế này và chúng ta có 10 neuron thì chúng ta sẽ có 10 cái đoạn thẳng và chúng ta thấy rằng mỗi một cái neuron sẽ là một cái weak classifier tức là một cái bộ phân lớp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 15,
      "start_timestamp": "0:09:28",
      "end_timestamp": "0:10:07"
    }
  },
  {
    "page_content": "cái weak classifier tức là một cái bộ phân lớp yếu với một cái phân lớp màu xanh lá như thế này chúng ta thấy nó sẽ phân ra là màu xanh dương là những cái điểm nào mà nằm về phía bên đây là chắc chắn là xanh dương còn những điểm nào mà nằm ở phía ngược lại thì không chắc do đó thì nó sẽ phải phối hợp nhiều cái neuron lại với nhau và khi chúng ta thấy khi phối hợp nhiều cái neuron lại với nhau thì nó đã giúp cho chúng ta tách được các cái điểm màu xanh và màu đỏ ra những cái điểm nào màu đỏ thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 16,
      "start_timestamp": "0:10:02",
      "end_timestamp": "0:10:40"
    }
  },
  {
    "page_content": "xanh và màu đỏ ra những cái điểm nào màu đỏ thì nó sẽ nằm bên trong và những cái điểm màu xanh thì nó sẽ nằm bên ngoài như đây như vậy thì đây chính là một cái cách để cho chúng ta có thể trực quan hóa mạng Neural Network với các cái node ẩn của mình mỗi một cái neuron trong cái lớp ẩn này sẽ được à vẽ lên dưới dạng là một cái đường thẳng và một cái mạng Neural Network thì nó sẽ là tổ hợp của nhiều cái neuron tương ứng là tổ hợp của nhiều các cái weak classifier các cái bộ phân lớp yếu nhiều bộ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 17,
      "start_timestamp": "0:10:35",
      "end_timestamp": "0:11:10"
    }
  },
  {
    "page_content": "weak classifier các cái bộ phân lớp yếu nhiều bộ phân lớp yếu nó sẽ tạo ra thành một cái bộ phân lớp mạnh và như vậy thì nó đã giúp cho chúng ta chia tách hai cái tập điểm màu xanh và màu đỏ này ra làm hai phần thì trên đây chính là cái minh họa cho việc à tạo ra các cái bộ phân lớp trên dữ liệu phi tuyến tính sử dụng cả Logistic Regression và Neural Network đối với Logistic Regression thì chúng ta đối với dữ liệu phi tuyến thì chúng ta phải là chịu khó chúng ta làm thêm cái bước feature",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 18,
      "start_timestamp": "0:11:05",
      "end_timestamp": "0:11:18"
    }
  },
  {
    "page_content": "là chịu khó chúng ta làm thêm cái bước feature engineering mà để đạt được cái feature engineering này mà tốt thì chúng ta sẽ phải có cái kinh nghiệm có cái kiến thức về cái dữ liệu của mình Mình biết cái dữ liệu của mình nó có cái phụ thuộc như thế nào để mà mình chọn cái đặc trưng mới cho nó phù hợp Còn trong trường hợp mà chúng ta không có được cái đặc trưng mới xin lỗi chúng ta không biết được cái thông tin không có được cái tri thức thì chúng ta sẽ sử dụng mạng Neural Network và mạng Neural",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ta sẽ sử dụng mạng Neural Network và mạng Neural Network này thì một cách tổng quát nó có thể là có nhiều layer ẩn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7w5EiDHtIII",
      "filename": "7w5EiDHtIII",
      "title": "[CS116 - Buổi 8] Part 9",
      "chunk_id": 20,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Kỹ thuật cơ bản của Ensemble Model Voting, trung bình, Weighted Averaging, Voting, bầu cử Đây là một mô hình thường được sử dụng cho bài toán phân loại. Bài toán phân loại là gì? Tức là output của mình trả ra là một giá trị thuộc một tập. Tập này là tập rời rạc nào đấy? Các giá trị C1, C2 cho đến CN này là các giá trị rời rạc và không có tính thứ tự. và chúng ta sẽ phải chọn ra là cái output y của mình, nó sẽ là c1, c2 hay là cn và như vậy thì cái cơ chế này, cái cơ chế chọn lựa ra một cái giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:01:11"
    }
  },
  {
    "page_content": "cơ chế này, cái cơ chế chọn lựa ra một cái giá trị dự đoán cuối cùng, cái giá trị output cuối cùng nó giống giống như là một cái cơ chế trong bầu cử một người đứng đầu vậy đó Mỗi một cái model là một cái đóng vai trò như là một cái cử tri Ví dụ như ở đây chúng ta có 4 model, thì model 1, model 2, model 3, model 4 chính là những cái cử tri đi bầu Và cái quyết định cuối cùng, cái quyết định cuối cùng, tức là cái output này của mình Nó sẽ thuộc về số đông Nó sẽ thuộc về số đông Ví dụ, model số 1",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:01:02",
      "end_timestamp": "0:01:55"
    }
  },
  {
    "page_content": "số đông Nó sẽ thuộc về số đông Ví dụ, model số 1 đưa ra dự đoán cho phân lớp 1, model số 2 đưa ra dự đoán 2, model số 3 đưa ra kết quả dự đoán 1, model số 4 đưa ra kết quả dự đoán 4. Vì vậy, tổng hợp lại, chúng ta thấy là với cái nhãn số 1 thì chúng ta có tất cả là 3 phiếu bầu Với cái nhãn số 2 thì chúng ta đã có 1 phiếu bầu Vì vậy, theo nguyên tắc về số đông thì rõ ràng kết quả của mình, output cuối cùng của mình chính là 1 Tại vì số phiếu bầu của nó là cao nhất Thì đây chính là ý tưởng của kỹ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:40",
      "end_timestamp": "0:02:40"
    }
  },
  {
    "page_content": "nó là cao nhất Thì đây chính là ý tưởng của kỹ thuật Voting Và đây cũng là một trong những kỹ thuật rất là đơn giản, dễ hiểu và dễ đo lường Tiếp theo là kỹ thuật về Averaging, tức là cộng trung bình Trung bình cộng Thì nói về Averaging, tức là chúng ta sẽ tính tổng sau đó chúng ta sẽ chia cho số cái phần tử, số cái kết quả mình dự đoán, tham gia vào. Thì cái kết quả mà cộng trung bình này thì thông thường nó dùng cho bài toán hồi quy. Bài toán hồi quy nghĩa là sao? là cái giá trị output của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:02:27",
      "end_timestamp": "0:03:17"
    }
  },
  {
    "page_content": "hồi quy nghĩa là sao? là cái giá trị output của mình thì nó sẽ thuộc một cái giá trị liên tục. Nó sẽ thuộc một giá trị liên tục. Và chính vì nó thuộc cái giá trị liên tục và có tính thứ tự. Nó sẽ có tính thứ tự. Nên khi chúng ta cộng trung bình, thì cái giá trị output của mình nó mới là một cái giá trị hợp lệ. Nghĩa là sao? Từng cái phần tử trong cái model của mình là một cái giá trị liên tục. khi chúng ta cộng lại và chia cho bình quân ra thì nó cũng sẽ ra một cái giá trị liên tục và thì nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:03:12",
      "end_timestamp": "0:03:54"
    }
  },
  {
    "page_content": "nó cũng sẽ ra một cái giá trị liên tục và thì nó mới có nghĩa còn cái việc mà nếu chúng ta áp dụng cho cái bài toán là phân lớp ví dụ như là C1, C2, Cn thì rõ ràng là các cái giá trị này là các giá trị không có tính chất và không có tính thứ tự cái thứ 2 đó là nó cũng có khả năng nó không phải là những cái giá trị mang tính chất số học để mà có thể cộng trung bình cộng được có thể thôi, tại vì người ta cũng có cách để có thể mã hóa được chuyện đấy Tuy nhiên thì về mặt ý nghĩa đó là không có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:03:47",
      "end_timestamp": "0:04:26"
    }
  },
  {
    "page_content": "đấy Tuy nhiên thì về mặt ý nghĩa đó là không có tính thứ tự mà khi không có tính thứ tự thì khi chúng ta cộng trung bình cộng thì nó sẽ tạo ra những cái giá trị mà không chắc là nó có nằm trong tập này hay không Đó là lý do tại sao kỹ thuật Averaging thì thông thường lại được áp dụng cho bài toán hồi quy chứ không có áp dụng cho bài toán về phân lớp Ý tưởng của Averaging là chúng ta sẽ tính trung bình cộng kết quả của mô hình để tổng hợp lại. Ví dụ, với một input đầu vào, chúng ta đưa qua mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:04:23",
      "end_timestamp": "0:05:07"
    }
  },
  {
    "page_content": "Ví dụ, với một input đầu vào, chúng ta đưa qua mô hình số 1, thì nó sẽ trả ra kết quả 120, 1 cái kết quả dự đoán là 120 đưa vào model số 2 thì nó ra kết quả dự đoán là 90 đưa vào cái model số 3 thì nó ra kết quả là 100 và đưa vào model số 4 nó ra là 110 thì tính trung bình cộng 4 cái kết quả này lại thì chúng ta sẽ ra được cái output của mình đó chính là 105 thì cái ý tưởng của kỹ thuật Averaging này cũng rất là đơn giản và dễ hiểu Tuy nhiên, chúng ta sẽ có thêm một cái vấn đề đó là nếu như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:05:04",
      "end_timestamp": "0:05:47"
    }
  },
  {
    "page_content": "chúng ta sẽ có thêm một cái vấn đề đó là nếu như trong kỹ thuật về Averaging, thì các mô hình đóng vai trò là như nhau, tức là trọng số là như nhau. Nhưng thực tế thì có phải là như vậy không? Các mô hình số 1, số 2, số 3 cho đến mô hình số n, thì nó sẽ là những cái thể loại mô hình khác nhau. Có những cái ưu, khuyết điểm khác nhau dẫn đến là cái việc cộng trung bình thì nó sẽ không công bằng lắm. Do đó Weighted Averaging là một cái kỹ thuật mà có cái hiệu quả và trọng số khác nhau. Tức là mỗi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:05:39",
      "end_timestamp": "0:06:28"
    }
  },
  {
    "page_content": "có cái hiệu quả và trọng số khác nhau. Tức là mỗi một cái mô hình mà có cái sự hiệu quả hay trọng số khác nhau thì nó nên có cái trọng số khác nhau. Tức là không có đánh đồng, chúng ta sẽ không cân bằng tất cả các mô hình này Mỗi mô hình nên có một trọng số Và trọng số này lấy đâu ra? Trọng số này lấy đâu ra? Một cách đơn giản và dễ hiểu nhất là chúng ta sẽ lấy từng mô hình này Chúng ta đi test, test trên, hay là chúng ta sẽ đi thử nghiệm Nhưng từ test sẽ dễ nhầm lẫn với tập kiểm thử Chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:06:22",
      "end_timestamp": "0:07:25"
    }
  },
  {
    "page_content": "từ test sẽ dễ nhầm lẫn với tập kiểm thử Chúng ta sẽ đi thử, chúng ta sẽ đi dự đoán trên tập validation Rồi sau đó chúng ta sẽ đi tính accuracy cho model số 1 Tương tự như vậy thì chúng ta cũng lấy model số 2 đi dự đoán trên tập validation và sẽ tính accuracy số 2 Rồi, accuracy số 3 và accuracy số n. Dựa trên các accuracy 1, 2, 3 cho đến N này, chúng ta sẽ đi tính trọng số tương ứng cho nó. Ở đây có nhiều kỹ thuật, ví dụ như W1 này cũng có thể được tính bằng công thức accuracy của phương pháp số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:07:12",
      "end_timestamp": "0:08:02"
    }
  },
  {
    "page_content": "tính bằng công thức accuracy của phương pháp số 1 chia cho tổng tất cả các accuracy. Với Y chạy từ 1 cho đến N thì đây là một kỹ thuật đơn giản nhất. Nó vừa có thể đưa ra được trọng số mà nó tỷ lệ thuận với độ chính xác của mô hình của mình. Đồng thời nó đáp ứng được điều kiện đó là các mô hình của mình sẽ không có đánh đồng vai trò như nhau mà nó sẽ phải có sự liên kết về mặt trọng số để phụ thuộc vào tính hiệu quả của mình thay vì là đánh đồng, đấy trung bình cộng. Vậy thì cuối cùng, chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:08:00",
      "end_timestamp": "0:08:34"
    }
  },
  {
    "page_content": "đấy trung bình cộng. Vậy thì cuối cùng, chúng ta sẽ ra được giá trị output dựa trên giá trị trung bình cộng có trọng số này. Thực sự mà nói thì phương pháp Averaging này, kỹ thuật Averaging này thì nó cũng đơn giản. Tuy nhiên, đâu đó nó vẫn sẽ có một điểm yếu đó chính là chúng ta sẽ phải tính trọng số này. làm sao chúng ta có được cái trọng số này một cách phù hợp và trong nhiều tình huống nếu như chúng ta sử dụng cái độ chính xác trên tập train hoặc tập validation này thì đâu đó nó sẽ tốn chi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:08:30",
      "end_timestamp": "0:08:51"
    }
  },
  {
    "page_content": "hoặc tập validation này thì đâu đó nó sẽ tốn chi phí để tính toán rồi nó sẽ tốn chi phí tính toán ra các cái bộ trọng số này thì đó chính là 3 cái kỹ thuật chính nhất cho hướng tiếp cận là các phương pháp ensemble cơ bản bao gồm là Voting, trung bình và trung bình trọng số, Weighted Averaging.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=7yfomH4cNXI",
      "filename": "7yfomH4cNXI",
      "title": "[CS116 - Buổi 13] Part 2",
      "chunk_id": 13,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "đầu tiên đó là chúng ta sẽ đến với mô hình hồi quy tuyến tính và sau đó thì chúng ta sẽ tìm hiểu về một số cái khái niệm như là bias và variance. Đây là hai cái khái niệm khá là quan trọng trong cái mô hình máy học để chúng ta có thể hiểu được về cái tính chất của cái mô hình máy học sau khi đã huấn luyện cũng như là hiểu được các cái hiện tượng có khả năng xảy ra trong cái quá trình huấn luyện như là hiện tượng overfitting quá khớp hoặc là underfitting chưa khớp với lại cái dữ liệu của mình. Và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:35"
    }
  },
  {
    "page_content": "chưa khớp với lại cái dữ liệu của mình. Và sau đó thì chúng ta sẽ tìm hiểu đến các cái biến thể của mô hình hồi quy tuyến tính như là mô hình Lasso, mô hình Ridge và mô hình Elastic Net. Và cuối cùng đó là chúng ta sẽ tìm hiểu về một số cái mô hình giúp giải quyết các cái bài toán trong đó cái dữ liệu đầu ra y nó có mối quan hệ phi tuyến tính với lại cái dữ liệu X thì cái phi tuyến tính nó thể hiện ở cái hàm f. này thì mô hình hồi quy tuyến tính, tên tiếng Anh đó là Linear Regression. Thì giả",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:30",
      "end_timestamp": "0:01:09"
    }
  },
  {
    "page_content": "tên tiếng Anh đó là Linear Regression. Thì giả sử như chúng ta có một cái mô hình trong thực tế là y = beta_0 cộng beta_1 x và ở đây chúng ta sẽ cộng thêm một cái đại lượng epsilon nữa thì đây chính là cái nhiễu. Cái nhiễu này nó sẽ gây ra là do đâu? Nhiễu này có thể là gây ra do quá trình chúng ta lấy mẫu, do sai số trong quá trình chúng ta tính toán các cái giá trị x và giá trị y. Và thông thường thì cái nhiễu epsilon này nó sẽ tuân theo cái phân bố đó là phân bố chuẩn. Đó, rồi thì đây là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:02",
      "end_timestamp": "0:01:49"
    }
  },
  {
    "page_content": "bố đó là phân bố chuẩn. Đó, rồi thì đây là cái mô hình thực tế và chúng ta luôn luôn mong muốn sẽ phải tìm cho ra được cái giá trị cái beta này. Một số bạn sẽ nói rằng là cái mô hình tuyến tính mà hồi xưa các bạn học được á nó không phải là công thức này và công thức của nó là y = ax cộng b đó, đúng không? Thì trong đó b là cái thành phần nó gọi là bias. Thì trong trường hợp này chúng ta phải hiểu là x của mình á đó chính là một cái vector bao gồm cái thành phần một là thành phần bias và x ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:01:42",
      "end_timestamp": "0:02:27"
    }
  },
  {
    "page_content": "gồm cái thành phần một là thành phần bias và x ở đây chính là cái giá trị của mình, cái giá trị mà biến số đầu vào của mình. Rồi, beta tương tự như vậy, beta nó sẽ là một cặp các cái giá trị bao gồm là beta 0 và beta 1. Thì đây là hai cái tham số của cái cái mô hình hồi quy tuyến tính trong thực tế. Và khi chúng ta tiến hành dự đoán thì chúng ta sẽ phải ước lượng, chúng ta sẽ phải ước lượng cái hàm mô hình là y mũ là bằng beta mũ nhân với x. Đó, thì giả sử như cái trục này chúng ta sẽ có là x",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:20",
      "end_timestamp": "0:03:07"
    }
  },
  {
    "page_content": "thì giả sử như cái trục này chúng ta sẽ có là x và trục này là y. x là cái biến số đầu vào và y chính là cái biến số đầu ra. Và từng cái điểm dữ liệu ở đây chính là các cái giá trị thực tế từ cái mô hình thực tế và đây sẽ là ký hiệu là y_i, trong đó y_i chính là cái chỉ số, chính là cái chỉ số của mẫu dữ liệu. Và hàm mô hình dự đoán của mình thì nó sẽ chính là cái đường thẳng này. Đó chính là cái đường thẳng này. Và mình luôn mong muốn tìm cái mô hình dự đoán làm sao đó để cho cái giá trị dự",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:03:01",
      "end_timestamp": "0:03:48"
    }
  },
  {
    "page_content": "mô hình dự đoán làm sao đó để cho cái giá trị dự đoán y_i mũ nó xấp xỉ với lại cái giá trị y_i này. Thì ở đây là y mũ và tại cái vị trí x_i ở đây ha, thì chúng ta giống nó lên chạm vào cái hàm mô hình dự đoán, chạm vào cái đường mô hình dự đoán thì cái giá trị ở đây sẽ là cái giá trị dự đoán y mũ. Và khi dự đoán thì ai cũng mong muốn là giá trị dự đoán xấp xỉ với lại giá trị thực tế. Thì khi đó chúng ta sẽ có một cái độ đo về mặt khoảng cách và độ đo ở đây chúng ta sẽ sử dụng đó là độ đo Mean",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:03:41",
      "end_timestamp": "0:04:24"
    }
  },
  {
    "page_content": "độ đo ở đây chúng ta sẽ sử dụng đó là độ đo Mean Squared Error (MSE). Và MSE là bằng L(beta). Thì beta của mình chính là cái hàm mô hình của mình ở đây. Và nó sẽ là bằng tổng các cái sai số bình phương là y_i trừ cho y_i mũ tất cả bình. Và khi triển khai cái y mũ này ra thì nó chính là beta x_i. Và khi chúng ta viết gọn nó lại thì nó sẽ có cái dạng công thức là y trừ cho beta X. Trong đó X của mình sẽ là bao gồm một tập hợp các cái mẫu dữ liệu huấn luyện của mình là 1 x_1, 1 x_2 vân vân cho đến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:04:18",
      "end_timestamp": "0:05:09"
    }
  },
  {
    "page_content": "luyện của mình là 1 x_1, 1 x_2 vân vân cho đến 1 x_n với N là số mẫu dữ liệu huấn luyện của mình. Và y trong trường hợp này chính là tập hợp các cái giá trị là y_1, y_2 cho đến y_n. Thì đây là chuỗi các cái giá trị dự đoán. Và cái công thức cho cái hàm độ lỗi của mình lúc này, MSE của mình á đó chính là bình phương, tức là trị tuyệt đối bình phương của y trừ cho beta X, trong đó mỗi beta X của mình nó chính là giá trị dự đoán và y của mình chính là cái giá trị mong muốn mình đạt được. Thì để",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:05:02",
      "end_timestamp": "0:05:49"
    }
  },
  {
    "page_content": "là cái giá trị mong muốn mình đạt được. Thì để huấn luyện cái mô hình hồi quy tuyến tính này thì chúng ta sẽ có hai giải pháp. Giải pháp đầu tiên đó là chúng ta dùng cái công thức normal equation đó là cái phương trình chuẩn và ước lượng được cái tham số của mình. Thì điều kiện để cho cái MSE hoặc là cái L(beta) này mà nhỏ nhất thì cái nghiệm của nó đó chính là công thức như sau: đó là beta mũ là bằng X chuyển vị nhân X rồi nghịch đảo nhân với lại X chuyển vị nhân y. Thì chúng ta lưu ý là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:05:44",
      "end_timestamp": "0:06:22"
    }
  },
  {
    "page_content": "lại X chuyển vị nhân y. Thì chúng ta lưu ý là cái thao tác này đâu đó nó sẽ không phải lúc nào chúng ta cũng có thể thực hiện được thao tác nghịch đảo này. X của mình nó phải thỏa mãn một số cái tính chất thì khi đó thì nó mới có thể tính được cái nghịch đảo. Tuy nhiên, đại đa số trong các cái trường hợp thì chúng ta đều có thể thực hiện được cái thao tác này. Và trong trường hợp mà X của mình nó là một cái ma trận lớn. Ma trận này lớn có thể là theo bề ngang và bề dọc. Lớn theo bề ngang có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 10,
      "start_timestamp": "0:06:17",
      "end_timestamp": "0:07:02"
    }
  },
  {
    "page_content": "là theo bề ngang và bề dọc. Lớn theo bề ngang có nghĩa là chúng ta sẽ có N lớn, tức là cái số mẫu dữ liệu của mình nó quá lớn. Còn theo bề dọc có nghĩa là cái số feature của mình, cái x_i này của mình là nó thuộc R^D. Ví dụ như ở đây là R^D với D là một con số lớn. Đầu vào của mình nó sẽ là một vector 1000 chiều, ví dụ vậy. Thì khi đó là cái ma trận X sẽ rất là lớn. Và khi đó thì cái thao tác mà tính toán này nó sẽ rất là tốn chi phí, rất là tốn chi phí. Do đó thì chúng ta có thể thực hiện bằng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 11,
      "start_timestamp": "0:06:55",
      "end_timestamp": "0:07:41"
    }
  },
  {
    "page_content": "chi phí. Do đó thì chúng ta có thể thực hiện bằng cách đó là chúng ta sẽ dùng thuật toán gradient để cập nhật. Và cái công thức cập nhật của mình đó là beta mũ bằng beta mũ trừ cho alpha nhân cho đạo hàm hay ký hiệu bằng nabla. Nabla chính là đạo hàm mà cho vector của cái hàm L(beta mũ). Và đương nhiên để cập nhật này thì ban đầu beta của mình nó sẽ là bằng một cái vector ngẫu nhiên, một cái vector ngẫu nhiên. Và chúng ta sẽ thực hiện lặp đi lặp lại cái cập nhật này cho đến khi nào mà nabla của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 12,
      "start_timestamp": "0:07:37",
      "end_timestamp": "0:08:16"
    }
  },
  {
    "page_content": "lại cái cập nhật này cho đến khi nào mà nabla của L(beta mũ) và cái giá trị này thì nó bé hơn một cái ngưỡng epsilon thì khi đó thuật toán của chúng ta sẽ kết thúc. Và toàn bộ cái quá trình huấn luyện mô hình máy học này thì đều được cài đặt ở trong cái thư viện Scikit-learn với cái module nó có tên là Linear Regression. Thì trong cái mô hình Linear Regression này thì chúng ta đã được cung cấp các cái phương thức ví dụ như là phương thức về phương thức `fit` là để huấn luyện và phương thức",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 13,
      "start_timestamp": "0:08:10",
      "end_timestamp": "0:08:49"
    }
  },
  {
    "page_content": "phương thức `fit` là để huấn luyện và phương thức `predict` để phục vụ cho quá trình chúng ta inference, thực hiện cho cái quá trình là test với một cái mẫu riêng biệt mới. Đó, thì đã được cài đặt, cái module này đã được cài đặt trong Scikit-learn. Và mô hình hồi quy tuyến tính thì nó sẽ có những cái ưu điểm nhất định. Ví dụ: thuật toán đơn giản, dễ hiểu và dễ cài đặt, và phù hợp với lại những cái dữ liệu có cái mối quan hệ tuyến tính đúng như cái tên gọi của nó. Thì cái tính tuyến tính này nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 14,
      "start_timestamp": "0:08:46",
      "end_timestamp": "0:09:21"
    }
  },
  {
    "page_content": "tên gọi của nó. Thì cái tính tuyến tính này nó thể hiện ở chỗ đó là đồng biến hoặc là nghịch biến. Nghĩa là sao? Nếu x của mình tăng, y cùng tăng, à, x của mình mà tăng thì y của mình nó cũng sẽ cùng tăng theo. Hoặc là nghịch biến, tức là x của mình nó giảm thì y của mình nó sẽ cùng giảm. Thì đó là cái mối quan hệ tuyến tính. Nhược điểm thì mô hình này nó sẽ không hiệu quả đối với lại những cái dữ liệu mà có mối quan hệ phức tạp. Thì cái khái niệm phức tạp ở đây đó chính là khái niệm về phi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 15,
      "start_timestamp": "0:09:15",
      "end_timestamp": "0:09:37"
    }
  },
  {
    "page_content": "niệm phức tạp ở đây đó chính là khái niệm về phi tuyến, tức là biến y của mình nó sẽ phụ thuộc một cách phi tuyến tính với lại cái biến x đầu vào. Và nó rất dễ bị ảnh hưởng bởi dữ liệu nhiễu. Nghĩa là sao? Nếu như chúng ta có các cái điểm dữ liệu ở đây rồi và cái đường của mình lẽ ra là như thế này, thì khi có cái sự xuất hiện của một cái điểm nhiễu ở đây thì nó sẽ kéo cái mô hình của mình bị lật về hướng này. Nó sẽ kéo cái mô hình của mình nó bị lệch về hướng này. Thì đây chính là cái ảnh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 16,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "nó bị lệch về hướng này. Thì đây chính là cái ảnh hưởng của cái điểm nhiễu hay còn gọi là outlier.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=A6vU3I4CK6U",
      "filename": "A6vU3I4CK6U",
      "title": "[CS116 - Buổi 7] Part 1",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và cuối cùng đó chính là Edge prediction nếu như trước đây mô hình tính toán sẵn rồi mô hình đặt ở trong cái server và mô hình đặt riêng ở một cái con server khác đúng không thì bây giờ mô hình của mình sẽ được đặt trên chính cái máy của người dùng cuối đặt trên chính cái máy của client đó thì cái Edge này á Nó có thể được hiểu đó là cái thiết bị biên cái tên tiếng Việt của mình đó chính là thiết bị biên hoặc là cái thiết bị của người dùng thì làm sao chúng ta có thể đưa cái mô hình của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:56"
    }
  },
  {
    "page_content": "làm sao chúng ta có thể đưa cái mô hình của mình chạy được trên các cái thiết bị này thì ở đây chúng ta sẽ gửi cái trọng số của mô hình chúng ta sẽ gửi cái trọng số của mình và đương nhiên đây là trọng số này là đã được huấn luyện cái trọng số này là đã được huấn luyện và chúng ta sẽ copy cái mô hình cái trọng số này lên trên các cái thiết bị Edge device rồi sau đó chúng ta load cái mô hình này lên và thực thi cái việc dự đoán trực tiếp ở trên cái máy trạm client này thì đây chính là cái Edge",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 1,
      "start_timestamp": "0:00:51",
      "end_timestamp": "0:01:38"
    }
  },
  {
    "page_content": "cái máy trạm client này thì đây chính là cái Edge và với cái cách làm này thì gần như không có độ trễ tức là chúng ta sẽ khi chúng ta có cái nhu cầu cần phải dự đoán đúng không cần phải gọi cái mô hình để dự đoán thì nó sẽ lập tức nó sẽ phản hồi ngay lưu ý là ở cái khái niệm độ trễ Ở đây nó không phải là cái tốc độ của mô hình nó không phải là cái tốc độ của mô hình mà cái độ trễ ở đây là cái thời gian kể từ khi chúng ta có cái yêu cầu mô hình thực thi và sau khi mô hình thực thi xong thì chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 2,
      "start_timestamp": "0:01:33",
      "end_timestamp": "0:02:15"
    }
  },
  {
    "page_content": "thi và sau khi mô hình thực thi xong thì chúng ta sẽ trả cái kết quả về thì cái độ trễ ở đây là cái thời gian không liên quan đến cái quá trình mà mô hình nó dự đoán nó chỉ liên quan đến cái thời gian trung chuyển dữ liệu từ lúc mà người dùng có yêu cầu đưa đến cho mô hình để mô hình biết là chúng ta đang có nhu cầu à cần phải thực thi dự đoán rồi sau khi có kết quả xong chúng ta trả cái kết quả đó về cho người dùng thì đó là cái khoảng thời gian độ trễ nó không liên quan đến cái thời gian mà",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 3,
      "start_timestamp": "0:02:11",
      "end_timestamp": "0:02:49"
    }
  },
  {
    "page_content": "độ trễ nó không liên quan đến cái thời gian mà mô hình của mình nó chạy bên dưới cái thuật toán hơn và với cái cách làm này thì độ trễ nó rất là thấp Edge prediction độ trễ thấp gần như là tức thì và nó cũng có xuất phát từ cái nguyên nhân đó là chúng ta không cần có cái mạng internet tại vì khi mô hình của mình được đặt trên chính cái thiết bị biên thì nó sẽ thực thi ngay trên chính mô hình đó nó không cần phải trung chuyển qua internet để nhờ một cái bên thứ ba tính toán thì không cần phải có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 4,
      "start_timestamp": "0:02:45",
      "end_timestamp": "0:03:18"
    }
  },
  {
    "page_content": "cái bên thứ ba tính toán thì không cần phải có Internet và như vậy thì nó đã tiết giảm được một cái yêu cầu một trong những cái yêu cầu rất là quan trọng đó là cái tính kết nối của cái máy trạm với lại cái môi trường internet không phải lúc nào máy trạm của mình cũng có khả năng kết nối được với Internet và một cái ưu điểm nữa của cái phương pháp Edge prediction này chính là bảo mật dữ liệu tại vì cái máy client của mình nó sẽ không có chuyển qua cái internet đúng để đưa về một cái con server",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 5,
      "start_timestamp": "0:03:14",
      "end_timestamp": "0:04:07"
    }
  },
  {
    "page_content": "cái internet đúng để đưa về một cái con server thì nếu như chúng ta đưa cái dữ liệu đưa cái dữ liệu qua mạng internet thì ở đây nó có thể bị đúng không là bị tấn công để cái dữ liệu mà chúng ta đưa lên mạng internet Nó sẽ bị trong cái quá trình trung chuyển nó sẽ bị bên thứ ba có thể khai thác có thể là lấy cắp cái dữ liệu đó chúng ta không đang nói về cái lỗi tại server nha Tức là trong cái quá trình Cái đường truyền đến được cái server này thì sẽ có một cái bên thứ ba có thể lấy cắp được đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 6,
      "start_timestamp": "0:04:01",
      "end_timestamp": "0:04:36"
    }
  },
  {
    "page_content": "sẽ có một cái bên thứ ba có thể lấy cắp được đó thì chúng ta đang thực hiện cái dữ liệu của mình gọi là trực tiếp trên chính cái thiết bị biên thì không thể chúng ta bị mất cái dữ liệu đó được đó thì dữ liệu nó không đưa ra khỏi cái máy trạm nên chúng ta cái khả năng mà chúng ta mất dữ liệu nó sẽ thấp hơn nhiều và cái khuyết điểm của cái phương pháp này đó chính là cái tài nguyên tính toán của máy trạm thì thường là nó sẽ yếu hơn so với các cái con server đúng không Tại vì các cái máy trạm nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 7,
      "start_timestamp": "0:04:29",
      "end_timestamp": "0:05:13"
    }
  },
  {
    "page_content": "con server đúng không Tại vì các cái máy trạm nó được sinh ra là để phục vụ đa chức năng lấy ví dụ như cái điện thoại của mình đúng không hoặc là cái Laptop của mình thì nó được sinh ra là phục vụ cho đa chức năng chứ không phải là thực gọi là tối ưu cho các cái mô hình máy học nó thực hiện cái việc là lưu trữ tính toán hiển thị hình ảnh tính toán những cái phép toán cơ bản xử lý những cái lưu trữ rồi hiển thị cơ bản chứ nó không có thực hiện các cái tính toán số học trên các cái mô hình máy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 8,
      "start_timestamp": "0:05:07",
      "end_timestamp": "0:05:48"
    }
  },
  {
    "page_content": "các cái tính toán số học trên các cái mô hình máy học do đó thì cái việc tối ưu của nó cho cái mô hình máy học là nó không hiệu quả đó thì yếu tố đầu tiên đó là cái tài nguyên máy trạm nó sẽ có hạn ở đây hiểu ý đó là nó sẽ không có phù hợp với các cái mô hình máy học và các cái thư viện và framework của máy trạm thì thường không có đủ cái tính năng tại vì các cái máy trạm của mình thường là những cái máy mà phục vụ đa năng nên nó sẽ không được cài sẵn trước những cái phần mềm hoặc là cài trước",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 9,
      "start_timestamp": "0:05:43",
      "end_timestamp": "0:06:25"
    }
  },
  {
    "page_content": "sẵn trước những cái phần mềm hoặc là cài trước những cái thư viện để cho cái mô hình máy học của mình có thể thực thi được rồi nó sẽ khó có thể cập nhật được mô hình bây giờ Nếu không có mạng internet thì làm sao chúng ta có thể đưa làm sao chúng ta có thể đưa cái mô hình của mình về trên cái máy trạm này đúng không Thì nó khó cập nhật rồi nó sẽ khó theo dõi và debug Ví dụ như khi người dùng người ta sử dụng và người ta báo là Ừ tôi đang dùng cái tính năng này nhưng mà nó bị lỗi Và bây giờ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 10,
      "start_timestamp": "0:06:20",
      "end_timestamp": "0:06:58"
    }
  },
  {
    "page_content": "cái tính năng này nhưng mà nó bị lỗi Và bây giờ chúng ta cũng không biết là làm sao để kiểm soát được tại vì chúng ta không được phép can thiệp vào bên trong cái log của các cái máy tính máy trạm Ví dụ nếu chúng ta đang thực hiện ở trên server của mình đúng không Thì chúng ta hoàn toàn có thể can thiệp vô cái log của cái server của mình để mà mình xem coi nguyên nhân ở đâu lỗi của nó là cái gì thì từ đó là mình sẽ biết được cái cách để mà debug cái cách để mà khắc phục đó còn ở đây là khi thực",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 11,
      "start_timestamp": "0:06:53",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "cái cách để mà khắc phục đó còn ở đây là khi thực hiện trên máy trạm Chúng ta không có quyền để truy xuất vô các cái file trong máy của người dùng hoặc là can thiệp vào bên trong các cái chỉ số hoặc là can thiệp vào bên trong các cái thông tin lưu trữ của người dùng nên chúng ta rất khó trong cái việc theo dõi và chẩn đoán lỗi thì đó chính là những cái ưu và khuyết điểm cho cái phương pháp tiếp cận đó là Edge prediction hay là dự đoán trên máy trạm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=aevGbPj9y6k",
      "filename": "aevGbPj9y6k",
      "title": "[CS116 - Buổi 14] Part 2_3",
      "chunk_id": 12,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Hôm nay chúng ta sẽ cùng đến với bài học tiếp theo đó là các cái mô hình học không giám sát và tên tiếng Anh của cái mô hình học không giám sát đó chính là un- supervised learning. Đầu tiên thì chúng ta sẽ cùng giới thiệu về các khái niệm trong học không giám sát và sau đó thì chúng ta sẽ cùng tìm hiểu chi tiết hơn các cái thuật toán trong học không giám sát bao gồm các cái mô hình gom nhóm hoặc là clustering, mô hình giảm chiều dữ liệu hay là dimension reduction, tức là giảm chiều dữ liệu. Đối",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:53"
    }
  },
  {
    "page_content": "reduction, tức là giảm chiều dữ liệu. Đối với cái khái niệm về học không giám sát thì đây là một cái nhánh trong cái lĩnh vực về Machine Learning và nó có cái nhiệm vụ, hai cái nhiệm vụ chính. Nhiệm vụ đầu tiên đó là nó học ra được cái phân bố của cái dữ liệu và tiếp theo sau khi chúng ta đã học được cái phân bố của dữ liệu rồi thì nó sẽ tiến hành là biểu diễn cái dữ liệu của mình sao cho nó hiệu quả hơn. Thì chi tiết về các cái khái niệm học phân bố dữ liệu hoặc là biểu diễn dữ liệu hiệu quả",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:47",
      "end_timestamp": "0:01:23"
    }
  },
  {
    "page_content": "bố dữ liệu hoặc là biểu diễn dữ liệu hiệu quả hơn thì chúng ta sẽ được trình bày trong những cái phần tiếp theo và đầu vào cho cái thuật toán học không giám sát của mình đó chính là chúng ta chỉ cần có cái dữ liệu X. Nếu như các cái mô hình dự đoán chúng ta sẽ phải có cái dữ liệu X và cái giá trị Y là cái giá trị dự đoán với cái đặc trưng đầu vào là X thì đây chính là học có giám sát hay còn gọi là supervised learning. Rồi thì đối với học không giám sát thì chúng ta sẽ không cần có cái thông",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:16",
      "end_timestamp": "0:02:08"
    }
  },
  {
    "page_content": "giám sát thì chúng ta sẽ không cần có cái thông tin đầu ra này mà chúng ta chỉ cần có cái dữ kiện đầu vào này thôi. Và như đã đề cập ở trước, tức là chúng ta sẽ tìm cách để gom nhóm các cái dữ liệu này sao cho nó đưa vô những cái phân bố, chúng ta sẽ gom nhóm dựa trên cái phân bố của cái dữ liệu. Và khi chúng ta đã phân nhóm xong rồi thì chúng ta có thể chuyển đổi cái X này thành một cái dạng thức là X' và cái X' này thì nó là một cái dạng biểu diễn mới, nó hiệu quả hơn so với X. Thì đó chính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:02:03",
      "end_timestamp": "0:02:38"
    }
  },
  {
    "page_content": "diễn mới, nó hiệu quả hơn so với X. Thì đó chính là cái mục tiêu của học không giám sát. Và dưới đây đó là một số cái chủ đề chính trong học giám sát bao gồm là chủ đề gom nhóm dữ liệu hay còn gọi là clustering và giảm chiều dữ liệu đó là dimension reduction. Đây là hai chủ đề chính được thảo luận rất là nhiều trong các cái mô hình học không giám sát. Đầu tiên chúng ta sẽ nói về cái khái niệm phân bố của dữ liệu, thế nào gọi là phân bố của dữ liệu thì chúng ta sẽ xét một cái ví dụ sau. Đầu tiên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:34",
      "end_timestamp": "0:03:25"
    }
  },
  {
    "page_content": "thì chúng ta sẽ xét một cái ví dụ sau. Đầu tiên đó là chúng ta có một cái câu hỏi là An có điểm trung bình môn học của bạn á là 8,8. Và câu hỏi đặt ra đó là điểm của bạn An sẽ được xếp vào loại là giỏi, khá hay là trung bình? Chắc hẳn đa số các bạn ở đây sẽ chọn cái đáp án của mình là giỏi. Tuy nhiên các bạn cần phải nhớ rằng chúng ta không biết trước điểm của bạn An là 8,8 là nó nằm trong cái khoảng giá trị từ bao nhiêu nhỏ nhất là bao nhiêu cho đến cao nhất là bao nhiêu. Muốn biết điểm của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:03:20",
      "end_timestamp": "0:03:57"
    }
  },
  {
    "page_content": "cho đến cao nhất là bao nhiêu. Muốn biết điểm của bạn An được xếp loại là giỏi, khá hay là Trung bình thì chúng ta phải đưa cái điểm của bạn An vào trong cái bố cục trong cái phân bố tổng thể của điểm của các cái bạn khác trong lớp thì khi đó chúng ta mới biết trước là mới biết được là bạn An là giỏi, khá hay là trung bình. Ví dụ với cái phân bố điểm như sau thì chúng ta thấy là điểm của bạn An là nằm ở cái nửa sau đúng không, nằm ở nửa sau của cái phân bố. Như vậy điểm của bạn An là thuộc loại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:03:52",
      "end_timestamp": "0:04:42"
    }
  },
  {
    "page_content": "phân bố. Như vậy điểm của bạn An là thuộc loại giỏi hoặc là xuất sắc. Và với cái phân bố điểm như thế này thì chúng ta hiểu rằng là à, có lẽ đây là cái điểm ở trong lớp của bạn. Điểm của bạn là nhỏ nhất của mình là 0 và lớn nhất của mình là 10. Tuy nhiên nếu như chúng ta nhìn ở trong một cái phân bố khác đúng không, điểm 8,8 của bạn nằm ở đây, tức là nó nằm ở khoảng giữa của cái phân bố điểm thì rõ ràng là với cái phân bố này, với cái phân bố này điểm của bạn An sẽ nằm ở mức độ là trung bình so",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:04:36",
      "end_timestamp": "0:05:18"
    }
  },
  {
    "page_content": "điểm của bạn An sẽ nằm ở mức độ là trung bình so với mặt bằng chung của lớp. Và chúng ta thấy rằng là có rất nhiều cái cuộc thi hoặc là có rất nhiều những cái chương trình mà điểm của mình nó sẽ không từ 0 cho đến 10 mà nó có thể là từ 0 cho đến 20. Do đó thì với cái điểm 8,8 của bạn thì nó sẽ nằm ở cái mức độ là ở giữa, tức là mức độ trung bình. Và cuối cùng đó là nếu như cái phân bố điểm của bạn mà nằm ở đây thì rõ ràng là điểm của bạn nằm trong cái nhóm gọi là kém hoặc là yếu. Thì có một số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:05:10",
      "end_timestamp": "0:05:57"
    }
  },
  {
    "page_content": "cái nhóm gọi là kém hoặc là yếu. Thì có một số cái chương trình học điểm của mình nó trải dài từ 0 cho đến 100, tức là cái hệ 100 điểm. Như vậy thì cái điểm 8,8 này là một cái điểm rất là thấp. Như vậy thì cả ba cái phân bố ở đây thì nó tượng trưng cho ba cái tình huống, nó sẽ tượng trưng cho ba cái tình huống và nó chỉ có thể tính toán ra được, vẽ ra được các cái biểu đồ này khi chúng ta đặt cái điểm của bạn An với những cái bạn khác ở trong cùng một cái lớp học thì khi đó chúng ta mới có được",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:05:52",
      "end_timestamp": "0:06:31"
    }
  },
  {
    "page_content": "một cái lớp học thì khi đó chúng ta mới có được cái sự so sánh. Và cái biểu đồ này thì nó được gọi là phân bố của dữ liệu hoặc là một cái tên gọi khác đó là cái biểu đồ histogram. Tuy nhiên với cái biểu đồ histogram thì nó sẽ là ở dạng biểu đồ cột, còn ở đây là ở cái dạng đường liên tục nên mình sẽ gọi đó là phân bố của cái dữ liệu. Histogram chỉ là một cái trường hợp rời rạc của cái phân bố của dữ liệu thôi. Ví dụ như nếu chúng ta thay vì chúng ta vẽ cái đường liên tục như thế này, chúng ta vẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 10,
      "start_timestamp": "0:06:25",
      "end_timestamp": "0:07:10"
    }
  },
  {
    "page_content": "ta vẽ cái đường liên tục như thế này, chúng ta vẽ dưới dạng là biểu đồ cột thì khi đó là nó gọi là biểu đồ histogram đó. Thì ở cái dạng rời rạc như thế này. Và như vậy thì kết luận của chúng ta đó là chúng ta không thể biết được cái xếp loại của bạn An nếu như chúng ta không biết được cái phân bố của dữ liệu. Và như vậy thì cái khả năng biểu diễn dữ liệu này nó còn cho chúng ta thấy cái ẩn ý ở đằng phía sau đó là gì? Chúng ta xét đến một cái ví dụ tiếp theo: cho trước hai cái điểm môn Văn và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 11,
      "start_timestamp": "0:07:05",
      "end_timestamp": "0:07:41"
    }
  },
  {
    "page_content": "dụ tiếp theo: cho trước hai cái điểm môn Văn và môn Toán của các bạn trong lớp học và chúng ta sẽ phân loại học lực của từng bạn như thế nào? Thì giả sử như đây là cái thang điểm ha. Ví dụ như đây là điểm thấp nhất của mình là 0 và điểm cao nhất của mình là ví dụ như là 10. Tương tự như vậy điểm Văn thấp nhất là 0 và điểm cao nhất là 10. Thì chúng ta thấy rằng là ở đây những cái bạn, ba cái bạn này nè, có cái cùng một cái tính chất đó là điểm môn Toán và điểm môn Văn đều thấp. Thì điều đó có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 12,
      "start_timestamp": "0:07:36",
      "end_timestamp": "0:08:17"
    }
  },
  {
    "page_content": "môn Toán và điểm môn Văn đều thấp. Thì điều đó có nghĩa là gì? Tức là đây là những bạn có học lực rất là yếu đúng không? Điểm Toán và điểm Văn đều là thấp. Rồi đây là những cái tính chất của các cái bạn khác trong lớp. Ví dụ như nhóm các bạn ở đây. Đây là những bạn mà có điểm Văn rất là cao nhưng mà điểm Toán thì là thấp. Các bạn ở trong nhóm này thì là những bạn có điểm Toán và điểm Văn đều rất là cao. Thì hay nói cách khác đó là những bạn này là những bạn có cái thành tích học lực rất là xuất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 13,
      "start_timestamp": "0:08:13",
      "end_timestamp": "0:08:58"
    }
  },
  {
    "page_content": "những bạn có cái thành tích học lực rất là xuất sắc. Và ở đây là những bạn mà có điểm Toán rất là cao và điểm Văn thì lại rất là thấp. Thì đây là mình xếp vào loại trung bình. Còn nếu như hai cái trung bình này chúng ta ánh xạ nó sang cái cái khái niệm trong cái cuộc sống của mình á, khi mà chúng ta học ở chương trình cấp hai, cấp ba thì những bạn nằm ở đây chính là những bạn mà có học lực trung bình nhưng mà theo kiểu đó là học lệch. Các bạn ở đây sẽ là học lệch Toán. Còn các bạn ở đây là học",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 14,
      "start_timestamp": "0:08:52",
      "end_timestamp": "0:09:32"
    }
  },
  {
    "page_content": "đây sẽ là học lệch Toán. Còn các bạn ở đây là học lệch Văn. Như vậy thì chúng ta thấy là với cái điểm số của hai môn Toán và Văn, chúng ta đã có được bốn cụm. Mỗi cụm thì sẽ bao gồm các cái bạn có cùng một cái tính chất. Ví dụ ba bạn ở đây là ba bạn có cùng một tính chất đó là điểm Toán và Văn đều rất là thấp hay là những bạn có học lực rất là yếu. Những bạn ở đây đúng không, năm bạn ở đây thì đều có một chung một cái tính chất đó là điểm Toán và điểm Văn thì ở mức độ là cộng lại thì đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 15,
      "start_timestamp": "0:09:26",
      "end_timestamp": "0:10:05"
    }
  },
  {
    "page_content": "và điểm Văn thì ở mức độ là cộng lại thì đó là trung bình. Nhưng mà những bạn ở trong nhóm này thì thuộc xếp vào loại đó là học lệch Toán. Còn những bạn ở đây thì được xếp vào loại là học lệch Văn. Và cuối cùng đó là bốn cái bạn ở đây thì đều có chung một cái tính chất đó chính là học lực xuất sắc. Và như vậy thì thay vì chúng ta biểu diễn cái dữ liệu thô, thay vì chúng ta biểu diễn dữ liệu thô tức là bao gồm điểm Toán và Văn thì chúng ta chỉ cần lưu cái đặc trưng học lực của cái bạn đó thôi.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 16,
      "start_timestamp": "0:10:01",
      "end_timestamp": "0:10:44"
    }
  },
  {
    "page_content": "lưu cái đặc trưng học lực của cái bạn đó thôi. Chúng ta chỉ cần lưu đây là bạn xuất sắc, đây là bạn yếu, đây là bạn Trung Bình học lệch Văn, đây là bạn Trung Bình mà học lệch Toán thì điều đó là nó để góp phần giúp cho chúng ta giảm chiều của dữ liệu. Bình thường chúng ta phải lưu hai trường là Toán và Văn. Bây giờ chúng ta chỉ cần lưu đúng một trường thôi đó là học lực của bạn. Bạn đó là yếu, là trung bình lệch Toán hay là trung bình lệch Văn hay là bạn đó xuất sắc. Như vậy thì từ hai trường,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 17,
      "start_timestamp": "0:10:35",
      "end_timestamp": "0:11:17"
    }
  },
  {
    "page_content": "là bạn đó xuất sắc. Như vậy thì từ hai trường, chúng ta giảm xuống dưới còn một trường, tức là chúng ta đã giảm được 50% số thuộc tính. Khi giảm từ hai cái feature, từ hai feature xuống còn một feature thì đã giảm cho mình được là 50% cái số lượng thuộc tính rồi. Và giảm chiều dữ liệu sẽ được thảo luận chi tiết hơn ở trong cái phần tiếp theo. Và tiếp theo đó là nó đã thể hiện được cái đặc trưng theo nhóm của mẫu dữ liệu. Nghĩa là sao? Tất cả những bạn mà nằm trong cùng một cái nhóm như thế này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 18,
      "start_timestamp": "0:11:13",
      "end_timestamp": "0:11:56"
    }
  },
  {
    "page_content": "bạn mà nằm trong cùng một cái nhóm như thế này thì nó sẽ có cùng một cái đặc trưng với nhau. Thì như đã nói ở trước đây thì ba cái bạn này là đều có chung một cái đặc trưng đó là yếu cả về Toán và Văn. Trong khi đó những bạn ở đây thì đều là có chung một cái đặc trưng theo nhóm đó là những bạn có thành tích xuất sắc. Và lưu ý đó là ở đây các cái khái niệm yếu, xuất sắc, học lệch Toán, học lệch Văn đó là những cái khái niệm mà chúng ta ánh xạ từ cái môi trường bên ngoài, từ cái kinh nghiệm trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 19,
      "start_timestamp": "0:01:51",
      "end_timestamp": "0:12:29"
    }
  },
  {
    "page_content": "môi trường bên ngoài, từ cái kinh nghiệm trong thực tế của chúng ta để chúng ta đặt tên cho nó là yếu, xuất sắc hay là trung bình. Còn thực tế thì các cái thuật toán gom nhóm nó không quan tâm đến cái tên gọi đó. Mỗi nhóm này nó chỉ được gán bởi một cái cluster ID, một cái định danh thôi. Ví dụ, trung bình thì nó sẽ được gán là 3, yếu thì nó sẽ gán là 2, trung bình bên đây thì nó sẽ gán là 1 và xuất sắc ở bên đây thì nó sẽ gán là 0. Và lưu ý là các cái con số 0, 1, 2, 3 này nó không có thể hiện",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 20,
      "start_timestamp": "0:02:24",
      "end_timestamp": "0:12:40"
    }
  },
  {
    "page_content": "cái con số 0, 1, 2, 3 này nó không có thể hiện cái sự tăng giảm, cái sự gọi là tính thứ tự ở đây. Thôi có thể là các cái nhãn này có thể đặt là nhãn bất kỳ và không nhất thiết là nhãn nào, ví dụ những bạn xuất sắc thì là cái ID của mình nó sẽ cao hơn, không nhất thiết như vậy. Ở đây là các cái giá trị nó được gán ngẫu nhiên. Như vậy thì với cái thuật toán gom cụm nó sẽ được gán các cái điểm, các cái đặc trưng mà có cùng một cái tính chất vào cùng một cái ID. Và việc đặt tên cho nó thì đó là dựa",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "một cái ID. Và việc đặt tên cho nó thì đó là dựa trên kinh nghiệm của chúng ta, chứ nó không phải là thuật toán, nó sẽ không có cần quan tâm và nó cũng không cần biết đó là những bạn đó trong cái cuộc sống thực của mình thì bạn đó gọi tên như thế nào.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ANx3DPwHEGI",
      "filename": "ANx3DPwHEGI",
      "title": "[CS116 - Buổi 6] Part 1",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ tìm hiểu về một cái thư viện cũng rất là nổi tiếng của Python trong cái việc trực quan hóa dữ liệu đó chính là thư viện Matplotlib thì đây thư viện Matplotlib là một trong những cái thư viện mà trực quan hóa phổ biến trong cái ngôn ngữ Python và một số cái hàm cơ bản một số cái hàm cơ bản trong Matplotlib đầu tiên đó là cái hàm plot. Hàm plot này có thể giúp cho chúng ta vẽ các cái đồ thị Ờ dưới dạng đường ví dụ như là dạng như thế này đó thì chúng ta sẽ có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Apb2REK9UqA",
      "filename": "Apb2REK9UqA",
      "title": "[CS116 - Buổi 2] Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:42"
    }
  },
  {
    "page_content": "dụ như là dạng như thế này đó thì chúng ta sẽ có hai cái chiều là chiều X và chiều Y trong đó x là cái biến độc lập và y là cái biến phụ thuộc của mình đó thì nếu như biến độc lập và biến phụ thuộc chúng ta sẽ vẽ các cái điểm rồi sau đó chúng ta sẽ nối các cái điểm lại với nhau đó thì đây là cái kiểu vẽ đầu tiên vẽ dưới dạng đường vẽ dưới dạng Line dạng đường cái kiểu thứ hai đó là chúng ta có thể vẽ dưới dạng là điểm rời rạc hay còn gọi là scatter đó thì thay vì chúng ta nối lại thì chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Apb2REK9UqA",
      "filename": "Apb2REK9UqA",
      "title": "[CS116 - Buổi 2] Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:36",
      "end_timestamp": "0:01:25"
    }
  },
  {
    "page_content": "đó thì thay vì chúng ta nối lại thì chúng ta có thể vẽ dưới dạng là như thế này đó thì các cái điểm này sẽ là các cái điểm rời rạc và chúng ta có hỗ trợ cái hàm là subplot tức là trong trường hợp chúng ta không muốn vẽ Ờ các cái ảnh các cái biểu đồ này là các cái biểu đồ rời rạc mà chúng ta muốn đưa nó về cùng một cái cụm biểu diễn để chi để sau này chúng ta có thể dễ dàng so sánh được các cái biểu đồ với nhau đó thì ở đây chúng ta sẽ vẽ như thế này chúng ta sẽ chia cái màn hình vẽ của mình ra",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Apb2REK9UqA",
      "filename": "Apb2REK9UqA",
      "title": "[CS116 - Buổi 2] Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:18",
      "end_timestamp": "0:02:01"
    }
  },
  {
    "page_content": "này chúng ta sẽ chia cái màn hình vẽ của mình ra thành à Nhiều cái vùng nhỏ hơn nó gọi là subplot và sau đó chúng ta có thể vẽ các cái loại biểu đồ ở trên đây ở đây chúng ta có thể vẽ là biểu đồ tròn biểu đồ pie hoặc là chúng ta sẽ vẽ biểu đồ boxplot à Xin lỗi chúng ta có thể biểu đồ dạng đường như thế này hoặc là chúng ta có thể vẽ biểu đồ dưới dạng histogram đó rồi thì đây là subplot và các cái loại biểu đồ trong thư viện Matplotlib có hỗ trợ thì vì cái thư viện Matplotlib là một trong những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Apb2REK9UqA",
      "filename": "Apb2REK9UqA",
      "title": "[CS116 - Buổi 2] Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:01:56",
      "end_timestamp": "0:02:55"
    }
  },
  {
    "page_content": "thì vì cái thư viện Matplotlib là một trong những cái thư viện mà rất là nổi tiếng và được sử dụng rất là nhiều trong cộng đồng khoa học nên gần như tất cả mọi cái loại biểu đồ nào mà chúng ta có nhu cầu cần thiết để trình diễn dữ liệu thì các cái biểu đồ đó đều có trong thư viện Matplotlib Ví dụ như ở đây là những cái biểu đồ tròn biểu đồ đường biểu đồ histogram Vân Vân biểu đồ dạng scatter thì đều có hỗ trợ trong cái thư viện à Matplotlib và cuối cùng thì chúng ta sẽ cùng tìm hiểu về à các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Apb2REK9UqA",
      "filename": "Apb2REK9UqA",
      "title": "[CS116 - Buổi 2] Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:50",
      "end_timestamp": "0:03:30"
    }
  },
  {
    "page_content": "cuối cùng thì chúng ta sẽ cùng tìm hiểu về à các cái phương thức để giúp cho chúng ta có thể đọc load và hiển thị một cái ảnh trên thư viện Matplotlib như thế nào thì toàn bộ những cái thao tác xử lý này đều có ở bên trong cái file Colab ở dưới đây và chúng ta có thể thực hành về sau",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Apb2REK9UqA",
      "filename": "Apb2REK9UqA",
      "title": "[CS116 - Buổi 2] Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:03:26",
      "end_timestamp": "0:03:33"
    }
  },
  {
    "page_content": "đầu tiên đó là chúng ta sẽ cùng tìm hiểu về một cái thư viện của Python được sử dụng rất là phổ biến hiện nay đó chính là thư viện NumPy thì đây là một trong những cái thư viện phổ biến nè Có hiệu năng rất là cao tốc độ tính toán rất là nhanh và có hỗ trợ rất nhiều những cái thao tác tính toán trên các cái đối tượng đại số ví dụ như là giá trị scalar giá trị vô hướng vector array một chiều hay còn gọi là array một chiều rồi ma trận hai chiều và tensor có số chiều từ ba trở lên thì để sử dụng thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:50"
    }
  },
  {
    "page_content": "có số chiều từ ba trở lên thì để sử dụng thì chúng ta sẽ import thư viện là numpy as np thì np này chính là alias là viết tắt của cái chữ N và P ở đây thì sau này các cái hàm mà mình sử dụng á thì chúng ta chỉ cần gõ là np. Cái gì đó thì như vậy thì nó sẽ tiết kiệm được cho chúng ta trong cái gọi là câu lệnh của mình nó gọn gàng hơn à các cái bước đầu tiên khi chúng ta tìm hiểu đó chính là khởi tạo một cái array như thế nào thì nếu như trong kiểu dữ liệu list các cái phần tử của mình Nó sẽ phải",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:00:45",
      "end_timestamp": "0:01:27"
    }
  },
  {
    "page_content": "dữ liệu list các cái phần tử của mình Nó sẽ phải có cùng à khác kiểu dữ liệu cũng được đúng không Nhưng mà trong NumPy array thì các cái phần tử của mình nó phải là những phần tử cùng kiểu dữ liệu thì ví dụ chúng ta thấy đây là chúng ta đang khởi tạo ra một cái array một chiều với các cái con số nguyên có giá trị lần lượt là 1 2 3 đó thì khi chúng ta tạo ra thì chúng ta sẽ có một cái NumPy array có giá trị như thế này rồi và điều gì xảy ra nếu như chúng ta đang xen giữa kiểu số nguyên và kiểu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:01:20",
      "end_timestamp": "0:02:03"
    }
  },
  {
    "page_content": "như chúng ta đang xen giữa kiểu số nguyên và kiểu chuỗi đúng không Thì chúng ta cũng thử chạy thì nó sẽ tự động nó sẽ tự động ép các cái phần tử 1 và 3 về cái kiểu dữ liệu tổng quát hơn đó là kiểu chuỗi thì trong các cái kiểu dữ liệu của mình thì kiểu chuỗi là tổng quát nhất tại vì nó có khả năng biểu diễn được số nguyên, số thực hoặc là boolean đúng không Nhưng mà ở đây trong ví dụ này thì chúng ta sử dụng đó là array của mình là kiểu số nguyên rồi thì ở đây chúng ta sẽ có in ra một số cái hàm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:01:57",
      "end_timestamp": "0:02:40"
    }
  },
  {
    "page_content": "rồi thì ở đây chúng ta sẽ có in ra một số cái hàm phụ trợ Ví dụ như kiểu dữ liệu của a là gì rồi kích thước theo từng chiều hoặc là dimension của a là gì thì chúng ta sẽ có lệnh là a.shape rồi chúng ta muốn truy xuất đến ba cái phần tử đầu tiên thì cái cách thức chúng ta truy xuất cũng giống như trong list là a mở ngoặc vuông 0 a mở ngoặc vuông 1 và a[2] và cái cách thức chúng ta thay đổi cái giá trị của mình cũng tương tự như list đó là A0 là bằng 5 rồi và a sau khi chúng ta cập nhật xong thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:02:35",
      "end_timestamp": "0:03:16"
    }
  },
  {
    "page_content": "5 rồi và a sau khi chúng ta cập nhật xong thì chúng ta sẽ có giá trị như thế nào thì chúng ta sẽ in ra màn hình thì ở đây ta sẽ in ra ha A của mình type của nó đó là kiểu NumPy array ndarray thì nd là dimension tức là số chiều và array là kiểu array và trong cái ví dụ này thì chúng ta thấy đây là một vector nên số chiều của mình nó chỉ có một chiều. Đây là một cái tuple chỉ có một phần tử và à số phần tử Cho cái chiều duy nhất này á đó là 3 nó có ba phần tử thì đây sẽ là 3 rồi khi chúng ta truy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:03:11",
      "end_timestamp": "0:03:59"
    }
  },
  {
    "page_content": "ba phần tử thì đây sẽ là 3 rồi khi chúng ta truy xuất đến các cái phần tử ba phần tử đầu tiên thì nó sẽ là 1 2 và 3 kết quả ở đây và chúng ta muốn thay đổi cái con số 1 này cái phần tử đầu tiên này bằng con số 5 thì chúng ta sẽ để là A0 = 5 và Kết quả nó sẽ ra là 5 2 3 rồi 5 2 3 à tương tự như vậy khi chúng ta muốn làm việc trên kiểu ma trận thì số chiều của mình trong trường hợp này nó sẽ có hai chiều là bề cao và bề ngang chiều dọc và chiều ngang thì ở đây chúng ta sẽ tạo ra là mở ngoặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:03:52",
      "end_timestamp": "0:04:38"
    }
  },
  {
    "page_content": "ngang thì ở đây chúng ta sẽ tạo ra là mở ngoặc vuông, mở một cái list là 1 2 rồi một cái list là 34 rồi đóng ngoặc vuông rồi và chúng ta muốn tạo ra một cái tensor với số chiều là ba chiều thì ở đây chúng ta sẽ có là mở ngoặc vuông của một cái ma trận tiếp tục theo là một cái ma trận khác thì ở trên là ma trận 12, 34 34 và tiếp theo sẽ là ma trận 56 78 56 78 thì nó sẽ nối hai cái thằng này lại với nhau để tạo ra thành một cái array có ba chiều thì ở đây là 1 2 3 4 rồi và shape của B nó sẽ là 2",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:04:31",
      "end_timestamp": "0:05:24"
    }
  },
  {
    "page_content": "ở đây là 1 2 3 4 rồi và shape của B nó sẽ là 2 x 2 tại vì có hai chiều theo chiều cao hai phần tử theo chiều cao và hai phần tử theo chiều ngang tức là xin lỗi ở đây chính là hai hàng và hai cột à tương tự như vậy c ma trận c thì sẽ là cái tensor có kích thước là 2 x 2 x 2 tức là hai hàng hai cột và hai chiều theo độ sâu rồi và chúng ta muốn khởi tạo những cái giá trị cho trước thì chúng ta có NumPy có hỗ trợ các cái hàm các cái phương thức như là ones, zeros và random thì np.ones truyền vào số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:05:20",
      "end_timestamp": "0:06:04"
    }
  },
  {
    "page_content": "ones, zeros và random thì np.ones truyền vào số 3 thì nó sẽ tạo ra một cái vectơ có ba chiều và gồm toàn các số 1 np.zeros((3,2)) thì nó sẽ tạo ra là một cái array hai chiều với kích thước là 3 x 2 Tức là nó sẽ có ba hàng và hai cột à tương tự như vậy khi chúng ta truyền vô cái tuple là 32 thì tuple là gì thì đây là một cái dạng dữ liệu của Python ha thì cái đầu tiên là số phần tử theo cái chiều thứ nhất là ba số phần tử theo chiều thứ hai là 2 tức là ba hàng hai cột thì tương tự như vậy cho",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:05:59",
      "end_timestamp": "0:06:49"
    }
  },
  {
    "page_content": "2 tức là ba hàng hai cột thì tương tự như vậy cho các cái phương thức là np.zeros và np.random đối với tensor thì chúng ta sẽ có tuple gồm nhiều giá trị hơn ở đây là có ba chiều trong đó Chiều thứ nhất có bốn phần tử chiều thứ hai có ba phần tử và chiều thứ ba có hai phần tử chiều đầu tiên là bốn hàng chiều thứ hai đó là ba cột và 2 là hai độ sâu rồi thì ở đây chúng ta cũng sẽ có các cái câu lệnh tương ứng ha Đây là array gồm toàn số 0 có hai chiều và mỗi chiều sẽ có hai phần tử đây là hai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:06:41",
      "end_timestamp": "0:07:33"
    }
  },
  {
    "page_content": "chiều và mỗi chiều sẽ có hai phần tử đây là hai chiều và chiều thứ nhất có một phần tử tức là có một hàng có hai cột Rồi np.full thì là khởi tạo gồm toàn cái giá trị là một cái hằng số thì ở đây chúng ta sẽ để vào là số 7 tức là chúng ta đang muốn tạo ra một cái ma trận kích thước là 2 x 2 gồm toàn bộ là số 7 đó 7 7 77 một cách tương đương đó là chúng ta có thể dùng np.ones Sau đó chúng ta nhân với 7 thì cái cách này nó thực hiện cái thao tác nhân trên một cái array thì cái này chúng ta sẽ được",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:07:26",
      "end_timestamp": "0:08:08"
    }
  },
  {
    "page_content": "trên một cái array thì cái này chúng ta sẽ được tìm hiểu trong những cái phần sau đó nó cũng tạo ra gồm toàn các số 7 np.eye là một cái ma trận đơn vị trong đó các cái phần tử trên đường chéo chính nó sẽ bằng 1 còn các phần tử còn lại bằng 0 đó thì trên đường chéo chính nè Ở đây chúng ta sẽ truyền số 4 4 tức là bốn hàng và bốn cột số phần tử trên đường chéo chính là 1 và các phần tử còn lại bằng 0 np.random sẽ khởi tạo ngẫu nhiên các số từ 0 cho đến 1 rồi thì trên đây là một số các cái phương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:08:03",
      "end_timestamp": "0:08:51"
    }
  },
  {
    "page_content": "đến 1 rồi thì trên đây là một số các cái phương thức khởi tạo cho các cái vector rồi ma trận array ngoài ra thì chúng ta muốn khởi tạo các cái giá trị theo một cái gọi là theo một cái quy luật cấp số cộng thì ở đây chúng ta sẽ có các cái phương thức là np.arange Ví dụ ở đây chúng ta thấy là arange(10, 50, 5) thì hàm ý đó là chúng ta tạo ra một cái array gồm một chuỗi bắt đầu từ số 10 và đến dưới à lưu ý là nó sẽ không chạm đến cái số 50 Tức là nó sẽ chạm đến tối đa là 49 thôi với cái bước nhảy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 13,
      "start_timestamp": "0:08:45",
      "end_timestamp": "0:09:37"
    }
  },
  {
    "page_content": "sẽ chạm đến tối đa là 49 thôi với cái bước nhảy của các phần tử của mình là 5 như vậy Ở đây kết quả của mình nó sẽ ra là 10 15 20 25 30 cho đến 45 nó sẽ không chạm đến cái phần tử 50 ha rồi nó sẽ có một cái phương thức khác để khởi tạo một cấp số nhân nó sẽ khởi tạo ra một cái chuỗi các cái giá trị được chia đều đó là linspace. np.linspace là viết tắt của linear Space à số đầu tiên là số bắt đầu và số 1 ở đây là số Kết thúc và num bằng 11 ở đây hàm ý đó là từ 0 cho đến 1 mình sẽ lấy mẫu là 11",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 14,
      "start_timestamp": "0:09:30",
      "end_timestamp": "0:10:23"
    }
  },
  {
    "page_content": "hàm ý đó là từ 0 cho đến 1 mình sẽ lấy mẫu là 11 phần tử Ví dụ ở đây chúng ta để là 5 thì từ 0 cho đến 1 mà chúng ta lấy mẫu 5 phần tử thì nó sẽ là 0 0.25 0.5 và 0.75 rồi 1 ở đây chúng ta để là bằng 11 thì nó sẽ là 0 0.1 0.2 cho đến 0.9 và 1 thì tất cả phần tử ở đây số lượng phần tử ở đây sẽ là 11 phần tử nó sẽ được rải đều lấy đều trong cái khoảng là từ 0 cho đến 1 nếu như chúng ta muốn cái mảng cái hoặc là cái array của mình tạo ra nó được tạo bởi từ các cái array trước đó thì có hai cái thao",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 15,
      "start_timestamp": "0:10:18",
      "end_timestamp": "0:11:06"
    }
  },
  {
    "page_content": "bởi từ các cái array trước đó thì có hai cái thao tác phổ biến đó là chồng chúng ta sẽ chồng theo chiều vertical tức là theo chiều dọc hoặc là chồng theo chiều ngang là horizontal stack thì vertical stack thì 1 2 3 nó sẽ chồng lên trên là 4 56 do đó kết quả sẽ ra là một cái ma trận một cái array là dạng ma trận 1 2 3 chồng lên trên là 456 còn ở đây chúng ta thấy là A của mình là gồm 7, 8, 9 tức là các cái giá trị là 7 8 9 và 4 5 6 thì 7, 8, 9 mà ráp với lại 456 theo chiều cột thì nó sẽ ra là 7",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 16,
      "start_timestamp": "0:11:02",
      "end_timestamp": "0:11:46"
    }
  },
  {
    "page_content": "ráp với lại 456 theo chiều cột thì nó sẽ ra là 7 74 85 và 96 nó sẽ ráp hai cái cột này lại với nhau Nó sẽ ráp hai cái cột này lại với nhau rồi Tiếp theo thì chúng ta sẽ tìm hiểu về cái cơ chế indexing thì tương tự như là các cái kiểu dữ liệu cơ bản trong Python thì NumPy cũng sẽ có các cái cơ chế đánh chỉ mục giống như vậy cái giống đầu tiên đó là chỉ mục của mình sẽ đánh từ 0 0 1 2 nó sẽ đánh từ 0 cái việc truy xuất các phần tử của mình thì chúng ta sẽ truyền vô các cái chỉ số dạng đơn hoặc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 17,
      "start_timestamp": "0:11:38",
      "end_timestamp": "0:12:25"
    }
  },
  {
    "page_content": "ta sẽ truyền vô các cái chỉ số dạng đơn hoặc là dạng một cái lát cắt thì cái lát cắt này á hay còn gọi là slice này thì cho chúng ta các cái giá trị là từ bao nhiêu đến bao nhiêu ví dụ 0:2 thì hàm ý đó là chạy từ 0 cho đến cái phần tử trước cái phần tử số 2 đó là số 1 như vậy là data[0:2] tức là lấy ra hai phần tử đầu tiên là chỉ số 0 và 1 ở đây tương ứng là hai giá trị là 1 và 2 data[1:] thì cái dấu hai chấm này ngay phía sau hai chấm chúng ta không thấy nó điền cái giá trị gì đúng không Tức",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 18,
      "start_timestamp": "0:12:18",
      "end_timestamp": "0:13:21"
    }
  },
  {
    "page_content": "không thấy nó điền cái giá trị gì đúng không Tức là hàm ý là đi lấy hết từ 1 trở đi thì từ 1 trở đi Tức là bao gồm 2 và 3 2 và 3 tương tự như vậy cho ma trận thì ở đây là nếu như chúng ta chỉ truyền data[0,1] tức là chúng ta lấy hàng số 0 và cột số 1 rồi nếu như chúng ta truyền vô là data[1:3, :] Chúng ta không có cái dấu phẩy ở đây để cho biết cái cột là gì thì hàm ý cột của mình sẽ là lấy hết rồi Như vậy Ở đây chúng ta sẽ lấy là hàng từ 1 cho đến trước số 3 tức là hàng 1 hàng 2 cột thì sẽ lấy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 19,
      "start_timestamp": "0:13:11",
      "end_timestamp": "0:14:01"
    }
  },
  {
    "page_content": "trước số 3 tức là hàng 1 hàng 2 cột thì sẽ lấy hết tất cả các cột tức là giá trị của cái mảng con của mình lấy ra là 34 56 data[:, 0:2] tức là lấy hai dòng đầu tiên hai dòng đầu tiên và cột sẽ lấy cột 0 như vậy là cái mảng con mình lấy ra sẽ là 1 và 3 rồi Ở đây là một cái ví dụ ha A gốc của mình sẽ là 1 2 3 4 5 6 7 8 9 10 11 12 và b là bằng a[0:2, 1:3] có nghĩa là gì Là hai hàng đầu tiên từ đầu cho đến trước số 2 tức là hai hàng đầu tiên rồi cột sẽ lấy là cột 1 cho đến trước số 3 tức là cột 1",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 20,
      "start_timestamp": "0:13:58",
      "end_timestamp": "0:14:48"
    }
  },
  {
    "page_content": "sẽ lấy là cột 1 cho đến trước số 3 tức là cột 1 cột 2 0 1 nè 1 2 như vậy là nó sẽ lấy ra hai cái phần tử này xin lỗi lấy hai cái cột này như vậy nó sẽ là 23 và 67 như vậy Đáp số của B của mình nó sẽ là 2367 và chúng ta có một cái lưu ý đó là khi chúng ta gán b là bằng a[0:2, 1:3] thì b là tham chiếu chứ không phải là b nó đang tạo ra một cái đối tượng mới có cái giá trị là 2 3 và 67 B ở đây nó đang tham chiếu trực tiếp vô cái phần tử này trực tiếp vô cái ma trận con này do đó thì nếu như đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 21,
      "start_timestamp": "0:14:40",
      "end_timestamp": "0:15:25"
    }
  },
  {
    "page_content": "tiếp vô cái ma trận con này do đó thì nếu như đây chúng ta B để cập nhật là B[0,0] là bằng 77 thì hàm ý đó là cái phần tử [0,0] là phần tử này nè đúng không phần tử [0,0] là phần tử này số 2 này sẽ được thay bằng số 77 rồi Dạ sẽ thay số 2 sẽ được thay bằng số 77 A[0,1] ban đầu là phần tử này giá trị của nó là 2 nhưng khi chúng ta lấy B cập nhật mới là B[0,0] bằng 77 á thì A ở đây chúng ta in lại A[0,1] một lần nữa thì số của mình nó không còn là số 2 nữa mà là số 77 ở đây thì chúng ta sửa số 7",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 22,
      "start_timestamp": "0:15:19",
      "end_timestamp": "0:16:03"
    }
  },
  {
    "page_content": "số 2 nữa mà là số 77 ở đây thì chúng ta sửa số 7 à Xin lỗi ở đây chúng ta sửa là trên cái biến là biến B Nhưng thực tế là nó đang thay đổi trên cái cái mảng cái array A của mình thì ở đây chúng ta sẽ in ra là toàn bộ cái A của mình ha thì chúng ta thấy bình thường ở đây là có số 2 nè bây giờ nó đã chuyển sang là thành số 77 rồi rồi và chú ý là trong một số trường hợp thì chúng ta có thể giảm chiều của array khi tạo ra cái lát cắt thì ở đây chúng ta sẽ có một cái ví dụ ha chúng ta khởi tạo ra",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 23,
      "start_timestamp": "0:15:57",
      "end_timestamp": "0:16:38"
    }
  },
  {
    "page_content": "ta sẽ có một cái ví dụ ha chúng ta khởi tạo ra một cái mảng A có hai chiều A có hai chiều và chiều đầu tiên là có ba dòng chiều thứ hai là có bốn Cột rồi thì chúng ta sẽ thấy là có ba cái cách thức để lấy ra cái dòng thứ hai cùng là cái nội dung dòng thứ hai nhưng chúng ta có ba cách row_r1 chúng ta để là A[1, :] chấm tức là lấy dòng số 1 dòng số 1 và cột thì là lấy hết nhưng cũng như vậy chúng ta để là row R2 và cái chỉ số dòng của mình là từ 1 cho đến 2 thì cái sự khác biệt giữa cái cách ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 24,
      "start_timestamp": "0:16:32",
      "end_timestamp": "0:17:20"
    }
  },
  {
    "page_content": "1 cho đến 2 thì cái sự khác biệt giữa cái cách ở dưới đây với cái cách ở đây cái cách ở trên nó sẽ trả về cho mình một cái array có một chiều thôi Còn cái cách ở dưới là nó sẽ tạo ra cho mình một cái hai chiều Tại vì nó sẽ chiều đầu tiên là từ 1 cho đến 2 thì mặc dù từ 1 cho đến 2 là nó chỉ có một hàng nhưng mà vì cái chỉ thị là từ bao nhiêu đến bao nhiêu Nên nó đã đóng gói cái thằng này trong một cái array hai chiều tương tự như vậy chúng ta để là mở ngoặc vuông một Mặc dù trong cái list này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 25,
      "start_timestamp": "0:17:09",
      "end_timestamp": "0:18:04"
    }
  },
  {
    "page_content": "là mở ngoặc vuông một Mặc dù trong cái list này nó chỉ có một phần tử là cái hàng số 1 Nhưng cái việc chúng ta đưa nó vô cái list thì hàm ý cho cái thư viện nó biết rằng là ở đây chúng ta đang muốn tạo ra một array hai chiều Tuy nhiên hai chiều nhưng mà số phần tử trong cái chiều hàng của mình cái hàng của mình là chỉ có một phần tử Thôi thì hai cách đầu ha à Cách cách đầu tiên nè R1 nè Thì nó tạo ra cho chúng ta là một cái mảng một cái vector có kích thước là 5 678 nhưng mà nó chỉ có số chiều",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 26,
      "start_timestamp": "0:18:00",
      "end_timestamp": "0:18:59"
    }
  },
  {
    "page_content": "kích thước là 5 678 nhưng mà nó chỉ có số chiều của mình là 1 còn hai cái cách ở dưới thì nó đều tạo ra là 5 6 7 8 nhưng mà shape của nó là (1,4) tức là à hai chiều bao gồm là một hàng bốn cột thì tương tự như vậy Khi chúng ta làm việc trên cột rồi và trong cái cơ chế đánh chỉ mục của NumPy nó có một cái điểm đặc thù riêng biệt khác so với lại những cái kiểu dữ liệu như là list đó chính là chúng ta có thể đưa vô mảng số nguyên ở đây chúng ta sẽ có một cái array gồm là 12 2 3 4 56 rồi bây giờ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 27,
      "start_timestamp": "0:18:53",
      "end_timestamp": "0:19:41"
    }
  },
  {
    "page_content": "có một cái array gồm là 12 2 3 4 56 rồi bây giờ chúng ta thử ha truyền vô là a mở ngoặc vuông là một list là [0,1,2] và [0,1,0] thì hàm ý ở đây nó đang muốn trả về là một cái list nó trả về một cái array bao gồm các cái phần tử là 1, 5 và 7 thì cái cách ở trên đây nó tương đương với cái cách bên dưới đó là trả về một cái array bao gồm các phần tử là a[0,0] nè A[1,1] nè và a[2,0] rồi thì A gốc của mình là 1 2 3 4 5 6 và khi chúng ta muốn lấy là 00 tức là con số này 1 nè 1 1 nè tức là hàng 1 cột",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tức là con số này 1 nè 1 1 nè tức là hàng 1 cột 1 tức là con số 4 nè giá trị trả về ở đây 20 tức là hàng 2 cột 0 tức là con số 5 số 5 nè Vậy thì đây là cái cách thức để chỉ mục của mình đó là một cái mảng các cái số nguyên và chúng ta hoàn toàn làm tương tự ha các cái ví dụ ở đây thì B của mình là array là [0, 2, 0, 1] rồi chúng ta trả về là A = np.arange arrange của mình arange(4) á Tức là nó sẽ trả về một cái array gồm các con số là 0, 1, 2, 3. B của mình sẽ là [0, 2, 0, 1]. Như vậy kết quả",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "3. B của mình sẽ là [0, 2, 0, 1]. Như vậy kết quả của mình sẽ trả về là 1, 6, 7 và 11. Ví dụ: 00 thì tương ứng nó sẽ là con số 1 nó sẽ trả về đây 1 2 hàng 1 cột 2 tức là con số 6 số 6 20 tức là hàng 2 cột 0 tức là con số 7 và 3 1 tức là hàng 3 cột 1 tức là con số 11",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B1LCA6nxyCs",
      "filename": "B1LCA6nxyCs",
      "title": "[CS116 - Buổi 2] Part 4",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Cuối cùng thì chúng ta sẽ cùng đến tìm hiểu một số cái mô hình mà dữ liệu của mình nó có cái mối quan hệ phi tuyến tính thì chúng ta sẽ sử dụng những cái mô hình nào chúng ta sẽ xét cái ví dụ sau đây chúng ta có các cái điểm dữ liệu và cái đường đi của cái hàm dự đoán của mình á là nó sẽ không phải là một đường thẳng mà nó sẽ là ở một cái dạng Đường Cong Và ở đây chúng ta phỏng đoán chúng ta phỏng đoán rằng là ở đây nó có hai cái điểm cực tiểu một một điểm cực một điểm cực đại thì chúng ta đoán",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B5cpY9SY7CY",
      "filename": "B5cpY9SY7CY",
      "title": "[CS116 - Buổi 7] Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:36"
    }
  },
  {
    "page_content": "một điểm cực một điểm cực đại thì chúng ta đoán Đây là một cái hàm bậc ba đúng không Thì đối với cái dữ liệu của mình mà có cái mối quan hệ phi tuyến tính và chúng ta biết được cái 43.3 Nhưng cái cách này thì nó đã bỏ qua cái khoảng cách xa gần giữa cái điểm đặc trưng với các cái k cái láng giềng gần nhất này rồi do đó cái cách số hai đó là chúng ta có thể sử dụng một cái Công thức trung bình trọng số theo khoảng cách nghĩa là khoảng cách nào mà càng nhỏ thì trọng số sẽ càng lớn và khoảng cách",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B5cpY9SY7CY",
      "filename": "B5cpY9SY7CY",
      "title": "[CS116 - Buổi 7] Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:00:30",
      "end_timestamp": "0:04:20"
    }
  },
  {
    "page_content": "càng nhỏ thì trọng số sẽ càng lớn và khoảng cách nào càng lớn thì trọng số sẽ càng nhỏ như vậy là đây là hai cách để tính trung bình và ước đưa ra được cái ước lượng cái giá trị output cho cái đặc trưng đầu vào là tại đây thì cái mô hình K-Nearest Neighbor Đó là một cái mô hình mà nó gọi là học lười (lazy learning) Tại sao nó gọi là lazy learning tại vì cái mô hình này nó không thật sự mà nói nó không có học gì hết Nó không có tạo ra những cái tham số của mô hình ở đây nó chỉ có duy nhất một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B5cpY9SY7CY",
      "filename": "B5cpY9SY7CY",
      "title": "[CS116 - Buổi 7] Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:04:15",
      "end_timestamp": "0:05:02"
    }
  },
  {
    "page_content": "tham số của mô hình ở đây nó chỉ có duy nhất một cái siêu tham số là k láng giềng gần nhất này thôi còn nó không có cái tham số của mô hình và nó sẽ trông cậy hoàn toàn vô các cái mẫu dữ liệu của mình do đó cái K-Nearest Neighbor này nó sẽ rất là tốn tài nguyên khi chúng ta triển khai Tại vì sao chúng ta sẽ phải lưu trữ chúng ta sẽ phải lưu lại hết tất cả các cái dữ liệu trong cái dataset của mình để khi có một cái mẫu dữ liệu mới chúng ta sẽ làm thao tác lookup tra cứu cái điểm đặc trưng này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B5cpY9SY7CY",
      "filename": "B5cpY9SY7CY",
      "title": "[CS116 - Buổi 7] Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:04:56",
      "end_timestamp": "0:05:33"
    }
  },
  {
    "page_content": "thao tác lookup tra cứu cái điểm đặc trưng này so với lại các cái điểm đặc trưng trong cái tập dữ liệu huấn luyện xem cái đặc trưng nào là gần nhất thì chúng ta sẽ lấy ra và đó chính là cái điểm yếu của toán K-Nearest Neighbor ý tưởng thì rất là đơn giản nhưng mà khi chúng ta triển khai thì chúng ta sẽ tốn rất nhiều bộ nhớ để mà lưu trữ và để giải quyết cho cái dữ liệu mà có cái dạng phức tạp phi tuyến tính thì một trong những cái giải pháp cũng rất là nổi tiếng đó chính là sử dụng mạng Neural",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B5cpY9SY7CY",
      "filename": "B5cpY9SY7CY",
      "title": "[CS116 - Buổi 7] Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:05:26",
      "end_timestamp": "0:06:12"
    }
  },
  {
    "page_content": "rất là nổi tiếng đó chính là sử dụng mạng Neural Network hay còn gọi là Multi-layer Perceptron và trong thì trong Scikit-learn nó sẽ có cái module tương ứng đó là MLP Và nếu như chúng ta làm cho bài toán regression thì nó sẽ là MLP Regressor Còn nếu như chúng ta làm cho bài toán phân loại thì đó là MLP Classifier thì ý tưởng của Multi-layer Perceptron trong á Tức là ngoài cái input feature tức là toàn bộ cái dữ kiện đầu vào ở đây và cái output layer ở đây thì chúng ta ta sẽ có thêm cái thành",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B5cpY9SY7CY",
      "filename": "B5cpY9SY7CY",
      "title": "[CS116 - Buổi 7] Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:06:06",
      "end_timestamp": "0:06:56"
    }
  },
  {
    "page_content": "layer ở đây thì chúng ta ta sẽ có thêm cái thành phần nó gọi là hidden layer và cái dữ liệu đầu ra của mình mà nó càng phức tạp của cái đầu ra này của mình mà càng phức tạp Tức là nó rất là phi tuyến so với lại cái đầu vào thì chúng ta sẽ phải tăng cái số hidden layer này lên nó có thể tăng lên là hai lớp ba lớp Và thậm chí trong một số bài toán đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=B5cpY9SY7CY",
      "filename": "B5cpY9SY7CY",
      "title": "[CS116 - Buổi 7] Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:06:51",
      "end_timestamp": "0:06:59"
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng đến với một trong những cái mô hình rất là quan trọng đó chính là mô hình Cây quyết định Decision Tree và cây quyết định là một trong những cái mô hình nền tảng cho các cái mô hình học tổ hợp về sau Ví dụ như Random Forest thì chúng ta thấy là cái từ Random Forest là rừng đúng không Thì rừng là bao gồm rất nhiều cây thì mỗi một cái cây chính là cái cây quyết định mà mình đề cập trong bài ngày hôm nay tương tự như vậy cho các cái mô hình boosting thì cũng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:35"
    }
  },
  {
    "page_content": "tự như vậy cho các cái mô hình boosting thì cũng rất hay sử dụng những cái mô hình nền tảng là dạng cấu trúc cây thì với cái mô hình cây quyết định thì chúng ta sẽ sử dụng một cái dataset để minh họa cho cái việc sử dụng cái cây quyết định này đó là chúng ta sử dụng bộ tập bộ dữ liệu là Iris dataset thì Iris dataset này nó sẽ bao gồm các cái thành phần là X Iris data đó chính là các feature đầu vào, các cái đặc trưng đầu vào. Iris target chính là cái giá trị đầu ra của mình thì mình sẽ xem coi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 1,
      "start_timestamp": "0:00:31",
      "end_timestamp": "0:01:17"
    }
  },
  {
    "page_content": "cái giá trị đầu ra của mình thì mình sẽ xem coi cái y này của mình nó là cái gì. Y này tương ứng là các cái nhãn phân lớp cho cái bài toán của mình nó sẽ có tất cả là ba phân lớp là 0 1 và 2 thì mỗi cái nhãn này nó tương ứng là tên của một cái loài hoa rồi và X thì nó là gì? X là một cái ma trận trong đó mỗi một hàng tương ứng là một cái đặc trưng của một cái mẫu dữ liệu. Và ở đây chúng ta có tất cả là bốn đặc trưng và tổng số hàng của mình sẽ là bao nhiêu thì chúng ta sẽ xem qua cái X.shape.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 2,
      "start_timestamp": "0:01:10",
      "end_timestamp": "0:02:03"
    }
  },
  {
    "page_content": "là bao nhiêu thì chúng ta sẽ xem qua cái X.shape. Chúng ta có tất cả là 150 mẫu và mỗi mẫu thì có số lượng đặc trưng là 4. Tiếp theo thì chúng ta sẽ cùng xây dựng cái mô hình Decision Tree. Thì để xây dựng cái mô hình Decision Tree thì chúng ta cũng sử dụng một cái phong cách rất là tương tự như những cái mô hình trước đây. Chúng ta sử dụng thư viện sklearn.tree và chúng ta sẽ import cái module là Decision TreeClassifier. Là do cái bài toán này Y của mình, Y của mình là cái nhãn phân loại nên ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 3,
      "start_timestamp": "0:01:56",
      "end_timestamp": "0:02:42"
    }
  },
  {
    "page_content": "của mình, Y của mình là cái nhãn phân loại nên ở đây mình sẽ chọn cái cái cái loại mô hình đó là Classifier tức là cho bài toán phân loại. Decision Tree cũng có thể được sử dụng cho cái bài toán là hồi quy tức là dự đoán các cái giá trị output thuộc cái miền liên tục. Thì để mà sử dụng cái Decision Tree cho bài toán dự đoán giá trị liên tục chúng ta sẽ sử dụng DecisionTreeRegressor. Rồi và cách thức khai báo cho Decision Tree cũng rất là đơn giản và đi theo cùng một cái phong cách của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 4,
      "start_timestamp": "0:02:37",
      "end_timestamp": "0:03:15"
    }
  },
  {
    "page_content": "đơn giản và đi theo cùng một cái phong cách của scikit-learn trước giờ. Model sẽ là bằng Decision TreeClassifier và chúng ta sẽ fit cái dữ liệu huấn luyện vào. Sau khi chúng ta đã huấn luyện xong cái dữ liệu này thì chúng ta sẽ tiến hành trực quan hóa cái mô hình cây. Và để trực quan hóa thì chúng ta sẽ sử dụng module đó là tree và tree sẽ chấm export_text. Chúng ta sẽ truyền cái model đã được huấn luyện ở bước trước và khi export xong thì chúng ta sẽ ra được cái dạng biểu diễn thì chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 5,
      "start_timestamp": "0:03:10",
      "end_timestamp": "0:03:53"
    }
  },
  {
    "page_content": "ta sẽ ra được cái dạng biểu diễn thì chúng ta sẽ in ra. Rồi và cái cách này thì nó cũng khá giống với lại cái cách biểu diễn cây thư mục ở bên trong hệ điều hành Windows đúng không? Ở đây thì chúng ta sẽ có các cái feature số 2. Feature 2 là gì? Feature 2 nó tương ứng chính là cái cột thứ hai nó tương ứng là cái cột thứ hai trong cái X của mình ha. Rồi. Rồi và cái feature số 2 này nó sẽ kiểm tra xem là cái ngưỡng của mình là có bé hơn một cái ngưỡng là 2.45 hay không. Nếu cái feature số 2 mà có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 6,
      "start_timestamp": "0:03:47",
      "end_timestamp": "0:04:51"
    }
  },
  {
    "page_content": "là 2.45 hay không. Nếu cái feature số 2 mà có giá trị bé hơn ngưỡng 2.45 thì chúng ta sẽ kết luận luôn đó là class số 0. Nó sẽ kết luận là class số 0. Còn nếu như cái feature 2 mà lớn hơn 2.45 thì chúng ta sẽ qua cái nhánh này. Ngược lại chúng ta, chúng ta sẽ qua cái nhánh này, qua cái nhánh này và chúng ta sẽ tiếp tục kiểm tra. Rồi kiểm tra xem cái feature số 2 này có thỏa mãn cái điều kiện là lớn hơn 2.45 thì chúng ta sẽ vào cái nhánh này để kiểm tra tiếp cái feature số 3 có bé hơn 1.75",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 7,
      "start_timestamp": "0:04:44",
      "end_timestamp": "0:05:28"
    }
  },
  {
    "page_content": "để kiểm tra tiếp cái feature số 3 có bé hơn 1.75 không. Nếu feature số 3 không bé hơn 1.75 thì chúng ta sẽ xuống nhánh này. Tức là feature 3 lớn hơn 1.75 thì chúng ta lại tiếp tục kiểm tra xem feature số 2 có bé hơn 4.85 hay không. Nếu bé hơn 4.85 thì chúng ta sẽ đến đây, đến cái nhánh này. Còn nếu không thì chúng ta sẽ xuống đây và đưa ra cái kết luận và class của mình sẽ lần lượt thuộc cái class số 2. Thế thì với cái cách biểu diễn cấu trúc cây như thế này chúng ta sẽ thấy có rất nhiều vấn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 8,
      "start_timestamp": "0:05:23",
      "end_timestamp": "0:05:58"
    }
  },
  {
    "page_content": "cây như thế này chúng ta sẽ thấy có rất nhiều vấn đề. Vấn đề đầu tiên đó là chúng ta rất khó theo dõi đến đâu xuống nhánh thế nào rẽ nhánh thế nào. Mặc dù cái này nó cũng tương đối là đơn giản, dễ hiểu, nhưng mà khó cho chúng ta hình dung ở một số yếu tố. Yếu tố đầu tiên, feature 2 chúng ta sẽ không biết được cái tên ý nghĩa của cái feature số 2 đó là gì. Cái class số 0 đúng không? Chúng ta cũng không biết cái ý nghĩa của class số 0 là gì. Tại vì mọi thứ nó đều đưa về dạng con số. Thế thì ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 9,
      "start_timestamp": "0:05:54",
      "end_timestamp": "0:06:40"
    }
  },
  {
    "page_content": "mọi thứ nó đều đưa về dạng con số. Thế thì ở đây chúng ta sẽ sử dụng thư viện với cái hàm/phương thức đó là tree.plot_tree. tree.plot_tree và chúng ta sẽ truyền cái model đã được huấn luyện trước đó vào cái phương thức này. Rồi sau đó chúng ta sẽ quan sát xem đồng thời là nó thực hiện một cái việc là gán cái tên của cái đặc trưng Iris.feature_names. Nó gán cái tên vào rồi nó gán cái nhãn của của cái output vào. Bình thường nhãn của output của mình đó là 012 thì nó gán vô cái target_names của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 10,
      "start_timestamp": "0:06:34",
      "end_timestamp": "0:07:12"
    }
  },
  {
    "page_content": "mình đó là 012 thì nó gán vô cái target_names của mình nó tương ứng sẽ là các cái class có tên là gì thì chúng ta sẽ cùng quan sát ở đây. Sau khi vẽ cái cấu trúc cây Decision Tree, chúng ta thấy nó rất là trực quan, nó rất là đẹp đúng không? Nó đẹp. Đầu tiên đó là nó chia ra làm các cái nhánh rất là dễ theo dõi so với cái việc dùng text như ở trên. Và với một cái node ở đây chúng ta sẽ thấy có bốn, thông thường là sẽ có bốn cái giá trị. Giá trị đầu tiên là để thể hiện xem điều kiện mình đang",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 11,
      "start_timestamp": "0:07:06",
      "end_timestamp": "0:07:50"
    }
  },
  {
    "page_content": "đầu tiên là để thể hiện xem điều kiện mình đang muốn kiểm tra đó là gì, là petal length có bé hơn 2.45 hay không. Thì trong cái cách biểu diễn trước chúng ta chỉ dùng là feature 2 có bé hơn 2.45 hay không. Feature 2 đó là gì? Feature 2 đó chính là petal length đó là chiều dài của petal. Và nếu như nó bé hơn 2.45 thì chúng ta sẽ sang cái nhánh bên tay trái và chúng ta sẽ có cái hệ số Gini là bằng 0. Hệ số Gini nó sẽ là một cái hệ số để đo cái sự hỗn tạp. Hệ số Gini nó sẽ nhận cái giá trị là từ 0",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 12,
      "start_timestamp": "0:07:45",
      "end_timestamp": "0:08:25"
    }
  },
  {
    "page_content": "tạp. Hệ số Gini nó sẽ nhận cái giá trị là từ 0 cho đến 1. À, từ 0 cho đến 1. 0 có nghĩa là không hỗn tạp, 1 tức là rất hỗn tạp. Thì khi mà nó đạt được cái Gini bằng 0 tức là gần như không có sự hỗn tạp thì cái độ tin cậy của mình khi đưa ra kết luận rất là cao. Thì ở đây chúng ta thấy nè, khi đến được cái nhánh số, cái nhánh mà màu cam ở đây, chúng ta thấy cái số mẫu còn lại của mình trong cái tập dữ liệu huấn luyện á mà có cái petal length bé hơn 2.45 là sẽ có 50 mẫu. Và 50 mẫu này đều rớt vào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 13,
      "start_timestamp": "0:08:19",
      "end_timestamp": "0:09:08"
    }
  },
  {
    "page_content": "2.45 là sẽ có 50 mẫu. Và 50 mẫu này đều rớt vào bên trong cái class đầu tiên đó chính là Setosa. Còn hai cái class còn lại là không có mẫu nào nên cái sự pha trộn hỗn tạp của mình nó rất là thấp và cụ thể ở đây là bằng 0. Thì lúc này mình kết luận đó là Setosa. Nếu như petal length mà không có bé hơn 2.45, tức là nó đi theo cái nhánh này, thì mình sẽ kiểm tra cái điều kiện tiếp theo là petal width có bé hơn hoặc bằng 1.75 hay không. Và nếu như chúng ta đến được cái nhánh này thì cái số sample,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 14,
      "start_timestamp": "0:09:01",
      "end_timestamp": "0:09:44"
    }
  },
  {
    "page_content": "ta đến được cái nhánh này thì cái số sample, số mẫu còn lại của mình nó sẽ là 100 mẫu. Tức là 100 mẫu thỏa mãn cái điều kiện là petal length bé hơn 2.45 thì nó nó sẽ rải vô hai cái nhánh này. Lúc này là không, à cái cái class đầu tiên của mình là 0 và 100 cái mẫu còn lại của mình nó sẽ rớt vô hai cái class này. Như vậy thì cái hệ số Gini của mình trong trường hợp này là 50 50, tức là 50 % thì nếu như đến đây chúng ta kết luận cái class của mình là Versicolor thì cái hệ số hỗn tạp của mình nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 15,
      "start_timestamp": "0:09:38",
      "end_timestamp": "0:10:32"
    }
  },
  {
    "page_content": "là Versicolor thì cái hệ số hỗn tạp của mình nó cũng còn tương đối cao, chưa có cái độ tin cậy cao. Chúng ta chỉ đưa ra cái kết luận có tin cậy cao khi cái Gini của mình nó rất là thấp, cụ thể là Gini bằng 0 ha. Rồi chúng ta sẽ rẽ nhánh như vậy. Rồi nếu petal width mà bé hơn 1.75 đúng thì nó sẽ qua nhánh bên tay trái, nó lại kiểm tra xem petal length có bé hơn 4.95 hay không. Thì đến đây là cái hệ số Gini của mình nó đã rất là thấp là 0.16. Tại vì sao? Tại vì không mẫu đến đây thì không mẫu rớt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 16,
      "start_timestamp": "0:10:27",
      "end_timestamp": "0:02:13"
    }
  },
  {
    "page_content": "sao? Tại vì không mẫu đến đây thì không mẫu rớt vô cái class đầu tiên, 49 mẫu rớt vô cái class ở giữa và 5 mẫu. Như vậy là có cái sự chênh lệch rất là lớn nhưng cái số 5 mẫu này nó rất bé so với 49 nên cái sự hỗn tạp của mình trong trường hợp này thấp. Nếu petal length mà bé hơn 4.95 nó lại xuống dưới đây. Còn xuống dưới đây thì chúng ta thấy là chỉ còn có 48 mẫu thôi. Chỉ còn có 48 mẫu đi theo cái con đường này đến đây và 48 mẫu nó phân ra là 47 mẫu là ở class thứ hai và một mẫu ở class thứ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 17,
      "start_timestamp": "0:02:07",
      "end_timestamp": "0:02:45"
    }
  },
  {
    "page_content": "47 mẫu là ở class thứ hai và một mẫu ở class thứ ba. Và đến đây thì chúng ta có thể kết luận đó là Versicolor nhưng nó cái độ hỗn tạp của mình nó vẫn chưa tuyệt đối, nó vẫn là 0.041. Xuống dưới, xuống dưới nữa đúng không? Tức là nếu cái điều kiện petal width này thỏa mãn là bé hơn 1.65 thật thì là toàn bộ 47 mẫu đều rớt vô cái class số 2 tức là class của mình là Versicolor. Thì đến đây mình có thể hoàn toàn an tâm kết luận đó là nhãn của mình là Versicolor với cái độ hỗn tạp bằng 0. Thì đây là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 18,
      "start_timestamp": "0:02:40",
      "end_timestamp": "0:12:17"
    }
  },
  {
    "page_content": "Versicolor với cái độ hỗn tạp bằng 0. Thì đây là cái cách mà mình vận hành cái cây của mình, cái cây quyết định của mình. Và cũng tương tự như các cái mô hình trước, đó là chúng ta sẽ phải đánh giá, chúng ta sẽ phải đánh giá thông qua cái hàm là model.predict. Chúng ta sẽ truyền cái X này vào. Và accuracy thì chúng ta có thể dùng cái hàm accuracy của scikit-learn hoặc nếu bạn nào thích code thì chúng ta có thể tự cài lại theo cái công thức như sau, đó là sẽ đếm tổng số lượng các cái giá trị dự",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 19,
      "start_timestamp": "0:12:13",
      "end_timestamp": "0:12:57"
    }
  },
  {
    "page_content": "đó là sẽ đếm tổng số lượng các cái giá trị dự đoán mà trúng với lại cái giá trị output chia cho tổng số mẫu thì nó sẽ ra accuracy ở đây của mình là bằng 100%, tức là 1.0. Rồi thì như vậy qua cái bài này thì chúng ta đã được tìm hiểu về một cái cấu trúc cây. Và chúng ta thấy là cái cây này nó cũng đi khá là sâu đúng không? Nó đi khá là sâu. Và cấu trúc cây này thì nó có một cái đặc điểm đó là nó sẽ dễ bị overfit, nó sẽ dễ bị overfit. Và để tránh cái hiện tượng overfit cho cái cấu trúc cây thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 20,
      "start_timestamp": "0:12:51",
      "end_timestamp": "0:13:02"
    }
  },
  {
    "page_content": "cái hiện tượng overfit cho cái cấu trúc cây thì thường người ta sẽ làm cái phương pháp là cắt tỉa, sẽ làm các cái phương pháp cắt tỉa, cắt tỉa một số cái nhánh nào mà nó quá là tiểu tiết và cái hệ số Gini của mình nó quá thấp thì mình có thể dừng lại. Và một cái cách nữa đó là chúng ta có thể truyền các cái tham số để cho cái cây này của mình nó giới hạn độ sâu. Thay vì cắt tỉa, cái cây này chúng ta giới hạn cái độ sâu của cái cây này là tối đa là 5 tầng, 6 tầng hay là 7 tầng ví dụ vậy. Thì đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "là 5 tầng, 6 tầng hay là 7 tầng ví dụ vậy. Thì đó là các cái cách mà chúng ta thao tác ở trên cấu trúc Cây quyết định Decision Tree.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ccgq3dzD0A4",
      "filename": "ccgq3dzD0A4",
      "title": "[CS116 - Buổi 8] Part 10",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chúng ta đã cùng đi qua các cái nội dung như sau cái nội dung đầu tiên đó chính là chúng ta À tìm hiểu về cái cách để mà chúng ta triển khai mô hình trong thực tế như thế nào và chúng ta sẽ có một số cái loại à hình thức để mà triển khai mô hình máy học trong thực tế ví dụ như là dưới dạng Batch prediction tức là chúng ta xử lý trước theo khối dữ liệu chúng ta có thể Model triển khai với dạng là Model-in- service tức là triển khai cái mô hình chung với lại cái web server của mình hoặc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CHywALVycG4",
      "filename": "CHywALVycG4",
      "title": "[CS116 - Buổi 14] Part 5_3",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:54"
    }
  },
  {
    "page_content": "chung với lại cái web server của mình hoặc là Model-as-a-service tức là chúng ta sẽ triển khai cái mô hình trên một cái máy khác chuyên biệt cho các cái mô hình máy học đó hoặc là chúng ta có thể làm trên triển khai mô hình trên edge device trên các cái thiết bị biên thì đó là những cái cách thức triển khai mô hình trong thực tế và chúng ta đã lần lượt được tìm hiểu hai cái cách thức để mà triển khai mô hình rất là phổ biến hiện nay đó là triển khai mô hình dưới dạng là web App với cái cách",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CHywALVycG4",
      "filename": "CHywALVycG4",
      "title": "[CS116 - Buổi 14] Part 5_3",
      "chunk_id": 1,
      "start_timestamp": "0:00:50",
      "end_timestamp": "0:01:29"
    }
  },
  {
    "page_content": "khai mô hình dưới dạng là web App với cái cách triển khai này thì nó sẽ giúp cho chúng ta demo nhanh và người dùng có thể tiếp cận được đến cái mô hình máy học của mình một cách dễ dàng và cái kiểu tiếp theo đó chính là kiểu API hay còn gọi là dịch vụ web thì cái cách mà dịch vụ web này á nó sẽ có cái tính linh động cao hơn và nó có thể giúp cho chúng ta chia sẻ với lại cái bên thứ ba cần sử dụng cái dịch vụ này của mình thì đây là hai cái cách sử dụng triển khai mô hình cũng rất là phổ biến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CHywALVycG4",
      "filename": "CHywALVycG4",
      "title": "[CS116 - Buổi 14] Part 5_3",
      "chunk_id": 2,
      "start_timestamp": "0:01:24",
      "end_timestamp": "0:02:08"
    }
  },
  {
    "page_content": "sử dụng triển khai mô hình cũng rất là phổ biến hiện nay bên cạnh đó thì chúng ta cũng có thể gọi là triển khai cái mô hình ở trên dịch vụ cloud dịch vụ điện toán đám mây nó gọi là serverless tức là các cái mô hình của mình nó sẽ được triển khai dưới dạng là Lambda tức là dưới dạng các cái hàm chứ nó không phải là một cái mô hình Vật Lý à Nó không phải là cái mô hình mà nó sẽ là một cái hàm ở trên cloud nhưng bản chất bên dưới thì nó vẫn là triển khai mô hình thôi Nhưng mà mình tiếp cận nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CHywALVycG4",
      "filename": "CHywALVycG4",
      "title": "[CS116 - Buổi 14] Part 5_3",
      "chunk_id": 3,
      "start_timestamp": "0:02:00",
      "end_timestamp": "0:02:44"
    }
  },
  {
    "page_content": "triển khai mô hình thôi Nhưng mà mình tiếp cận nó giống như là một cái hàm và nó sẽ tự động gọi là điều chỉnh cái tài nguyên sao cho phù hợp với lại cái số lượng request của người dùng tại thời điểm hiện tại rồi cuối cùng đó là chúng ta tìm hiểu về cách thức để mà chúng ta giám sát Giám sát cái mô hình giám sát mô hình của mình để kiểm tra xem là thứ nhất cái dữ liệu của mình dữ liệu khi mà triển khai trong thực tế có bị biến đổi hay không rồi nếu bị biến đổi thì nó sẽ thuộc cái loại nào chứ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CHywALVycG4",
      "filename": "CHywALVycG4",
      "title": "[CS116 - Buổi 14] Part 5_3",
      "chunk_id": 4,
      "start_timestamp": "0:02:40",
      "end_timestamp": "0:03:27"
    }
  },
  {
    "page_content": "nếu bị biến đổi thì nó sẽ thuộc cái loại nào chứ không phải là dữ liệu nào biến đổi thì chúng ta cũng sẽ cập nhật cái mô hình ha dữ liệu nó biến đổi nhưng mà nó sẽ thuộc cái loại nào ngắn hạn hay dài hạn đó rồi sau đó thì chúng ta sẽ tiến hành Cập nhật cái mô hình khi mà cái tình huống đó đó là bắt buộc chúng ta phải cập nhật cái mô hình rồi sau đó thì chúng ta sẽ sử dụng một số cái độ đo một số cái thông tin giám sát Ví dụ như chúng ta sử dụng cái độ đo về độ chính xác rồi chúng ta có thể sử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CHywALVycG4",
      "filename": "CHywALVycG4",
      "title": "[CS116 - Buổi 14] Part 5_3",
      "chunk_id": 5,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:18"
    }
  },
  {
    "page_content": "cái độ đo về độ chính xác rồi chúng ta có thể sử dụng cái độ đo về business về kinh tế rồi Hoặc là chúng ta sử dụng cái dạng là input rồi prediction và cuối cùng đó là các cái system performance Tức là cái hiệu năng của hệ thống giám sát cái hiệu năng của hệ thống thì trên đây đó là toàn bộ những cái nội dung chính của cái bài học ngày hôm nay",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CHywALVycG4",
      "filename": "CHywALVycG4",
      "title": "[CS116 - Buổi 14] Part 5_3",
      "chunk_id": 6,
      "start_timestamp": "0:04:13",
      "end_timestamp": "0:04:21"
    }
  },
  {
    "page_content": "tiếp theo thì chúng ta sẽ cùng tìm hiểu về hàm. Thì trong quá trình lập trình chúng ta sẽ có cái nhu cầu đó là tái sử dụng mã nguồn, tức là sẽ có những cái đoạn mã nguồn mà chúng ta sẽ dùng đi dùng lại nhiều lần. Trong quá trình mà làm việc của mình thì mình sẽ đóng gói nó lại thành một cái cái hàm. Và để thực hiện được cái việc đóng gói này thì chúng ta sẽ sử dụng cái cú pháp sau: `def` chính là cái keyword, và function name này sẽ do chúng ta đặt. Và đây sẽ là các cái tham số số 1, tham số số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CkX4yE2fN1w",
      "filename": "CkX4yE2fN1w",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.5: Lập trình Python -  Hàm",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:58"
    }
  },
  {
    "page_content": "Và đây sẽ là các cái tham số số 1, tham số số 2 để đưa vào để có thể thực hiện được với cái hàm này. Và đây sẽ là những cái câu lệnh logic. Đây là những câu lệnh. Và đối với hàm mà có trả kết quả về thì chúng ta sẽ dùng cái từ khóa là `return`. Rồi thì ưu điểm đó là sẽ giúp cho tái sử dụng được mã nguồn và dễ dàng quản lý được cái mã nguồn. Thì sau đây chúng ta sẽ làm một cái ví dụ đó là cái hàm đếm số lượng điểm trung bình của lớp học. Trong đó thì có bao nhiêu điểm là lớn hơn 5 và có bao",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CkX4yE2fN1w",
      "filename": "CkX4yE2fN1w",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.5: Lập trình Python -  Hàm",
      "chunk_id": 1,
      "start_timestamp": "0:00:54",
      "end_timestamp": "0:01:31"
    }
  },
  {
    "page_content": "đó thì có bao nhiêu điểm là lớn hơn 5 và có bao nhiêu điểm là nhỏ hơn 5. Lưu ý lớn hơn ở đây chúng ta hiểu là lớn hơn hoặc bằng. Thì chúng ta sẽ qua cái phần lập trình tương ứng ở đây ha. Đầu tiên đó là khởi tạo cái điểm trung bình GPA là điểm trung bình. Cụ thể sẽ là một số nhiều. Chúng ta sẽ có một list các cái điểm trung bình ví dụ như là 4.5, 7.5, 9.0, 5.0, nhiêu vậy. Rồi 8.0. Và bây giờ chúng ta sẽ viết một cái hàm để kiểm tra xem. Và chúng ta sẽ truyền vào cái GPA. Chú ý là chúng ta không",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CkX4yE2fN1w",
      "filename": "CkX4yE2fN1w",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.5: Lập trình Python -  Hàm",
      "chunk_id": 2,
      "start_timestamp": "0:01:28",
      "end_timestamp": "0:02:19"
    }
  },
  {
    "page_content": "ta sẽ truyền vào cái GPA. Chú ý là chúng ta không nhất thiết phải đặt cái tên biến trùng với cái tên biến ở đây. Chúng ta có thể để tên là list GPA. Ở đây nếu như chúng ta thực hiện, đương nhiên chúng ta hoàn toàn có thể dùng cái vòng lặp `for` để đếm một cách gọi là theo cái phong cách sử dụng ngôn ngữ lập trình giống như C++. Chúng ta sẽ dùng `for`, đó là `for` `gpa` `in a` `list` `GPA`. Đây là cái phong cách của C nha. Và đương nhiên khi lập trình Python thì chúng ta hoàn toàn không có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CkX4yE2fN1w",
      "filename": "CkX4yE2fN1w",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.5: Lập trình Python -  Hàm",
      "chunk_id": 3,
      "start_timestamp": "0:02:14",
      "end_timestamp": "0:03:05"
    }
  },
  {
    "page_content": "lập trình Python thì chúng ta hoàn toàn không có khuyến khích sử dụng cái vòng lặp `for`, nhưng mà để đơn giản chúng ta chỉ đang minh họa cho cái việc lập trình một cái hàm do đó mình cũng muốn là làm phức tạp cái này một chút đó là viết trong vòng lặp `for`. Thì `for gpa in list_GPA:` `if gpa` lớn hơn hoặc bằng 5 thì mình sẽ có một cái biến đếm là bằng 0. Và ở đây thì chúng ta sẽ tăng cái biến đếm pass này lên 1 đơn vị. Và ngược lại thì sao? Thì chúng ta sẽ tăng biến đếm fail lên một đơn vị.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CkX4yE2fN1w",
      "filename": "CkX4yE2fN1w",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.5: Lập trình Python -  Hàm",
      "chunk_id": 4,
      "start_timestamp": "0:03:01",
      "end_timestamp": "0:04:16"
    }
  },
  {
    "page_content": "chúng ta sẽ tăng biến đếm fail lên một đơn vị. Và kết thúc cái vòng `for` này thì chúng ta sẽ `return` đó là `count_pass`, `count_fail`. Các bạn lưu ý đó là cái hàm này mình đang cố tình viết nó phức tạp và nó sẽ không thực sự tối ưu. Các bạn hoàn toàn có thể viết cái hàm này mà không có sử dụng vòng `for` được. Thì đây là minh họa cho cái việc là dùng một cái vòng lặp `for`. Chúng ta sẽ đóng gói cái dữ liệu `count`. Thì bây giờ chúng ta sẽ tiến hành gọi cái hàm `count` này ha. Chúng ta sẽ tiến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CkX4yE2fN1w",
      "filename": "CkX4yE2fN1w",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.5: Lập trình Python -  Hàm",
      "chunk_id": 5,
      "start_timestamp": "0:04:12",
      "end_timestamp": "0:05:17"
    }
  },
  {
    "page_content": "hành gọi cái hàm `count` này ha. Chúng ta sẽ tiến hành gọi cái hàm `count` và truyền vào cái tham số. Trong trường hợp này thì chúng ta sẽ sử dụng một tham số thôi đó là `GPAs`. Và kết quả sẽ trả về ví dụ như là `pass` và `fail_count`. đó thì mình sẽ in ra số lượng sinh viên rớt Nguyên cái này là mình không mong muốn ha. Rồi, `fail_count`. Rồi số lượng đậu. Đó thì với cái ví dụ ở trên chúng ta thấy là số sinh viên rớt sẽ là 1, 2 và số sinh viên đậu sẽ là 1, 2, 3, 4. Rồi thì đây là một cái minh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CkX4yE2fN1w",
      "filename": "CkX4yE2fN1w",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.5: Lập trình Python -  Hàm",
      "chunk_id": 6,
      "start_timestamp": "0:05:10",
      "end_timestamp": "0:05:58"
    }
  },
  {
    "page_content": "đậu sẽ là 1, 2, 3, 4. Rồi thì đây là một cái minh họa cho cái việc là chúng ta viết một cái hàm, viết một cái hàm `count` và có truyền tham số cũng như là có cái trả về kết quả. Và hàm này nhắc lại một lần nữa hàm này chúng ta hoàn toàn có thể viết mà không sử dụng một vòng lặp `for`.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CkX4yE2fN1w",
      "filename": "CkX4yE2fN1w",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.5: Lập trình Python -  Hàm",
      "chunk_id": 7,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và đến cái tầng à tiếp theo đó chính là tầng activation tầng activation này thì đây là một cái tầng mà Biến đổi Phi tuyến thì như chúng ta đã từng nhận xét trước đó cái phép conclusion này á đó là cái phép biến đổi tuyến tính nếu như chúng ta thực hiện cái phép conversion nối tiếp với một cái phép convolution mà không có cái phép tuyến tính ở giữa thì có không có một cái phép Phi tuyến ở giữa đó thì đâu đó nó nó sẽ tạo ra thành một cái tổ hợp một cái tổ hợp tuyến tính mà thôi tức là tuyến tính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:38"
    }
  },
  {
    "page_content": "cái tổ hợp tuyến tính mà thôi tức là tuyến tính rồi lại biến đổi tuyến tính thì nó sẽ tạo ra một cái tổ hợp tuyến tính mà cái tổ hợp tuyến tính thì nó sẽ không giải được à nó sẽ không giải quyết được các cái bài toán Phi tuyến do đó thì chúng ta sẽ phải Ngay sau cái phép tiến nửa conclusion chúng ta phải có một cái tầng activation Phi tuyến thì trước đây người ta sử dụng cái hàm là hàm sig nhưng mà gần đây thì khi cái khối lượng dữ liệu lớn khi cái kiến trúc mạng nó càng sâu hơn thì người ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:35",
      "end_timestamp": "0:01:13"
    }
  },
  {
    "page_content": "cái kiến trúc mạng nó càng sâu hơn thì người ta nhận thấy rằng là đổi từ sigmo sang relu thì sẽ giúp cho cái Việc huấn luyện sẽ nhanh hơn cái Việc huấn luyện sẽ nhanh hơn và cái việc này đó là do chúng ta làm giảm cái hiện tượng vaning radient đó thì đây sẽ là một cái chủ đề thêm để cho các bạn tìm hiểu về sau ha Nhưng đại khí đó là với cái việc sử dụng tầng activation là rue thì nó đã giúp cho mình giảm cái hiện tượng vanishing radient tức là tiêu biến cái cái đạo hàm đạo hàm của mình mà trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:09",
      "end_timestamp": "0:01:56"
    }
  },
  {
    "page_content": "biến cái cái đạo hàm đạo hàm của mình mà trong quá trình cập nhật mà nó càng lúc càng nhỏ thì dẫn đến cái bước cập nhật của mình nó sẽ càng chậm đúng không Thì activation mà dùng hàm relu thì cái đạo hàm của mình nó sẽ bị không có bị cái hiện tượng này và không bị hiện tượng này thì nó sẽ huấn luyện nhanh hơn thì đối với cái tầng activation thì chúng ta sử dụng hàm ru và cái công thức của cái hàm rue nó sẽ là bằng rue của hàm của j j là đầu vào ha sẽ là bằng max của 0 và j thì hiểu một cách nô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 3,
      "start_timestamp": "0:01:49",
      "end_timestamp": "0:02:31"
    }
  },
  {
    "page_content": "ha sẽ là bằng max của 0 và j thì hiểu một cách nô na Đó là những cái dữ liệu j mà bé hơn 0 á thì nó sẽ trệt tiêu đi nó sẽ đưa về cái con số đó là 0 rồi còn những cái dữ liệm J Những cái giá trị đầu vào của mình là những cái giá trị lớn hơn Không thì nó sẽ giữ nguyên Nếu j mà lớn hơn 0 thì nó sẽ giữ nguyên hay hiểu một cách nô na rue này nó sẽ lọc những cái thông tin không cần thiết và chỉ chừa những cái thông tin quan trọng mà thôi rồi và cái tầng Chúng ta có một cái lưu ý đó là trong cái mạng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 4,
      "start_timestamp": "0:02:27",
      "end_timestamp": "0:03:12"
    }
  },
  {
    "page_content": "Chúng ta có một cái lưu ý đó là trong cái mạng CNN thì cái tầng value là thường phải Ngay sau Thường ngay theo sau tầng conion tại vì cái thằng này là conion đó là tuyến tính đó và ngay sau tuyến tính thì chúng ta phải có một cái phép biến đổi Phi tuyến Ngoài ra thì ru chúng ta có thể thay cho các cái hàm khác là hàm sigmo hàm Tank licky ru vân vân Nhưng mà như chúng ta nói cái biến thể của cái mạng CNN mà trong những thời trong trong cái thời gian gần đây á thì người ta rất hay sử dụng ru là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 5,
      "start_timestamp": "0:03:07",
      "end_timestamp": "0:03:40"
    }
  },
  {
    "page_content": "gian gần đây á thì người ta rất hay sử dụng ru là vì nó giúp cho cái mạng của mình nó huấn luyện nhanh thì trong cái phần bài tập chúng ta sẽ có cái phần thử nghiệm thay vì sử dụng value chúng ta sẽ dùng sigmo thì khi mà chúng ta đưa vô với hàm xmo nó sẽ huấn luyện rất là chậm Nhưng mà nếu như chúng ta sử dụng cái HP ru thì tốc độ huấn luyện nó sẽ rất là nhanh rồi thì ở đây chúng ta sẽ có một cái bài tập để tính nháp trên cái phép biến đổi à trên cái tầng activation này ha giả sử như chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 6,
      "start_timestamp": "0:03:37",
      "end_timestamp": "0:04:23"
    }
  },
  {
    "page_content": "cái tầng activation này ha giả sử như chúng ta có một cái input à là một cái tensor 3 x 3 nhân 2 3 x 3 x 2 thì ở đây chúng ta sẽ có hai lá cắt thì ở đây mỗi cái Ma Trận này nó tương ứng là một cái lá cắt thì chúng ta sẽ có cái giá trị này và nếu như chúng ta nhân Xin lỗi chúng ta thực hiện với cái tầng activation và hàm R thì cái output của mình nó sẽ ra cái cal như thế nào thì các bạn sẽ tính toán thử ha số 0 nó sẽ biến thành số 0 -1 nó nó sẽ biến thành số 0 0 sẽ biến thành số 0 đó Cứ như vậy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 7,
      "start_timestamp": "0:04:17",
      "end_timestamp": "0:05:11"
    }
  },
  {
    "page_content": "thành số 0 0 sẽ biến thành số 0 đó Cứ như vậy Số này là số dương đúng không nó sẽ giữ nguyên rồi đó thì đây là những cái số chữ cái màu đỏ đó chính là cái kết quả sau khi chúng ta thực hiện với lại cái phép biến đổi rectify linear unit relu tầng thứ ba trong cái kiến trúc mạng cdn chính là cái tầng pulling thì cái pulling này á là phi tham số phi tham số nghĩa là sao Tức là chúng ta sẽ không có cái tham số để huấn luyện không có cái tham số huấn luyện nó nhiệm vụ của cái tầng pooling này nó chỉ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 8,
      "start_timestamp": "0:05:05",
      "end_timestamp": "0:05:48"
    }
  },
  {
    "page_content": "luyện nó nhiệm vụ của cái tầng pooling này nó chỉ đơn giản là để giảm cái kích thước của cái feature Map của mình Ví dụ trong trường hợp này chúng ta có một cái ảnh 4 x 4 khi áp dụng với cái filter 2 nh 2 2 nhân 2 và với cái bức nhảy là 2 thì đâu đó chúng ta sẽ thấy là ảnh 4 x 4 nó sẽ giảm xuống còn một cái ảnh kích thước là 2 x 2 và cái cách thức chúng ta sẽ thực hiện với hai cái phép biến đổi Max spoling và average pulling max pooling là gì khi chúng ta Ờ khi chúng ta đưa cái filter này lên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 9,
      "start_timestamp": "0:05:43",
      "end_timestamp": "0:06:27"
    }
  },
  {
    "page_content": "chúng ta Ờ khi chúng ta đưa cái filter này lên trên đây thì chúng ta sẽ lấy ra được bốn giá trị là 20 1 1 và chúng ta sẽ thực hiện cái phép biến đổi là max thì 2011 giá trị lớn nhất của mình đó chính là 2 chúng ta sẽ điền 2 qua đây và 2011 mà cộng trung bình đúng không Thì nó sẽ ra là 1 đó do đó thì giá trị lớn nhất max pulling thì tại đây nó sẽ ra là 2 nhưng mà average pulling thì ở đây nó sẽ ra là 1 rồi chúng ta sẽ trượt với cái bước nhảy Strike là bằng 2 ha Như vậy chúng ta bỏ qua Cái ô này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 10,
      "start_timestamp": "0:06:23",
      "end_timestamp": "0:07:10"
    }
  },
  {
    "page_content": "là bằng 2 ha Như vậy chúng ta bỏ qua Cái ô này chúng ta bỏ qua ô này và đến đây thì chúng ta sẽ đ tiếp các giá trị max của nó sẽ là 4 và trung bình của nó sẽ là 2 rồi lại tiếp tục nhảy khóc vàở đây max của nó sẽ là 3 trung bình sẽ là 2 rồi max sẽ là 5 và trung bình sẽ là 3 thì đây chính là cái phép biến đổ pulling và Strike thì thường có kích thước bằng với lại cái kích thước của cái filter Ví dụ như ở đây filter là 2 nhân 2 thì st của mình nó sẽ là bằng 2 và các cái futter này thì được áp dụng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 11,
      "start_timestamp": "0:07:02",
      "end_timestamp": "0:07:47"
    }
  },
  {
    "page_content": "là bằng 2 và các cái futter này thì được áp dụng độc lập à áp dụng độc lập đó ví dụ như cái feature map đầu vào của mình không nó sẽ có cái độ sâu là D thì nó sẽ lấy cái cơ đồ này nó sẽ áp dụng độc lập trên từng cái l Cup feature này và sau đó nó sẽ tạo ra với cái phép pulling này ha với cái phép pulling nó sẽ tạo ra một cái feature m kích thước à Có cái độ sâu đúng bằng D luôn Ví dụ ở đây là D thì ở đây đúng bằng D tại vì cứ một cái lá CT bên đây nó sẽ tạo ra một lá cắt bên đây một cái lá cắt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 12,
      "start_timestamp": "0:07:42",
      "end_timestamp": "0:08:48"
    }
  },
  {
    "page_content": "nó sẽ tạo ra một lá cắt bên đây một cái lá cắt bên đây nó sẽ tạo ra một lá CT bên đây còn kích thước của bè ngang bề cao thì có thể thay đổi nha do Strike bằng 2 thì kích thước này nó có thể giảm xuống còn nữa thôi rồi và cuối cùng đó chính là tầng Fully conned Thì trước khi thực hiện cái tầng Fully coned này nó sẽ có một cái bước nó là flattening tại sao lại như vậy Tại vì sao cái phép biến đổi convolution đúng không Nó biến một cái tensor nó sẽ biến thành một cái tensor rồi cái phép ru cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 13,
      "start_timestamp": "0:08:41",
      "end_timestamp": "0:09:22"
    }
  },
  {
    "page_content": "sẽ biến thành một cái tensor rồi cái phép ru cái hàm kích hoạt ru thì nó cũng sẽ biến đổi một cái tensor thành một cái tenser rồi cái phép biến đổi Ờ fulling thì nó cũng sẽ biến đổi một cái tensor biến thành một cái tensor Tuy nhiên cái tensor này thường nó sẽ có kích thước nhỏ hơn đó thì suy cho cùng contion ru và pulling một chuỗi phối hợp các cái phép biến đổi này nó sẽ biến tenser thành một cái tensor đó rồi mà tensor thì nó không phải là cái dạng chuẩn đầu vào để mà cho chúng ta thực hiện",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 14,
      "start_timestamp": "0:09:16",
      "end_timestamp": "0:10:06"
    }
  },
  {
    "page_content": "dạng chuẩn đầu vào để mà cho chúng ta thực hiện với cái phép Fully connected đây chính là cái mạng neuron đây chính là cái mạng neuron Network của mình như vậy thì chúng ta sẽ phải có một cái bước để chuyển đổi cái tensor này biến nó thành một cái vector đó để làm đầu vào cho cái mạng Fully contic ở đây ha rồi thì ở đây chúng ta Giả sử có một cái tenser kích thước là 2 x 2 nhân 2 và ở đây thì chúng ta sẽ cắt cái thằng này ra đúng không mỗi lá cắt chúng sẽ tạo ra ở đây thì 0 10 1 đó mỗi cái lá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 15,
      "start_timestamp": "0:09:58",
      "end_timestamp": "0:10:52"
    }
  },
  {
    "page_content": "chúng sẽ tạo ra ở đây thì 0 10 1 đó mỗi cái lá Cát này chúng ta sẽ có các cái giá trị đầu bào như thế này thì flaton bản chất nó là duỗi nó duỗi một cái tenser 3D để tạo thành một cái tensor 1D tức là một cái vector thì số 0 chép qua đây số 1 chép qua đây rồi số 0 chép qua đây số 1 chép qua đây r số 0 đó thì nó sẽ tạo thành vectơ và với cái vectơ này thì nó sẽ thực hiện cái phép biến đổi Fully connected để tạo ra từ một cái vectơ tạo ra thành một cái vectơ khác thì trong trường hợp Ví dụ như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 16,
      "start_timestamp": "0:10:43",
      "end_timestamp": "0:11:33"
    }
  },
  {
    "page_content": "một cái vectơ khác thì trong trường hợp Ví dụ như bài này chúng ta nhận dạng ba lớp đó là à nhạc cửa nè người nè cây nè đúng không Thì ở đây nó sẽ có ba cái nốt đồ ra thì ở đây chúng ta sẽ có cái bộ tham số thta để phân loại cái đặc trưng đã rút trích được từ cái bước là conion relu Và poing đây là cái đặc trưng đó và chúng ta sẽ đi qua cái f contic này như là một cái máy phân lớp đó để phân lớp và tạo ra một cái neuron output thì đây chính là các cái thành phần để tạo ra một cái mạng CNN đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 17,
      "start_timestamp": "0:11:30",
      "end_timestamp": "0:12:22"
    }
  },
  {
    "page_content": "các cái thành phần để tạo ra một cái mạng CNN đó Như vậy tổng kết thì mạng CNN nó sẽ kế thừa từ cái mạng neuro Network đúng không và cái đầu tiên của nó đó là nó không có sử dụng cái phép biến đổi Fully connected à nó sẽ không còn sử dụng cái cơ chế Fully contic nữa mà nó sẽ dùng cơ chế là chia sẻ trọng số và kết nối của bộ đó thì bản chất của th này đó chính là cái phép convolution rồi đồng thời CNN sẽ bao gồm các cái tầng biến đổi đó là tầng conion activation pulling và kết nối đầy đủ thì sau",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 18,
      "start_timestamp": "0:12:17",
      "end_timestamp": "0:13:07"
    }
  },
  {
    "page_content": "activation pulling và kết nối đầy đủ thì sau đây à mình sẽ vẽ một cái mạng CNN mà nó có cái sự kết nối giữa các cái tầng này ha và đương nhiên cái mạng cnm này thì chúng ta sẽ phải ở mức độ là đơn giản thôi đầu vào của mình nó sẽ có một cái tấm ảnh đó và thường ảnh này là ảnh màu thì dep ở đây nó sẽ là bằng 3 qua cái phép biến đổi conclusion với d cái filter D cái filter thì chúng ta sẽ tạo ra một cái feature map có kích thước là D rồi sau đó chúng ta nếu mà chúng ta kết hợp cả cái conion này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 19,
      "start_timestamp": "0:13:01",
      "end_timestamp": "0:13:57"
    }
  },
  {
    "page_content": "ta nếu mà chúng ta kết hợp cả cái conion này cộng với lại ru luôn ha cộng với Ru thì nó sẽ tạo ra một cái feature map như thế này rồi sau đó chúng ta thực hiện cái phép pulling đó thì nó sẽ tạo ra một cái feature map có cái bèn ngang và bề cao nhỏ hơn một nửa nếu như Strike là bằng 2 ha Nó sẽ nhỏ hơn một nửa và cái độ sâu của mình nó cũng giữ nguyên đó là bằng D tại vì cái phép pulling này nó sẽ thực hiện độc lập trên từng cái kênh độc lập trên từng kênh do đó Ở đây có D cái l cắ thì qua bên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 20,
      "start_timestamp": "0:13:50",
      "end_timestamp": "0:14:40"
    }
  },
  {
    "page_content": "từng kênh do đó Ở đây có D cái l cắ thì qua bên đây nó sẽ là có D cái l rồi sau đó nó lại tiếp tục contion kết hợp với lại relu đúng không nó sẽ tạo ra một cái tensor và cái số lượng tensor này nó có thể thay đổi do là cái số lượng filter của mình thay đổi nó sẽ ra là D ph đi rồi sau đó nó lại p link rồi sau đó nó sẽ thực hiện cái này là phép pulling ha rồi sau đó nó sẽ thực hiện cái phép flatten để tạo ra thành một cái vector rồi cái vector này chúng ta sẽ thực hiện cái phép biến đổi Fully",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 21,
      "start_timestamp": "0:14:36",
      "end_timestamp": "0:15:22"
    }
  },
  {
    "page_content": "này chúng ta sẽ thực hiện cái phép biến đổi Fully connected Fully connected biết tắt ha rồi và lưu ý là cái phép Fully connected này nó có thể kết hợp à Nhiều cái phép Fully connected với nhau Ví dụ như đây là một lớp nè chúng ta sẽ tạo ra thêm một lớp nữa nè đó rồi FC nè Rồi cái lớp cuối thì chúng ta sẽ qua cái hàm s max đó để tạo nó ra thành một cái vector nó thỏa mãn một cái phân bố xác suất rồi thì đây chính là cái bước số một toàn bộ nãy giờ mình nói đó chính là cái bước số 1 trong cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 22,
      "start_timestamp": "0:15:17",
      "end_timestamp": "0:16:13"
    }
  },
  {
    "page_content": "giờ mình nói đó chính là cái bước số 1 trong cái việc thiết kế f thx Thế thì cái câu hỏi đó là cái bước số hai đúng không cái bước số hai là hàm loss của mình trong trường hợp này là như thế nào thì ở đây chúng ta có cái giá trị là y Ngã là giá trị Dự đoán và mình sẽ có cái giá trị y là giá trị thực tế và để hai cái thằng này gần xắp xỉ với nhau thì chúng ta sẽ sử dụng một cái hàm l theta và hàm l này chúng ta sẽ sử dụng luôn đó chính là công thức cross entropy y chang như cái bài s max y chang",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 23,
      "start_timestamp": "0:16:07",
      "end_timestamp": "0:16:50"
    }
  },
  {
    "page_content": "cross entropy y chang như cái bài s max y chang như cái bài sop max thì đây là toàn bộ cái mạng CNN khi chúng ta đã biến đổi thì cái giai đoạn đầu cái giai đoạn đầu đó là feature instruction rút chích đặc trưng rồi cái giai đạn sau thì nó tương ứng đó là đi phân lớp các cái đặc trưng và nó sử dụng cái mạng neuron Network rồi khi chúng ta đã có cái loss này rồi chúng ta sẽ có cái l này rồi thì chúng ta sẽ sử dụng cái tực toán radian descend với cái tên gọi khác cho cái mạng CNN này đó là Thục",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 24,
      "start_timestamp": "0:16:44",
      "end_timestamp": "0:17:28"
    }
  },
  {
    "page_content": "cái tên gọi khác cho cái mạng CNN này đó là Thục toán back propagation và lưu ý đó là cái back propagation này á thì đâu đó trong cái Deep learning Framework nó đã giúp cho chúng ta đi tối ưu tìm cái thta để cho cái hàm loss này là nhỏ nhất rồi Ở đây chúng ta sẽ có một cái câu hỏi theta của mình nó là cái gì đó thì theta của mình trong trường hợp này nó chính là những cái trọng số n đó là những cái trọng số nè Ví dụ đây là th 1 nè đến đây ping là không có tham số đến đây là conclusion và chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 25,
      "start_timestamp": "0:17:21",
      "end_timestamp": "0:17:58"
    }
  },
  {
    "page_content": "không có tham số đến đây là conclusion và chúng ta sẽ có là theta 2 nè rồi pulling không có tham số đến đây là FC đúng không Chúng ta sẽ có là theta 3 đến đây chúng ta sẽ có theta 4 nè đó thì toàn bộ theta 1 theta 2 cho đến theta 4 chính là những cái tham số của cái mạng CNN của mình và cái mạng CNN này nó có ứng dụng cực kỳ nhiều trong các cái bài toán của lĩnh vực thị giá máy tính nó có ứng dụng trong bài toán là phân loại phân lớp à phân lớp đối tượng nó có tác dụng trong cái bài là định vị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 26,
      "start_timestamp": "0:17:52",
      "end_timestamp": "0:18:21"
    }
  },
  {
    "page_content": "đối tượng nó có tác dụng trong cái bài là định vị đối tượng à tức là khi chúng ta đã phân lớp là biết trong cái tấm hình này nó đã có cái đối tượng tên là con mèo rồi thì chúng ta sẽ cho biết là cái vị trí của con mèo này nó nằm ở đâu và chúng ta sẽ có thể dùng cái mạng CNN này để ứng dụng cho cái bài toán là object detection tức là phát hiện xem trong tấm tấm hình này có những cái loại đối tượng gì đây là khu vực có hình con chó Đây là khu vực có hình con vịt đây là khu vực có kh hình con mèo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "có hình con vịt đây là khu vực có kh hình con mèo nó sẽ chỉ ra được cái vị trí và ở trong trường hợp object detection thì nó sẽ là nhiều object có thể phát hiện cùng lúc nhiều object và ở cấp độ cao nhất của cái việc định vị đối tượng á đó chính là instant segmentation tức là chúng ta sẽ khoanh vùng chính xác đến cái cấp độ là Pixel đối với object detection thì chúng ta phân vùng chính xác đến cái cấp độ là bing box còn instant segmentation thì nó sẽ chính xác đến cái cấp độ là Pixel và mạng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "nó sẽ chính xác đến cái cấp độ là Pixel và mạng CNN của mình cho đến bây giờ tất cả các cái mô hình localized object định vị object rồi phát hiện đối tượng rồi phân đoạn Ngư nghĩa đối tượng thì đều sử dụng cái kiến trức mạng CNN",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CN9KChN5skw",
      "filename": "CN9KChN5skw",
      "title": "[CS116 - Buổi 9] Part 2_1",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng đến với một số cái biến thể của mô hình hồi quy tuyến tính đó là Lasso, Ridge và Elastic Net. Đầu tiên đó là mô hình Lasso regression thì bản chất của cái mô hình này chính là cái sự kết hợp của mô hình hồi quy tuyến tính phiên bản gốc với lại một cái chuẩn hóa L1 thì cái công thức của mình nó sẽ có công thức là như sau: y trừ cho beta X thì đây chính là cái sai số, đây chính là cái sai số hay là Mean Squared của cái dự liệu dự đoán so với lại cái dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:46"
    }
  },
  {
    "page_content": "Squared của cái dự liệu dự đoán so với lại cái dữ liệu mong muốn. Thì đây là cái công thức mà hồi quy tuyến tính bình thường. Nhưng mà để tránh để tránh cái hiện tượng gọi là overfitting thì chúng ta sẽ thêm vào một cái thành phần chuẩn hóa đó là lambda nhân với Beta. Và lưu ý ở đây là chúng ta sẽ lấy norm bậc 1. Công thức của cái norm bậc 1 đó là gì? Ví dụ như chúng ta có Beta là bằng beta 0 và beta 1 đi ha. Một cách tổng quát thì nó có thể là beta 1, beta 2 đó. Thì khi đó norm của Beta là bậc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:40",
      "end_timestamp": "0:01:37"
    }
  },
  {
    "page_content": "1, beta 2 đó. Thì khi đó norm của Beta là bậc 1. Thì nó chính là bằng beta 0 cộng cho beta 1. Thì đây chính là cái công thức của norm bậc 1. Và thêm cái đại lượng này thì cái cái cái việc mà chúng ta thêm cái đại lượng chuẩn hóa này nó sẽ làm cho cái mô hình cố gắng đưa các cái hệ số, đưa các cái hệ số beta của mình về cái con số 0, đưa cái hệ số của mình nó về không với những cái đặc trưng không quan trọng. Thì rõ ràng là với những cái đặc trưng nó không thật sự liên quan đến cái mô hình của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:26",
      "end_timestamp": "0:02:14"
    }
  },
  {
    "page_content": "nó không thật sự liên quan đến cái mô hình của mình đúng không? Thì khi đó nó sẽ không đóng góp nhiều, nó sẽ không đóng góp nhiều vào cái công thức hồi quy của mình đó. Thì khi chúng ta thêm cái đại lượng này vào thì nó sẽ ép (dùng từ ép thì nó hơi quá) nhưng mà nó sẽ cố gắng đưa các cái beta đó, đưa các cái hệ số tương ứng cho cái mô hình cho những cái đặc trưng mà nó không có quan trọng thì nó sẽ kéo cái giá trị đó xuống. Ví dụ y của mình, ờ giả sử như chúng ta xét cái trường hợp là có nhiều",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:02:09",
      "end_timestamp": "0:03:01"
    }
  },
  {
    "page_content": "sử như chúng ta xét cái trường hợp là có nhiều biến ha, là bằng beta 0 cộng cho beta 1 X1 cộng cho beta 2 X2 cộng cho chấm chấm cộng cho beta n Xn. Thì giả sử như cái đại lượng X1 nó không quan trọng, tức là X1 là một cái đặc trưng mà nó không có liên quan gì với cái y này hết thì chúng ta mong muốn là loại cái thằng này ra khỏi cái mô hình của mình đúng không? Nhưng chúng ta sẽ không thể nào biết là cái đặc trưng X1 này nó có gọi là có cái mối quan hệ với thằng y hay không, do đó chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:57",
      "end_timestamp": "0:03:32"
    }
  },
  {
    "page_content": "quan hệ với thằng y hay không, do đó chúng ta sẽ để cho mô hình nó tự tìm ra thông qua cái việc đó là trong cái quá trình huấn luyện thì những cái đại lượng X nào mà khi có cái sự thay đổi mà nó không làm ảnh hưởng đến cái giá trị y. Tức là những cái thành phần không quan trọng thì cái đại lượng beta của mình nó sẽ được đưa gọi là bị đẩy xuống cái giá trị xấp xỉ với lại cái con số 0. Còn những cái đại lượng nào mà quan trọng đối với y thì cái giá trị của nó ví dụ như X_i đây thì cái đại lượng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:03:28",
      "end_timestamp": "0:04:07"
    }
  },
  {
    "page_content": "trị của nó ví dụ như X_i đây thì cái đại lượng beta 2 của nó nó sẽ được đẩy lên. Đó thì đó là cái ý nghĩa của Lasso regression. Như vậy thì Lasso regression nó sẽ hướng đến chọn lựa đặc trưng quan trọng. Và Lasso regression nhờ cái tính năng mà chọn lựa đặc trưng này á thì nó được sử dụng cho các cái công việc liên quan đến Feature Selection, tức là chọn lựa đặc trưng. Ở trong cái bước gọi là data preprocessing hoặc là Feature Engineering thì chúng ta sẽ phải có một cái bước là chọn xem trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:04:03",
      "end_timestamp": "0:04:45"
    }
  },
  {
    "page_content": "ta sẽ phải có một cái bước là chọn xem trong số các cái đặc trưng đầu vào những cái đặc trưng nào thực sự quan trọng và có ý nghĩa. Và cái biến thể tiếp theo của hồi quy tuyến tính đó chính là Ridge regression. Thì đây chính là cái biến thể mà có cái sự kết hợp của mô hình hồi quy tuyến tính với cái chuẩn hóa bậc hai thì chúng ta sẽ có cái công thức của mình là như sau. Thì giả sử như cái beta mũ của mình đó là bằng hai cái giá trị là beta 0 và beta 1. Thì cái beta mũ norm bậc hai bình phương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:04:41",
      "end_timestamp": "0:05:36"
    }
  },
  {
    "page_content": "beta 1. Thì cái beta mũ norm bậc hai bình phương thì nó sẽ là công thức như sau, nó sẽ là bằng beta 0 bình phương cộng cho beta 1 bình phương. Thì đây chính là cái công thức norm bậc hai. Và cái công thức này nó sẽ khác gì so với cái công thức norm bậc 1 trước đây? Đối với công thức norm bậc 1 trước đây thì nó sẽ là beta 1 cộng cho beta 2. Thì chúng ta thấy rõ ràng là nếu xét về mặt giá trị thì cái hàm bình phương nó sẽ cho cái giá trị của mình nó lớn hơn đúng không? Và khi đó thì cái vai trò",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:05:30",
      "end_timestamp": "0:06:24"
    }
  },
  {
    "page_content": "nó lớn hơn đúng không? Và khi đó thì cái vai trò của mình trong cái tình huống này đó là cái chuẩn hóa bậc hai này á nó sẽ cố gắng (ở đây nó sẽ cố gắng) để tất cả các cái thành phần beta 0 và beta 1 đều tham gia vào. Tại sao nó lại như vậy thì chút nữa chúng ta sẽ có cái ví dụ ha. Đó, cái beta bình phương này nè, nó sẽ hướng đến khai thác hết các cái đặc trưng, trái với lại cái norm bậc 1. Norm bậc 1 đó là nó chỉ cố gắng chọn ra những cái đặc trưng nào quan trọng thì nó sẽ giữ lại. Còn đặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:06:18",
      "end_timestamp": "0:07:10"
    }
  },
  {
    "page_content": "trưng nào quan trọng thì nó sẽ giữ lại. Còn đặc trưng nào không quan trọng thì nó sẽ loại bỏ đi. Còn norm bậc 2 thì nó sẽ tìm cách là đưa tất cả các cái beta 0, beta 1, beta 2 ví dụ vậy. Giả sử trong trường hợp mà chúng ta có nhiều hơn một biến ha. Thì nó sẽ có beta 2, beta 3. Nó sẽ tìm cách để đưa cả cái beta 1, beta 2, beta 3 này vào tham gia. Thì ở đây chúng ta sẽ xét vào một cái ví dụ đó là giả sử như chúng ta có cái vectơ beta là bằng 1 0 0 0 rồi. Thì khi đó chúng ta thực hiện cái thao tác",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 10,
      "start_timestamp": "0:07:03",
      "end_timestamp": "0:07:55"
    }
  },
  {
    "page_content": "0 rồi. Thì khi đó chúng ta thực hiện cái thao tác là bình phương đúng không? Thì cái sai số, à cái cái đại lượng chuẩn hóa này ha, cái chuẩn hóa L2 này nè. Thì khi đó nó sẽ có cái công thức đó là 1 bình phương cộng cho 0 bình phương cộng cho 0 bình phương vân vân thì nó sẽ ra là 1. Trong khi đó nếu như chúng ta có một cái beta khác đó là 0.25, 0.25 và 0.25 (bốn cái giá trị 0.25) thì các cái giá trị này bình phương thì chúng ta thấy nó có tính chất gì như thế nào? Vector beta à khi này thì chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 11,
      "start_timestamp": "0:07:50",
      "end_timestamp": "0:08:34"
    }
  },
  {
    "page_content": "gì như thế nào? Vector beta à khi này thì chúng ta sẽ có là các cái giá trị thành phần này bình phương lên ha. Thì khi đó là norm của mình nó sẽ là chuẩn hóa L2 của mình nó sẽ là 0.25 bình phương tất cả nhân 4. Và cái con số 0.25 bình phương này thì nó sẽ là một con số rất là bé, tại vì con số mà nhỏ hơn 1 mà thì khi bình phương lên nó sẽ ra con số còn nhỏ hơn nữa. Như vậy thì cái 4 nhân cho cái này chắc chắn nó sẽ ra một con số bé hơn 1. Như vậy thì giữa hai cái cách chọn đó là 1 và 0.25,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 12,
      "start_timestamp": "0:08:29",
      "end_timestamp": "0:09:16"
    }
  },
  {
    "page_content": "vậy thì giữa hai cái cách chọn đó là 1 và 0.25, 0.25, 0.25. Tức là cả hai thằng này, cả hai cái cách chọn này nó đều có cái tổng là bằng 1. Nhưng cái cái vectơ bên dưới tức là beta bằng 0.25, 0.25, 0.25 và 0.25 này nó đang trải đều ra. Tức là nó đang khai thác hết, nó tìm cách khai thác hết các cái đặc trưng của mình. Tại sao nó gọi là khai thác hết? Tại vì khi chúng ta chia nhỏ cái con số 1 này ra rải đều ra cho các cái thành phần beta thì khi khi chúng ta bình phương lên á thì nó sẽ ra cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 13,
      "start_timestamp": "0:09:12",
      "end_timestamp": "0:09:46"
    }
  },
  {
    "page_content": "khi chúng ta bình phương lên á thì nó sẽ ra cái con số nhỏ hơn nữa. Như vậy thì cái norm bậc hai của cái beta này nó sẽ nhỏ hơn so với lại norm bậc hai của beta này. Rõ ràng, chúng ta đang đi tìm cái hàm nhỏ nhất mà, chúng ta đang đi tìm cái hàm nhỏ nhất mà đi tìm cái giá trị nhỏ nhất mà thì rõ ràng mô hình nó sẽ hướng đến chọn cái beta sao cho có cái đại lượng chuẩn hóa này nhỏ mà. Như vậy thì cái việc rải đều với cái việc tụ lại cho một cái giá trị thì mô hình của mình, Ridge regression của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 14,
      "start_timestamp": "0:09:41",
      "end_timestamp": "0:10:27"
    }
  },
  {
    "page_content": "trị thì mô hình của mình, Ridge regression của mình nó sẽ hướng đến là chọn cái giá trị beta này. Đó là lý do tại sao Ridge regression nó có xu hướng là khai thác hết tất cả các cái đặc trưng. Và cuối cùng đó chính là Elastic Net. Thì đây là một cái biến thể có cái sự kết hợp của cả chuẩn hóa L1 và chuẩn hóa L2. Thì giống như là cái kiểu \"nước đôi\" á thì ở đây chúng ta sẽ có cái công thức là đây là cái độ đo MSE như bình thường ha, chúng ta sẽ có thêm một cái đại lượng lambda ở đây, và ở đây sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 15,
      "start_timestamp": "0:10:20",
      "end_timestamp": "0:11:06"
    }
  },
  {
    "page_content": "thêm một cái đại lượng lambda ở đây, và ở đây sẽ là 1 - Alpha nhân cho ờ chuẩn hóa L2 và đây sẽ là chuẩn hóa L1. Thì đây là cái sự kết hợp của chuẩn hóa L2 và L1 thì cái phương pháp này nó hy vọng rằng là nó có thể ờ khắc phục được những cái điểm yếu của Lasso và Ridge, và khai thác được những cái điểm mạnh của Lasso và Ridge regression. Thì đây nó nằm trong cái nhóm nó gọi là ensemble hay là kết hợp các cái mô hình. Ở đây thì cả ba cái mô hình là Elastic Net, rồi Ridge regression và Lasso",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 16,
      "start_timestamp": "0:11:01",
      "end_timestamp": "0:11:37"
    }
  },
  {
    "page_content": "là Elastic Net, rồi Ridge regression và Lasso regression thì chúng ta đều thấy có sự xuất hiện của một cái siêu tham số đó là lambda. Vậy thì lambda ở đây nó có vai trò là gì? Thì nếu nói theo cái kiểu vui á, MSE nó là đại diện cho cái sai số của giá trị dự đoán và giá trị mong muốn. trong khi đó, beta nó lại có một cái ý nghĩa khác hoàn toàn đó là cái chuẩn hóa, đó là cái norm ờ của các cái tham số của mình. Như vậy nếu xét về ý nghĩa thì hai cái đại lượng này là nó không liên quan với nhau.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 17,
      "start_timestamp": "0:11:32",
      "end_timestamp": "0:12:04"
    }
  },
  {
    "page_content": "cái đại lượng này là nó không liên quan với nhau. Một bên là đo lường cái sai số, một bên là người ta mong muốn là đưa vào cái cái tham số của mình vào. Như vậy nó nó khác với thứ nguyên. Thì đưa cái lambda này vào thì nó sẽ giúp cho mình cân bằng giữa hai cái thứ nguyên này. Nếu như lambda này mà càng lớn, tức là mình đang muốn tập trung cái mô hình vào để cố gắng đưa các cái giá trị norm của beta của các cái beta này (beta mũ này) sẽ càng lúc càng nhỏ. Tức là chúng ta sẽ dồn lực để huấn luyện",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "nhỏ. Tức là chúng ta sẽ dồn lực để huấn luyện ở đây. Còn nếu như lambda mà nhỏ, tức là chúng ta đang dồn lực ưu tiên cho cái việc đó là tối ưu cái sai số của cái độ lỗi của mình đó. Thì đó chính là cái ý nghĩa của lambda.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=CYj_-IiXSIg",
      "filename": "CYj_-IiXSIg",
      "title": "[CS116 - Buổi 7] Part 3",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tiếp theo đó là chúng ta sẽ tổng hợp đặc trưng một cái kỹ thuật nữa đó là kỹ thuật tổng hợp đặc trưng thì nó sẽ là cái phần ngược của cái kỹ thuật ở phía trên đó là phân rã đặc trưng ha tức là chúng ta từ một cái chuỗi chúng ta sẽ tách nó làm hai đặc trưng còn ở đây chúng ta làm cái thao tác ngược lại đó là chúng ta từ hai cái chuỗi chúng ta sẽ trộn nó lại để thành một cái đặc trưng mới ví dụ ở đây chúng ta rồi Ở đây thì chúng ta chưa có cái mẫu dữ liệu đúng không Ờ đây cái mẫ d liện của mình nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:42"
    }
  },
  {
    "page_content": "liệu đúng không Ờ đây cái mẫ d liện của mình nó nằm bên đây rồi thì chúng ta sẽ có ma là giống như nhà sản xuất và hãng ATT Tức là cái dòng xe sedan crossover dướ SUV rồi thì ở đây chúng ta sẽ trộn Chúng ta sẽ kết hợp ma và type này để tạo ra thành một cái đặc trưng mới đó thì với cái ma type này thì nó sẽ có là Toyota sedan Audi sedan Honda sedan thì đây sẽ là một cái đặc trưng mới được tổng hợp từ hai cái đặc trưng cũ theo cái kiểu là nối chuỗi tiếp theo đó là kỹ thuật gom nhóm tổng hợp đặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 1,
      "start_timestamp": "0:00:39",
      "end_timestamp": "0:01:28"
    }
  },
  {
    "page_content": "tiếp theo đó là kỹ thuật gom nhóm tổng hợp đặc trưng theo kiểu theo theo nhóm thì chúng ta sẽ xét một cái dữ liệu như sau Đà Nẵng đúng không ở đây là cái cột thành phố và cột mức lương đó thì Đà Nẵng mức lương 10 triệu Hồ Chí Minh mức lương 20 triệu Hà Nội mất lôn 15 triệu Hồ Chí Minh mất lươn 8 triệu vân vân thì chúng ta đang muốn chia cái này ra thành các cái phân khúc chúng ta đang muốn gom nhóm nhóm nó thành các cái mức lương trung bình ví dụ Đà Nẵng thì cái người này có cái mức lương là 10",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 2,
      "start_timestamp": "0:01:23",
      "end_timestamp": "0:02:05"
    }
  },
  {
    "page_content": "Đà Nẵng thì cái người này có cái mức lương là 10 nhưng nó sẽ muốn tạo ra thêm một cái cột nữa trong cái cột này á thì nó sẽ có mức Lưu Trung bình của cái thành phố Đà Nẵng rồi Hà Nội đúng không Thì nó sẽ ngoài cái lương của cái cái cái dòng dữ liệu quan sát được là 15 nó sẽ có thêm một cái giá trị nữa đó là trung bình mức lương của Hà Nội để sau này ví dụ như chúng ta có thể đối chiếu được cái salary với lại cái lương trung bình của Hà Nội thì để làm được cái việc này chúng ta sẽ dùng cái lệnh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 3,
      "start_timestamp": "0:01:57",
      "end_timestamp": "0:02:34"
    }
  },
  {
    "page_content": "làm được cái việc này chúng ta sẽ dùng cái lệnh Là rou Bu chúng ta sẽ r by City tức là thành phố thì ở đây là chúng ta sẽ gom nhóm theo từng cái thành phố khác nhau ví dụ Hà Nội sẽ đi một nhóm Hà Nội Hồ Chí Minh sẽ đi một nhóm Hồ Chí Minh rồi sau đó chúng ta sẽ lấy ra cái cột salary sau khi đã gom nhóm xong chúng ta sẽ lấy cái thông tin của cộp salary và agg tổng hợp lại thông qua cái phương thức đó là trung bình tức là lấy trung bình theo từng thành phố trung bình mức lương theo từng thành phố",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 4,
      "start_timestamp": "0:02:30",
      "end_timestamp": "0:03:16"
    }
  },
  {
    "page_content": "phố trung bình mức lương theo từng thành phố rồi rồi Cách thứ hai đó là chúng ta có thể dùng cái lệnh là transform đó rồi thì cả hai cách Và bây giờ chúng ta đã tạo ra thêm chúng ta sẽ tạo ra thêm một cái cột mới đó là lương trung bình average salary thì nó sẽ được gán bằng là rú by theo City salary transform me này rồi sau đó chúng ta sẽ lấy cái cột này để gắn vào cái cột mới đó là average salary thì hai cái cách làm này nó khác vì nhau với cái cách làm aggregation đầu tiên á là nó sẽ đi theo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 5,
      "start_timestamp": "0:03:10",
      "end_timestamp": "0:03:54"
    }
  },
  {
    "page_content": "cách làm aggregation đầu tiên á là nó sẽ đi theo nhóm Đà Nẵng đương Trung bình 12 Hà Hồ Chí Minh lương trung bình 13 Hà Nội lương trung bình 15 ví dụ vậy đây Các cái con số ở đây là các cái con số mình fake mình generate ra ngẫu nhiên chứ không có ý nghĩa về mặt thực tiễn Nha và với cái cách làm arig này thì chúng ta sẽ rap sẽ không thể nối cái cột này vào bên trong cái bản dữ liệu này Tại vì nó bị trên về à cái số lượng đúng không Thì thì mình sẽ dùng cái phương pháp là transform mình sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 6,
      "start_timestamp": "0:03:47",
      "end_timestamp": "0:04:28"
    }
  },
  {
    "page_content": "mình sẽ dùng cái phương pháp là transform mình sẽ transform thì với cái cách transform này thì số dòng dữ liệu của mình nó sẽ trùng với cái số dòng dữ liệu ở đây khi đó chúng ta r vào nó sẽ dễ hơn đó thì cái 12 12 13.3 thì đây là những cái con số bản chất là những con số ở trên thôi nhưng nó khác ở chỗ đó là nó đã được trải ra cho từng dòng dữ liệu Và khi đó thì cái việc chúng ta gắn thêm vào cái cột lương trung bình ở đây thì nó rất là dễ dàng một cái kỹ thuật khác nữa đó chính là kỹ thuật về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 7,
      "start_timestamp": "0:04:23",
      "end_timestamp": "0:05:03"
    }
  },
  {
    "page_content": "một cái kỹ thuật khác nữa đó chính là kỹ thuật về gom cụng phân khúc ở phía trên á là chúng ta sẽ gom nhóm gom nhóm theo từng cái giá trị từng giá trị và sau đó chúng ta sẽ thực hiện một cái thao tác thống kê Ví dụ như chúng ta có thể thực hiện là tính giá trị lớn nhất giá trị nhỏ nhất giá trị trung bình trong ví dụ này chúng ta sẽ làm cái thao tác là tính giá trị trung bình sau khi Đạ C nhóm xong còn ở đây là chúng ta sẽ gom nhóm dựa trên chín cái giá trị à của mình để phân nó ra thành các cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 8,
      "start_timestamp": "0:04:57",
      "end_timestamp": "0:05:38"
    }
  },
  {
    "page_content": "giá trị à của mình để phân nó ra thành các cái phân khúc khác nhau đó thì ở đây chúng ta sẽ xét một cái ví dụ ha Cũng là cái dataframe ở phía trên nhưng à giá trị lương của một người ở Đà Nẵng vậy thì trong trường hợp này à CT chúng ta sẽ không còn xem xét nữa mà chúng ta sẽ xem xét trực tiếp dựa trên cái giá trị ở đây và chúng ta ta sẽ xem cái 10 này nè Nó sẽ có cái mối tương quan như thế nào so với các cái giải lương còn lại thì trong cái phần lý thuyết chúng ta thấy rồi có một cái ví dụ rồi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 9,
      "start_timestamp": "0:05:35",
      "end_timestamp": "0:06:10"
    }
  },
  {
    "page_content": "lý thuyết chúng ta thấy rồi có một cái ví dụ rồi một người là 8,8 điểm mình sẽ không biết người đó là cao hay thấp khi mình không đặt nó trong cái bối cảnh là một cái phân bố thế thì ở đây cũng vậy 10 mình sẽ không biết Cái người này là phân phúc nào do đó mình sẽ dùng cái Thục toán gom nhóm trên tất cả các cái dữ liệu của Lương ở đây thì ở đây chúng ta sẽ phải sử dụng một cái mô hình học không giám sát ờ và trong những cái bài tiếp theo chúng ta sẽ học đến cái chi tiết về cái lý thuyết của nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 10,
      "start_timestamp": "0:06:05",
      "end_timestamp": "0:06:47"
    }
  },
  {
    "page_content": "sẽ học đến cái chi tiết về cái lý thuyết của nó nhưng ở đây chúng ta sẽ sử dụng cái thực toán C cụng như là một cái công cụ để giúp cho mình có thể là tạo mới đặc trưng ha thì chúng ta sẽ khai báo là ờ cit l. cluster và thụ toán ở đây mình dùng là camin và số cụng ở đây mình đang muốn tức là tương ứng là cái số phân Cúc tức là các cái giải lương ở đây mình đang muốn chia nó ra làm ba phân khúc do đó mình sẽ để là n cluster là bằng 3 và nó sẽ được khởi tạo một cách tự động rồi và camin chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 11,
      "start_timestamp": "0:06:40",
      "end_timestamp": "0:07:19"
    }
  },
  {
    "page_content": "khởi tạo một cách tự động rồi và camin chúng ta sẽ fit predict cái cột Gallery salary để chúng ta sẽ xem coi là ừ với từng cái giá trị lương ở đây là sẽ được xếp vào cái phân khúc nào Ờ 10 sẽ xếp phân khúc nào 20 sẽ xếp ph phúc trào rồi sau đó thì chúng ta sẽ é cái kiểu giá trị này chúng ta sẽ é cái kiểu này về cái kiểu category rồi Tức là bình thường đây là con số nhưng mà mình hiểu đó là con số theo kiểu category chứ nó không phải là một cái con số dạng hồi quy Tức là cái giá trị liên tục và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 12,
      "start_timestamp": "0:07:14",
      "end_timestamp": "0:08:00"
    }
  },
  {
    "page_content": "số dạng hồi quy Tức là cái giá trị liên tục và ở đây chúng ta sẽ có ba giá trị thì chúng ta thấy là salary thì mức lương của mình là phân khúc số 1 8 Xin lỗi 10 là phân khúc Số 1 12 là phân húc số 1 8 là phân húc số 1 nhưng chúng chúng ta sẽ có một số cái phân khúc rất là cao Ví dụ như 35 30 thì đây là hai cái phân Cúc là nằm trong nhóm số hai rồi hai cái nhóm phương Cúc khác đó là 10 xin lỗi 20 và 15 đúng không Thì nó sẽ nằm trong cùng một cái nhóm là ở giữa m số 0 và chúng ta lưu ý là do cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 13,
      "start_timestamp": "0:07:55",
      "end_timestamp": "0:08:34"
    }
  },
  {
    "page_content": "nhóm là ở giữa m số 0 và chúng ta lưu ý là do cái salary coaster này nó là ở dạng catery nên các cái giá trị này không có cái tính so sánh được Tức là không có cái sự so sánh lớn bé phân khúc này lớn hơn phân khúc kia các cái phân khúc này độc lập nhau chứ nếu không chúng ta sẽ hiểu là ờ 20 15 Mà tại sao nó lại là phân khúc số 0 nó nhỏ hơn cái phân khúc là 10 là phân khúc số 1 tức là lương ở đây thì lớn hơn là salary là 10 nhưng mà cái giá trị phân khúc nó lại thấp hơn thì một lần nữa khẳng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 14,
      "start_timestamp": "0:08:29",
      "end_timestamp": "0:09:10"
    }
  },
  {
    "page_content": "phân khúc nó lại thấp hơn thì một lần nữa khẳng định đó là các cái giá trị cluster ở đây không mang tính chất so sánh chỉ mang tính chất đại diện cuối cùng đó là chúng ta sử dụng K thuật giảm chiều với thuật toán không giám sát đó là pca thì cũng tương tự như vậy cái lý thuyết của pca chúng ta sẽ thảo luận ở trong cái phần các cái mô hình học không giám sát Còn trong trường hợp này chúng ta sẽ sử dụng PC như là một cái công cụ thì để chạy được cái Thục toán pca này chúng ta sẽ load dataset Lan",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 15,
      "start_timestamp": "0:09:05",
      "end_timestamp": "0:09:51"
    }
  },
  {
    "page_content": "Thục toán pca này chúng ta sẽ load dataset Lan rồi cũng sử dụng các cái phương pháp scale dữ liệu scale dữ liệu tức là các cái Thục toán pca mà muốn hoạt động tốt thì trước khi làm chúng ta sẽ phải scale cái dữ liệu đó về cái dạng phân bố chuẩn dùng là scaler scaler sẽ fit transform cái đặc trưng X này vào và chúng ta sẽ gán trực tiếp vào cái miếng x Ở Đây Rồi sau đó thì chúng ta convert cái X này về dạng dataframe và chúng ta sẽ gọi cái tập toán pci với cái số lượng component mình muốn giảm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 16,
      "start_timestamp": "0:09:44",
      "end_timestamp": "0:10:25"
    }
  },
  {
    "page_content": "pci với cái số lượng component mình muốn giảm xuống là còn 2 mặc định ban đầu là mình có B BN đặc trưng nhưng mà ở đây mình đang muốn giảm nó xuống còn hai chiều đó thì PC sẽ là bằng 2 và chúng ta sẽ fit transform chúng ta sẽ tạo ra cái x new x new này sẽ là hai cái cột cuối là pc1 và pc2 nếu chúng ta chỉ dùng pci 1 pci để mà đi phân lớp thì chúng ta có thể sử dụng trực tiếp Còn khi chúng ta không chắc chắn là các cái đặc trưng này nó có tốt hay không tốt thì chúng ta hãy combine Chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 17,
      "start_timestamp": "0:10:18",
      "end_timestamp": "0:11:03"
    }
  },
  {
    "page_content": "không tốt thì chúng ta hãy combine Chúng ta sẽ kết hợp nó với lại cái đặc trưng gốc là các cái đặc trưng mà chúng ta đã tô màu ở đây Đây là hai đặc trưng mới được nén được giảm chiều từ bốn cái đặc trưng này hay nói cách khác là hai cái đặc trưng này nó có chứa cái thông tin phân loại tốt Ồ có chứa nhiều thông tin để giúp cho chúng ta có thể phân loại và chúng ta sẽ tích hợp với lại các cái đặt trưng góc như vậy thì chúng ta từ bốn đặc trưng chúng ta đã tạo ra thêm hai đặc trưng nữa hai đặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chúng ta đã tạo ra thêm hai đặc trưng nữa hai đặc trưng này bản chất là cái Ờ phái sinh từ bốn cái đặc trưng đầu vào ở đây rồi và trên đây đó là những cái phương pháp à một số cái phương pháp mà chúng ta có thể tạo mới thêm cái đặc trưng đấy để cho cái các cái mô hình máy học về sau có đủ cái thông tin để giúp cho chúng ta có thể đưa vào các cái máy phân lớp một cách hiệu quả",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dckcCVv4tUI",
      "filename": "dckcCVv4tUI",
      "title": "[CS116 - Buổi 4] Part 6 (tt)",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "đối với thư viện pandas thì ở đây chúng ta sẽ có một cái file là pandas cheat sheet hay còn gọi là một cái cuốn sổ tay lưu các cái hàm hoặc là các cái phương thức mà chúng ta thường sử dụng ở trong thư viện này thì đầu tiên đó chính là các cái hàm liên quan đến việc là tạo DataFrame creating DataFrame thì một cái DataFrame nó sẽ là một cái cấu trúc bảng trong đó sẽ bao gồm các cái cột như chúng ta có thể thấy ở đây à cột của mình sẽ bao gồm các cái tên cột A, B, C và hàng của mình thì sẽ lưu các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:37"
    }
  },
  {
    "page_content": "tên cột A, B, C và hàng của mình thì sẽ lưu các cái quan sát. Mỗi một cái hàng dữ liệu này sẽ là một cái quan sát, một cái mẫu dữ liệu. Ở bên trái ngoài cùng thì chúng ta sẽ thấy là nó không có cái tên cột đó tương ứng là cái chỉ số là index. Thì mục tiêu của cái chỉ số này là để giúp cho cái cấu trúc bảng có thể truy xuất nhanh, có thể làm các cái thao tác sắp xếp, vân vân được thực hiện một cách nhanh chóng. Và các cái giá trị ở trong các cái dòng dữ liệu này thì nó có thể là những kiểu dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 1,
      "start_timestamp": "0:00:32",
      "end_timestamp": "0:01:12"
    }
  },
  {
    "page_content": "dòng dữ liệu này thì nó có thể là những kiểu dữ liệu bất kỳ chứ không nhất thiết phải là kiểu dữ liệu số. Nó có thể là kiểu dữ liệu chuỗi, có thể là kiểu dữ liệu số thực, vân vân. Và để tạo ra một cái DataFrame thì chúng ta chỉ đơn giản đó là PD. Thì PD là cái alias là viết tắt của pandas. PD. DataFrame và chúng ta sẽ truyền vào một cái dictionary. Trong cái dictionary này thì sẽ có chứa các cái tên cột và tương ứng các cái giá trị theo hàng, tên cột và các giá trị cho từng hàng. Và chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 2,
      "start_timestamp": "0:01:05",
      "end_timestamp": "0:01:46"
    }
  },
  {
    "page_content": "tên cột và các giá trị cho từng hàng. Và chúng ta lưu ý là số lượng các cái phần tử trong à cái list này á nó phải bằng nhau. Chứ nếu mà chúng ta cho nó chênh lệch nhau thì nó vẫn sẽ chạy được nhưng mà nó sẽ điền các cái giá trị NaN vào. Rồi cái cột chỉ số này thì như đã đề cập, nó chính là cái chỉ mục của cái pandas để giúp cho chúng ta có thể tăng cái tốc độ truy xuất. Rồi à cái phần thứ hai đó là liên quan đến cái hàm Reshaping data, tức là mình sẽ thực hiện cái việc là thay đổi các cái kích",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 3,
      "start_timestamp": "0:01:39",
      "end_timestamp": "0:02:21"
    }
  },
  {
    "page_content": "sẽ thực hiện cái việc là thay đổi các cái kích thước của bảng dữ liệu của mình. Thì đơn giản nhất mà chúng ta hay sử dụng đó chính là chúng ta làm thao tác nối bảng, nối cái bảng DataFrame 1 và DataFrame 2. Đây là DataFrame 1 và đây là DataFrame 2. Thì nếu như chúng ta nối mặc định là cái axis, cái axis của mình nè, là cái tham số này nè, nó mặc định là bằng 0. Do đó ở đây người ta không điền và nó sẽ chồng lên hàng trên hàng dưới, nó sẽ chồng lên. Thì nó sẽ tạo ra một cái DataFrame như thế",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 4,
      "start_timestamp": "0:02:15",
      "end_timestamp": "0:02:52"
    }
  },
  {
    "page_content": "lên. Thì nó sẽ tạo ra một cái DataFrame như thế này. Thì hai cái DataFrame df1 và df2 nó sẽ phải có cùng cái số lượng cột và tên cột giống nhau. Rồi nếu như chúng ta nối cột, à xin lỗi, chúng ta nối cái bảng mà theo kiểu là nối ngang hàng thì đây là DataFrame 1 và đây là DataFrame 2. Thì khi nối ngang hàng thì đây là DataFrame 1 và DataFrame 2 nó sẽ phải có cùng cái số dòng, sẽ có cùng số dòng hoặc là có cùng số quan sát. Ngoài ra thì DataFrame còn có hỗ trợ các cái phương thức như là melt và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 5,
      "start_timestamp": "0:02:47",
      "end_timestamp": "0:03:28"
    }
  },
  {
    "page_content": "còn có hỗ trợ các cái phương thức như là melt và pivot. Melt thì thực hiện cái việc đó là chuyển đổi các cái cột dữ liệu của mình sang cái dạng hàng, sang các cái dạng hàng. Ví dụ như ở đây là chúng ta có ba cột tương ứng là ba màu là màu xanh, màu cam và màu xanh dương. Thì ở đây các cái giá trị của xanh cam và xanh dương thì nó sẽ được gắn các cái giá trị tương ứng. Ví dụ như ở đây là màu xanh lá ha, thì nó sẽ có hai giá trị. Thì tương ứng nó sẽ có xanh lá giá trị một, xanh lá giá trị hai.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 6,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:02"
    }
  },
  {
    "page_content": "sẽ có xanh lá giá trị một, xanh lá giá trị hai. Màu cam thì nó sẽ có hai giá trị. Thì tương ứng ở đây nó sẽ tên cột là màu cam giá trị một, màu cam giá trị hai. Và cứ như vậy. Pivot là cái thao tác ngược lại, nó chuyển từ, nó sẽ chuyển từ cái dạng dòng sang cái dạng cột, các cái giá trị dạng dòng về cái giá trị dạng cột. Rồi ngoài ra thì nó còn hỗ trợ các cái thao tác khác, ví dụ như là reset index, reset_index trong DataFrame. Rồi sắp xếp các index của mình theo thứ tự tăng dần hoặc giảm dần,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 7,
      "start_timestamp": "0:03:56",
      "end_timestamp": "0:04:44"
    }
  },
  {
    "page_content": "của mình theo thứ tự tăng dần hoặc giảm dần, hoặc là đổi cột, à xin lỗi, đổi tên của các cái cột của mình. Ví dụ như cái cột nào có tên là Y thì sẽ được đổi tên lại thành là YE như vậy. Ngoài ra thì pandas còn hỗ trợ các cái thao tác truy vấn và lấy những cái hàng hoặc là lấy những cái cột riêng biệt. Ví dụ chúng ta thấy ở nguyên một cái bảng như thế này và df['Length'] lớn hơn 7. Tức là trích ra những cái dòng mà nó thỏa mãn cái điều kiện là cái giá trị của một cái cột nào đó, ví dụ cột này là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 8,
      "start_timestamp": "0:04:38",
      "end_timestamp": "0:05:17"
    }
  },
  {
    "page_content": "giá trị của một cái cột nào đó, ví dụ cột này là cột Length, cột chiều dài lớn hơn 7. Thì trong số những cái giá trị trong cái cột này, cái cột Length này thì giá trị nào mà lớn hơn 7 thì nó sẽ lấy ra. Ví dụ như ở đây nó có hai dòng này có hai giá trị này là lớn hơn 7 thì nó sẽ pick ra hai dòng. Thì nó sẽ tạo ra là một cái bảng mới bao gồm là hai cái quan sát với cái trường Length của mình là lớn hơn 7. Rồi drop_duplicates. Tức là cái bảng của mình nó sẽ có tình huống là hai cái dòng dữ liệu có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 9,
      "start_timestamp": "0:05:12",
      "end_timestamp": "0:05:51"
    }
  },
  {
    "page_content": "nó sẽ có tình huống là hai cái dòng dữ liệu có giá trị giống nhau thì nó sẽ loại bỏ đi, nó chỉ chừa lại duy nhất một cái một cái dòng thôi. Rồi ngoài ra thì còn rất nhiều những cái hàm khác, ví dụ như là df.head() tức là lấy ra N dòng đầu tiên. Hoặc là df.tail() là lấy ra N dòng cuối cùng. Rồi các cái thao tác trên cột. Ví dụ như đây là cái hàm, đây là cái phương thức để cho chúng ta có thể lấy ra những cái cột. Ví dụ như trong cái bảng này có rất nhiều cột, nhưng mà bây giờ chúng ta đang muốn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 10,
      "start_timestamp": "0:05:48",
      "end_timestamp": "0:06:24"
    }
  },
  {
    "page_content": "nhiều cột, nhưng mà bây giờ chúng ta đang muốn lọc ra những cái cột màu xanh như thế này thì chúng ta sẽ điền cái tên cột mà chúng ta muốn lấy dữ liệu, ví dụ cột Width, cột Height và cột Species. À cột Width, cột Length, Species. Thì ở đây chúng ta có ba cột và nó sẽ trích ra ba cột này thôi. Rồi ngoài ra thì nó có thể cho phép chúng ta truy vấn ví dụ như là df.query() và chúng ta sẽ truyền vào một cái chuỗi. Trong đó thì có tên của cái cột, tên của cái cột của mình và cái điều kiện. Điều kiện",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 11,
      "start_timestamp": "0:06:20",
      "end_timestamp": "0:06:57"
    }
  },
  {
    "page_content": "của cái cột của mình và cái điều kiện. Điều kiện để mà mình truy vấn ra. Thì cái này cái lệnh này nó cũng tương đương với lại cái lệnh này. Ngoài ra chúng ta có thể kết hợp, ví dụ Length lớn hơn 7 và Width nó phải bằng 8. Chúng ta có thể kết hợp. Rồi chúng ta cũng có thể sử dụng với các cái regular expression, biểu thức chính quy. Rồi để truy xuất đến các cái tập con của dòng vừa, dòng vừa cột thì chúng ta có thể sử dụng các cái phương thức liên quan ví dụ như là .loc và .iloc để chọn ra các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 12,
      "start_timestamp": "0:06:51",
      "end_timestamp": "0:07:34"
    }
  },
  {
    "page_content": "quan ví dụ như là .loc và .iloc để chọn ra các cái dòng và cột hoặc là cả hai. Thì đây là một số cái ví dụ. Ví dụ ở đây là chọn ra các cái dòng có chỉ số là từ 10 cho đến 20 là .iloc từ cho đến 20. Rồi hoặc là chúng ta muốn lấy ra những cái cột, những cái cột tại cái vị trí là số 1, số 2 hoặc là số 5. Tức là chúng ta có rất nhiều cột, chúng ta sẽ lấy hết tất cả các dòng, nhưng mà cột thì chúng ta chỉ lấy ra cột có chỉ số là 1, 2 và 5 vân vân. Thì đây là những cái hàm liên quan đến cái việc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 13,
      "start_timestamp": "0:07:28",
      "end_timestamp": "0:08:10"
    }
  },
  {
    "page_content": "đây là những cái hàm liên quan đến cái việc là lấy ra một tập con của các cái dòng và cột. Rồi các cái thao tác liên quan đến cái việc là tổng hợp dữ liệu hoặc là xử lý dữ liệu thì ở giữa đây là có lẽ là một trong những cái nhóm phương thức mà được sử dụng rất nhiều trong phạm vi môn học này. dropna() tức là trong cái bảng của mình nếu như có những cái ô nào mà có giá trị là không xác định, là NaN hoặc là null á thì nó sẽ loại bỏ đi. Nó sẽ loại bỏ đi những cái dòng đó. fillna() tức là những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 14,
      "start_timestamp": "0:08:03",
      "end_timestamp": "0:08:41"
    }
  },
  {
    "page_content": "đi những cái dòng đó. fillna() tức là những cái giá trị nào mà có giá trị là NaN thì nó sẽ được thay thế bằng một cái giá trị mà mình chỉ định. Thì đây là Handling Missing data, tức là xử lý với những cái dữ liệu bị thiếu. Rồi chúng ta có thể tạo thêm những cái cột mới. Thì đây cũng là những cái phương thức được sử dụng rất là nhiều cho cái môn học này, ví dụ như cái bước gọi là Feature Engineering thì chúng ta sẽ tạo ra những cái đặc trưng mới. Mà muốn tạo ra những đặc trưng mới thì chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 15,
      "start_timestamp": "0:08:34",
      "end_timestamp": "0:09:10"
    }
  },
  {
    "page_content": "Mà muốn tạo ra những đặc trưng mới thì chúng ta sẽ phải tạo thêm những cái cột mới. Ví dụ ở đây chúng ta sẽ có một cái phương thức là đơn giản đó là chúng ta tạo ra thêm một cái cột nữa có tên là Volume. Và Volume này thì được tính là bằng cột Length nhân với cột Height nhân với lại cột Width. Thì ở đây là rất nhiều những cái phương thức và chúng ta hoàn toàn có thể tham khảo cũng như là tìm hiểu chi tiết hơn. Đối với những cái phương thức nào chúng ta không biết thì chúng ta có thể click vào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 16,
      "start_timestamp": "0:09:05",
      "end_timestamp": "0:09:10"
    }
  },
  {
    "page_content": "chúng ta không biết thì chúng ta có thể click vào đây. Ví dụ như groupby, chúng ta đang không hiểu groupby là gì thì chúng ta có thể là click vô đây để đến cái trang web gốc của pandas. Và trong cái trang web gốc của pandas này thì chúng ta sẽ xem các cái ví dụ minh họa tương ứng để chúng ta có thể hiểu rõ hơn.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dDjSutHDckw",
      "filename": "dDjSutHDckw",
      "title": "[CS116 - Buổi 2] Part 6",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và chúng ta sẽ có bốn cái loại thông tin khi chúng ta giám sát cái mô hình để kiểm tra xem là có cái sự biến động của cái mô hình của mình hay không á hoặc là của cái dữ liệu của mình hay không thì chúng ta sẽ có Ờ có thể giám sát mô hình với bốn cái loại thông tin sau cái thông tin từ trên xuống dưới thì chúng ta sẽ thấy là cái mức độ thông tin thông tin informative của mình nó sẽ càng lúc càng giảm giờ nhưng đồng thời là từ trên xuống thì cái cách mà chúng ta đo lường á là nó cái độ khó của nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:44"
    }
  },
  {
    "page_content": "mà chúng ta đo lường á là nó cái độ khó của nó nó sẽ càng lúc nó càng tăng lên càng xuống dưới thì cái xin lỗi càng xuống dưới thì cái cách mà chúng ta đo lường nó sẽ càng dễ và càng lên trên thì cái cách đo lường của chúng ta sẽ càng khó và về yếu tố thông tin thì càng lên trên thì cái lượng thông tin của chúng ta đó có nhiều thông tin hơn còn càng phía dưới thì cái lượng thông tin của chúng ta nó sẽ càng ít hơn thì điều này nó cũng là một cái yếu tố cân bằng cái gì mà khó đo lường thì nó sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 1,
      "start_timestamp": "0:00:39",
      "end_timestamp": "0:01:18"
    }
  },
  {
    "page_content": "yếu tố cân bằng cái gì mà khó đo lường thì nó sẽ có cái thông tin nó nhiều hơn và cái gì mà nó dễ đo lường thì cái lượng thông tin của nó ít hơn thì đầu tiên đó chính là các cái Model Metrics tức là các cái độ đo để đánh giá hiệu năng à mô hình của mô hình ví dụ như độ đo về độ chính xác hoặc là cái độ đo về sai số cho cái việc dự đoán trên các cái bài toán hồi quy ví dụ độ đo MSE độ đo về khoảng cách thì đây là các cái độ đo mà dùng phổ biến để đánh giá cái mô hình của mình do đó thì ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 2,
      "start_timestamp": "0:01:13",
      "end_timestamp": "0:02:10"
    }
  },
  {
    "page_content": "để đánh giá cái mô hình của mình do đó thì ở đây chúng ta sẽ không có thảo luận lại cách mà chúng ta giám sát cái mô hình dựa trên các cái độ đo này nó cũng hoàn toàn tương tự như cái cách mà chúng ta giám sát mô hình chúng ta đánh giá mô hình trong cái quá trình mà huấn luyện cũng như là tìm ra những cái bộ tham số tốt nhất cho cái mô hình của mình và cái loại metric tiếp theo cũng khá là thú vị đó chính là Business Metric bình thường á thì mình sử dụng các cái độ đo mang tính chất gọi là độ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 3,
      "start_timestamp": "0:02:05",
      "end_timestamp": "0:02:49"
    }
  },
  {
    "page_content": "sử dụng các cái độ đo mang tính chất gọi là độ đo khoa học độ đo về chính xác độ đo về khoảng cách đúng không độ phủ vân vân thì đó là những cái độ đo khoa học và đó là những độ đo chuẩn nhưng mà có nhiều tình huống chúng ta sẽ rất khó để có thể đánh giá được cái độ chính xác của cái mô hình lấy ví dụ như cho cái bài toán về gợi ý cái sản phẩm recommendation system thì không biết là một cái gợi ý là đúng hay sai chúng ta sẽ rất khó để có thể xác định rất khó để mà có thể gán nhãn được vậy thì ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 4,
      "start_timestamp": "0:02:42",
      "end_timestamp": "0:03:28"
    }
  },
  {
    "page_content": "định rất khó để mà có thể gán nhãn được vậy thì ở đây chúng ta sẽ phải sử dụng những cái yếu tố về kinh doanh Ví dụ như khi từ khi chúng ta vận hành cái hệ thống gợi ý sản phẩm thì chúng ta thấy là cái doanh thu của mình giảm xuống Tức là cái việc gợi ý này nó không hiệu quả Nhưng mà đồng thời ngược lại nếu như cái doanh thu của mình nó tăng lên kể từ khi mình áp dụng cái mô hình gợi ý sản phẩm này thì điều đó chứng tỏ cho thấy là mô hình của mình nó đã có những cái sự phản hồi tích cực đối với",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 5,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:05"
    }
  },
  {
    "page_content": "nó đã có những cái sự phản hồi tích cực đối với cái thuật toán mà mình đã triển khai đó thì đây là một cái loại độ đo khá là thú vị nó liên quan đến yếu tố về hiệu quả của mô hình về mặt kinh tế và một cái kiểu nữa đó cái loại thông tin nữa để chúng ta có thể giám sát đó chính là Model Input và Prediction cái này thì nó giống như là chúng ta sẽ giám sát xem với những cái đầu vào và những cái đầu ra dự đoán của mô hình nó có đáp ứng được với lại cái định dạng của cái hệ thống hay không Tức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 6,
      "start_timestamp": "0:04:00",
      "end_timestamp": "0:04:44"
    }
  },
  {
    "page_content": "cái định dạng của cái hệ thống hay không Tức là chúng ta sẽ kiểm tra xem khi mô hình vận hành thì cái dữ liệu đầu vào của mình đưa vào nó có đúng hay không rồi cái dữ liệu đầu ra cái dữ liệu dự đoán của mình nó ra đúng cái định dạng hay không đồng thời đó là cái kết quả của mình nó có phù hợp hay không thì đó gọi là đánh giá về cái Input và cái Prediction Tức là cái Input và cái Output của mình Cuối cùng đó chính là cái System Performance Tức là cái hiệu năng của hệ thống thì cái hiệu năng của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 7,
      "start_timestamp": "0:04:39",
      "end_timestamp": "0:05:26"
    }
  },
  {
    "page_content": "cái hiệu năng của hệ thống thì cái hiệu năng của hệ thống này nó có thể là cái tốc độ thực thi hoặc là cái tài nguyên mà mình sử dụng của hệ thống Ví dụ như kể từ khi chúng ta triển khai cái mô hình thì chúng ta thấy là cái mô hình của mình à Xin lỗi cái hệ thống của mình nó bị quá tải nhiều hơn cái quá tải này nó thể hiện ở việc là cái Lượng tài nguyên tính toán nó tăng lên hoặc là cái tốc độ thực thi nó chậm hơn hoặc là cái số lượng GPU nó được sử dụng tại một thời điểm nhiều hơn cái tỷ lệ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 8,
      "start_timestamp": "0:05:18",
      "end_timestamp": "0:06:04"
    }
  },
  {
    "page_content": "sử dụng tại một thời điểm nhiều hơn cái tỷ lệ phần trăm của cái lượng CPU sử dụng là cái lượng RAM mà chúng ta sử dụng nó nhiều hơn dẫn đến là cái mô hình của mình à Nó gây hại cho cái hệ thống của mình về mặt hiệu năng thì bây giờ chúng ta sẽ nhìn từ trên xuống dưới ha hai cái nhóm đầu tiên á đó chính là Model Metrics và Business metric thì để làm được hai để mà có thể đánh giá được hai cái thông tin này để giám sát được hai cái thông tin này thì chúng ta cần phải xây dựng một cái bộ ground",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 9,
      "start_timestamp": "0:06:01",
      "end_timestamp": "0:06:46"
    }
  },
  {
    "page_content": "thì chúng ta cần phải xây dựng một cái bộ ground truth đây sẽ là một cái bộ dữ liệu rất là quan trọng để giúp cho chúng ta có thể đánh giá một cách khách quan muốn mà có được đánh giá tính toán ra được những cái metrics này thì chúng ta phải có cái dữ liệu ground truth rồi đối với hai cái loại metric này Business Metric và Model Input và Prediction thì ở đây nó chỉ mang tính chất là tương đối Dạ và đối với hai cái hình thức cuối cùng thì chúng ta thấy đó là cái hàm lượng thông tin của mình nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 10,
      "start_timestamp": "0:06:39",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "ta thấy đó là cái hàm lượng thông tin của mình nó sẽ ít hơn cái hàm lượng thông tin của mình nó sẽ sẽ ít hơn hai cái phần đầu tiên hai cái cái thông tin đầu tiên thì nó sẽ cho cái Ờ cái thông tin của mình nó nhiều hơn nhưng bù lại để mà có thể đo được hai cái này thì nó sẽ khó hơn cái khó nó nằm ở chỗ đó là làm sao chúng ta có được một cái bộ ground truth chuẩn làm sao chúng ta có thể đánh giá được cái mô hình cái hiệu quả kinh tế của mô hình của mình là tốt hay xấu thì đây chính là những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 11,
      "start_timestamp": "0:07:14",
      "end_timestamp": "0:07:59"
    }
  },
  {
    "page_content": "mình là tốt hay xấu thì đây chính là những cái yếu tố gây ra ờ trở ngại cho cái quá trình mà đánh giá mô hình của mình có nhiều khi cái độ đo này Công thức tính thì rất là rõ ràng nhưng mà cái gán nhãn này nè thì không hẳn lúc nào nó cũng đúng nó bị yếu tố chủ quan bởi cái người gán nhãn đó thì đó là một số cái loại thông tin được sử dụng để khảo sát cho cái mô hình và làm sao để có thể giám sát cái mô hình một cách gọi là hiệu quả thì chúng ta sẽ chia cái trục thời gian của mình ra chia cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 12,
      "start_timestamp": "0:07:54",
      "end_timestamp": "0:08:48"
    }
  },
  {
    "page_content": "sẽ chia cái trục thời gian của mình ra chia cái trục thời gian của mình ra vào cái thời điểm đầu á thì chúng ta sẽ thực hiện cái bước số một đó là chúng ta sẽ chọn một cái phạm vi hay là một cái cửa sổ một cái Window của cái dữ liệu mà chúng ta được cho đó là tốt tức là chúng ta cho rằng cái dữ liệu này là tốt tổng quát và phù hợp đó thì cái dữ liệu này sẽ được sử dụng để làm tham chiếu sau đó thì sang bước số hai chúng ta sẽ chọn một cái phạm vi mới một cái phạm vi mới của dữ liệu và chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 13,
      "start_timestamp": "0:08:42",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "mới một cái phạm vi mới của dữ liệu và chúng ta sẽ tiến hành lấy cái dữ liệu của cái phạm vi mới này để so sánh và đối chiếu với lại cái dữ liệu mà chúng ta đã chọn ở cái mức số 1 trước đó Thế thì làm sao để xác định xem hai cái dữ liệu này có cái sự biến động hay không thì chúng ta sẽ phải sử dụng những cái metric Tại sao Tại vì nếu như chúng ta nhìn bằng mắt thường á thì chúng ta sẽ dễ nếu mà dùng trực giác á thì nó rất dễ bị gọi là chủ quan bởi cái yếu tố con người mọi đánh giá thì nó chỉ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 14,
      "start_timestamp": "0:09:19",
      "end_timestamp": "0:10:19"
    }
  },
  {
    "page_content": "bởi cái yếu tố con người mọi đánh giá thì nó chỉ nên dựa trên những cái số liệu gọi là tính toán được những cái con số đó thì chúng ta sẽ phải sử dụng những cái metric và để so sánh hai cái metric này thì chúng ta có rất nhiều cách khác nhau Ví dụ như chúng ta có thể sử dụng các cái độ đo về khoảng cách của dữ liệu hoặc là chúng ta có thể sử dụng các cái độ đo về phân bố so nó cũng là khoảng cách nhưng mà thay vì là khoảng cách giữa từng phần tử với nhau Ví dụ như phần tử này với phần tử này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 15,
      "start_timestamp": "0:10:14",
      "end_timestamp": "0:10:57"
    }
  },
  {
    "page_content": "tử với nhau Ví dụ như phần tử này với phần tử này phần tử này với phần tử này đó thì nó gọi là Element- distance thì chúng ta sẽ sử dụng những như là KL divergence thì đây là một cái độ đo về khoảng cách giữa hai cái phân bố thế thì dựa trên những cái độ đo khoảng cách này chúng ta sẽ phải set những cái ngưỡng và chúng ta sẽ phải chọn những cái ngưỡng nào sao cho cái độ tin cậy của mình cao nhất thế thì ở đây nó thuộc cái phạm trù của thống kê thuộc cái phạm trù thống kê do đó thì trong phạm vi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 16,
      "start_timestamp": "0:10:50",
      "end_timestamp": "0:11:49"
    }
  },
  {
    "page_content": "cái phạm trù thống kê do đó thì trong phạm vi của cái bài học này thì chúng ta chỉ nêu cái lý thuyết để làm sao chúng ta có thể giám sát được cái mô hình đó là chúng ta chọn hai cái thời điểm cái thời điểm đầu tiên là cái thời điểm mà mình nghĩ rằng dữ liệu của mình tốt và đây sẽ là cái tham chiếu và sau đó thì chúng ta sẽ theo dõi giám sát cái dữ liệu của mình tại một cái thời điểm mình tham chiếu Sau đó chúng ta sẽ phải sử dụng những độ đo để đánh giá một cách định lượng cái sự phân bố của dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 17,
      "start_timestamp": "0:11:42",
      "end_timestamp": "0:12:30"
    }
  },
  {
    "page_content": "giá một cách định lượng cái sự phân bố của dữ liệu của mình tại hai cái thời điểm này thì khi đó chúng ta mới biết rằng dữ liệu của mình nó có bị biến động hay không Thế thì trong trường hợp nếu chúng ta kết luận Nếu chúng ta kết luận là mô hình của mình nó đã có cái sự dịch chuyển thì chúng ta sẽ làm gì mà nếu như không có sự dịch chuyển thì chúng ta sẽ làm gì đối với trường hợp mà mô hình của mình có cái sự dịch chuyển thì chúng ta sẽ đánh giá xem cái sự dịch chuyển này nguyên nhân của nó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 18,
      "start_timestamp": "0:12:26",
      "end_timestamp": "0:13:12"
    }
  },
  {
    "page_content": "xem cái sự dịch chuyển này nguyên nhân của nó là gì và cái phạm vi của nó ra sao ví dụ nguyên nhân của mình đó là do có những cái người người dùng mà xấu Họ tạo ra những cái bộ dữ liệu giả hoặc là tạo ra những cái mẫu dữ liệu không thật nhưng mà nó chỉ có tác dụng trong ngắn hạn thì khi đó chúng ta sẽ không cần phải thay đổi mô hình đúng không Chúng ta không cần thay đổi mô hình Tại vì chúng ta sẽ không phục vụ cho một nhóm đối tượng như vậy chúng ta chỉ phục vụ cho những cái nhóm đối Trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 19,
      "start_timestamp": "0:13:06",
      "end_timestamp": "0:13:43"
    }
  },
  {
    "page_content": "chúng ta chỉ phục vụ cho những cái nhóm đối Trong trường hợp có cái sự dịch chuyển nhưng mà đây là một cái sự dịch chuyển theo chu kỳ đúng không thì chúng ta sẽ phải xây dựng cái mô hình làm sao đó nó có thể hành xử tốt trên cái loại dữ liệu có yếu tố về chu kỳ này thì hiện nay nó biệt cho cái loại dữ liệu có chu kỳ do đó chúng ta sẽ chọn cái mô hình phù hợp cho cái loại dữ liệu có chu kỳ Còn trong trường hợp dữ liệu của mình gọi là biến động đột ngột Ví dụ như khi đại dịch COVID diễn ra và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 20,
      "start_timestamp": "0:13:39",
      "end_timestamp": "0:14:20"
    }
  },
  {
    "page_content": "đột ngột Ví dụ như khi đại dịch COVID diễn ra và chúng ta đánh giá rằng là nó sẽ không thay đổi trong ngắn hạn mà nó đã thay đổi Ờ trong thời điểm hiện tại cho đến tương lai luôn Tức là cái sự thay đổi này là dài hạn và gần như không thể quay trở lại cái phân bố chuẩn hoặc là về cái phân bố mà tham chiếu trước đây thì khi đó chúng ta sẽ buộc phải thay đổi cái mô hình của mình Chúng ta sẽ phải thay đổi mô hình của mình bằng cách đó là chúng ta sẽ lấy mẫu lại dữ liệu và chúng ta huấn luyện lại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 21,
      "start_timestamp": "0:14:16",
      "end_timestamp": "0:14:44"
    }
  },
  {
    "page_content": "sẽ lấy mẫu lại dữ liệu và chúng ta huấn luyện lại cái mô hình thì trên đây đã là một số cái tình huống là khi cái dữ liệu trong cái thời điểm cái phạm vi mới nó có cái sự dịch chuyển nhưng mà À Sự dịch chuyển này thì ngắn hạn hay là sự thay đổi gọi là dài hạn thì chúng ta sẽ có những cái hành vi khác nhau lên trên cái mô hình của mình tùy ha nếu mà ngắn hạn chúng ta sẽ không cần Còn nếu mà Sự dịch chuyển này là dài hạn và thay đổi mang tính chất là bản chất của cái sự việc thì chúng ta sẽ phải",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "là bản chất của cái sự việc thì chúng ta sẽ phải cập nhật lại cái mô hình của mình bằng cách là chúng ta sẽ lấy mẫu lại dữ liệu và huấn luyện lại còn trường hợp cái phân bố dữ liệu của mình nó không có cái sự dịch chuyển này không có cái sự dịch chuyển thì chúng ta sẽ giữ nguyên mô hình nhưng đồng thời chúng ta cũng sẽ phải kiểm tra và giám sát cái sự dịch sự dịch chuyển này thì trong cái bài học ngày hôm nay thì chú",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=dJaFUvTRrTw",
      "filename": "dJaFUvTRrTw",
      "title": "[CS116 - Buổi 14] Part 5_2",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chào mừng các bạn đến với môn học CS116 lập trình Python cho máy học hôm nay chúng ta sẽ đến với bài mở đầu thì tôi xin tự giới thiệu Tôi tên là Nguyễn Văn Thiệu hiện đang là trưởng phòng thí nghiệm truyền thông đa phương tiện Đại học Công Nghệ Thông Tin Đại học Quốc gia thành phố Hồ Chí Minh và nội dung của ngày hôm nay thì chúng ta sẽ tìm hiểu về các cái nội dung chính trong cái môn học này, sau đó thì chúng ta sẽ lướt qua một số lịch sử và thành tựu của máy học và cuối cùng đó là chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:48"
    }
  },
  {
    "page_content": "tựu của máy học và cuối cùng đó là chúng ta sẽ giới thiệu về cái ngôn ngữ lập trình Python, thật ra không phải là giới thiệu mà chúng ta sẽ là ôn tập tại vì cái ngôn ngữ lập trình Python các bạn chắc đã cũng đã từng học trong một số cái môn học trước đây cũng như là có thể sử dụng nó như là một cái thành phần quan trọng trong cái đồ án môn học của các bạn. Về nội dung của khóa học này thì khóa học này sẽ diễn ra trong vòng 15 tuần và sau đây sẽ là nội dung của các cái kiến thức mà chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 1,
      "start_timestamp": "0:00:43",
      "end_timestamp": "0:01:29"
    }
  },
  {
    "page_content": "là nội dung của các cái kiến thức mà chúng ta sẽ được thảo luận trong cái môn học này. Đầu tiên đó là Tuần số 1 thì chúng ta sẽ giới thiệu môn học và lướt qua lịch sử, rồi ôn tập ngôn ngữ Python như đã đề cập trước đây. Tiếp theo Tuần thứ hai chúng ta sẽ học về hai cái thư viện rất là phổ biến và nổi tiếng của Python đó là thư viện NumPy và Matplotlib. NumPy là một cái thư viện giúp cho chúng ta có thể lập trình tính toán trên các cái công cụ sử dụng các cái công cụ của đại số tuyến tính.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 2,
      "start_timestamp": "0:01:24",
      "end_timestamp": "0:02:09"
    }
  },
  {
    "page_content": "cụ sử dụng các cái công cụ của đại số tuyến tính. Matplotlib là một trong những cái thư viện rất là nổi tiếng để mà giúp cho chúng ta trực quan hóa dữ liệu. Thì đây sẽ là hai cái thư viện, hai cái công cụ sẽ đi xuyên suốt với chúng ta trong suốt môn học này. Bên cạnh đó thì chúng ta sẽ còn một cái thư viện nữa. Tuy nhiên thì cái thư viện này nó tên là Scikit-learn. Cái thư viện này nó sẽ đi xuyên suốt trong toàn bộ những cái Tuần số 3 và số 4 cho đến hết. Do đó thì chúng ta sẽ không có cái phần",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 3,
      "start_timestamp": "0:02:04",
      "end_timestamp": "0:02:38"
    }
  },
  {
    "page_content": "đến hết. Do đó thì chúng ta sẽ không có cái phần ôn tập này mà chúng ta sẽ sử dụng nó như là một cái công cụ chính cho cái môn học, còn các cái thư viện như là NumPy và Matplotlib là nền tảng. Tuần thứ ba thì chúng ta sẽ tiến hành tìm hiểu về một cái quy trình xây dựng một cái mô hình máy học như thế nào, nó sẽ gồm các cái bước thực hiện như thế nào. Tuần thứ tư thì chúng ta sẽ được học về các cái kỹ thuật về tiền xử lý dữ liệu, đó là cái bước đầu tiên. Và đánh giá một cái mô hình máy học đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 4,
      "start_timestamp": "0:02:33",
      "end_timestamp": "0:03:17"
    }
  },
  {
    "page_content": "tiên. Và đánh giá một cái mô hình máy học đó là cái bước cuối cùng. Sang các cái tuần tiếp theo như là Tuần 5, Tuần 6 cho đến các tuần tiếp theo thì chúng ta sẽ học về các cái mô hình máy học, ví dụ như là mô hình máy học không giám sát. Tuần 7 cho đến Tuần 10 thì chúng ta sẽ học về các cái mô hình có giám sát. Tuần 11 cho đến Tuần 12 thì chúng ta sẽ tìm cách tối ưu các siêu tham số. Tuần thứ 13 thì chúng ta sẽ tiến hành đó là học tổng hợp, còn gọi là đây là một trong những cái kỹ thuật để giúp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 5,
      "start_timestamp": "0:03:10",
      "end_timestamp": "0:03:55"
    }
  },
  {
    "page_content": "là đây là một trong những cái kỹ thuật để giúp tăng cường hiệu quả độ chính xác của hệ thống rất là nhiều và được sử dụng trong các cuộc thi của Kaggle. Và Tuần 14 và 15 sẽ được dành để báo cáo đồ án cuối kỳ cũng như là ôn tập chuẩn bị đề thi cuối kỳ. Về hình thức đánh giá thì môn học này chúng ta sẽ có 3 cái thành phần điểm chính. Thành phần đầu tiên đó chính là bài tập sẽ bao gồm là 30% điểm. Để có được cái cột điểm này thì chúng ta sẽ phải làm các cái bài quiz, tức là các cái bài trắc nghiệm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 6,
      "start_timestamp": "0:03:51",
      "end_timestamp": "0:04:33"
    }
  },
  {
    "page_content": "các cái bài quiz, tức là các cái bài trắc nghiệm trên lớp và bài tập lập trình hàng tuần. Một điểm thứ hai đó chính là đồ án chiếm 30% điểm thì chúng ta sẽ làm đồ án theo nhóm và chúng ta sẽ nộp báo cáo vào cuối kỳ. Và thành phần thứ ba có tỷ trọng điểm cao nhất, 40% điểm đó là cột điểm cuối kỳ thì nó sẽ là cột điểm của phần thi viết và đề sẽ là đề đóng được tổ chức tập trung. Tiếp theo thì chúng ta sẽ cùng lướt qua một số cái thành tựu lịch sử và thành tựu của máy học. Thì như đã đề cập ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 7,
      "start_timestamp": "0:04:26",
      "end_timestamp": "0:05:08"
    }
  },
  {
    "page_content": "sử và thành tựu của máy học. Thì như đã đề cập ở trong cái tên môn học của chúng ta, tên môn học đó chính là lập trình Python cho máy học. Thế thì máy học nó xuất hiện từ khi nào? Thì trước khi máy học thì chúng ta sẽ có cái khái niệm nó gọi là AI hay còn gọi là Artificial Intelligence. Và ngay từ khi máy tính mới ra đời thì các cái nhà khoa học đã có một cái mong muốn đó là làm sao cho máy tính có khả năng thông minh như con người. Thì cái khái niệm về AI nó đã xuất hiện từ những năm 1950.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 8,
      "start_timestamp": "0:05:05",
      "end_timestamp": "0:05:47"
    }
  },
  {
    "page_content": "niệm về AI nó đã xuất hiện từ những năm 1950. Nhưng mà trong cái giai đoạn từ năm 1950 cho đến những năm 1980 thì nó chưa có nhiều cái thành tựu nổi bật. Mãi cho đến khi cái khái niệm về Machine Learning, tức là máy học ra đời, tức là vào khoảng những năm 1980 thì các nhà khoa học họ suy nghĩ rằng là nếu như mình thiết kế các cái thuật toán AI mà một cách không tường minh, tức là chúng ta sẽ lên các cái rule, các cái luật hoặc là lập trình các cái bước xử lý thuật toán cố định thì nó sẽ khiến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 9,
      "start_timestamp": "0:05:42",
      "end_timestamp": "0:06:18"
    }
  },
  {
    "page_content": "cái bước xử lý thuật toán cố định thì nó sẽ khiến cho cái trí tuệ nhân tạo của mình nó không có khả năng uyển chuyển và thích ứng dần theo thời gian. Mà đối với cái bộ não của con người thì một trong những cái tính chất rất là quan trọng đó chính là có khả năng thích ứng theo môi trường, thích ứng theo thời gian. Do đó thì cái khái niệm Machine Learning ra đời và nó sẽ lấy được cái ý tưởng chính đó chính là có thể học từ dữ liệu, tức là các thuật toán máy học nó sẽ có tính thích nghi và uyển",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 10,
      "start_timestamp": "0:06:13",
      "end_timestamp": "0:06:53"
    }
  },
  {
    "page_content": "toán máy học nó sẽ có tính thích nghi và uyển chuyển theo thời gian dựa trên dữ liệu. Nếu như chúng ta đưa vào những cái dữ liệu khác nhau thì cái mô hình nó sẽ thay đổi cái hành vi đi theo đó. Và gần đây thì Deep Learning là một nhánh của Machine Learning. Deep Learning thì xuất hiện cũng tương đối là lâu. Tuy nhiên đến năm 2010 và chính xác là năm 2012 trong một cái cuộc thi của ImageNet về phân loại hình ảnh thì các cái mô hình cho cái kết quả vượt trội so với các cái mô hình Machine",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 11,
      "start_timestamp": "0:06:47",
      "end_timestamp": "0:07:28"
    }
  },
  {
    "page_content": "kết quả vượt trội so với các cái mô hình Machine Learning truyền thống. Và từ đó thì các nhà khoa học máy tính họ đã chuyển sang cái hướng là nghiên cứu về Deep Learning để khai thác những cái điểm mạnh cũng như là tối ưu được cái vấn đề về dữ liệu. Tại vì sau cuộc cách mạng về Internet và sự phát triển rầm rộ của mạng xã hội thì các cái dữ liệu do người dùng tạo ra ngày càng nhiều. Và với cái khối lượng dữ liệu ngày càng nhiều như vậy thì các cái mô hình máy học cũng phải có khả năng học được",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 12,
      "start_timestamp": "0:07:23",
      "end_timestamp": "0:08:07"
    }
  },
  {
    "page_content": "mô hình máy học cũng phải có khả năng học được các dữ liệu này thì Deep Learning ra đời là để khai thác được cái nguồn dữ liệu rất là lớn của cái kỷ nguyên Internet. Thì máy học nói chung và trí tuệ nhân tạo, máy học nói chung và Deep Learning nói riêng thì gần đây có rất nhiều những cái thành tựu. Thì ở đây có thể kể đến ví dụ trong lĩnh vực về robot thì các cái bot có khả năng chiến thắng các cái nhà dựa trên trò chơi hoặc là chơi game, các game thủ. Ví dụ như cái con bot AlphaGo có thể thắng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 13,
      "start_timestamp": "0:08:03",
      "end_timestamp": "0:08:45"
    }
  },
  {
    "page_content": "thủ. Ví dụ như cái con bot AlphaGo có thể thắng được các kiện tướng cờ vây. Hoặc là các cái con bot trong AI và có thể chiến thắng được các cái game StarCraft, Warcraft là các game chiến thuật và có cái tính linh động rất là cao nhưng mà các cái bot này vẫn có thể chiến thắng được các game thủ. Ngoài ra thì trong lĩnh vực về xử lý dữ liệu bảng và ứng dụng trong những cái ngành nghề về tài chính thì chúng ta thấy rằng là nó ứng dụng rất là nhiều. Mình khá là mọi nơi. Thì các cái mô hình tài",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 14,
      "start_timestamp": "0:08:40",
      "end_timestamp": "0:09:17"
    }
  },
  {
    "page_content": "Mình khá là mọi nơi. Thì các cái mô hình tài chính định lượng hiện nay thì đâu đó đều có sử dụng các cái kỹ thuật của học máy. Và không chỉ dừng lại ở đó thì các cái mô hình máy học còn có ứng dụng trong các lĩnh vực về xử lý và liên quan đến cái xử lý dữ liệu hình ảnh và xử lý ngôn ngữ tự nhiên. Và các thành tựu này thì nó áp dụng trong rất nhiều những cái lĩnh vực của cuộc sống bao gồm lĩnh vực chăm sóc sức khỏe, lĩnh vực về tài chính, thương mại điện tử và môi trường thông minh. Thì trong đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 15,
      "start_timestamp": "0:09:11",
      "end_timestamp": "0:09:53"
    }
  },
  {
    "page_content": "điện tử và môi trường thông minh. Thì trong đó đình đám nhất gần đây chính là cái môi trường thông minh thì chúng ta thấy là các cái xe hơi nó đã có khả năng gọi là tự lái rồi. Các cái con bot có khả năng hỗ trợ người dùng trong cái việc là theo dõi công việc rồi theo dõi lịch trình hoặc là trả lời các cái câu hỏi từ những cái yêu cầu cá nhân. Và gần đây thì trong các cái thiết bị thông minh ở bên trong gia đình như tivi chẳng hạn thì chúng ta có thể điều khiển bằng giọng nói. Thay vì trước đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 16,
      "start_timestamp": "0:09:48",
      "end_timestamp": "0:10:28"
    }
  },
  {
    "page_content": "thể điều khiển bằng giọng nói. Thay vì trước đây chúng ta sẽ phải sử dụng các cái lệnh, các cái nút lệnh tốn rất là nhiều thời gian thì ở đây chúng ta có thể điều khiển bằng giọng nói bằng cách dễ dàng và tự nhiên. Thì trước cái sự bùng nổ về các cái thành tựu về AI, về Machine Learning như vậy thì nó làm cho chúng ta có một cái động lực đó là trong cái môn học này làm sao chúng ta có thể sử dụng các công nghệ của máy học để mình có thể áp dụng vào trong cuộc sống. Và có rất nhiều những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 17,
      "start_timestamp": "0:10:23",
      "end_timestamp": "0:11:07"
    }
  },
  {
    "page_content": "vào trong cuộc sống. Và có rất nhiều những cái hướng tiếp cận khác nhau hiện nay. Tuy nhiên thì đối với cái lập trình truyền thống thì chúng ta thấy rằng là các cái mô hình máy tính nó đòi hỏi là chúng ta phải cung cấp cho nó những cái rule, tức là những cái quy luật. Thì các cái rule này thì thông thường là sẽ dựa trên những cái kinh nghiệm của các cái nhà khoa học, chúng ta biết rồi, các kinh nghiệm của các nhà khoa học. Về lưu ý là các nhà khoa học này thì không phải là đến từ ngành máy tính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 18,
      "start_timestamp": "0:11:01",
      "end_timestamp": "0:11:46"
    }
  },
  {
    "page_content": "học này thì không phải là đến từ ngành máy tính mà các cái rule này thì sẽ đến từ các cái nhà khoa học trong cái lĩnh vực chuyên môn. Ví dụ như chúng ta làm một cái hệ thống cho tài chính thì chúng ta cần các cái chuyên gia trong lĩnh vực về tài chính. Chúng ta làm trong lĩnh vực y tế thì chúng ta cần các cái chuyên gia về y tế sẽ ngồi lại và liệt kê ra những cái rule, những cái quy luật được sử dụng trong các lĩnh vực đó để từ đó chúng ta sẽ hiện thực hóa, chúng ta sẽ cài đặt các cái rule này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 19,
      "start_timestamp": "0:11:40",
      "end_timestamp": "0:12:33"
    }
  },
  {
    "page_content": "thực hóa, chúng ta sẽ cài đặt các cái rule này vào bên trong máy tính và đưa ra được cái kết quả. Còn cái hướng tiếp cận mà máy học hay còn gọi là học máy thì chúng ta sẽ cung cấp các cái câu hỏi và câu trả lời hay còn gọi các đáp án. Kết hợp với một số cái dữ liệu khác thì các cái mô hình Machine Learning nó sẽ tự tìm ra quy luật. Khác ở chỗ đầu vào và đầu ra này. Đối với phương pháp truyền thống thì chúng ta cần phải có những cái rule do các chuyên gia đưa ra. Còn trong cái mô hình máy học",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 20,
      "start_timestamp": "0:12:28",
      "end_timestamp": "0:13:14"
    }
  },
  {
    "page_content": "chuyên gia đưa ra. Còn trong cái mô hình máy học thì Machine Learning nó sẽ giống như là cái chuyên gia, nó sẽ dựa trên dữ liệu thô và các cái đáp án để mà tự rút trích rút trích ra được các quy luật. Như vậy thì sau này chúng ta chỉ cần cung cấp cho các cái mô hình máy học các cái dữ liệu đầu vào, các cái bộ câu hỏi hoặc là đáp án, câu hỏi và đáp án thì nó sẽ thích nghi và nó sẽ tìm ra được các quy luật mới. Tiếp theo chúng ta sẽ tìm hiểu về ngôn ngữ lập trình Python. Thì tại tiếp theo lại là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 21,
      "start_timestamp": "0:13:06",
      "end_timestamp": "0:13:54"
    }
  },
  {
    "page_content": "ngữ lập trình Python. Thì tại tiếp theo lại là ngôn ngữ lập trình Python. Hiện nay thì chúng ta đã biết, ngoài Python, chúng ta có rất nhiều những cái ngôn ngữ lập trình khác, ví dụ như là C, C++, rồi C#, Java, rồi PHP, và gần đây thì cũng có ngôn ngữ rất là nổi tiếng là Go. Vậy thì câu hỏi là tại sao chúng ta lại dùng Python cho máy học mà không phải là C++ cho máy học, C# cho máy học, Java cho máy học? Để trả lời câu hỏi này thì chúng ta phải xem xét rất nhiều những cái khía cạnh khác nhau",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 22,
      "start_timestamp": "0:13:50",
      "end_timestamp": "0:14:06"
    }
  },
  {
    "page_content": "xem xét rất nhiều những cái khía cạnh khác nhau của các ngôn ngữ lập trình. Python. Chúng ta thấy rằng là Python có thể vừa có thể lập trình được ứng dụng. Ví dụ như chúng ta có thể dùng Python để lập trình web với thư viện là Django, rồi chúng ta có thể dùng Python để lập trình app trên desktop. Và Python thì cũng có thể dùng để lập trình về máy học. Python thì cũng có thể được sử dụng để lập trình về Big Data. Như vậy thì chúng ta có thể thấy liệt kê sơ qua một số cái phạm vi ứng dụng của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "liệt kê sơ qua một số cái phạm vi ứng dụng của Python. Thì Python ứng dụng trong rất nhiều những cái lĩnh vực khác nhau, dẫn đến là chúng ta thấy Python nó rất là đa năng. Chính cái sự đa năng này thì nó cho cái kết quả đó là Python là một trong những cái top trending, tức là những cái ngôn ngữ lập trình được sử dụng phổ biến trong vài năm gần đây.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=eY--6WX1hAQ",
      "filename": "eY--6WX1hAQ",
      "title": "[CS116 - Lập trình Python cho Máy học] Video 1.1: Giới thiệu môn học",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng tìm hiểu về cách thức triển khai một cái mô hình máy học ở dưới dạng ứng dụng web tức là chúng ta sẽ xây dựng một cái web interface để cho phép người dùng có thể nhập vào các cái input và sau đó thì chúng ta sẽ gọi cái request lên trên server để server có thể load mô hình và dự đoán cái giá trị đầu ra dựa trên các cái input đầu vào của người dùng. Thế thì tình huống sử dụng cho cái việc là sử dụng ứng dụng web triển khai cái mô hình máy học đó chính là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:39"
    }
  },
  {
    "page_content": "web triển khai cái mô hình máy học đó chính là chúng ta muốn demo những cái tính năng chính của mô hình máy học đối với khách hàng. Trong thực tế thì thông thường các cái tính năng của mô hình máy học á là chỉ một phần nhỏ trong cái hệ thống của mình, tức là khi chúng ta đưa ra được các cái dự đoán thì chúng ta sẽ dựa trên các cái giá trị dự đoán của mô hình máy học chúng ta sẽ đi làm tiếp các cái tính năng về mặt phần mềm khác đó. Tuy nhiên thì nếu mà tích hợp cái tính năng đó vào bên trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:35",
      "end_timestamp": "0:01:11"
    }
  },
  {
    "page_content": "nếu mà tích hợp cái tính năng đó vào bên trong một cái phần mềm khác thì nó sẽ tốn rất là nhiều thời gian. Trong khi đó cái mục tiêu chính của mình là mình muốn xem mô hình của mình dự đoán như thế nào với những cái yêu cầu đầu vào của người dùng. Do đó, web sẽ là một trong những cái phương thức để giúp cho mình demo cái tính năng chính của cái việc dự đoán đó một cách nhanh nhất. Và đây là một cái cách tiếp cận nó sẽ giúp cho mô hình của mình có thể đến được với cái số đông người dùng một cách",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:07",
      "end_timestamp": "0:01:38"
    }
  },
  {
    "page_content": "thể đến được với cái số đông người dùng một cách rất là dễ dàng thông qua cái môi trường web thì chúng ta chỉ cần có mạng internet và chúng ta không cần phải cài đặt gì trên máy của khách hàng hết. Khách hàng chỉ cần sử dụng một cái trình duyệt phổ biến như là Google Chrome, Safari hoặc là Firefox là đã có thể sử dụng được cái mô hình máy học của mình rồi. Họ không cần phải cài đặt các cái thư viện rất là phức tạp. Ví dụ như không cần phải cài đặt ngôn ngữ lập trình Python, không cần cài đặt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 3,
      "start_timestamp": "0:01:34",
      "end_timestamp": "0:02:14"
    }
  },
  {
    "page_content": "đặt ngôn ngữ lập trình Python, không cần cài đặt thư viện là Scikit-learn rồi TensorFlow hay PyTorch vân vân. Thì đây là những cái ờ thư viện nó cài cũng là phức tạp đối với những cái người dùng mà không chuyên về lập trình đúng không? Thì cách tiếp cận mà làm ra một cái giao diện web này sẽ giúp cho rất nhiều người không có chuyên môn về lập trình có thể sử dụng được cái mô hình máy học một cách dễ dàng. Và ở đây chúng ta sẽ nhắc lại cái mô hình, cái sơ đồ à cho cái việc triển khai ứng dụng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 4,
      "start_timestamp": "0:02:10",
      "end_timestamp": "0:02:51"
    }
  },
  {
    "page_content": "cái sơ đồ à cho cái việc triển khai ứng dụng web. Mô hình sẽ được cài đặt ở một cái server. Mô hình sẽ được triển khai ở một cái server và cái server này sẽ tạo ra các cái API để cho phép các cái ứng dụng nội bộ cũng như là máy trạm có thể tiếp cận được đến cái ứng dụng của mình một cách dễ dàng đó. Rồi sau đó thì chúng ta sẽ viết một cái ứng dụng web, ứng dụng web này nó sẽ gọi cái API của cái model để mà thực thi. Thì đây là cái cách làm rất là bình thường của mình. Thế thì nếu như muốn làm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 5,
      "start_timestamp": "0:02:45",
      "end_timestamp": "0:03:27"
    }
  },
  {
    "page_content": "là bình thường của mình. Thế thì nếu như muốn làm một cái ứng dụng web bình thường chúng ta sẽ phải có hai mảng, mảng đầu tiên đó là frontend, mảng thứ hai đó là backend. Đối với frontend thì chúng ta sẽ cần phải học các cái ngôn ngữ lập trình để có thể làm được các cái giao diện. Ví dụ chúng ta sẽ phải học về HTML, CSS, rồi JavaScript, rất là phức tạp, rất là nhiều ngôn ngữ lập trình đúng không? Về backend thì chúng ta sẽ phải sử dụng các cái ngôn ngữ Ví dụ như là Node.js hoặc là Java hoặc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 6,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:09"
    }
  },
  {
    "page_content": "ngữ Ví dụ như là Node.js hoặc là Java hoặc là PHP. Thì đây là những cái ngôn ngữ lập trình cho phía backend. Và để làm một cái ứng dụng web chúng ta sẽ phải học hết tất cả thảy đó, các cái ngôn ngữ này cũng như là một trong các cái ngôn ngữ backend như là Node.js, Java và PHP thì nó sẽ tốn rất là ít thời gian. Thế thì làm sao mà chúng ta có thể sử dụng được à Cái ngôn ngữ lập trình Python? Đây là một cái ngôn ngữ lập trình mà những cái người chuyên về mô hình họ rất là thuần thục đúng không? Mà",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 7,
      "start_timestamp": "0:04:03",
      "end_timestamp": "0:04:47"
    }
  },
  {
    "page_content": "về mô hình họ rất là thuần thục đúng không? Mà chúng ta có thể sử dụng Python để có thể lập trình web được thì đó là một cái điều tuyệt vời. Thì rất may mắn đó là chúng ta đã có hai cái thư viện để giúp cho chúng ta làm được cái việc này đó chính là Streamlit và Gradio. Thì đây là hai cái, hai cái thư viện giúp cho chúng ta có thể tạo ra một cái ứng dụng web để thử nghiệm các cái mô hình máy học của mình với ngôn ngữ lập trình Python. Như vậy chúng ta sẽ sử dụng Python để lập trình web mà không",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 8,
      "start_timestamp": "0:04:41",
      "end_timestamp": "0:05:20"
    }
  },
  {
    "page_content": "ta sẽ sử dụng Python để lập trình web mà không hề biết và không cần thiết phải sử dụng HTML, CSS, JavaScript Hoặc là các cái ngôn ngữ để lập trình backend như trên đây. Như vậy thì với cái cách sử dụng Streamlit và Gradio á thì chúng ta cũng sẽ không cần hiểu lắm các cái khái niệm về API. Tại vì bên dưới ngầm bên dưới nó đã tạo ra các cái API để sử dụng cái mô hình của mình luôn rồi đó. Thì đây chính là một cái điểm mạnh đó là giúp cho cái người không chuyên về phần mềm, không chuyên về lập",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 9,
      "start_timestamp": "0:05:15",
      "end_timestamp": "0:05:47"
    }
  },
  {
    "page_content": "không chuyên về phần mềm, không chuyên về lập trình web vẫn có thể tạo ra được một trang web một cách nhanh chóng với cái ngôn ngữ Python. Tức là chúng ta chỉ chuyên môn về mô hình thôi, biết sử dụng Python với các cái thư viện machine learning thôi thì vẫn có thể tạo ra được ứng dụng web một cách dễ dàng và nhanh chóng. Thì trên đây là hai cái thư viện rất là nổi tiếng và phổ biến trong cái việc xây dựng những cái ứng dụng web nhằm thử nghiệm các cái mô hình máy học. Đầu tiên đó chính là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 10,
      "start_timestamp": "0:05:42",
      "end_timestamp": "0:06:16"
    }
  },
  {
    "page_content": "các cái mô hình máy học. Đầu tiên đó chính là Streamlit. Streamlit rất là phù hợp để cho những cái người làm về data science, về khoa học dữ liệu. Khi chúng ta đã huấn luyện xong cái mô hình chúng ta có thể sử dụng cái thư viện này để customize, để có thể tạo ra những cái giao diện tùy biến để cho người dùng có thể nhập vào các cái điều kiện đầu vào, cấu hình, chọn lựa các cái cái tham số và có thể trực quan hóa vẽ các cái biểu đồ rất là đẹp. Còn Gradio thì nó sẽ chuyên hơn cho lĩnh vực về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 11,
      "start_timestamp": "0:06:14",
      "end_timestamp": "0:06:49"
    }
  },
  {
    "page_content": "Còn Gradio thì nó sẽ chuyên hơn cho lĩnh vực về machine learning, tức là người dùng chỉ cần tập trung vào cái phần machine learning. Còn cái việc thiết kế các cái ứng dụng, các cái giao diện web để mà có thể thử nghiệm các cái mô hình máy học này thì Gradio nó đã có sẵn những cái mẫu cho chúng ta có thể sử dụng rất là dễ dàng. Thì trong phạm vi của bài học này thì chúng ta sẽ tập trung vào cái thư viện đó là Streamlit. Và đây là cái video quảng cáo của Streamlit đó là chúng ta sẽ code hoàn toàn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 12,
      "start_timestamp": "0:06:43",
      "end_timestamp": "0:07:24"
    }
  },
  {
    "page_content": "của Streamlit đó là chúng ta sẽ code hoàn toàn bằng ngôn ngữ Python đó. Chúng ta sẽ import thư viện là Streamlit và in ra màn hình là st. Như vậy chúng ta thấy là chúng ta sẽ viết lập trình web, tạo ra một cái trang web bằng cái phong cách lập trình rất là Python. Sau khi chúng ta thử thay đổi các các control cấu hình cái giao diện xong, chúng ta sẽ deploy cái ứng dụng này thông qua cái dịch vụ hosting của Streamlit thông qua những cái cú click chuột. Nó có thể giúp cho chúng ta tạo ra được một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 13,
      "start_timestamp": "0:07:17",
      "end_timestamp": "0:08:07"
    }
  },
  {
    "page_content": "Nó có thể giúp cho chúng ta tạo ra được một cái trang web một cách dễ dàng. Thì đây là cái video quảng cáo của Streamlit. Trong phạm vi của bài này thì chúng ta sẽ sử dụng Streamlit để làm một cái ví dụ web. Thì để học trong cái lĩnh vực về lập trình web nó sẽ có rất nhiều những cái control để cho chúng ta có thể customize, chúng ta có thể tạo ra cái giao diện ngoài cái label để giúp cho chúng ta hiển thị cái nhãn hoặc là cái đoạn text mà mình muốn người dùng người ta đọc đúng không? Textbox là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 14,
      "start_timestamp": "0:08:03",
      "end_timestamp": "0:08:45"
    }
  },
  {
    "page_content": "người dùng người ta đọc đúng không? Textbox là hiển thị những cái ô để cho người input. Rồi button tức là để kích hoạt cái sự kiện khi người dùng người ta click vào một cái button nó sẽ tạo ra một cái sự kiện để mà thực thi một cái công việc nào đấy. Thì đó là kích hoạt một cái sự kiện. Thì ngoài ba cái control chính này á mà chúng ta sẽ sử dụng trong cái bài này thì nó sẽ còn rất nhiều những cái control khác. Lấy ví dụ như là sẽ có các cái control liên quan đến cái việc là hiển thị hình ảnh,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 15,
      "start_timestamp": "0:08:38",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "liên quan đến cái việc là hiển thị hình ảnh, rồi có các cái control liên quan đến chọn lựa những cái nó gọi là dropdown button, rồi radio button đó. Thì đây sẽ là những cái giao diện để giúp cho chúng ta cấu hình và đưa ra các cái chọn lựa, các cái option rồi checkbox. Checkbox là chúng ta sẽ có những cái ô như thế này, option đó, rồi chúng ta sẽ tích chọn hay không tích chọn. Radio button thì nó sẽ có là những cái ô như thế này đó. Thì chúng. Radio button thì chỉ được phép chọn một thôi. Đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 16,
      "start_timestamp": "0:09:17",
      "end_timestamp": "0:09:55"
    }
  },
  {
    "page_content": "Radio button thì chỉ được phép chọn một thôi. Đây là option A, option B, option C, option D. Chúng ta chỉ được phép chọn một option thôi. Dropdown thì nó sẽ tạo ra một cái cửa sổ để hiển thị rất nhiều cái option A, option B, option C rồi D. Hình ảnh thì là để hiển thị các cái biểu đồ Hoặc là các cái ảnh đầu vào. Thì nếu như bình thường chúng ta muốn học nhanh một cái ngôn ngữ hoặc một cái thư viện nào thì chúng ta sẽ sử dụng công cụ Google search. Sau đó chúng ta sẽ tìm hiểu về các cái bài",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 17,
      "start_timestamp": "0:09:49",
      "end_timestamp": "0:10:10"
    }
  },
  {
    "page_content": "Sau đó chúng ta sẽ tìm hiểu về các cái bài hướng dẫn đúng không? Nhưng mà gần đây thì nó đã có một cái công cụ rất là hiệu quả đó là chatbot AI. Chatbot AI nó sẽ giúp cho chúng ta đạt được những cái mục tiêu một cách rất là nhanh chóng đó. Ví dụ như nổi tiếng nhất mà chúng ta biết đó chính là ChatGPT. Sau đó thì có cái công cụ là Copilot của Microsoft đó. Thì chúng ta trong cái phần này chúng ta sẽ dùng ChatGPT và Copilot để tiến hành prompting. Chúng ta sẽ nhờ các cái công cụ AI này tạo ra bản",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ nhờ các cái công cụ AI này tạo ra bản mã nguồn và sau đó chúng ta sẽ triển khai nó lên trên cái ứng dụng web.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=fHQuBYhg_pA",
      "filename": "fHQuBYhg_pA",
      "title": "[CS116 - Buổi 14] Part 3_1",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "thì đối với cái phương và ngoài ra thì chúng ta sẽ còn có phương pháp wrapper theo cái kiểu là random feature tức là với cái đặc trưng X chúng ta có cái đặc trưng là các cái cột ở đây và chúng ta sẽ đưa một cái đặc trưng nữa một cái đặc trưng đặc biệt đó là random feature các cái giá trị trên cái cột này chúng ta sẽ được khởi tạo ngẫu nhiên. Sang bước thứ hai chúng ta sẽ đem cái dữ liệu đã có đặc trưng ngẫu nhiên này vào cái mô hình huấn luyện và mô hình huấn luyện này thì thông thường sẽ là sử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:41"
    }
  },
  {
    "page_content": "mô hình huấn luyện này thì thông thường sẽ là sử dụng các cái mô hình mà có cái độ đo để đánh giá cái tầm quan trọng của đặc trưng ha. Và sau khi chúng ta thực hiện supervised learning với cái mô hình này xong chúng ta sẽ đánh giá xem là cái mức độ quan trọng của đặc trưng, mức độ quan trọng của đặc trưng nó được tính hoặc được trích ra từ cái mô hình này ha. Và đối với cái đặc trưng mà random ở đây và chúng ta có cái độ quan trọng là như thế này thì tất cả những cái đặc trưng nào mà có cái độ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 1,
      "start_timestamp": "0:00:36",
      "end_timestamp": "0:01:18"
    }
  },
  {
    "page_content": "thì tất cả những cái đặc trưng nào mà có cái độ quan trọng nhỏ hơn cái độ quan trọng của đặc trưng random thì chúng ta sẽ loại bỏ đi. Và chúng ta lặp đi lặp lại cái quá trình này. Chúng ta lại tiếp tục thêm một cái cột đặc trưng random trên những cái dữ liệu trên những cái đặc trưng mà chúng ta đã lọc ở cái bước đầu tiên đó thì chúng ta lặp đi lặp lại cho đến khi nào mà chúng ta đạt được một cái ngưỡng dừng thì đó chính là những cái đặc trưng còn lại quan trọng phục vụ cho cái model của mình. Ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 2,
      "start_timestamp": "0:01:11",
      "end_timestamp": "0:01:55"
    }
  },
  {
    "page_content": "lại quan trọng phục vụ cho cái model của mình. Ở đây thì chúng ta lưu ý là cái phương pháp này là phương pháp số hai ha. Rồi cuối cùng thì chúng ta nhận xét đó là ưu điểm của phương pháp wrapper đó là có cái sự nó đã bắt đầu có cái sự tương tác giữa các cái đặc trưng với nhau thông qua cái việc là đưa vào một cái mô hình để huấn luyện. Và tập con của các cái đặc trưng thì nó sẽ được chọn lựa để tối ưu theo mô hình, nó sẽ tối ưu theo mô hình. Tuy nhiên cái khuyết điểm của cái phương pháp này đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 3,
      "start_timestamp": "0:01:51",
      "end_timestamp": "0:02:32"
    }
  },
  {
    "page_content": "nhiên cái khuyết điểm của cái phương pháp này đó là chi phí tính toán lớn tại vì chúng ta phải thực hiện đi thực hiện lại, thực hiện đi thực hiện lại cái việc huấn luyện cái mô hình nhiều lần. Và phương pháp này thì nó sẽ dễ bị hiện tượng overfitting dẫn đến là cái kết quả của mình nó sẽ tốt cho dữ liệu train nhưng mà khi chúng ta test trên một cái dữ liệu chưa thấy bao giờ thì độ chính xác nó lại thấp. Và phương pháp này thì nó phức tạp hơn, cách thức nó thực hiện nó phức tạp hơn so với lại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 4,
      "start_timestamp": "0:02:26",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "cách thức nó thực hiện nó phức tạp hơn so với lại phương pháp filter và phương pháp số một. Chúng ta sẽ qua cái phương pháp số ba đó là phương pháp embedded Model tức là bản thân trong cái mô hình của mình nó đã có cái khả năng chọn lọc đặc trưng. Đó thì phương pháp đầu tiên đó chính là phương pháp lasso. Thì trong cái phương pháp lasso này nó sử dụng cái regularization là L1. Thì cái regularization L1 này nó sẽ ép cái mô hình của mình nó sẽ cố gắng chọn ra những cái đặc trưng nào mà ít quan",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 5,
      "start_timestamp": "0:03:01",
      "end_timestamp": "0:03:47"
    }
  },
  {
    "page_content": "gắng chọn ra những cái đặc trưng nào mà ít quan trọng nó sẽ cho cái hệ số tiến về 0. Cái hệ số của ví dụ chúng ta có cái đặc trưng x_i này không quan trọng thì cái hệ số beta tương ứng với cái đặc trưng x_i này nó sẽ tiến về 0 do cái thành phần regularization thành phần chính quy hóa L1 này. Còn tương tự như vậy cho các cái phương pháp ridge regression và elastic net nó cũng sẽ góp phần cho chúng ta chọn lựa cái đặc trưng nào quan trọng hơn. Những đặc trưng nào không quan trọng thì cái hệ số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 6,
      "start_timestamp": "0:03:39",
      "end_timestamp": "0:04:19"
    }
  },
  {
    "page_content": "đặc trưng nào không quan trọng thì cái hệ số của nó nó thường sẽ được ép về cái giá trị thấp hơn. Và chúng ta cũng có một số cái mô hình khác những cái mô hình mà dạng cây tree-based Model. Những cái mô hình dạng cây thì trong cái quá trình mà xây dựng cây nó cũng đã có cái ngầm thực hiện cái thao tác đó là chọn lọc đặc trưng, chọn những cái đặc trưng mà có chứa nhiều thông tin, có chứa nhiều thông tin hoặc là chọn ra những cái đặc trưng mà có cái tính phân loại cao, tính phân loại cao. Còn các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 7,
      "start_timestamp": "0:04:14",
      "end_timestamp": "0:05:00"
    }
  },
  {
    "page_content": "tính phân loại cao, tính phân loại cao. Còn các cái đặc trưng mà không có cái tính phân loại cao hoặc là các cái đặc trưng dư thừa thì cái phương pháp mà dựa trên cây nó sẽ loại bỏ đi, nó sẽ không có đưa vào bên trong cái cấu trúc cây để mà phân lớp. Thì đó là cái phương pháp số ba là embedded Model tức là chúng ta ngầm bên trong Model nó đã thực hiện cái việc chọn lựa đặc trưng cho mình rồi. Và ưu điểm của phương pháp này đó là nó sẽ có cái hiệu quả tính toán cao hơn so với wrapper do nó không",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 8,
      "start_timestamp": "0:04:55",
      "end_timestamp": "0:05:34"
    }
  },
  {
    "page_content": "quả tính toán cao hơn so với wrapper do nó không phải thực hiện đi thực hiện lại cái việc huấn luyện mô hình nhiều lần và cái tính tổng quát hóa của nó cũng cao hơn và có được cái sự tương tác giữa các cái đặc trưng cũng như là các tham số của mô hình. Và khuyết điểm của nó đó là cái khả năng giải thích của đặc trưng nó sẽ thấp hơn so với lại filter. Tại vì ở bên trong mô hình nó vận hành nó chạy ngầm và nó thực hiện cái việc chọn lựa đặc trưng một cách ngầm định. Do đó thì khi nó ra được cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 9,
      "start_timestamp": "0:05:30",
      "end_timestamp": "0:06:07"
    }
  },
  {
    "page_content": "một cách ngầm định. Do đó thì khi nó ra được cái kết quả rồi thì chúng ta rất khó để có thể giải thích cho những cái người mà không có chuyên môn về machine learning biết là tại sao mô hình nó chọn cái đặc trưng này mà không chọn cái đặc trưng kia. Và nó vẫn có một cái khả năng đó là overfit với dữ liệu. Ví dụ như với một cái mô hình tree-based thì có khả năng là cái cây mà nó được tạo ra nó sẽ đúng cho cái dữ liệu huấn luyện của mình. Nhưng khi chúng ta chỉ thay đổi nhỏ trên những cái dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 10,
      "start_timestamp": "0:06:02",
      "end_timestamp": "0:06:47"
    }
  },
  {
    "page_content": "chúng ta chỉ thay đổi nhỏ trên những cái dữ liệu huấn luyện hoặc là dữ liệu test thì có khả năng là độ chính xác của nó nó sẽ không có còn cao nữa. Thì đó chính là cái ưu khuyết điểm của phương pháp số ba. Và phương pháp số 4 đó chính là chúng ta sẽ giảm chiều dựa trên một số thuật toán học không giám sát ví dụ như là thuật toán PCA. Chi tiết trong cái phần các cái mô hình un supervised learning thì chúng ta sẽ được hiểu rõ hơn về thuật toán PCA này. Nhưng mà đại khái đó là với cái đặc trưng,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 11,
      "start_timestamp": "0:06:39",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "này. Nhưng mà đại khái đó là với cái đặc trưng, với cái tập dữ liệu đặc trưng đầu vào là x1, x2 cho đến xn thì qua cái thuật toán PCA nó sẽ đưa về cái đặc trưng là x phẩy. Lưu ý x phẩy này nó khác với x này ha, x phẩy 1, x phẩy 2 và x phẩy k, trong đó k nó phải bé hơn cái con số n này thì khi đó là nó giảm số chiều. Tương tự như vậy cho cái thuật toán là independent component analysis và thuật toán phân tích các thành phần độc lập. Thì ưu điểm của phương pháp giảm chiều dữ liệu đó chính là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 12,
      "start_timestamp": "0:07:17",
      "end_timestamp": "0:07:57"
    }
  },
  {
    "page_content": "phương pháp giảm chiều dữ liệu đó chính là cái hiệu quả tính toán của nó cao do các cái nhóm thuật toán này được thực hiện trên các cái phép biến đổi tuyến tính nên tốc độ tính toán rất là nhanh. Và nó có thể trực quan hóa được dưới dạng là các cái, nó có thể trực quan hóa được do chúng ta có thể giảm cái số chiều của mình xuống là K có thể là bằng 2 và bằng 3 tức là hai chiều cho đến 3 chiều thì khi đó chúng ta có thể vẽ được trong cái không gian và chúng ta có thể quan sát được. Và cái việc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 13,
      "start_timestamp": "0:07:52",
      "end_timestamp": "0:08:29"
    }
  },
  {
    "page_content": "và chúng ta có thể quan sát được. Và cái việc loại bỏ các cái đặc trưng nhiễu thì nó sẽ là đặc trưng có cái phương sai thấp. Đó thì cái việc loại bỏ cái đặc trưng này thì nó cũng có cái tính chất gọi là có thể giải thích được. Điểm yếu của cái phương pháp giảm chiều dữ liệu đó là khả năng giải thích các cái đặc trưng, tức là khả năng giải thích đặc trưng của mình nó là thấp do các cái thao tác tính toán trên PCA và ICA này đó là những cái thao tác cũng tương đối là ngầm tính toán. Và cái mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 14,
      "start_timestamp": "0:08:24",
      "end_timestamp": "0:09:08"
    }
  },
  {
    "page_content": "tác cũng tương đối là ngầm tính toán. Và cái mô hình của mình nó sẽ ngầm chọn ra những cái đặc trưng. Và khi chúng ta chuyển sang cái dạng đặc trưng là x phẩy 1, x phẩy 2 cho đến X phẩy k thì các cái giải giá trị của x phẩy này nó không còn giống với lại cái giá trị x1, x2 ban đầu nữa dẫn đến là khó giải thích. Và các cái phương pháp này thì nó chỉ có thể tính toán được trên các cái dữ liệu dạng số, dạng số học. Do đó thì nó không phù hợp với các cái dữ liệu dạng phân loại hoặc là dạng danh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 15,
      "start_timestamp": "0:09:01",
      "end_timestamp": "0:09:42"
    }
  },
  {
    "page_content": "các cái dữ liệu dạng phân loại hoặc là dạng danh mục. Và cái việc chuyển cái đặc trưng sang cái không gian khác thì nó sẽ không cung cấp được cái tập con cụ thể là các cái đặc trưng quan trọng. Đó thì đây chính là những cái điểm yếu của cái phương pháp số 4. Và chúng ta sẽ có một số cái công cụ để giúp cho chúng ta chọn lựa đặc trưng. Đó là thông qua các cái thư viện. Thì nổi tiếng nhất và có thể dễ sử dụng đó chính là thư viện scikit-learn. Thì chúng ta sẽ có các cái API nằm trong cái thư viện",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 16,
      "start_timestamp": "0:09:38",
      "end_timestamp": "0:10:31"
    }
  },
  {
    "page_content": "chúng ta sẽ có các cái API nằm trong cái thư viện của scikit-learn. Rồi chúng ta sẽ có cái thư viện là Leave-One-Feature-Out (LOFO). Rồi chúng ta sẽ có thư viện là SHAP. Thì đây cũng là một trong những cái thư viện mà có cái số lượt citation rất là nhiều. Rồi thư viện là Boruta SHAP vân vân. Thì đây chính là những cái thư viện mà thường được sử dụng cho cái việc là chọn lựa đặc trưng. Và như vậy thì trong cái bài ngày hôm nay thì chúng ta đã cùng lượt qua các cái thao tác tiền xử lý dữ liệu. Nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 17,
      "start_timestamp": "0:10:25",
      "end_timestamp": "0:11:00"
    }
  },
  {
    "page_content": "lượt qua các cái thao tác tiền xử lý dữ liệu. Nó bao gồm là các cái thao tác liên quan đến cái xử lý dữ liệu bị thiếu, dữ liệu bị nhiễu. Và sau khi chúng ta đã tiền xử lý dữ liệu để mà làm sạch dữ liệu rồi thì chúng ta sẽ có ba cái thao tác trên đặc trưng. Đầu tiên đó là chúng ta tạo đặc trưng rồi sau đó chúng ta biến đổi đặc trưng. Cái việc biến đổi này nó sẽ giúp chúng ta đưa cái đặc trưng từ dạng gốc về cái đặc trưng mà mô hình máy học có thể tính toán một cách dễ dàng. Và cuối cùng đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 18,
      "start_timestamp": "0:10:57",
      "end_timestamp": "0:11:00"
    }
  },
  {
    "page_content": "tính toán một cách dễ dàng. Và cuối cùng đó là chúng ta chọn lựa đặc trưng. Tại vì sau khi chúng ta đã tạo đặc trưng, biến đổi đặc trưng xong thì có rất nhiều những cái đặc trưng nó không thực sự cần thiết cho mô hình của mình. Thì những cái đặc trưng đó sẽ được loại bỏ đi. Còn những đặc trưng nào quan trọng thì sẽ được giữ lại. Thì đó là toàn bộ những cái nội dung mà chúng ta học trong cái bài học ngày hôm nay.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=f_rMY30-bRQ",
      "filename": "f_rMY30-bRQ",
      "title": "[CS116 - Buổi 4] Part 5_2",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng tìm hiểu thư viện pandas và đây là một trong những cái thư viện rất là phổ biến và nổi tiếng trong cái xử lý dữ liệu dạng bảng thì một số cái chủ đề chính trong thư viện pandas đó là chúng ta sẽ khởi tạo một cái bảng dữ liệu như thế nào rồi chúng ta sẽ gom nhóm dữ liệu theo từng cột như thế nào rồi nếu như chúng ta muốn nối các cái bảng dữ liệu với nhau thì chúng ta sẽ nối như thế nào và ngoài ra thì thư viện pandas còn hỗ trợ các cái thao tác để giúp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=g8uw5jp2pi0",
      "filename": "g8uw5jp2pi0",
      "title": "[CS116 - Buổi 2] Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:34"
    }
  },
  {
    "page_content": "viện pandas còn hỗ trợ các cái thao tác để giúp cho chúng ta can thiệp và thay đổi cái giá trị bên trong cái dữ liệu bảng của mình, chỉnh sửa cái dữ liệu bảng của mình, chỉnh sửa các cái giá trị trong bảng dữ liệu của mình rồi chúng ta có thể trích xuất cái bảng con ở bên trong cái cái dữ liệu của mình như thế nào rồi chúng ta có thể tạo ra thêm các cái cột mới hoặc là tạo thêm các cái hàng mới như thế nào trong thư viện pandas và cuối cùng đó là chúng ta có thể vẽ biểu đồ cơ bản và chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=g8uw5jp2pi0",
      "filename": "g8uw5jp2pi0",
      "title": "[CS116 - Buổi 2] Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:29",
      "end_timestamp": "0:01:07"
    }
  },
  {
    "page_content": "là chúng ta có thể vẽ biểu đồ cơ bản và chúng ta lưu ý cái hàm vẽ biểu đồ ở đây đó chính là các cái hàm được thiết kế và cài đặt bởi thư viện pandas chứ không phải là các cái hàm mà được cài đặt bởi thư viện bên ngoài pandas như là thư viện Matplotlib. Thì đầu tiên đó là chúng ta sẽ tạo một cái dữ liệu mới như thế nào thì trong pandas có một cái cấu trúc đó là DataFrame thì đây chính là cái dữ liệu dạng bảng của mình và để tạo dữ liệu thì chúng ta có thể khai báo theo cái kiểu là cột hoặc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=g8uw5jp2pi0",
      "filename": "g8uw5jp2pi0",
      "title": "[CS116 - Buổi 2] Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:02",
      "end_timestamp": "0:01:42"
    }
  },
  {
    "page_content": "ta có thể khai báo theo cái kiểu là cột hoặc là theo kiểu dòng thì ví dụ ở đây là chúng ta đang khai báo tạo ra một cái DataFrame với cái kiểu là theo cột đó thì chúng ta sẽ phải truyền vào cái tham số đầu tiên đó là một cái kiểu dictionary rồi trong cái dictionary này thì các cái key, à cái khóa của mình nó sẽ là các cái biến x, y, z, t tương ứng là x, y, z, t ở đây. Và ứng với từng cái khóa x, y, z, t chúng ta sẽ có các cái value tương ứng đó thì ở đây chúng ta sẽ thấy là value của trường x",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=g8uw5jp2pi0",
      "filename": "g8uw5jp2pi0",
      "title": "[CS116 - Buổi 2] Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:01:35",
      "end_timestamp": "0:02:24"
    }
  },
  {
    "page_content": "thì ở đây chúng ta sẽ thấy là value của trường x đó chính là 13, 30 và A thì tương ứng đó là 13, 30 và A và ở đây thì nó sẽ được lưu trong cái dạng là list nên các cái giá trị này nó có thể là những cái giá trị thuộc những cái kiểu dữ liệu khác nhau nên các cái cột ở đây, các cái giá trị trong cột ở đây nó có thể là những cái giá trị khác nhau. Và cái tham số thứ hai cho cái hàm `pd.DataFrame` đó chính là `index`. Cái `index` này nó sẽ giúp cho các cái thao tác truy xuất rồi tìm kiếm ở bên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=g8uw5jp2pi0",
      "filename": "g8uw5jp2pi0",
      "title": "[CS116 - Buổi 2] Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:21",
      "end_timestamp": "0:03:04"
    }
  },
  {
    "page_content": "cho các cái thao tác truy xuất rồi tìm kiếm ở bên trong DataFrame được thực hiện nhanh hơn. Thì ở đây là Index chúng ta sẽ đánh chỉ mục đó là 1 2 3 tương ứng đó là các giá trị ở bên đây đây chính là cái cột Index. Rồi thao tác tiếp theo đó là chúng ta có thể load cái dữ liệu DataFrame và chúng ta load lên từ file và một trong những cái file rất là nổi tiếng và đơn giản đó chính là CSV chúng ta sẽ dùng hàm `pd.read_csv` và chúng ta sẽ truyền vào cái đường dẫn đến cái nơi chứa của cái file này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=g8uw5jp2pi0",
      "filename": "g8uw5jp2pi0",
      "title": "[CS116 - Buổi 2] Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:02:57",
      "end_timestamp": "0:03:40"
    }
  },
  {
    "page_content": "cái đường dẫn đến cái nơi chứa của cái file này chúng ta sẽ truyền cái đường dẫn này vào và khi chúng ta load cái dữ liệu từ cái file CSV này lên thì chúng ta sẽ được một cái file có cái cấu trúc là DataFrame. Và khi chúng ta thực hiện cái việc là vẽ cái DataFrame này lên trên cái màn hình thì nó sẽ ra cái bảng dữ liệu như thế này và các cái trường thông tin như là `day`, `symbol` rồi `Open`, `high`, `low`, `close`, `volume` vân vân. Thì đó chính là các cái cột mà được lưu ở bên trong cái file",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=g8uw5jp2pi0",
      "filename": "g8uw5jp2pi0",
      "title": "[CS116 - Buổi 2] Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:03:35",
      "end_timestamp": "0:04:24"
    }
  },
  {
    "page_content": "là các cái cột mà được lưu ở bên trong cái file `stock.csv` và các cái giá trị như thế này thì là cũng đưa ở các cái hàng trong file CSV. Này và một số cái quy ước đầu tiên đó là ở hàng trên cùng thì chúng ta đặt tên cho nó đó là cột hay còn gọi là `column` và các cái giá trị trên một cái dòng này thì nó gọi là một cái cột dữ liệu hay còn gọi là `variable` hay biến và mỗi một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=g8uw5jp2pi0",
      "filename": "g8uw5jp2pi0",
      "title": "[CS116 - Buổi 2] Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:04:15",
      "end_timestamp": "0:04:27"
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ tìm hiểu về cái phương pháp tạo ra các cái đặc trưng mới thì tên tiếng Anh của nó đó là feature extraction Ờ ở đây chúng ta sẽ có một cái ví dụ đó là chúng ta đã có các cái cột thông tin như là nhân viên nè vận tốc và thời gian và chúng ta có thể thực hiện các cái biến đổi toán học các cái biến đổi toán học giữa các đặc trưng đã có ví dụ như cột vận tốc và cột thời gian thì chúng ta có thể suy ra được cái quãng đường di chuyển đó là bằng vận tốc nhân với thời",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:40"
    }
  },
  {
    "page_content": "đường di chuyển đó là bằng vận tốc nhân với thời gian thì đây chính là một cái biến đổi toán học để tạo ra một cái cột dữ liệu mới Ngoài ra thì chúng ta cũng có thể thực hiện cái thao tác là đếm cái tần số xuất hiện như là một cái đặc trưng lấy ví dụ ở đây chúng ta thấy là cái cột Màu sắc này thì màu đỏ Red là xuất hiện ba lần, Blue là xuất hiện hai lần và Green là xuất hiện một lần thì chúng ta suy đoán rằng là cái tần suất xuất hiện nó cũng thể hiện được một số cái tính chất nhất định cho cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:34",
      "end_timestamp": "0:01:20"
    }
  },
  {
    "page_content": "hiện được một số cái tính chất nhất định cho cái dữ liệu của mình do đó chúng ta có thể tạo ra thêm một cái cột mới đó là Color Count và số lần xuất hiện của Red nó sẽ là 3 và cứ bất cứ những cái dòng nào mà có giá trị là Red thì nó sẽ điền là 3 rồi Chỗ nào mà có sự xuất hiện của dòng Blue thì chúng ta sẽ để là 2 thì tạo ra thêm một cái đặc trưng mới dựa trên cái số lần xuất hiện tổng hợp đặc trưng theo nhiều theo cái nhiều cột thì ở đây chúng ta giả sử rằng là có ba cái cột là Bus, Car và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:14",
      "end_timestamp": "0:01:56"
    }
  },
  {
    "page_content": "ta giả sử rằng là có ba cái cột là Bus, Car và Motor. Đây là các cái phương tiện di chuyển ở đây là mỗi hàng là tương ứng cách thức mà một người chọn cái phương tiện di chuyển thì chúng ta có thể tạo ra một cái cột mới đó là Use Vehicle Tức là cái người đó có sử dụng bất cứ một cái phương tiện nào hay không thì cái cột Use Vehicle này nó sẽ thực hiện cái thao tác đó là tìm max của các cái giá trị trong một hàng này ví dụ như max của 0 0 và 1 nó sẽ ra là 1 rồi max của 0 0 thì nó ra là 0 thì ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:01:51",
      "end_timestamp": "0:02:38"
    }
  },
  {
    "page_content": "sẽ ra là 1 rồi max của 0 0 thì nó ra là 0 thì ở đây chúng ta sẽ dùng cái hàm gọi là hàm Max rồi max của 011 chính là là 1 như vậy thì đây sẽ là tổng hợp đặc trưng theo nhiều cột và phương pháp tiếp theo đó chính là phương pháp phân rã đặc trưng Tức là trong nhiều tình huống thì cái dữ liệu của mình dữ liệu mà cột của mình nó đã chứa rất nhiều thông tin trong đó lấy ví dụ như thông tin mã số sinh viên hồi nãy thì mình nói là mã số sinh viên đôi khi là nó không có cái Ờ mang cái trong nhiều tình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:32",
      "end_timestamp": "0:03:20"
    }
  },
  {
    "page_content": "là nó không có cái Ờ mang cái trong nhiều tình huống thì cái mã số sinh viên của mình nó có quy định một số cái tính chất ví dụ 06 đó là hệ cái năm học Ví dụ như cái năm tuyển đầu vào của mình là khóa 2006 một tương ứng người đó là học theo hệ chính quy con số 2 ở đây nó tương ứng là cho cái khoa Ví dụ như số 2 người ta quy định đó là Khoa Khoa Học Máy Tính và số 450 cuối cùng đó là cái số thứ tự thì cái này có thể là một cái đặc trưng không quan trọng và như vậy thì chúng ta có thể dựa trên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:03:13",
      "end_timestamp": "0:03:52"
    }
  },
  {
    "page_content": "trọng và như vậy thì chúng ta có thể dựa trên một cái Đặc trưng nào đó chúng ta sẽ phân rã nó ra thành nhiều cái đặc trưng thành phần ở dưới đây thì chúng ta sẽ có một cái ví dụ khác đó là giả sử như chúng ta có một cái cột đặc trưng là dạng chuỗi và nó có cái tên của cái hệ điều hành của mình thì ở đây chúng ta có thể tách cái cột đặc trưng này ra làm hai cái cột đặc trưng đó là cột operating system là macOS đó là một cái đặc trưng Rồi phiên bản là một cái đặc trưng hoặc là cái cột về policy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:03:46",
      "end_timestamp": "0:04:37"
    }
  },
  {
    "page_content": "là một cái đặc trưng hoặc là cái cột về policy corporate L3 thì cái cái cái loại dữ liệu xin lỗi cái loại policy của mình nó sẽ là corporate và cái mức độ cái Level của mình sẽ là level 3 đó thì từ một cái dạng chuỗi chúng ta có thể dùng cái kỹ thuật tách tách chuỗi cắt chuỗi để tạo ra những cái đặc trưng mới và cách tạo đặc trưng tiếp theo đó chính là tổng hợp đặc trưng thì ở đây nó sẽ ngược so với lại cái phương pháp trước đó phương pháp trước đó là từ một cột chúng ta sẽ tách ra làm nhiều",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:04:31",
      "end_timestamp": "0:05:12"
    }
  },
  {
    "page_content": "đó là từ một cột chúng ta sẽ tách ra làm nhiều cái đặc trưng con còn ở đây là chúng ta có nhiều cái đặc trưng con như là Make và Type chúng ta có thể tạo ra thành một cái đặc trưng tổng hợp đó chính là nối hai cái chuỗi này lại ví dụ như ở đây là Toyota và Sedan thì ở đây chúng ta sẽ có thêm một cái đặc trưng đó là vừa có kết hợp Make và Type đó là Toyota gạch Sedan rồi tổng hợp theo nhóm thì ở đây chúng ta có thể thực hiện các cái thao tác là group theo nhóm Sau đó chúng ta sẽ tính các cái giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:05:06",
      "end_timestamp": "0:05:48"
    }
  },
  {
    "page_content": "theo nhóm Sau đó chúng ta sẽ tính các cái giá trị mang tính chất thống kê trên các cái nhóm dữ liệu đó ví dụ đối với cái cột dữ liệu là Đà Nẵng chúng ta sẽ gom nhóm tất cả những cái Ờ dòng dữ liệu nào mà có cái cột là Đà Nẵng có cái cái cái trường thông tin CT là Đà Nẵng thì chúng ta sẽ thấy là có hai giá trị có hai cái hàng dữ liệu ở đây và chúng ta sẽ gom nhóm lại thì sẽ có hai cái giá trị lương là 10 triệu và 14 triệu ở đây Sau đó chúng ta thực hiện cái thao tác là tính trung bình cộng thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:05:42",
      "end_timestamp": "0:06:24"
    }
  },
  {
    "page_content": "hiện cái thao tác là tính trung bình cộng thì 10 + 14 chia 2 thì chúng ta sẽ ra là 12 như vậy thì ứng với cái cột Đà Nẵng chúng ta sẽ có thêm một cái cột nữa đó là Lương Trung bình đó là 12 thì hi vọng rằng là với cái cột lương trung bình này thì nó sẽ giúp cho chúng ta biết là lương của cái record của cái dòng dữ liệu này là đang thấp hơn hay là nhỏ hơn so với cái giá trị trung bình của tất cả những cái dòng dữ liệu thuộc về Đà Nẵng tương tự như vậy thì cho cái trường thông tin CT đối với các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 10,
      "start_timestamp": "0:06:16",
      "end_timestamp": "0:07:04"
    }
  },
  {
    "page_content": "vậy thì cho cái trường thông tin CT đối với các cái giá trị là Hồ Chí Minh và Hà Nội chúng ta cũng sẽ thêm vô Ờ thêm một cái đặc trưng mới đó là lương trung bình của cái thành phố đó và tiếp theo đó là chúng ta có thể thêm cái đặc trưng dạng cụm thêm cái đặc trưng dạng cụm lấy ví dụ như Ờ ở đây chúng ta sẽ có là sử dụng cái thuật toán gom cụm đó thì các cái năm mà xây dựng á là từ bên trái sang bên phải là từ 1880 cho đến những năm 2000 giả sử như chúng ta có ba cụm Chúng ta có ba cụm thì chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 11,
      "start_timestamp": "0:07:00",
      "end_timestamp": "0:07:46"
    }
  },
  {
    "page_content": "chúng ta có ba cụm Chúng ta có ba cụm thì chúng ta sẽ chia ra làm ba phần bằng một cái thuật toán gom cụm nào đó và những cái giá trị nào từ đầu cho đến cái giá trị 1990 thì nó được xếp vào một cụm từ 1940 cho đến 1980 thì nó sẽ xếp vào một cái cụm được biểu hiện bởi màu xanh lá và từ 1980 trở về sau thì nó được đánh dấu bằng màu xanh dương và giả sử như ba cái giá trị này chúng ta được tạo cho nó là cái cluster ID Tức là cái định danh cho cái cho các cái cụm đó là các con số là 0 1 2 thì tất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 12,
      "start_timestamp": "0:07:42",
      "end_timestamp": "0:08:30"
    }
  },
  {
    "page_content": "cho các cái cụm đó là các con số là 0 1 2 thì tất cả những cái phần tử nào những cái giá trị nào mà có n trong khoảng này thì chúng ta thay thế nó bằng giá trị là là 0 còn ở đây sẽ là 2 và ở đây sẽ là là 1 thì chúng ta sẽ thay thế các cái giá trị tương ứng đó tương tự như vậy cho cái trường hợp mà đặc trưng của mình nó bao gồm hai cột dữ liệu là longitude và latitude Tức là cái tọa độ trong cái bản đồ đó thì cái thuật toán gom cụm của mình có thể thực hiện trên những cái dữ liệu mà scalar hoặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 13,
      "start_timestamp": "0:08:25",
      "end_timestamp": "0:09:10"
    }
  },
  {
    "page_content": "thực hiện trên những cái dữ liệu mà scalar hoặc là dữ liệu là dạng một feature hoặc là trên một tổ hợp của nhiều hơn ờ lớn hơn hoặc bằng hai feature thì đều có thể thực hiện được cái thuật toán gom cụm và khi gom cụm xong thì chúng ta sẽ có cái định danh cho cái cụm và chúng ta sẽ tạo ra thêm một cái cột mới có cái giá trị tương ứng là cái định danh của cái cụm đó thì chúng ta sẽ xét đến cái ví dụ cụ thể như sau chúng ta có hai cái cột là CT và salary và chúng ta sẽ tạo ra thêm hai cái cột mới,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 14,
      "start_timestamp": "0:09:02",
      "end_timestamp": "0:09:56"
    }
  },
  {
    "page_content": "và chúng ta sẽ tạo ra thêm hai cái cột mới, xin lỗi, chúng ta sẽ tạo ra thêm một cái cột mới đó là cái cluster cái cluster này tương ứng nó sẽ thể hiện là cái mức lương của mình nó nằm trong cái phân cụm nào thì chúng ta sẽ thấy là cái mức lương là 35 triệu và 30 triệu thì nó nằm trong cùng một cái cụm có định danh là 2 nếu như chúng ta đối chiến vào các cái giá trị trên cái cột lương này thì chúng ta thấy 35 và 30 nó nằm ở cái ngưỡng cái giá trị lương là mức độ cao ví dụ từ 30 trở về sau thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 15,
      "start_timestamp": "0:09:49",
      "end_timestamp": "0:10:50"
    }
  },
  {
    "page_content": "lương là mức độ cao ví dụ từ 30 trở về sau thì đây là ngưỡng lương cao và à ở các cái giá trị số 0 đó hoặc là giá trị số 1 đi chúng ta thấy là 10 nè 8 nè 12 nè và 5 Tức là nó đang nằm ở nửa dưới à những cái mức lương mà dưới 12 10 nè 8 nè 5 thì đây sẽ là những cái mức lương ở nửa dưới thì đây là mức lương dạng thấp và các cái giá trị như là 0 là 20 15 15 14 14 nè 15 20 thì đây là cái nhóm trung bình và nó được ký hiệu đó là 1 cao thì nó sẽ ký hiệu là 0 mức thấp đó là 1 và lưu ý đó là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 16,
      "start_timestamp": "0:10:45",
      "end_timestamp": "0:11:38"
    }
  },
  {
    "page_content": "ký hiệu là 0 mức thấp đó là 1 và lưu ý đó là cái cluster ID này thì không có thể hiện cái tính ờ cao thấp khi chúng ta chọn Ví dụ như mức thấp chúng ta có thể chọn một cái con số bất kỳ để đại diện cho mức thấp à chứ không nhất thiết phải là cao phải lớn hơn thấp ở đây cái từ khóa Cao và Thấp trung bình đó là do chúng ta quy ước thôi thì những cái giá trị của mức lương mà nằm trong cùng một cụm thì sẽ nhận một cái À cái cluster ID tương ứng thì đây là đặc trưng theo phân cụm và tiếp theo thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 17,
      "start_timestamp": "0:11:33",
      "end_timestamp": "0:01:23"
    }
  },
  {
    "page_content": "đây là đặc trưng theo phân cụm và tiếp theo thì chúng ta có thể sử dụng những cái công cụ phân tích thành phần chính PCA, PCA là viết tắt của chữ principal component analysis thì đây là một cái phương pháp phân tích các cái thành phần chính thì các cái thành phần chính của dữ liệu nó sẽ mang nhiều thông tin hơn nó sẽ mang nhiều thông tin hơn à so với lại các cái đặc trưng ban đầu đó thì với phương pháp PCA nó sẽ giúp cho chúng ta loại bỏ loại bỏ những cái thành phần Hoặc là những cái đặc trưng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 18,
      "start_timestamp": "0:01:16",
      "end_timestamp": "0:02:01"
    }
  },
  {
    "page_content": "những cái thành phần Hoặc là những cái đặc trưng mà không quan trọng hoặc là không có nhiều thông tin đó thì ở đây chúng ta sẽ có một cái ví dụ là bốn cái đặc trưng Green là xuất hiện một lần thì chúng ta suy đoán rằng là cái tần suất xuất hiện nó cũng thể hiện được một số cái tính chất nhất định cho cái dữ liệu của mình do đó chúng ta có thể tạo ra thêm một cái cột mới đó là Color Count và số lần xuất hiện của Red nó sẽ là 3 và cứ bất cứ những cái dòng nào mà có giá trị là Red thì nó sẽ điền",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 19,
      "start_timestamp": "0:01:54",
      "end_timestamp": "0:02:41"
    }
  },
  {
    "page_content": "cái dòng nào mà có giá trị là Red thì nó sẽ điền là 3 rồi Chỗ nào mà có sự xuất hiện của dòng Blue thì chúng ta sẽ để là 2 thì tạo ra thêm một cái đặc trưng mới dựa trên cái số lần xuất hiện tổng hợp đặc trưng theo nhiều theo cái nhiều cột thì ở đây chúng ta giả sử rằng là có ba cái cột là Bus, Car và Motor. Đây là các cái phương tiện di chuyển ở đây là mỗi hàng là tương ứng cách thức mà một người chọn cái phương tiện di chuyển thì chúng ta có thể tạo ra một cái cột mới đó là Use Vehicle Tức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 20,
      "start_timestamp": "0:02:35",
      "end_timestamp": "0:03:22"
    }
  },
  {
    "page_content": "tạo ra một cái cột mới đó là Use Vehicle Tức là cái người đó có sử dụng bất cứ một cái phương tiện nào hay không thì cái cột Use Vehicle này nó sẽ thực hiện cái thao tác đó là tìm max của các cái giá trị trong một hàng này ví dụ như max của 0 0 và 1 nó sẽ ra là 1 rồi max của 0 0 thì nó ra là 0 thì ở đây chúng ta sẽ dùng cái hàm gọi là hàm Max rồi max của 011 chính là là 1 như vậy thì đây sẽ là tổng hợp đặc trưng theo nhiều cột và phương pháp tiếp theo đó chính là phương pháp phân rã đặc trưng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 21,
      "start_timestamp": "0:03:16",
      "end_timestamp": "0:03:56"
    }
  },
  {
    "page_content": "theo đó chính là phương pháp phân rã đặc trưng Tức là trong nhiều tình huống thì cái dữ liệu của mình dữ liệu mà cột của mình nó đã chứa rất nhiều thông tin trong đó lấy ví dụ như thông tin mã số sinh viên hồi nãy thì mình nói là mã số sinh viên đôi khi là nó không có cái Ờ mang cái trong nhiều tình huống thì cái mã số sinh viên của mình nó có quy định một số cái tính chất ví dụ 06 đó là hệ cái năm học Ví dụ như cái năm tuyển đầu vào của mình là khóa 2006 một tương ứng người đó là học theo hệ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 22,
      "start_timestamp": "0:03:50",
      "end_timestamp": "0:04:38"
    }
  },
  {
    "page_content": "khóa 2006 một tương ứng người đó là học theo hệ chính quy con số 2 ở đây nó tương ứng là cho cái khoa Ví dụ như số 2 người ta quy định đó là Khoa Khoa Học Máy Tính và số 450 cuối cùng đó là cái số thứ tự thì cái này có thể là một cái đặc trưng không quan trọng và như vậy thì chúng ta có thể dựa trên một cái Đặc trưng nào đó chúng ta sẽ phân rã nó ra thành nhiều cái đặc trưng thành phần ở dưới đây thì chúng ta sẽ có một cái ví dụ khác đó là giả sử như chúng ta có một cái cột đặc trưng là dạng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 23,
      "start_timestamp": "0:04:34",
      "end_timestamp": "0:05:15"
    }
  },
  {
    "page_content": "sử như chúng ta có một cái cột đặc trưng là dạng chuỗi và nó có cái tên của cái hệ điều hành của mình thì ở đây chúng ta có thể tách cái cột đặc trưng này ra làm hai cái cột đặc trưng đó là cột operating system là macOS đó là một cái đặc trưng Rồi phiên bản là một cái đặc trưng hoặc là cái cột về policy corporate L3 thì cái cái cái loại dữ liệu xin lỗi cái loại policy của mình nó sẽ là corporate và cái mức độ cái Level của mình sẽ là level 3 đó thì từ một cái dạng chuỗi chúng ta có thể dùng cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 24,
      "start_timestamp": "0:05:10",
      "end_timestamp": "0:05:51"
    }
  },
  {
    "page_content": "từ một cái dạng chuỗi chúng ta có thể dùng cái kỹ thuật tách tách chuỗi cắt chuỗi để tạo ra những cái đặc trưng mới và cách tạo đặc trưng tiếp theo đó chính là tổng hợp đặc trưng thì ở đây nó sẽ ngược so với lại cái phương pháp trước đó phương pháp trước đó là từ một cột chúng ta sẽ tách ra làm nhiều cái đặc trưng con còn ở đây là chúng ta có nhiều cái đặc trưng con như là Make và Type chúng ta có thể tạo ra thành một cái đặc trưng tổng hợp đó chính là nối hai cái chuỗi này lại ví dụ như ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 25,
      "start_timestamp": "0:05:45",
      "end_timestamp": "0:06:26"
    }
  },
  {
    "page_content": "là nối hai cái chuỗi này lại ví dụ như ở đây là Toyota và Sedan thì ở đây chúng ta sẽ có thêm một cái đặc trưng đó là vừa có kết hợp Make và Type đó là Toyota gạch Sedan rồi tổng hợp theo nhóm thì ở đây chúng ta có thể thực hiện các cái thao tác là group theo nhóm Sau đó chúng ta sẽ tính các cái giá trị mang tính chất thống kê trên các cái nhóm dữ liệu đó ví dụ đối với cái cột dữ liệu là Đà Nẵng chúng ta sẽ gom nhóm tất cả những cái Ờ dòng dữ liệu nào mà có cái cột là Đà Nẵng có cái cái cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 26,
      "start_timestamp": "0:06:20",
      "end_timestamp": "0:07:06"
    }
  },
  {
    "page_content": "liệu nào mà có cái cột là Đà Nẵng có cái cái cái trường thông tin CT là Đà Nẵng thì chúng ta sẽ thấy là có hai giá trị có hai cái hàng dữ liệu ở đây và chúng ta sẽ gom nhóm lại thì sẽ có hai cái giá trị lương là 10 triệu và 14 triệu ở đây Sau đó chúng ta thực hiện cái thao tác là tính trung bình cộng thì 10 + 14 chia 2 thì chúng ta sẽ ra là 12 như vậy thì ứng với cái cột Đà Nẵng chúng ta sẽ có thêm một cái cột nữa đó là Lương Trung bình đó là 12 thì hi vọng rằng là với cái cột lương trung bình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 27,
      "start_timestamp": "0:07:02",
      "end_timestamp": "0:07:48"
    }
  },
  {
    "page_content": "thì hi vọng rằng là với cái cột lương trung bình này thì nó sẽ giúp cho chúng ta biết là lương của cái record của cái dòng dữ liệu này là đang thấp hơn hay là nhỏ hơn so với cái giá trị trung bình của tất cả những cái dòng dữ liệu thuộc về Đà Nẵng tương tự như vậy thì cho cái trường thông tin CT đối với các cái giá trị là Hồ Chí Minh và Hà Nội chúng ta cũng sẽ thêm vô Ờ thêm một cái đặc trưng mới đó là lương trung bình của cái thành phố đó và tiếp theo đó là chúng ta có thể thêm cái đặc trưng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 28,
      "start_timestamp": "0:07:44",
      "end_timestamp": "0:08:32"
    }
  },
  {
    "page_content": "theo đó là chúng ta có thể thêm cái đặc trưng dạng cụm thêm cái đặc trưng dạng cụm lấy ví dụ như Ờ ở đây chúng ta sẽ có là sử dụng cái thuật toán gom cụm đó thì các cái năm mà xây dựng á là từ bên trái sang bên phải là từ 1880 cho đến những năm 2000 giả sử như chúng ta có ba cụm Chúng ta có ba cụm thì chúng ta sẽ chia ra làm ba phần bằng một cái thuật toán gom cụm nào đó và những cái giá trị nào từ đầu cho đến cái giá trị 1990 thì nó được xếp vào một cụm từ 1940 cho đến 1980 thì nó sẽ xếp vào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 29,
      "start_timestamp": "0:08:28",
      "end_timestamp": "0:09:13"
    }
  },
  {
    "page_content": "một cụm từ 1940 cho đến 1980 thì nó sẽ xếp vào một cái cụm được biểu hiện bởi màu xanh lá và từ 1980 trở về sau thì nó được đánh dấu bằng màu xanh dương và giả sử như ba cái giá trị này chúng ta được tạo cho nó là cái cluster ID Tức là cái định danh cho cái cho các cái cụm đó là các con số là 0 1 2 thì tất cả những cái phần tử nào những cái giá trị nào mà có n trong khoảng này thì chúng ta thay thế nó bằng giá trị là là 0 còn ở đây sẽ là 2 và ở đây sẽ là là 1 thì chúng ta sẽ thay thế các cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 30,
      "start_timestamp": "0:09:05",
      "end_timestamp": "0:09:57"
    }
  },
  {
    "page_content": "ở đây sẽ là là 1 thì chúng ta sẽ thay thế các cái giá trị tương ứng đó tương tự như vậy cho cái trường hợp mà đặc trưng của mình nó bao gồm hai cột dữ liệu là longitude và latitude Tức là cái tọa độ trong cái bản đồ đó thì cái thuật toán gom cụm của mình có thể thực hiện trên những cái dữ liệu mà scalar hoặc là dữ liệu là dạng một feature hoặc là trên một tổ hợp của nhiều hơn ờ lớn hơn hoặc bằng hai feature thì đều có thể thực hiện được cái thuật toán gom cụm và khi gom cụm xong thì chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 31,
      "start_timestamp": "0:09:53",
      "end_timestamp": "0:10:53"
    }
  },
  {
    "page_content": "toán gom cụm và khi gom cụm xong thì chúng ta sẽ có cái định danh cho cái cụm và chúng ta sẽ tạo ra thêm một cái cột mới có cái giá trị tương ứng là cái định danh của cái cụm đó thì chúng ta sẽ xét đến cái ví dụ cụ thể như sau chúng ta có hai cái cột là CT và salary và chúng ta sẽ tạo ra thêm hai cái cột mới, xin lỗi, chúng ta sẽ tạo ra thêm một cái cột mới đó là cái cluster cái cluster này tương ứng nó sẽ thể hiện là cái mức lương của mình nó nằm trong cái phân cụm nào thì chúng ta sẽ thấy là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 32,
      "start_timestamp": "0:10:47",
      "end_timestamp": "0:11:42"
    }
  },
  {
    "page_content": "trong cái phân cụm nào thì chúng ta sẽ thấy là cái mức lương là 35 triệu và 30 triệu thì nó nằm trong cùng một cái cụm có định danh là 2 nếu như chúng ta đối chiến vào các cái giá trị trên cái cột lương này thì chúng ta thấy 35 và 30 nó nằm ở cái ngưỡng cái giá trị lương là mức độ cao ví dụ từ 30 trở về sau thì đây là ngưỡng lương cao và à ở các cái giá trị số 0 đó hoặc là giá trị số 1 đi chúng ta thấy là 10 nè 8 nè 12 nè và 5 Tức là nó đang nằm ở nửa dưới à những cái mức lương mà dưới 12 10 nè",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 33,
      "start_timestamp": "0:11:35",
      "end_timestamp": "0:12:26"
    }
  },
  {
    "page_content": "ở nửa dưới à những cái mức lương mà dưới 12 10 nè 8 nè 5 thì đây sẽ là những cái mức lương ở nửa dưới thì đây là mức lương dạng thấp và các cái giá trị như là 0 là 20 15 15 14 14 nè 15 20 thì đây là cái nhóm trung bình và nó được ký hiệu đó là 1 cao thì nó sẽ ký hiệu là 0 mức thấp đó là 1 và lưu ý đó là cái cluster ID này thì không có thể hiện cái tính ờ cao thấp khi chúng ta chọn Ví dụ như mức thấp chúng ta có thể chọn một cái con số bất kỳ để đại diện cho mức thấp à chứ không nhất thiết phải",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 34,
      "start_timestamp": "0:12:20",
      "end_timestamp": "0:12:51"
    }
  },
  {
    "page_content": "đại diện cho mức thấp à chứ không nhất thiết phải là cao phải lớn hơn thấp ở đây cái từ khóa Cao và Thấp trung bình đó là do chúng ta quy ước thôi thì những cái giá trị của mức lương mà nằm trong cùng một cụm thì sẽ nhận một cái À cái cluster ID tương ứng thì đây là đặc trưng theo phân cụm và tiếp theo thì chúng ta có thể sử dụng những cái công cụ phân tích thành phần chính PCA, PCA là viết tắt của chữ principal component analysis thì đây là một cái phương pháp phân tích các cái thành phần",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 35,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "một cái phương pháp phân tích các cái thành phần chính thì các cái thành phần chính của dữ liệu nó sẽ mang nhiều thông tin hơn nó sẽ mang nhiều thông tin hơn à so với lại các cái đặc trưng ban đầu đó thì với phương pháp PCA nó sẽ giúp cho chúng ta loại bỏ loại bỏ những cái thành phần Hoặc là những cái đặc trưng mà không quan trọng hoặc là không có nhiều thông tin đó thì ở đây chúng ta sẽ có một cái ví dụ là bốn cái đặc trưng Ờ bốn cái đặc trưng của tập dữ liệu là Iris dataset ha Thì sau khi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 36,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "của tập dữ liệu là Iris dataset ha Thì sau khi chúng ta áp dụng cái thuật toán PCA là từ bốn chiều chúng ta sẽ giảm xuống là còn hai chiều tức là chúng ta Giả định rằng là chúng ta chỉ cần lấy thông tin của hai cái đặc trưng mà tốt nhất hai đặc trưng mà có nhiều thông tin nhất để chúng ta bổ trợ thêm đó thì nó sẽ có hai cái thành phần là PC1 và PCA2, PC3 và PC4 chúng ta sẽ loại bỏ đi à và lưu ý chính là thuật toán PCA ở đây sẽ được thực hiện trên các cái đặc trưng đã được chuẩn hóa và như vậy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 37,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "các cái đặc trưng đã được chuẩn hóa và như vậy thì cái dữ liệu của mình nó đã được bổ sung từ 4 lên là thành 6 đặc trưng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GA7IpvwIQTQ",
      "filename": "GA7IpvwIQTQ",
      "title": "[CS116 - Buổi 4] Part 3",
      "chunk_id": 38,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Hôm nay thì chúng ta sẽ đến với bài số 5 đó là bài đánh giá cái mô hình máy học như thế nào thì tại sao chúng ta lại tìm hiểu về cách đánh giá mô hình trước khi chúng ta học về một số cái mô hình máy học có rất nhiều cái lý do cái lý do đầu tiên đó là để mà có thể chọn lựa được một cái mô hình tốt Một cái mô hình phù hợp á thì chúng ta phải hiểu được cái bản chất của cái bài toán mình đang muốn giải đó là gì và đồng thời chúng ta phải biết cái cách để mà đánh giá được xem cái kết quả này tốt hơn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:04:21"
    }
  },
  {
    "page_content": "để mà đánh giá được xem cái kết quả này tốt hơn cái kết quả kia như thế nào như vậy thì chúng ta phải biết cái cách đánh giá bài toán trước khi chúng ta chọn lựa cái mô hình để giải quyết cái bài toán đó đó là lý do tại sao chúng ta đưa cái bài số đánh giá mô hình lên trước cái bài xây dựng một cái mô hình máy học thì nội dung của ngày hôm nay bao gồm các cái thành phần đó là tại sao chúng ta lại phải đánh giá một cái mô hình rồi các cái độ đo đánh giá cho bài toán hồi quy rồi độ đo đánh giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:04:16",
      "end_timestamp": "0:04:52"
    }
  },
  {
    "page_content": "đánh giá cho bài toán hồi quy rồi độ đo đánh giá cho bài toán phân lớp thì đây là hai cái loại bài toán mà rất là phổ biến hiện nay khi mà chúng ta xây dựng một cái mô hình máy học rồi quy trình đánh giá khách quan là gì đó thì ở đây chúng ta sẽ có cái khái niệm là quy trình hoặc là và tên tiếng Anh nó gọi là protocol rồi thì tại sao chúng ta cần phải đánh giá một cái mô hình đó là để chúng ta xác thực được cái mô hình của mình có thật sự hiệu quả hay không đó mô hình của mình nó đoán chính xác",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:04:47",
      "end_timestamp": "0:02:00"
    }
  },
  {
    "page_content": "hay không đó mô hình của mình nó đoán chính xác hay là nó chỉ nhớ dữ liệu huấn luyện tức là có rất nhiều cái tình huống là mô hình của mình nó cho kết quả tốt đưa ra được cái phán đoán đúng như là cái chúng ta mong muốn nhưng đó chỉ là thực hiện trên cái dữ liệu huấn luyện thôi Còn khi chúng ta thực hiện trên những cái tập dữ liệu mới hoàn toàn nó chưa bao giờ thấy đó thì nó không có thực hiện được chính xác nữa thì đó cũng chính là cái hiện tượng ta gọi là overfitting và overfitting là một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:01:56",
      "end_timestamp": "0:02:31"
    }
  },
  {
    "page_content": "tượng ta gọi là overfitting và overfitting là một trong những cái vấn đề lớn mà các cái mô hình máy học cần phải giải quyết tiếp theo đó là cái việc đánh giá mô hình sẽ giúp cho chúng ta có thể chọn lựa ra được cái mô hình tốt nhất Nó sẽ giúp cho chúng ta chọn lựa được cái mô hình tốt nhất tại vì nó cho phép chúng ta có thể so sánh được rất nhiều các cái mô hình với nhau đúng không Ví dụ mô hình `Decision Tree` với mô hình `k-nearest` `neighbor` với mô hình `Random Forest` thì cái mô hình nào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:26",
      "end_timestamp": "0:03:02"
    }
  },
  {
    "page_content": "với mô hình `Random Forest` thì cái mô hình nào cho cái kết quả nó tốt hơn một cách định lượng thì chúng ta sẽ chọn cái mô hình đó như vậy thì đó chính là một cái tiêu chí để mà chúng ta `lượng hóa` đánh giá được cái sự cao thấp giữa cái sự cao thấp về mặt độ chính xác giữa các cái mô hình với nhau à tức là nó thể thực hiện một cái việc so sánh một cách định lượng so sánh một cách định lượng thay vì chúng ta chỉ là làm một cái `so sánh` định tính bằng cách là chúng ta đưa vào một vài mẫu và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:02:57",
      "end_timestamp": "0:03:28"
    }
  },
  {
    "page_content": "tính bằng cách là chúng ta đưa vào một vài mẫu và chúng ta cảm giác là mô hình a tốt hơn mô hình B nhưng mà cái cách đó thì nó sẽ không có hiệu quả Còn cái việc mà sử dụng các cái độ đo à những cái phép so sánh và định lượng á thì giúp cho chúng ta có cái số liệu `tin cậy` khách quan để mà biết được là mô hình nào tốt hơn mô hình nào để từ đó chúng ta có thể chọn được cái mô hình tốt nhất cho mình và việc đánh giá mô hình thì sẽ tạo ra cái sự tin cậy cái sự tin cậy này á nó sẽ đến trong chính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:03:24",
      "end_timestamp": "0:04:01"
    }
  },
  {
    "page_content": "cậy cái sự tin cậy này á nó sẽ đến trong chính cái nội bộ cái team phát triển cái hệ thống hoặc cũng là cái sự tin cậy đối với khách hàng nếu như chúng ta đưa cho khách hàng chúng ta chứng minh với khách hàng rằng là cái mô hình của mình đã được triển khai có cái độ chính xác là 80 `phần trăm` trên các cái dữ liệu với một cái quy trình rất là khách quan như thế này thế kia thì khách hàng họ sẽ `cảm thấy` cảm giác là chúng ta thực hiện một cách khoa học và có cái sự tin tưởng trong cái việc mà",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:03:57",
      "end_timestamp": "0:04:31"
    }
  },
  {
    "page_content": "khoa học và có cái sự tin tưởng trong cái việc mà triển khai ứng dụng lên trên thực tế đó như vậy thì cái sự `tin cậy` này nó còn thể hiện được cái sự ổn định của mô hình cái sự đáng tin của mô hình khi triển khai trong thực tế hay không đó chính là cái sự tin cậy và tiếp theo đó chính là nó sẽ giúp cho chúng ta định hướng được cái cách thức để cải thiện mô hình cái việc mà chúng ta thử nghiệm với rất nhiều những cái độ đo khác nhau đúng không có rất nhiều những cái độ đo đánh giá khác nhau Ví",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:04:26",
      "end_timestamp": "0:05:07"
    }
  },
  {
    "page_content": "rất nhiều những cái độ đo đánh giá khác nhau Ví dụ như chúng ta có cái độ đo là `recall` hoặc là `precision` chúng ta thấy là `precision` rất cao nhưng mà cái `recall` rất thấp thì chúng ta biết là à Như vậy là cái bước tiếp theo để mà cải tiến cái mô hình này là chúng ta phải đi cải thiện cái `recall` Tức là cái độ phủ kết quả của mình thì cái việc mà biết được là mô hình của mình nó đang mạnh chỗ nào yếu chỗ nào thì nó sẽ giúp cho chúng ta đề ra được cái phương hướng nó đề ra được cái phương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:05:03",
      "end_timestamp": "0:05:44"
    }
  },
  {
    "page_content": "ra được cái phương hướng nó đề ra được cái phương hướng là sẽ cải tiến cái mô hình tiếp theo trong tương lai như thế nào và đến đây thì chúng ta sẽ bắt đầu đi đến phân biệt hai cái bài toán mà kinh điển cũng như là được đề cập rất là nhiều trong các cái mô hình máy học hiện đại hiện nay đó chính là mô hình hồi quy regression là phân lớp classification Thế thì đối với một số người thì chúng ta hiểu cái cách rất là đơn giản đó là hồi quy chính là cái bài toán mà cái đầu ra của cái dữ liệu của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 10,
      "start_timestamp": "0:05:40",
      "end_timestamp": "0:06:18"
    }
  },
  {
    "page_content": "là cái bài toán mà cái đầu ra của cái dữ liệu của mình đầu ra của cái dữ liệu của mình đó là những cái giá trị liên tục còn đối với cái bài toán phân lớp thì cái đầu ra của mình đó là chính là những cái giá trị `rời rạc` thì đây là một cái cách hiểu rất là `nôm na` rất là nó `ngắn gọn` là dễ hiểu và nhanh thì là chúng ta dùng hai cái khái niệm liên tục và `rạc` cho cái giá trị `đầu ra` cho cái giá trị đầu ra của cái mô hình Tuy nhiên thì với cái định nghĩa này với cái cách phân biệt này thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 11,
      "start_timestamp": "0:06:13",
      "end_timestamp": "0:06:57"
    }
  },
  {
    "page_content": "cái định nghĩa này với cái cách phân biệt này thì chúng ta hãy thử trả lời cái câu hỏi đó là bài toán dự đoán tuổi là bài toán hồi quy hay phân lớp đây là bài toán hồi quy hay phân lớp ví dụ Chúng ta có ảnh đầu vào của một người nào đó và chúng ta sẽ đoán xem là với cái gương mặt này thì cái tuổi của mình sẽ là bao nhiêu tuổi đó ví dụ như cái `cô gái bên` trái tuổi là 25 cô gái bên phải tuổi là 23 thì rõ ràng à một số người sẽ nói đó là bài toán hồi quy nhưng mà một số người sẽ nói đó là bài",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 12,
      "start_timestamp": "0:06:50",
      "end_timestamp": "0:07:25"
    }
  },
  {
    "page_content": "hồi quy nhưng mà một số người sẽ nói đó là bài toán `phân lớp` đó như vậy là chúng ta sẽ có hai cái luồng ý kiến trái chiều nhau những người nói đây là bài toán hồi quy là vì các cái giá trị của mình nó là những cái giá trị liên tục đúng không ví dụ như là từ 0 cho đến cái người mà có thể là cao tuổi nhất mà mình biết là 150 tuổi đi Chẳng hạn có người sẽ nhận xét là ừ tuổi nó là các cái giá trị nó liên tục từ 0 cho đến 150 nhưng cũng có một số người thì nói rằng đây là một `bài toán` `phân lớp`",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 13,
      "start_timestamp": "0:07:20",
      "end_timestamp": "0:08:10"
    }
  },
  {
    "page_content": "thì nói rằng đây là một `bài toán` `phân lớp` tại vì cái tuổi của mình á Nó nằm trong một cái tập hợp chứ nó không phải là nằm trong cái giải giá trị liên tục nó nằm trong tập hợp là 0 1 2 cho đến 150 mà đây là những cái giá trị rời `rạc` Tại vì nó là số nguyên nó là số nguyên còn giá trị liên tục thì người ta sẽ phải hiểu đó là số thực đó thì nó sẽ có hai cái luồng ý kiến như vậy Vậy thì ý kiến nào đúng thì chúng ta sẽ có một cái cách phân biệt rõ ràng hơn à đầu tiên đó là hồi quy là bài toán",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 14,
      "start_timestamp": "0:08:04",
      "end_timestamp": "0:08:49"
    }
  },
  {
    "page_content": "rõ ràng hơn à đầu tiên đó là hồi quy là bài toán mà với hai cái giá trị output bất kỳ Ví dụ như chúng ta có hai cái giá trị là i1 và i2 `bất kỳ` ha thì chúng ta có thể thực hiện được cái phép so sánh đó là so sánh lớn bé bằng và khác như vậy thì nếu như hai cái giá trị output bất kỳ của cái bài toán đó mà chúng ta có thể thực hiện được có thể thực hiện được tất cả thực hiện được tất cả các cái phép so sánh lớn bé bằng khác thì đó chính là bài toán `hồi quy` còn đối với cái bài toán phân lớp thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 15,
      "start_timestamp": "0:08:44",
      "end_timestamp": "0:09:22"
    }
  },
  {
    "page_content": "`hồi quy` còn đối với cái bài toán phân lớp thì hai cái giá trị output bất kỳ chỉ có thể chỉ có thể thực hiện được cái phép so sánh bằng hoặc là khác thì nó sẽ là bài toán `phân lớp` vậy vậy đáp án của cái bài toán dự đoán tuổi của mình đó chính là bài toán hồi quy tại sao tại vì ví dụ ở trên hình này chúng ta thấy là hai cái người này một người là 25 tuổi và một người là 23 tuổi thì đây chính là hai cái giá trị i1 và i2 mà chúng ta đã đề cập ở trên ha thì cái `thao tác` chúng ta có thể thực",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 16,
      "start_timestamp": "0:09:18",
      "end_timestamp": "0:09:52"
    }
  },
  {
    "page_content": "ở trên ha thì cái `thao tác` chúng ta có thể thực hiện được cái `thao tác` So sánh lớn so sánh bé đúng không Ví dụ như 25 là lớn hơn 23 tuổi thì đây là một cái thao tác So sánh lớn bé được nó cũng đồng thời cũng có thể so sánh là 25 Ờ Bằng hoặc là khác so với lại 23 như vậy có thể thực hiện `thao tác` Bằng và `thao tác` khác được như vậy thì đây sẽ là bài toán `hồi quy` Vì nó có thể thực hiện được các cái phép so sánh là lớn hơn bé hơn bằng `khác` còn tương tự như vậy thì chúng ta sẽ có cái bài",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 17,
      "start_timestamp": "0:09:47",
      "end_timestamp": "0:10:28"
    }
  },
  {
    "page_content": "còn tương tự như vậy thì chúng ta sẽ có cái bài toán đoán cái đối tượng đoán cái đối tượng là chó hay mèo ví dụ đầu vào của mình sẽ có một cái tấm hình đó là hình của một con vật và chúng ta sẽ đoán xem đó là chó hay mèo thì `rõ ràng` hai cái đối tượng chó mèo đó là bài toán phân loại đúng không Tại sao lại như vậy Tại vì chúng ta chỉ có thể thực hiện được thao tác là bằng và khác thôi chứ chúng ta không thể thực hiện được cái thao tác là lớn bé chúng ta không thể nào nói là chó thì lớn hơn mèo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 18,
      "start_timestamp": "0:10:24",
      "end_timestamp": "0:11:13"
    }
  },
  {
    "page_content": "chúng ta không thể nào nói là chó thì lớn hơn mèo đúng không có người sẽ nói ừ chó lớn hơn mèo không có những con chó nó vẫn bé hơn con mèo mà về `kích thước` đó chúng ta không thể nói là chó bé hơn mèo chó lớn hơn mèo chúng ta chỉ có thể nói là chó à cái này là không được ha chúng ta chỉ có thể nói là chó là bằng chó rồi chó khác mèo như vậy là ở đây chúng ta chỉ thực hiện được `thao tác` là bằng và khác thôi Thì đó chính là bài toán phân loại đối tượng hay là là bài toán phân lớp rồi Vậy thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 19,
      "start_timestamp": "0:11:07",
      "end_timestamp": "0:11:49"
    }
  },
  {
    "page_content": "đối tượng hay là là bài toán phân lớp rồi Vậy thì ờ Tại sao chúng ta cần phải thực hiện cái công việc là phân biệt bài toán cho đúng à chúng ta cần phải thực hiện cái việc phân biệt cái bài toán cho đúng là vì để chọn được cái hàm mục tiêu huấn luyện cái hàm huấn luyện cho nó phù hợp Chúng ta sẽ chọn được cái hàm mục tiêu huấn luyện phù hợp hay còn gọi là các cái hàm loss các cái hàm loss hay là hàm độ lỗi hàm mất mát hàm lỗi hoặc là hàm mất mát thì cái việc mà chúng ta chọn `lựa` chúng ta phân",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 20,
      "start_timestamp": "0:11:44",
      "end_timestamp": "0:12:19"
    }
  },
  {
    "page_content": "thì cái việc mà chúng ta chọn `lựa` chúng ta phân biệt được bài toán là phân lớp thì chúng ta sẽ chọn được những cái hàm loss hàm lỗi hàm `mất mát` là tương ứng với lại bài toán phân lớp rồi chúng ta biết được bài toán đó là bài toán hồi quy thì nó sẽ giúp cho chúng ta chọn lựa được cái hàm mất mát hoặc là cái hàm mục tiêu phù hợp với lại cái bài toán hồi quy đó thì đó là cái ý thứ nhất ý thứ hai đó là khi chúng ta đã xây dựng được một cái mô hình máy học rồi thì tùy vào cái bài toán là bài",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "hình máy học rồi thì tùy vào cái bài toán là bài toán phân loại hay là bài toán phân lớp mà chúng ta sẽ chọn lựa cái độ đo đánh giá nó phù hợp đó độ đo lưu ý độ đo đánh giá nó khác với cái hàm mục tiêu hàm mục tiêu thì liên quan trực tiếp đến cái việc là huấn luyện mô hình còn ở đây là `độ đo` đánh giá là chỉ đơn giản là để đánh giá xem cái mô hình của mình là mô hình nào tốt hơn mô hình nào thì như vậy thì nó sẽ giúp cho chúng ta đánh giá nó khách quan hơn phù hợp hơn đó thì mỗi một cái bài",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "khách quan hơn phù hợp hơn đó thì mỗi một cái bài toán nó sẽ có một cái độ đo đánh giá khác nhau",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=GanRdKpk31I",
      "filename": "GanRdKpk31I",
      "title": "[CS116 - Buổi 5] Part 1",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "bây giờ chúng ta sẽ tiến hành đánh giá cái mô hình này thì để đánh giá mô hình này chúng ta sẽ sử dụng cái độ lỗi đó là Mean Squared Error Mean Squared Error thì chúng ta sẽ có Đương nhiên trong scikit-learn có cái hàm đó nhưng mà ở đây chúng ta sẽ cài đặt rất là nhanh cái hàm cái cái cái cách để tính Mean Squared Error ha Thì prediction nó sẽ là bằng regression.predict và chúng ta sẽ truyền vào cái x chúng ta sẽ truyền vào cái x để ra cái giá trị dự đoán và predict trừ cho Y chính là cái sai số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:40"
    }
  },
  {
    "page_content": "dự đoán và predict trừ cho Y chính là cái sai số và mình sẽ phải lấy bình phương cái sai số này lên rồi sau đó mình sẽ tính tổng đúng không tổng các cái sai số và chia bình quân thì bình quân của mình sẽ là số phần tử đúng không số phần tử của mình chính là len của y số phần tử của số mẫu của mình sẽ là len của y Và khi đó thì cái error của mình nó sẽ là bằng đặt rất là nhanh mình có thể dùng hàm của scikit-learn cũng được nhưng mà ở đây mình cài luôn rồi thì error của mình trong trường hợp này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 1,
      "start_timestamp": "0:00:34",
      "end_timestamp": "0:01:14"
    }
  },
  {
    "page_content": "luôn rồi thì error của mình trong trường hợp này là bằng bao nhiêu error của mình trong trường hợp này là bằng 13. 1 rồi thì bây giờ chúng ta sẽ có cái sai số là à chúng ta quên chúng ta phải lấy căn nữa đúng không sqrt sai số của mình Tại vì ở đây là bình phương nó không đúng cái thứ nguyên nó mình phải lấy căn nữa np. sqrt rồi thì ở đây chúng ta có sai số là bằng 3,6 đó như vậy thì chúng ta đã hoàn thành một cái bước để thực hiện cái build mô hình, train mô hình và đánh giá một cái mô hình đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 2,
      "start_timestamp": "0:01:10",
      "end_timestamp": "0:02:02"
    }
  },
  {
    "page_content": "train mô hình và đánh giá một cái mô hình đó rồi Tiếp theo thì chúng ta sẽ xét đến cái tình huống đó là cái dữ liệu của mình là dạng phi tuyến nghĩa là sao y của mình bình thường là sẽ phụ thuộc bằng một cái hàm tuyến tính thì chúng ta sẽ thử nghiệm đó là y của mình sẽ là bằng một cái hàm bậc hai tức là một cái tình huống đơn giản nhất của phi tuyến ha thì chúng ta sẽ có công thức đó là y sẽ là bằng x bình phương nhân với một cái hệ số ví dụ ở đây hệ số của chúng ta là bằng trừ 6 thôi chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 3,
      "start_timestamp": "0:01:57",
      "end_timestamp": "0:02:45"
    }
  },
  {
    "page_content": "hệ số của chúng ta là bằng trừ 6 thôi chúng ta sẽ cho con số khác đi bằng 10 nhân với lại x bình phương trừ cho 7x cộng cho 2 đúng không và cộng cho thêm cái phần noise Ừ thì noise này chúng ta có thể cho là bằng 10 đi rồi thì bây giờ chúng ta sẽ cùng plot lên trên cái biểu đồ chúng ta sẽ thấy là nó có các cái giá trị đi theo cái đường là dạng parabol tuy nhiên với cái sai số bằng 10 thì cái nhiễu này nó Cái đường này nó nó chưa có cái sự phù hợp cho lắm chúng ta sẽ cho cái giá trị này là 20 đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 4,
      "start_timestamp": "0:02:39",
      "end_timestamp": "0:03:19"
    }
  },
  {
    "page_content": "cho lắm chúng ta sẽ cho cái giá trị này là 20 đó thì nó đã có cái sự phù hợp nhiều hơn có thể là do cái giá trị này nó lớn thì cái cái cái cái bằng cái mắt thường mình sẽ khó thấy cái sai số này có thể cho cái thằng này là khoảng bằng 3 thôi ha đó thì chúng ta đã thấy được cái sai số của nó tốt hơn và bây giờ chúng ta sẽ cùng tiến hành sử dụng cái mô hình hồi quy như hồi nãy để xem coi là điều gì xảy ra thì X.reshape rồi sau khi reshape xong thì chúng ta sẽ gọi cái hàm linear regression rồi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 5,
      "start_timestamp": "0:03:14",
      "end_timestamp": "0:04:20"
    }
  },
  {
    "page_content": "thì chúng ta sẽ gọi cái hàm linear regression rồi cũng là reg bằng rồi reg. fit x và y rồi và chúng ta sẽ cùng xem cái độ lỗi ha chúng ta sẽ cùng xem cái độ lỗi rồi độ lỗi của mình trong trường hợp này là một con số rất là lớn là một con số rất là lớn thế thì bây giờ mình sẽ trực quan hóa cái mô hình của mình Mình sẽ copy cái hàm ở đây ha hàm trực quan hóa đây để cho nó tiết kiệm thời gian thì rõ ràng là ở đây chúng ta vẫn đang sử dụng cái phương trình bậc hai à Xin lỗi phương trình bậc 1 đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 6,
      "start_timestamp": "0:04:14",
      "end_timestamp": "0:05:03"
    }
  },
  {
    "page_content": "trình bậc hai à Xin lỗi phương trình bậc 1 đó thì nó sẽ ra một cái đường thẳng ở đây muốn lấy cái điểm bên trái ngoài cùng bên đây chúng ta sẽ cho là -10 và ở đây sẽ là nhân cho -10 rồi thì khi đó Cái đường thẳng của mình nó sẽ ra là một cái đường như thế này đó nó sẽ đi xuyên qua như thế này và rõ ràng đây là thuộc cái tình huống underfitting Thế thì để chúng ta có thể vẫn sử dụng mô hình linear regression cho cái trường hợp là phi tuyến thì một trong những cái cách à chúng ta đã thảo luận",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 7,
      "start_timestamp": "0:04:57",
      "end_timestamp": "0:05:36"
    }
  },
  {
    "page_content": "một trong những cái cách à chúng ta đã thảo luận trên lớp đó chính là chúng ta sẽ dùng phương pháp à gọi là thêm cái biến thêm vô cái đặc trưng nó gọi là feature engineering mà cụ thể trong trường hợp này là thêm đặc trưng là x bình phương Tại vì chúng ta dựa trên cái trực quan hóa dữ liệu chúng ta dự đoán rằng là à cái mối quan hệ này nó không thể là một mối quan hệ tuyến tính Thì mình đoán mình đoán xem cái mối quan hệ này là bậc hai do đó thì mình sẽ add thêm một cái cột nữa là cột x bình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 8,
      "start_timestamp": "0:05:29",
      "end_timestamp": "0:06:14"
    }
  },
  {
    "page_content": "mình sẽ add thêm một cái cột nữa là cột x bình phương đó thì khi đó ở đây chúng ta sẽ nối X là bằng nối X và x bình phương thêm vô cái thành phần x bình phương ha rồi thì sau khi chúng ta đã concatenate nối thêm vô cái thành phần x bình phương thì chúng ta sẽ có cái đặc trưng X như thế này và X trong trường hợp này thì X.shape đó là bằng 40 nhân 2 tức là 2 của mình là hai chiều trong đó có một chiều là cái giá trị đặc trưng gốc và một chiều là x bình phương rồi sau đó chúng ta sẽ chạy lại cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 9,
      "start_timestamp": "0:06:09",
      "end_timestamp": "0:06:57"
    }
  },
  {
    "page_content": "x bình phương rồi sau đó chúng ta sẽ chạy lại cái mô hình này và chúng ta sẽ tiến hành đánh giá thì đánh giá chúng ta sẽ gọi lại cái hàm ở đây ha để xem coi là độ lỗi của mình à Cái này chúng ta sẽ không gọi lại cái này nữa Ok X à ở đây thì chúng ta sẽ phải dự đoán ở đây chúng ta sẽ phải dự đoán lại cái prediction đúng không Tại prediction ở đây đang dùng là cái prediction cũ Tức là cái giá trị dự đoán ở phía trên đây nó kéo xuống do đó thì chúng ta sẽ phải gọi lại cái hàm này chúng ta sẽ gọi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 10,
      "start_timestamp": "0:06:52",
      "end_timestamp": "0:07:40"
    }
  },
  {
    "page_content": "ta sẽ phải gọi lại cái hàm này chúng ta sẽ gọi lại cái hàm predict này rồi đó thì như vậy thì cái độ lỗi của mình đang từ 91 từ 91 và nó đã giảm xuống còn à trong trường hợp này là 25 như vậy là đã giảm rất là nhiều và bây giờ chúng ta sẽ cùng quan sát chúng ta sẽ cùng trực quan hóa cái mô hình này đó thì thay vì à chúng ta sử dụng cái hàm bậc hai xin lỗi hàm bậc một thì bây giờ chúng ta sẽ dùng cái hàm bậc hai trong đó nè trong đó cái hệ số của mình trước đây á là nó chỉ có một phần tử thôi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 11,
      "start_timestamp": "0:07:36",
      "end_timestamp": "0:08:30"
    }
  },
  {
    "page_content": "mình trước đây á là nó chỉ có một phần tử thôi bây giờ cái coefficient của mình nó đã có hai phần tử cái phần tử đầu tiên tương ứng là cái trọng số của cái thành phần X này và cái hệ số thứ hai là 2,96 nó tương ứng với lại cái x bình phương và chúng ta thấy là -8 x -8x à cộng cho 2x bình à Xin lỗi ở đây nếu mà chúng ta xét cái x bình phương trước đúng không Thì cái phương trình của mình nó sẽ là 2.96 nhân cho x mũ 2 tại vì cái thành phần này là x bình phương nó tương ứng với cái này là x bình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 12,
      "start_timestamp": "0:08:25",
      "end_timestamp": "0:09:19"
    }
  },
  {
    "page_content": "x bình phương nó tương ứng với cái này là x bình phương rồi à thành phần này -8.3 đúng không trừ 8.3 nhân cho x và chúng ta sẽ xem coi cái thành phần bias của mình là bao nhiêu ha bias của mình đó là regression. intercept_ rồi là bằng - 0.78 - 0.78 thì chúng ta sẽ xem cái phương trình này so với lại cái dữ liệu gốc à cái cái cái mô hình để tạo ra cái dữ liệu gốc của mình ha thì chúng ta thấy là khá là gần đúng không x bình phương ở đây thì đó là 2.96 còn ở đây là -7 thì ở đây sẽ là - 8.3 và 2",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 13,
      "start_timestamp": "0:09:14",
      "end_timestamp": "0:09:55"
    }
  },
  {
    "page_content": "2.96 còn ở đây là -7 thì ở đây sẽ là - 8.3 và 2 sẽ ở đây là trừ 0.78 như vậy cái mô hình của mình đã tạo ra khá là khớp với lại cái mô hình gốc của mình khi tạo ra cái dữ liệu huấn luyện rồi bây giờ chúng ta sẽ trực quan hóa thì thay vì chúng ta sử dụng hàm bậc 1 như ở trên thì chúng ta sẽ phải sử dụng công thức mới đó là x bình phương nhân với hệ số coefficient[1] và x nhân với hệ số coefficient[0] rồi cộng cho thành phần bias đó thì như vậy chúng ta đã ra được một cái đường cong giống như một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 14,
      "start_timestamp": "0:09:50",
      "end_timestamp": "0:10:07"
    }
  },
  {
    "page_content": "ta đã ra được một cái đường cong giống như một cái đường parabol và đi xuyên qua các cái điểm trong cái tập dữ liệu huấn luyện của mình thì trên đây đó là một cái bài hướng dẫn cài đặt mô hình linear regression với thư viện scikit-learn và trong cái bài này thì chúng ta cùng trực quan hóa được cái hàm mô hình của mình với các cái tham số đã được huấn luyện đó là regression.coefficient_ và regression.intercept_",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Gnb5JI9ynU4",
      "filename": "Gnb5JI9ynU4",
      "title": "[CS116 - Buổi 8] Part 7_2",
      "chunk_id": 15,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Kỹ thuật tiếp theo là kỹ thuật Bagging. Bagging là khi chúng ta chia ra thành các cái túi. Khác với hai kỹ thuật trước đây, Bagging sẽ sử dụng cùng một thuật toán. Nếu như trong kỹ thuật Blending hoặc Stacking, mô hình 123 cho đến N có thể là mô hình khác nhau. Ví dụ như là mô hình K-Nearest Neighbors, Neural Network, Decision Tree Thì đối với kỹ thuật Bagging, các mô hình mà mình học ở đây đều là cùng một loại mô hình Cùng một loại mô hình, cùng một loại thuật toán Mô hình 2, 3, đến Mô hình N",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:01:03"
    }
  },
  {
    "page_content": "một loại thuật toán Mô hình 2, 3, đến Mô hình N có cùng màu để thể hiện việc là cùng loại, cùng thuật toán. Bagging sẽ huấn luyện độc lập, đây chính là sự khác biệt giữa mô hình Bagging so với mô hình Boosting ở trong slide tiếp theo. Dữ liệu gốc của mình, dataset gốc của mình sẽ được split, Chia ra thành các cái túi là bag số 1, 2, 3, cho đến bag số n Đây sẽ là dữ liệu phục vụ cho việc huấn luyện mô hình Với từng dữ liệu này, chúng ta sẽ đi train cho các mô hình tương ứng Và một lần nữa, nhắc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:51",
      "end_timestamp": "0:01:52"
    }
  },
  {
    "page_content": "cho các mô hình tương ứng Và một lần nữa, nhắc lại, các mô hình này đều dùng chung một cái thuật toán và bag số 3, số 4 cho n, chúng ta sẽ train và chúng ta sẽ có n cái mô hình này sau đó cuối cùng chúng ta sẽ tổ hợp kết quả của cả n cái mô hình này thì kỹ thuật tổ hợp ở đây chúng ta có thể sử dụng kỹ thuật trước đây ví dụ như là Voting, Averaging, hoặc là thậm chí chúng ta có thể sử dụng Stacking hoặc là chúng ta có thể sử dụng kỹ thuật Weighted Averaging cũng được Rồi, thì tại sao kỹ thuật",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:46",
      "end_timestamp": "0:02:40"
    }
  },
  {
    "page_content": "Averaging cũng được Rồi, thì tại sao kỹ thuật Bagging này tạo ra sự hiệu quả? Tại vì chính việc chúng ta chia tập dữ liệu ra thành nhiều thành phần khác nhau thì nó sẽ giúp cho mô hình của mình sau này khi chúng ta tổng hợp, nó sẽ có tính chất tổng quát Nó sẽ không quá bị phụ thuộc vào một mẫu dữ liệu nào đó. Ví dụ, cái mô hình số 1 sẽ được train và thực thi rất tốt trên tập dữ liệu là bag số 1. Sang cái mô hình dữ liệu, nó sẽ có những điểm yếu và điểm yếu đó thông thường sẽ biểu hiện ở những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 3,
      "start_timestamp": "0:02:33",
      "end_timestamp": "0:03:26"
    }
  },
  {
    "page_content": "và điểm yếu đó thông thường sẽ biểu hiện ở những bag còn lại. Mô hình số 2 sẽ được huấn luyện và thực hiện rất tốt trên tập dữ liệu ở bag số 2. Mô hình số 3 cũng sẽ thực hiện rất tốt trên những tình huống của dữ liệu. Nhưng khi các mô hình này là cùng loại, khi mà mình Ensemble, nó sẽ đạt được ưu thế, đó là tính bổ trợ bổ sung cho nhau. Mô hình số 1 sẽ yếu ở những bag số 2, tình huống dữ liệu số 2, số 3, số n thì mô hình số 2 sẽ bù đắp Mô hình số 2 yếu ở những tình huống số 1, số 3, số n thì mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 4,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:14"
    }
  },
  {
    "page_content": "2 yếu ở những tình huống số 1, số 3, số n thì mô hình số 1, số 3 và số n sẽ bù đắp lại cho mô hình số 2 Đấy chính là ý nghĩa của kỹ thuật Bagging Kỹ thuật Bagging là kỹ thuật nền tảng của kỹ thuật Random Forest, đó là một ví dụ điển hình. Mô hình thành phần Mỗi một tree là một model thành phần, được huấn luyện trên những cái tập, những cái bag dữ liệu, những cái túi dữ liệu đã được phân ra từ cái bộ dữ liệu gốc. Chúng ta sẽ có nhiều cái cây này Và khi chúng ta có một cái mẫu dữ liệu mới cần",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 5,
      "start_timestamp": "0:04:01",
      "end_timestamp": "0:05:26"
    }
  },
  {
    "page_content": "Và khi chúng ta có một cái mẫu dữ liệu mới cần phải dự đoán Đây chính là cái feature, đây là một cái feature mới Thì qua cái cây số 1, nó sẽ đi theo cái đường như thế này Và nó đưa ra cái dự đoán đó là Class A Vì vậy, nếu chúng ta có thể sử dụng kỹ thuật Ensemble như đã học trong phần cơ bản, đó là kỹ thuật Voting, thì chúng ta sẽ đưa ra Final Class. Ví dụ, nếu chúng ta có thể sử dụng kỹ thuật Ensemble như đã học trong phần cơ bản, đó là kỹ thuật Voting, thì chúng ta sẽ đưa ra Final Class. Ví",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 6,
      "start_timestamp": "0:05:14",
      "end_timestamp": "0:06:11"
    }
  },
  {
    "page_content": "Voting, thì chúng ta sẽ đưa ra Final Class. Ví dụ như N trong trường hợp này bằng 3, thì chúng ta thấy 2 đáp án B và 1 đáp án E Vì vậy nó sẽ giúp chúng ta đưa ra kết luận cuối cùng, đây chính là cái nhãn Class B Và ưu điểm của kỹ thuật Bagging và Random Forest nó chính là nó có tính hiệu quả do đạt được mức độ chính xác cũng như là đạt được khả năng tổng quát hóa Như đã giải thích ở trong slide trước, tức là việc chia ra thành những dữ liệu khác nhau Rồi nó sẽ chia ra các tình huống dữ liệu Và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 7,
      "start_timestamp": "0:05:52",
      "end_timestamp": "0:06:58"
    }
  },
  {
    "page_content": "nhau Rồi nó sẽ chia ra các tình huống dữ liệu Và các mô hình của mình sẽ học cho các tình huống đó Thì khi chúng ta tổng hợp lại, nó sẽ thành một cái mô hình Có tính tổng quát cao, do nó khai thác được những điểm mạnh, điểm yếu Nó sẽ khai thác được điểm mạnh của tất cả các mô hình và các điểm yếu của từng mô hình sẽ bị giảm bớt do sự bổ trợ bù trừ từng mô hình còn lại. Ưu điểm là nó có thể thực hiện được trên số lượng đặc trưng rất là lớn mà không cần phải bước phân tích đặc trưng hay còn gọi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 8,
      "start_timestamp": "0:06:46",
      "end_timestamp": "0:07:33"
    }
  },
  {
    "page_content": "cần phải bước phân tích đặc trưng hay còn gọi là EDA hoặc Feature Engineering. Đây chính là một trong những ưu điểm của thuật toán của nhóm Random Forest. Tại vì sao? Khi chúng ta có rất nhiều đặc trưng, khi đưa vào mô hình Decision Tree, thì tại một cái node, nó sẽ làm việc cho một cái feature. Tại một cái node này, nó sẽ đưa ra và nó sẽ đưa ra cái quyết định cuối cùng khi đến được cái nút lá. Rất nhiều cái feature đó sẽ rải ra cho các cái cây này. sẽ rải đều ra cho các cái cây này, nó sẽ phân",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 9,
      "start_timestamp": "0:07:24",
      "end_timestamp": "0:08:11"
    }
  },
  {
    "page_content": "sẽ rải đều ra cho các cái cây này, nó sẽ phân tán. Và như vậy thì việc phân tán các cái feature này, nó đồng thời cũng sẽ giúp cho mình đó là không có bị quá biased, không có bị quá phụ thuộc vào một cái feature nào hết, mà nó đòi hỏi phải có cái sự tổng hợp, tổng thể của toàn bộ tất cả các cái feature với nhau. Cái sự phối hợp đó, nó tạo ra cái tính tổng quát cho cái mô hình của mình. Tính linh hoạt là chúng ta có thể dùng cả cho mô hình Random Forest này cho bài toán hồi quy, lẫn phân loại.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 10,
      "start_timestamp": "0:08:01",
      "end_timestamp": "0:08:51"
    }
  },
  {
    "page_content": "Forest này cho bài toán hồi quy, lẫn phân loại. Ví dụ như trong scikit-learn, chúng ta sẽ có Random Forest Regressor cho bài toán hồi quy và Random Forest Classifier cho bài toán phân loại. thì nó có thể giải quyết cho cả hai loại bài toán này nó có thể song song hóa được thuật toán đây chính là một trong những điểm mạnh của thuật toán này tại vì sao? tại vì việc chúng ta chia ra các mô hình với nhau thì dẫn đến là nó sẽ tổng hợp được nó sẽ có thể tách biệt ra được các dữ liệu và các mô hình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 11,
      "start_timestamp": "0:08:49",
      "end_timestamp": "0:09:26"
    }
  },
  {
    "page_content": "thể tách biệt ra được các dữ liệu và các mô hình không có dính dáng gì với nhau hết do đó thì mỗi một cái core xử lý của GPU và nó sẽ làm việc độc lập với nhau. Và cái cuối cùng, đó chính là tính bền vững. Tức là nó sẽ ít bị ảnh hưởng bởi cái outlier, tức là những cái đặc trưng nào, hoặc là cái mẫu dữ liệu nào, mà nó tạo ra cái sự gọi là khác biệt so với lại những cái còn lại. Thì nếu như nó có ảnh hưởng, thì nó chỉ bị ảnh hưởng bởi một cái khu vực nào đó thôi. Ví dụ, nếu như nó có ảnh hưởng,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 12,
      "start_timestamp": "0:09:23",
      "end_timestamp": "0:10:14"
    }
  },
  {
    "page_content": "vực nào đó thôi. Ví dụ, nếu như nó có ảnh hưởng, thì nó chỉ bị ảnh hưởng bởi một cái khu vực nào đó thôi. Ví dụ nó sẽ bị ảnh hưởng bởi một khu vực này Còn rất nhiều những nhánh còn lại hoặc là những cây còn lại thì nó đều có thể là không bị ảnh hưởng Nó chỉ bị ảnh hưởng bởi một yếu tố cục bộ thôi Bị ảnh hưởng một cách cục bộ mà không có sự lan truyền cho tất cả những node còn lại trong toàn bộ rừng Random Forest Và chính điều đó cũng góp phần vào việc ít có khả năng bị overfitting Tại vì sao?",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 13,
      "start_timestamp": "0:10:07",
      "end_timestamp": "0:10:54"
    }
  },
  {
    "page_content": "việc ít có khả năng bị overfitting Tại vì sao? Tại vì nó phân tán ra, phân tán dữ liệu ra rất nhiều các bag khác nhau Từng model của mình nếu như có overfit thì cũng chỉ overfit trên 1 bag thôi Nhưng tổ hợp của nhiều mô hình thì nó lại giúp cho mình giảm thiểu được overfitting này Đối với kỹ thuật Bagging, nó sẽ khó giải thích mô hình tại vì sao? Tại vì khi chúng ta chia ra làm rất nhiều cây, tổ hợp của các feature sẽ rải ra rất nhiều Tại vì sao? Tại vì khi chúng ta chia ra làm rất nhiều cây và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 14,
      "start_timestamp": "0:10:44",
      "end_timestamp": "0:11:31"
    }
  },
  {
    "page_content": "Tại vì khi chúng ta chia ra làm rất nhiều cây và tổ hợp của các feature ở đây nó sẽ rải ra rất nhiều Và việc tổng hợp nó lại để mà có thể biết là feature này nó sẽ kết hợp với feature kia để tạo ra được quyết định cuối cùng Rõ ràng là rất khó để có thể cảm nhận được tại sao mình lại có thể chia ra thành các cây như vậy và các cái cây này vận hành nhưng mà cái sự tương tác giữa các feature với nhau thì cũng rất là khó giải thích. Cái độ phức tạp của thuật toán nó cũng cao tại vì bản thân thuật",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 15,
      "start_timestamp": "0:11:28",
      "end_timestamp": "0:12:26"
    }
  },
  {
    "page_content": "của thuật toán nó cũng cao tại vì bản thân thuật toán Decision Tree là nó cũng đã có cái độ phức tạp cao rồi. Nó sẽ phải xét trên các cái cơ sở lý thuyết về Information Gain, tức là sự gia tăng về thông tin hoặc là sử dụng các độ đo như là Gini để giảm thiểu sự không đồng đều. Tính toán trên từng cái node này và sau đó thì nó sẽ tìm ra cái node nào cho lượng thông tin nhiều nhất để nó xây dựng cái cây. Tóm lại đó là độ phức tạp cao là nó đến từ việc xây dựng từng cái cấu trúc cây. Và nó có thể",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 16,
      "start_timestamp": "0:12:17",
      "end_timestamp": "0:13:09"
    }
  },
  {
    "page_content": "việc xây dựng từng cái cấu trúc cây. Và nó có thể bị bias với cái dữ liệu, cái tình huống đó là cái dữ liệu không cân bằng. Đối với mẫu dữ liệu có nhãn quá thiên lệch, ví dụ 3 nhãn là ABC, ABC quá thiên lệch cho một class nào đó, thì mô hình sẽ tập trung vào class A, mà chính bởi yếu tố ngẫu nhiên, ngẫu nhiên nên những mẫu nào nó xuất hiện nhiều thì nó sẽ bị thiên vị vào những mẫu đó do yếu tố xác suất thì xác suất liên quan đến việc là dữ liệu không cân bằng chứ còn nếu 3 cái mẫu, 3 cái class",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "không cân bằng chứ còn nếu 3 cái mẫu, 3 cái class A, B, C này mà có sự gọi là phân bố đồng đều thì nó sẽ không có sự quá thiên lệch cho 1 cái class nào hết Một số mô hình điển hình đó là Random Forest, Bagging, K-Nearest Neighbors, Bagging SVM",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gnpctQm2TkI",
      "filename": "gnpctQm2TkI",
      "title": "[CS116 - Buổi 13] Part 3_1",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và bên cạnh cái độ đo Information Gain thì chúng ta còn có thể sử dụng một số độ đo khác ví dụ độ đo về Gini, độ đo Gini thì đây cũng là một cái loại độ đo nhưng mà ở đây thì chúng ta chỉ tìm hiểu về cái ý tưởng của thuật toán Decision Tree do đó chúng ta chỉ lấy ra à cái độ đo Information Gain để làm một cái ví dụ và ở đây chúng ta sẽ nhận xét về thuật toán Decision Tree thì ưu điểm của thuật toán này đó chính là cái tính giải thích của mô hình rất là cao do chúng ta nhìn vào cái đường đi của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:35"
    }
  },
  {
    "page_content": "rất là cao do chúng ta nhìn vào cái đường đi của cái cây đó chúng ta thấy à nếu như cái đặc trưng này nó đạt được cái điều kiện này thì chúng ta sẽ đi như thế nào đó thì cái việc chia ra các cái giá trị theo các cái nhánh nó sẽ giúp cho chúng ta có thể giải thích được cái mô hình của mình nó vận hành như thế nào và nó có thể làm việc được trên cả những cái dữ liệu dạng số lẫn cái dữ liệu phân loại ví dụ đối với cái dữ liệu dạng phân loại thì rất là dễ rồi chúng ta sẽ đưa vào một cái biến X và ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 1,
      "start_timestamp": "0:00:30",
      "end_timestamp": "0:01:07"
    }
  },
  {
    "page_content": "là dễ rồi chúng ta sẽ đưa vào một cái biến X và ở đây chúng ta sẽ có có cái loại là X1, X2, X3. Trong trường hợp mà dữ liệu của mình dạng số thì chúng ta cũng có khả năng phân loại được. Ví dụ như chúng ta đưa vào X nhánh của mình đó là X sẽ bé hơn A. Rồi ở đây sẽ là X của mình là từ A cho đến B và ở đây sẽ là X lớn hơn B thì cho dù dữ liệu loại số hay là dữ liệu loại phân loại thì chúng ta vẫn có thể làm việc được. Và đây là một cái mô hình phi tham số do nó không đưa ra các cái giả định về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 2,
      "start_timestamp": "0:01:00",
      "end_timestamp": "0:01:42"
    }
  },
  {
    "page_content": "tham số do nó không đưa ra các cái giả định về cái sự phân bố của các cái biến và mối quan hệ giữa các cái đặc trưng với nhau của các cái đặc trưng với cái output. Tức là ở đây X và Y, à X và Y, chúng ta không có một cái sự tính toán nhân với một cái đại lượng theta nào đó, X nhân với theta nào đó để mà ra cái thằng Y. Tức là chúng ta sẽ không có cái sự tương tác, chúng ta sẽ không có cái sự tương tác này với lại một cái tham số nào đó. Do đó thì đây là một cái mô hình phi tham số. Và ưu điểm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 3,
      "start_timestamp": "0:01:35",
      "end_timestamp": "0:02:15"
    }
  },
  {
    "page_content": "đây là một cái mô hình phi tham số. Và ưu điểm tiếp theo đó là nó được sử dụng trong cái việc là lựa chọn đặc trưng. Decision Tree cũng được sử dụng cho cái bước gọi là lựa chọn đặc trưng Feature Selection. Tại vì sao? Tại vì khi chúng ta trong cái quá trình mà chúng ta xây dựng cái cây chúng ta thực hiện rất nhiều những cái loại độ đo và với những cái loại độ đo đó thì nó đã vô tình tạo cho chúng ta là xác định xem cái mối quan hệ giữa cái đặc trưng mà mình đang xem xét tại một cái nút, một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 4,
      "start_timestamp": "0:02:11",
      "end_timestamp": "0:02:48"
    }
  },
  {
    "page_content": "trưng mà mình đang xem xét tại một cái nút, một cái nút, một cái feature Xi nào đó tại một cái nút nó có cái mối quan hệ như thế nào so với cái output Y này. Nếu như chúng ta chọn cái nút này tức là cái Xi có một cái mối quan hệ gắn bó với lại cái giá trị output nếu như chúng ta chọn cái nút này để mà tiến hành là đi xuống các cái nhánh. Còn nếu như cái Xi này nó không có được chọn Tức là cái hàm lượng thông tin hoặc là cái mối liên hệ giữa Xi với lại Y này nó rất thấp. Đó, như vậy thì ưu điểm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 5,
      "start_timestamp": "0:02:42",
      "end_timestamp": "0:03:21"
    }
  },
  {
    "page_content": "lại Y này nó rất thấp. Đó, như vậy thì ưu điểm của nó đó là nhờ cái cơ chế lựa chọn đặc trưng nó sẽ ưu tiên các cái đặc trưng mà có nhiều thông tin để phân thành các cái nhánh mới. Thì đây chính là ưu điểm của nó và nó có thể sử dụng cái này để cho cái bước là Feature Selection, chọn được đặc trưng. Ờ mô hình nào cũng vậy nó cũng sẽ có những cái ưu điểm và khuyết điểm. Thì khuyết điểm của mô hình này chính là có khả năng nó sẽ bị overfitting, tức là nó dễ bị overfit với cái dữ liệu. Nếu như cây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 6,
      "start_timestamp": "0:03:17",
      "end_timestamp": "0:03:50"
    }
  },
  {
    "page_content": "là nó dễ bị overfit với cái dữ liệu. Nếu như cây của mình nó không được cắt tỉa, nó không có được cắt tỉa hoặc là cái cây của mình nó quá sâu, tức là cái mô hình của mình nó quá phức tạp thì khi đó nó sẽ dễ bị overfitting. Và để giải quyết vấn đề này thì trong những cái phiên bản của Decision Tree phía sau thì người ta có kết hợp cái việc là cắt tỉa cái cành để làm sao cho cái cây của mình nó bớt cái sự phức tạp đi. Đồng thời chúng ta sẽ có những cái siêu tham số để giới hạn cái độ sâu của cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 7,
      "start_timestamp": "0:03:43",
      "end_timestamp": "0:04:22"
    }
  },
  {
    "page_content": "cái siêu tham số để giới hạn cái độ sâu của cái mô hình. Và mấy cái mô hình nâng cao Ensemble thì thay vì chúng ta làm trên một cái toàn bộ cái dữ liệu của mình thì chúng ta sẽ làm trên ngẫu nhiên trên những cái bộ giá trị trên những cái tập dữ liệu ngẫu nhiên từ cái tập dữ liệu train để hy vọng rằng là cái cây của mình nó có cái tính tổng quát cao hơn tránh bị overfit vào cái dữ liệu. Cái khuyết điểm tiếp theo đó là cái tính không ổn định của cái Decision Tree. Ờ chỉ cần chúng ta chỉ cần thay",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 8,
      "start_timestamp": "0:04:16",
      "end_timestamp": "0:04:55"
    }
  },
  {
    "page_content": "Decision Tree. Ờ chỉ cần chúng ta chỉ cần thay đổi cái dữ liệu của của mình một phần nhỏ, chúng ta chỉ cần thay đổi cái dữ liệu một phần nhỏ thì cây của mình nó có thể thay đổi hoàn toàn, tức là nó thay đổi cái cấu trúc của toàn bộ cái cái cái cái cái cái cây quyết định này của mình luôn. Và kỹ thuật ở đây để chống cái hiện tượng là không ổn định này là như mình đã chúng đã đề cập ở trong cái phần overfitting, đó là chúng ta sẽ chọn ra ngẫu nhiên một cái tập con của cái dữ liệu của mình để để",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 9,
      "start_timestamp": "0:04:48",
      "end_timestamp": "0:05:28"
    }
  },
  {
    "page_content": "một cái tập con của cái dữ liệu của mình để để khi chúng ta làm trên những cái tập con đó và tạo ra nhiều cái cây á thì nó sẽ tạo ra cái mô hình có cái tính ổn định cao hơn. Nếu như có một cái dữ liệu nào đó mà nhiễu, à có một cái dữ liệu nhiễu nào đó thì cái mô hình mà cây nó chỉ ảnh hưởng trên cái phần ở trên cái tập dữ liệu đó thôi, tức là cái cây đó nó sẽ overfit trên cái dữ liệu mà bị nhiễu đó thôi. Còn rất nhiều những cái dữ liệu khác tổng quát hơn và nó sẽ tạo ra nhiều cái cây có cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 10,
      "start_timestamp": "0:05:22",
      "end_timestamp": "0:06:02"
    }
  },
  {
    "page_content": "quát hơn và nó sẽ tạo ra nhiều cái cây có cái tính gọi là tổng quát hóa cao thì nó sẽ bù trừ được cái cho cái cây mà bị nhiễu bởi cái cái dữ liệu nhiễu đó. Thì cái kỹ thuật này nó gọi là Ensemble của Random Forest. Và một cái điểm yếu khác đó chính là nó bị khó tối ưu cái việc tìm ra cái cây nó tốn cái chi phí rất là tính toán rất là cao. Tại vì sao? Trong một cái lần mà nó duyệt thì nó sẽ phải thực hiện tính toán trên toàn bộ tất cả các cái nút để tìm ra cái cái đặc trưng nào mà có cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 11,
      "start_timestamp": "0:05:57",
      "end_timestamp": "0:06:30"
    }
  },
  {
    "page_content": "cái nút để tìm ra cái cái đặc trưng nào mà có cái Information Gain tối ưu. Thì như vậy thì nó phải duyệt qua hết tất cả các đặc trưng và duyệt qua hết tất cả các cái biến của mình hết cái cái dữ liệu của mình. Như vậy thì cái chi phí tính toán của nó cao. Và khi dùng Heuristic, nếu như chúng ta có sử dụng một số kỹ thuật Heuristic thì lúc đó cái cây của mình nó không chắc là nó đảm bảo được tối ưu. Như vậy là đây là cái sự đánh đổi giữa độ chính xác và cái yếu tố tốc độ. Nếu như mình xây dựng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 12,
      "start_timestamp": "0:06:26",
      "end_timestamp": "0:07:12"
    }
  },
  {
    "page_content": "xác và cái yếu tố tốc độ. Nếu như mình xây dựng cái cây theo cái kiểu Heuristic thì chúng ta có thể đánh đổi là cái cây của mình nó không có đạt được cái mức độ tối ưu. Và cuối cùng đó chính là bias. Bias thì nó sẽ có cái xu hướng là bị ảnh hưởng bởi các cái đặc trưng mà có nhiều cái giá trị, tức là có nhiều cái biến phân loại hoặc là cái phạm vi của mình nó lớn hơn biến số. Cái phạm vi của mình nó lớn hơn vì nó sẽ giúp cho mình tạo ra nhiều nhánh hơn. Như vậy thì trong cái phần bias này nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 13,
      "start_timestamp": "0:07:04",
      "end_timestamp": "0:07:52"
    }
  },
  {
    "page_content": "nhánh hơn. Như vậy thì trong cái phần bias này nó cũng tương tự như cái overfitting. Ở đây bias nó tương tự overfitting, tức là vì cái mô hình của mình nó sẽ dễ bị bias dẫn đến là nó kéo theo cái hiện tượng overfit này. Thì nếu như trong trường hợp của mình mà chúng ta có một cái biến X1 nào đó và cái X1 này nó có rất nhiều cái giá trị, ví dụ như nó sẽ bao gồm là giá trị là A, giá trị là B, giá trị là C vân vân cho đến giá trị là Z. Tức là nó có rất nhiều cái giá trị thì cái cây của mình nó có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 14,
      "start_timestamp": "0:07:48",
      "end_timestamp": "0:08:32"
    }
  },
  {
    "page_content": "rất nhiều cái giá trị thì cái cây của mình nó có xu hướng là nó sẽ bias vào cái biến X mà có nhiều giá trị. Ví dụ nếu X2 của mình nó chỉ có hai giá trị thôi đó là U và P thôi ví dụ vậy. Thì mô hình của mình nó sẽ ưu tiên chọn cái X, nó sẽ chọn cái X thay vì nó chọn cái Y. Thì đây chính là cái tính bias. Và đây là một cái hình ảnh ví dụ cho cái một dataset đó là Titanic Dataset. Đây là hai cái cây được tạo ra bởi hai cái cấu hình, hai cái siêu tham số khác nhau của Decision Tree trong cái thư",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 15,
      "start_timestamp": "0:08:25",
      "end_timestamp": "0:09:07"
    }
  },
  {
    "page_content": "tham số khác nhau của Decision Tree trong cái thư viện là scikit-learn. Thì ở đây nếu như chúng ta dùng cái giới tính đúng không là ở đây là bé hơn 0.5 thì mình không rõ bé hơn 0.5 đó là nam hay nữ ha. Ví dụ bé hơn 0.5 là nữ đi thì chúng ta sẽ chia ra làm hai nhánh là true hay false. Nếu true tức là nữ thì đến đây là chúng ta sẽ xem cái PClass của mình là bé hơn 2.5 hay không rồi chúng ta sẽ đưa ra cái quyết định đó. Thì đây là một cái cấu trúc cây đó, mỗi một cái nút này nó sẽ tương ứng với",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 16,
      "start_timestamp": "0:09:02",
      "end_timestamp": "0:09:37"
    }
  },
  {
    "page_content": "cây đó, mỗi một cái nút này nó sẽ tương ứng với lại một cái feature, một cái feature. Và trong cái phần thực hành thì chúng ta sẽ thử nghiệm với cái dataset này. Và bên cạnh cái mô hình Decision Tree thì chúng ta sẽ còn rất nhiều những cái mô hình phân lớp khác à rất là hiệu quả ví dụ như là mô hình Support Vector Machine. Thì trước cái thời điểm năm 2012 khi mà Deep Learning ra đời thì các cái mô hình máy học đều dựa trên cái nền tảng ờ về margin machine, tức là có xây dựng cái mô hình sao cho",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 17,
      "start_timestamp": "0:09:33",
      "end_timestamp": "0:10:12"
    }
  },
  {
    "page_content": "machine, tức là có xây dựng cái mô hình sao cho cái biên phân loại của mình là lớn nhất. Thì Support Vector Machine là trong cái giai đoạn đó là thời kỳ hoàng kim và cho cái độ chính xác rất là cao cũng như là nó dựa trên cái nền tảng toán vững chắc. Ngoài ra thì chúng ta còn có các cái mô hình như là Naive Bayes dựa trên lý thuyết về thống kê. Random Forest thì chúng ta đã đề cập hồi nãy, tức là chúng ta sẽ xây dựng rất nhiều cái cây trên rất nhiều những cái tập dữ liệu con khác nhau rồi. Và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 18,
      "start_timestamp": "0:10:08",
      "end_timestamp": "0:10:58"
    }
  },
  {
    "page_content": "nhiều những cái tập dữ liệu con khác nhau rồi. Và dựa trên cái cơ chế đó là Bagging là thực hiện độc lập train các cái cây, cái cái cây quyết định nó độc lập. Và cuối cùng đó là nhóm các cái thuật toán về Boosting. Thì đây chính là những cái thuật toán mà cho cái độ chính xác rất là cao ở trong các cái cuộc thi của Kaggle. Như vậy thì bài hôm nay chúng ta đã cùng lướt qua các cái mô hình từ mô hình tuyến tính với Logistic Regression và các cái mô hình phi tuyến tính ví dụ như là K-Nearest",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 19,
      "start_timestamp": "0:10:52",
      "end_timestamp": "0:11:32"
    }
  },
  {
    "page_content": "cái mô hình phi tuyến tính ví dụ như là K-Nearest Neighbor, rồi MLP, mạng Neural Network, tức là mạng có nhiều lớp, mạng Neural có nhiều lớp, rồi Decision Tree. Và đồng thời chúng ta cũng được giới thiệu qua một số các một số cái cái cái tên của một số cái mô hình, trong đó có cái nhóm thuật toán về Boosting là những cái thuật toán mà cho cái độ chính xác rất là cao trên cái cuộc thi của Kaggle. Và sau này khi mà chúng ta cần thực hiện cái dự án mà đòi hỏi có cái sự gọi là đòi hỏi có cái cái độ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 20,
      "start_timestamp": "0:11:25",
      "end_timestamp": "0:11:32"
    }
  },
  {
    "page_content": "mà đòi hỏi có cái sự gọi là đòi hỏi có cái cái độ chính xác cao thì chúng ta sẽ sử dụng cái thuật toán về Boosting thay vì chúng ta sử dụng các cái thuật toán về Linear. Tại vì những cái dữ liệu của mình trong thực tế đa số là có mối quan hệ rất là phức tạp. Thì Decision Tree cũng là một trong những cái hướng tiếp cận và cũng được sử dụng khá là phổ biến hiện nay. Và các cái biến thể của Decision Tree như là Random Forest, các cái thuật toán như là Gradient Boost thì nó cũng đâu đó có sử dụng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "là Gradient Boost thì nó cũng đâu đó có sử dụng cái thành phần trong cái mô hình đó là Gradient.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=gSbV7SypJa4",
      "filename": "gSbV7SypJa4",
      "title": "[CS116 - Buổi 8] Part 6 (tt)",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng đến với các cái độ đo cho bài toán hồi quy thì ở đây chúng ta nhắc lại chúng ta sẽ có hai cái loại độ đo đầu tiên đó là độ đo của hàm lỗi và thứ hai đó là độ đo cho cái việc đánh giá độ đo cho vệ cái đánh giá mô hình thì cái độ đo cho Hạm lỗi á Nó sẽ được thực hiện ở ở trong cái quá trình huấn luyện còn độ đo đánh giá thì chúng ta sẽ thực hiện sau khi huấn luyện tại sao hai cái độ đo này nó phải khác nhau Tại vì có những cái độ đo nó phù hợp cho cái việc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:56"
    }
  },
  {
    "page_content": "Tại vì có những cái độ đo nó phù hợp cho cái việc đánh giá nhưng mà nó không có phù hợp cho cái việc là huấn luyện ví dụ để huấn luyện được thì cái hàm của mình nó phải thỏa mãn một số cái tính chất về mặt toán học Ví dụ như có khả năng tính được đạo hàm đó ví dụ như có thể dễ dàng tính hoặc là tránh được một số cái hiện tượng như là độ lỗi của mình nó bị à Cái radian của mình nó bị tiêu tiêu Yến hoặc là nó sẽ khiến cho cái mô hình của mình khó huấn luyện hơn đó thì rõ ràng ở đây là cái hàm độ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:30"
    }
  },
  {
    "page_content": "huấn luyện hơn đó thì rõ ràng ở đây là cái hàm độ lỗi cho cái quá trình huấn luyện nó sẽ khác so với lại cái hàm để mà đánh giá cái hiệu quả của cái mô hình của mình thì đối với cái bài toán hồi quy thì cái việc chọn lựa cái hàm độ lỗi á cái việc chọn lựa cái hàm độ lỗi nó sẽ có cái vai trò đó là làm sao để cho cái giá trị Dự đoán và cái giá trị thực tế giống nhau trong cái quá trình huấn luyện cái hàm mà dự đoán của cái mô hình của mình nó phải gần giống xấp xỉ với lại cái hàm với lại xin lỗi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:24",
      "end_timestamp": "0:02:04"
    }
  },
  {
    "page_content": "gần giống xấp xỉ với lại cái hàm với lại xin lỗi với lại cái giá trị trong thực tế của dữ liệu của mình Thế thì ở đây chúng ta sẽ có cái tập dữ liệu mẫu ở đây chúng ta sẽ chia ra làm hai tập đó là tập Trend và tập test và ở đây chúng ta sẽ có cái biến đầu vào là bốn cái cột đầu tiên và cái biến đầu ra đó chính là cái cột profit với cái tập dữ liệu Trend chúng ta sẽ lấy ra cái biến đầu vào X là bốn cái cột này rồi sau đó chúng ta sẽ đưa vào mô hình máy học bản chất của một cái hạ của một cái mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:01:59",
      "end_timestamp": "0:02:45"
    }
  },
  {
    "page_content": "máy học bản chất của một cái hạ của một cái mô hình máy học đó chính là một cái hàm số f th x nó nhận đầu vào của mình là x và nó sẽ đưa ra cái giá trị Dự đoán đưa ra cái giá trị Dự đoán và cái giá trị Dự đoán này thì ký hiệu bằng chữ y mũ và mình luôn mong muốn cái giá trị Dự đoán này nó phải xấp xỉ với lại cái giá trị thực tế nó phải xấp xỉ với cái giá trị thực tế và giá trị thực tế thì được ký hiệu bằng chữ y mong muốn hai thằng này sắp xỉ nhau và để để cho y và y ngã xắp xỉ nhau thì chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:39",
      "end_timestamp": "0:03:18"
    }
  },
  {
    "page_content": "và để để cho y và y ngã xắp xỉ nhau thì chúng ta sẽ phải có một cái hàm nó gọi là hàm độ lỗi để thể hiện cái sự sai khác giữa giá trị thực tế và giá trị Dự đoán và có rất nhiều những cái hàm độ lỗi khác nhau tuy nhiên đối với các cái bài toán hồi quy thì một trong những độ lỗi được sử dụng rất là phổ biến đó chính là độ lỗi msi hay là viết tắc của chữ Min Square error và công thức của cái Min Square chính là trung bình cộng của các cái sai số bình phương trong đó y y chính là cái giá trị thực",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:03:14",
      "end_timestamp": "0:04:09"
    }
  },
  {
    "page_content": "phương trong đó y y chính là cái giá trị thực tế còn y mũ chính là cái giá trị dựng đoán và chúng ta sẽ đến cái phần thứ hai của cái cái độ đo đánh giá cho mô hình hội quy đó chính là cái độ đo để giúp cho mình đánh giá mô hình cái này sẽ được thực hiện sau khi đã huấn luyện và cái như chúng ta đã đề cập trước đó đó thì cái độ đo đánh giá của mình nó không nhất thiết nó phải giống với lại cái cái hàm độ lỗi của cái mô hình khi mình huấn luyện đó thì tương tự như là cái độ độ lỗi thì chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:04:05",
      "end_timestamp": "0:04:40"
    }
  },
  {
    "page_content": "thì tương tự như là cái độ độ lỗi thì chúng ta sẽ đưa cái dữ kiện đầu vào cái đặc trưng đầu vào của mình trên cái tập dữ liệu test trên cái tập test đưa vào cái mô hình đã được huấn luyện ch Chúng ta có một cái chú ý ở đây là mô hình này đã được huấn luyện tức là hàm f theta x này theta ở đây là cái theta đã được chọn lựa để làm sao cho tối ưu cái độ lỗi của tập dữ liệu Trend rồi và T cũng tương tự như vậy chúng ta sẽ đưa ra được cái giá trị Dự đoán và cái giá trị Dự đoán này là cho cái tập dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:04:35",
      "end_timestamp": "0:05:12"
    }
  },
  {
    "page_content": "đoán và cái giá trị Dự đoán này là cho cái tập dữ liệu test và mình luôn mong muốn là cái giá trị Dự đoán này nó sẽ phải xắp xỉ với giá trị Dự đoán xin lỗi xấp xỉ với lại cái giá trị trong thực tế và để đánh giá được đúng không để đánh giá được cái size số này thì chúng ta sẽ sử dụng rất nhiều những cái độ đo khác nhau để tạo ra cái sự Khách quen khi chúng ta đánh giá cái hiệu quả của mô hình của mình thì ở đây chúng ta có những cái độ đo đánh giá ví dụ như là Mae mse và root me Square thì chi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:05:08",
      "end_timestamp": "0:05:55"
    }
  },
  {
    "page_content": "ví dụ như là Mae mse và root me Square thì chi tiết thì chúng ta sẽ bàn trong cái slide tiếp theo thì các cái độ đo đánh giá cho cái bài toán hồi quy thì chúng ta sẽ xét cái ví dụ dụ như sau ha Ờ ở đây thì chúng ta sẽ thấy là đầu vào của mình sẽ là x và cái giá trị đầu ra của mình sẽ là y và cái đường thẳng ở đây cho cái bài toán hồi Q giả sử như chúng ta có một cái đường là dạng đường tuyến tính thì với một cái dữ kiện đầu vào xero x y ở đây x y ở đây thì chiếu lên trên cái mô hình chiếu lên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:05:48",
      "end_timestamp": "0:06:33"
    }
  },
  {
    "page_content": "y ở đây thì chiếu lên trên cái mô hình chiếu lên trên mô hình thì chúng ta sẽ có được cái giá trị dự đoán là y mũ y rồi khi chúng ta chiếu lên chúng ta chạm vào cái mô Đường mô hình của mình cái đường hồi Q của mình thì nó sẽ ra được cái giá trị là dự đoán trong khi đó cái điểm thực tế của mình thì nó lại nằm ở đây cái điểm thực tế của mình nó nằm ở đây thì khoảng cách từ cái điểm thực tế yy cho đến cái giá trị Dự đoán y mũ y đó chính là cái sii số và chúng ta sẽ có các cái sii số để đánh giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:06:26",
      "end_timestamp": "0:07:15"
    }
  },
  {
    "page_content": "số và chúng ta sẽ có các cái sii số để đánh giá để thể hiện cái sự sai sai biệt giữa dữ liệu thực với lại cái đường hồi quy ha và đầu tiên đó chính là độ đo Min absolute error và nó cũng tương tự như là Min Square thì đây sẽ là trung bình cộng của các cái size trị tuyệt đối của các cái size số tiếp theo đó là Min Square thì chúng ta đã đề cập ở trong cái phần hàm độ lỗi khi huấn luyện mô hình root Min Square eror cái từ này là quyết tắt của chữ root còn Min Square eror thì chúng ta đã đề cập ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:07:07",
      "end_timestamp": "0:08:02"
    }
  },
  {
    "page_content": "root còn Min Square eror thì chúng ta đã đề cập ở trong slide trước chữ R AE thì r Ở đây nó không phải là root mà là relative tức là sai số tương đối sai số tương đối absolute ER rồi Tức là nó sẽ là bằng trung bình của các cái cái size tổng của các cái size số y và y m y chia cho cái Phương size thì ở ở đây lưu ý là nó sẽ là cái độ lạch trị tuyệt đối của độ lạch của y và cái giá trị y g y g ở đây chính là cái giá trị trung bình trung bình cộng giá trị trung bình rồi tương tự như vậy thì chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:07:58",
      "end_timestamp": "0:08:07"
    }
  },
  {
    "page_content": "giá trị trung bình rồi tương tự như vậy thì chúng ta sẽ có ờ relative Square error thì ở đây chúng ta sẽ dùng cái hàm là Bình Phương và tương tự như vậy thì cái y ở đây chính là cái giá trị trung bình của cái dự đoán của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=HJleMrK28qc",
      "filename": "HJleMrK28qc",
      "title": "[CS116 - Buổi 5] Part 2",
      "chunk_id": 13,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cuối cùng đó là sau khi chúng ta đã tạo ra rất nhiều đặc trưng rồi biến đổi các cái đặc trưng từ dạng này sang dạng khác thì chúng ta sẽ phải thực hiện một trong những cái bước rất là quan trọng đó chính là feature Selection hay còn gọi là lựa chọn đặc trưng. Tại vì không phải cái đặc trưng nào chúng ta tạo ra hoặc là không phải cái đặc trưng nào chúng ta biến đổi thì đều giúp cho cái mô hình huấn luyện tốt hơn. Nó sẽ có những cái đặc trưng thừa không quan trọng thì chúng ta cần phải loại bỏ đi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:36"
    }
  },
  {
    "page_content": "không quan trọng thì chúng ta cần phải loại bỏ đi và những cái đặc trưng nào mà đóng vai trò giúp ích cho cái mô hình của mình huấn luyện thì chúng ta sẽ đưa vào thì đó là ý nghĩa của cái việc chọn lựa đặc trưng ở đây. thì có một số cái lý do tại sao chúng ta phải chọn lựa đặc trưng đó là về vấn đề độ chính xác của mô hình thì các cái đặc trưng mà không liên quan Hoặc là các cái đặc trưng dư thừa nó sẽ làm cho mô hình của mình bị nhiễu hay nói cách khác đó là làm giảm cái độ chính xác của mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:31",
      "end_timestamp": "0:01:08"
    }
  },
  {
    "page_content": "cách khác đó là làm giảm cái độ chính xác của mô hình của mình đi. Và cái việc chọn lựa đặc trưng phù hợp nó sẽ giúp cho mình giảm nhiễu và đồng nghĩa là sẽ làm tăng cái độ chính xác của mình lên. Cái vấn đề thứ hai đó là vấn đề về overfitting nếu như cái mô hình của mình quá phức tạp và nó sẽ tìm cách là hấp thụ các cái đặc trưng nhiễu của mình, nó sẽ tìm cách hấp thụ cái đặc trưng nhiễu của mình nhiều hơn so với lại cái mô hình đơn giản, tức là mô hình đơn giản nó sẽ loại bỏ đi những cái đặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:05",
      "end_timestamp": "0:01:40"
    }
  },
  {
    "page_content": "mô hình đơn giản nó sẽ loại bỏ đi những cái đặc trưng nhiễu, nó sẽ lờ đi những cái đặc trưng nhiễu. Còn những cái mô hình phức tạp thì nó tìm cách là hấp thụ cái thông tin của đặc trưng nhiễu như vậy thì góp phần là làm giảm cái accuracy, làm giảm cái độ chính xác của mình xuống. Như vậy thì cái việc loại bỏ cái đặc trưng nhiễu nó sẽ giúp cho mô hình của mình nó đơn giản hơn và cái mô hình của mình nó đơn giản hơn nó sẽ không có hấp thụ những cái đặc trưng nhiễu này nhiều thì dẫn đến là tránh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 3,
      "start_timestamp": "0:01:36",
      "end_timestamp": "0:02:14"
    }
  },
  {
    "page_content": "đặc trưng nhiễu này nhiều thì dẫn đến là tránh được cái hiện tượng overfitting. Rồi à vấn đề về thời gian thì và chi phí huấn luyện thì khi mà chúng ta sử dụng quá nhiều đặc trưng thì mô hình của mình nó sẽ phức tạp và như vậy thì chi phí tính toán cũng như là cái thời gian huấn luyện cũng như là thời gian inference, thời gian thử nghiệm dự đoán của mình nó cũng sẽ lâu. Do đó cái việc chọn lựa đặc trưng quan trọng nhất Nó sẽ giúp cho mình giảm được cái chi phí và thời gian tính toán. Rồi vấn đề",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 4,
      "start_timestamp": "00:02:10",
      "end_timestamp": "0:02:41"
    }
  },
  {
    "page_content": "cái chi phí và thời gian tính toán. Rồi vấn đề về giải thích của mô hình. Mô hình nếu mà có quá nhiều đặc trưng thì nó sẽ khó giải thích do mình bị rối. Tại vì khách hàng của mình sẽ nhìn thấy một rừng cái đặc trưng như vậy thì họ sẽ bị rối và khi chúng ta chọn ra những cái đặc trưng quan trọng nhất để cho mô hình huấn luyện thì đồng thời khi chúng ta giải thích cho khách hàng là tại sao chúng ta chọn lựa cái mô hình của chúng ta chọn lựa những cái đặc trưng đó thì họ sẽ dễ giải thích hơn và họ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 5,
      "start_timestamp": "00:02:38",
      "end_timestamp": "0:03:18"
    }
  },
  {
    "page_content": "đặc trưng đó thì họ sẽ dễ giải thích hơn và họ sẽ dễ hiểu lý do tại sao chúng ta ờ lý do ra quyết định của cái mô hình hơn thì họ sẽ dễ cảm nhận được cái cái cách thức mà mô hình nó vận hành hơn. Và ở đây thì chúng ta sẽ có một số cái phương pháp chọn lựa đặc trưng. Phương pháp đầu tiên đó chính là phương pháp lọc, phương pháp filter. Phương pháp thứ hai đó là phương pháp wrapper. Phương pháp thứ ba đó là phương pháp embedded tức là nhúng và phương pháp thứ tư đó là phương pháp giảm số chiều.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 6,
      "start_timestamp": "00:03:13",
      "end_timestamp": "0:03:51"
    }
  },
  {
    "page_content": "pháp thứ tư đó là phương pháp giảm số chiều. Thì đối với cái phương pháp lọc chúng ta sẽ có các cái tiếp cận đó là lọc dựa trên các cái đặc trưng thỏa mãn một số cái tiêu chí nào đó ví dụ tiêu chí về độ tương quan Pearson, sử dụng độ đo là à Pearson hoặc là phương pháp mà có cái phương sai lớn hơn một cái ngưỡng nào đó hoặc là cái tỷ lệ các cái giá trị bị thiếu là bao nhiêu đó. Rồi đối với phương pháp wrapper thì chúng ta sẽ có thể có các phương pháp đó là forward selection, backward",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 7,
      "start_timestamp": "00:03:46",
      "end_timestamp": "0:04:25"
    }
  },
  {
    "page_content": "các phương pháp đó là forward selection, backward elimination, Recursive Feature Elimination. Rồi đối với phương pháp mà embedded thì chúng ta sẽ có phương pháp Lasso regression, Ridge regression, Elastic Net và các cái phương pháp mà dựa trên cấu trúc cây ví dụ như là Random Forest và GBM. Còn đối với phương pháp giảm chiều thì chúng ta sẽ có những cái phương pháp giảm chiều kinh điển như là PCA hoặc là phương pháp t-SNE. Thì sau đây chúng ta sẽ lần lượt đến với từng cái phương pháp. Đó thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 8,
      "start_timestamp": "00:04:20",
      "end_timestamp": "0:05:01"
    }
  },
  {
    "page_content": "sẽ lần lượt đến với từng cái phương pháp. Đó thì chọn lựa đặc trưng tức là đầu vào của chúng ta có rất nhiều cái đặc trưng ví dụ như là X1, X2 cho đến XN và sau khi chúng ta chọn lựa xong thì chúng ta chỉ còn đặc trưng X2 và XN -1 thôi ví dụ vậy. Và chúng ta sẽ loại bỏ đi các cái đặc trưng này. Và tập đặc trưng đầu vào thì chúng ta sẽ có ba cái, khi chúng ta loại bỏ các cái đặc trưng mà một cách trực tiếp thì chúng ta sẽ có ba hướng tiếp cận. Hướng tiếp cận đầu tiên đó là filter, hướng tiếp cận",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 9,
      "start_timestamp": "00:04:58",
      "end_timestamp": "0:05:36"
    }
  },
  {
    "page_content": "tiếp cận đầu tiên đó là filter, hướng tiếp cận thứ hai là wrapper và hướng tiếp cận thứ ba đó là embedded kết hợp hoặc là phương pháp giảm chiều dữ liệu. Thì đối với cái tiếp cận filter, chúng ta sẽ chọn ra tập con của các cái đặc trưng của mình, tức là chúng ta sẽ thực hiện ngay ở cái bước đầu tiên dựa trên một số cái tiêu chí lọc ra đặc trưng. Rồi sau đó chúng ta, sau khi chúng ta lọc xong thì chúng ta mới đưa vào cái mô hình máy học và sau khi máy đã học xong thì chúng ta sẽ đánh giá cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 10,
      "start_timestamp": "00:05:32",
      "end_timestamp": "0:06:12"
    }
  },
  {
    "page_content": "khi máy đã học xong thì chúng ta sẽ đánh giá cái hiệu quả của mô hình. Thì đây là phương pháp filter. Còn phương pháp wrapper đó là chúng ta cũng sẽ lọc ra một cái tập con à các cái đặc trưng, sau đó chúng ta sẽ đưa vào một cái mô hình máy học và dựa trên cái hiệu quả của cái mô hình máy học chúng ta sẽ quay trở lại chúng ta sẽ chọn lại cái tập đặc trưng mới và chúng ta lặp đi lặp lại cái quá trình này, sau đó thì kết thúc và chúng ta vẫn sẽ có một cái bước đánh giá hiệu quả của mô hình. Còn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 11,
      "start_timestamp": "00:06:06",
      "end_timestamp": "0:06:44"
    }
  },
  {
    "page_content": "một cái bước đánh giá hiệu quả của mô hình. Còn phương pháp embedded hoặc là giảm chiều dữ liệu thì chúng ta đã nhúng cái từ embedded này nó hàm ý đó là nhúng, tức là trong cái mô hình máy học của mình nó đã ngầm thực hiện cái việc chọn lựa đặc trưng luôn thông qua cái việc là huấn luyện trên các cái hệ số của cái mô hình của mình và nó thực hiện đánh giá hiệu quả luôn. Như vậy là chọn lựa đặc trưng nó đã được ngầm thực hiện bên trong cái mô hình máy học. Đầu tiên đó là phương pháp về filter",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 12,
      "start_timestamp": "00:06:39",
      "end_timestamp": "0:07:22"
    }
  },
  {
    "page_content": "máy học. Đầu tiên đó là phương pháp về filter thì chúng ta sẽ áp dụng một số cái loại chỉ số để loại bỏ những đặc trưng không liên quan Hoặc là các cái đặc trưng dư thừa ví dụ như là đặc trưng về hệ số tương quan. Nếu như hai cái đặc trưng mà có cái hệ số tương quan mà cao X Y và X J của mình mà có hệ số tương quan cao thì Hoặc là những cái đặc trưng X Y mà có cái ngưỡng phương sai tức là có cái sự dao động của mình nó quá thấp thì chúng ta cũng sẽ loại bỏ đi. Đó, cái sự cái cái cái phương sai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 13,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "sẽ loại bỏ đi. Đó, cái sự cái cái cái phương sai của cái đặc trưng X Y này quá thấp chúng ta sẽ loại bỏ đi. Hoặc với những cái đặc trưng mà có cái tỷ lệ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=hPxWhkAgyYw",
      "filename": "hPxWhkAgyYw",
      "title": "[CS116 - Buổi 4] Part 5_1",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong bài hướng dẫn thực hành ngày hôm nay thì chúng ta sẽ đến với cái phần là tạo mới đặc trưng hay còn gọi là Feature Extraction thì đây Có lẽ nói có thể nói là một trong những bài rất là quan trọng trong cái lĩnh vực về khoa học dữ liệu hoặc là trong lĩnh vực về máy học trên cái dữ liệu có cấu trúc Feature Extraction thì ở đây là chúng ta sẽ dựa trên một số cái kinh nghiệm trong cái lĩnh vực của cái miền dữ liệu của mình đang làm để mình có thể tạo ra thêm những cái đặc trưng mới nhằm giúp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:01"
    }
  },
  {
    "page_content": "thể tạo ra thêm những cái đặc trưng mới nhằm giúp cho việc dự đoán cái giá trị output nó tốt hơn và Feature Extraction này đã được chứng minh trong rất nhiều những cái cuộc thi trên Kaggle đối với những loại dữ liệu dạng bảng đó là một trong những cái bước quan trọng để giúp cho cái mô hình của mình tăng cái độ chính xác lên tăng độ chính xác lên một cách đáng kể và là cái sự khác biệt giữa các cái team với nhau bên cạnh những cái kỹ thuật sử dụng mô hình truyền thống như là sử dụng các cái mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:01:34"
    }
  },
  {
    "page_content": "mô hình truyền thống như là sử dụng các cái mô hình phân loại mô hình hồi quy rồi kết hợp nhiều mô hình thì tạo mới đặc trưng hay còn gọi là Feature Engineering hoặc là Feature Extraction thì lưu ý là Feature Extraction là một phần của Feature Engineering. Feature Engineering thì có thể bao gồm Feature Extraction nè Feature Transformation tức là biến đổi hoặc là chuẩn hóa cái đặc trưng nè rồi Feature Selection là chọn lựa đặc trưng nè thì đây là có thể nói là một trong những cái bước rất là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 2,
      "start_timestamp": "0:01:29",
      "end_timestamp": "0:02:05"
    }
  },
  {
    "page_content": "là có thể nói là một trong những cái bước rất là quan trọng. Thì à đầu tiên đó là cái kỹ thuật đầu tiên đó là chúng ta sẽ biến đổi toán học. À ví dụ như chúng ta có một cái bảng dữ liệu như sau à chúng ta sẽ có cái thông tin là vận tốc và thời gian đúng không? Thì đây là lần lượt là các giá trị vận tốc. Còn Đây là lần lượt là giá trị thời gian. Thì khi đó chúng ta sẽ tạo ra thêm một cái đặc trưng nữa dựa trên hai cái cột cho trước này đó là khoảng cách. Thì Khoảng cách sẽ là bằng vận tốc nhân",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 3,
      "start_timestamp": "0:02:00",
      "end_timestamp": "0:02:44"
    }
  },
  {
    "page_content": "cách. Thì Khoảng cách sẽ là bằng vận tốc nhân thời gian đó thì chúng ta sẽ có công thức biến đổi toán học là công thức nhân ở đây. Như vậy thì chúng ta truyền vào là tạo mới một cái đặc trưng nữa có tên là `distance` và đặc trưng này thì bằng hai cái cột tương ứng là cột `velocity` tức là vận tốc nhân với lại cái cột là `time` (thời gian). Và lưu ý là chúng ta thực hiện cái phép nhân này là nhân từng phần tử. Ví dụ cái kết quả ở đây chúng ta thấy là ờ 7 8 đúng không? Thì 7 x 8 là bằng 56. Như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 4,
      "start_timestamp": "0:02:38",
      "end_timestamp": "0:03:13"
    }
  },
  {
    "page_content": "là ờ 7 8 đúng không? Thì 7 x 8 là bằng 56. Như vậy là chúng ta đang nhân theo từng hàng, khái niệm nhân từng hàng chứ nó không phải là tích vô hướng hay cái gì hết. Nhân từng hàng. Rồi cái kỹ thuật thứ hai đó là chúng ta có thể đếm cái tần số xuất hiện. Trong nhiều trường hợp thì số lần xuất hiện hoặc là tần số xuất hiện của một cái thuộc tính nào đó nó cũng là một cái loại đặc trưng. Ờ ví dụ như một người à thường xuyên mà mua một cái món hàng nào đấy đúng không? Thì cái số lần mua một cái món",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 5,
      "start_timestamp": "0:03:08",
      "end_timestamp": "0:04:19"
    }
  },
  {
    "page_content": "đấy đúng không? Thì cái số lần mua một cái món hàng nào Đấy tức là là người đó có nhu cầu cho món hàng này nhiều thì sau đó chúng mẫu dữ liệu của mình thì mình sẽ tạo ra thêm một cái cột nữa là `color_count` ở đây. Rồi Nhưng mà trước khi mà chúng ta tạo ra một cái cột mới là `color_count` thì chúng ta sẽ phải chạy một cái dòng lệnh đó là cái cột `color` chúng ta gọi cái phương thức đó là `value_counts()`. Đếm theo `value` thì kết quả à và chúng ta sẽ đưa cái chuyển đổi nó về cái dạng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 6,
      "start_timestamp": "0:04:12",
      "end_timestamp": "0:04:55"
    }
  },
  {
    "page_content": "và chúng ta sẽ đưa cái chuyển đổi nó về cái dạng `dictionary` ha. Thì khi chúng ta gọi cái hàm này xong thì chúng ta sẽ tạo ra được một cái `dictionary` trong đó là cái `key` của mình nó chính là các cái giá trị ờ là các cái giá trị trên cái cột `color` ở đây là bao gồm `Red`, `Blue` và `Green`. Thì `Red` sẽ đếm là 3 và `Blue` thì sẽ Đếm là 2 và `Green` thì sẽ đếm là 1. Và đây chính là những cái giá trị đặc trưng mà mình sẽ thêm vào cho cái cột mới. Và cái cột này đó chính là cột `color_count`.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 7,
      "start_timestamp": "00:04:46",
      "end_timestamp": "0:05:29"
    }
  },
  {
    "page_content": "Và cái cột này đó chính là cột `color_count`. Thì `color_count` lúc này nó sẽ là bằng cái cột `color` mà chúng ta sẽ `map` vào cái `vc` (Value Counts). Tức là cái `color_count` của mình ở đây nó sẽ `map` vào đây. Tức là cái giá trị `color` ở đây mình sẽ tra trong cái bảng tra xem tương ứng nó giá trị đếm là bao nhiêu để mình lấy giá trị đó điền vào `color_count`. Ví dụ ở đây đang là `Red` đúng Chúng ta sẽ tra vào bảng này là 3, lấy cái giá trị 3 đó điền vào đây. Thì đây là cái một cái cột, nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 8,
      "start_timestamp": "00:05:24",
      "end_timestamp": "0:06:09"
    }
  },
  {
    "page_content": "3 đó điền vào đây. Thì đây là cái một cái cột, nó đã tạo ra được một cái cột mới là `color_count`. Kỹ thuật thứ ba đó là chúng ta có thể đếm số lượng nhiều cột. Chúng ta sẽ đếm số lượng theo nhiều cột. Bình thường chúng ta đếm trên một cột, bây giờ chúng ta sẽ đếm trên nhiều cột ha. Thì ở đây chúng ta sẽ có một cái cái bảng là các cái loại phương tiện mà mình thường xuyên sử dụng của một người nào đấy đúng không? Thì cái người đầu tiên họ không có sử dụng phương tiện `Bus`, `Car` hoặc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 9,
      "start_timestamp": "00:06:04",
      "end_timestamp": "0:06:44"
    }
  },
  {
    "page_content": "không có sử dụng phương tiện `Bus`, `Car` hoặc là `Motorbike`. Nhưng cái người thứ ba này nè, có cái chỉ số là 3 nè, thì họ dùng `Bus` là thường xuyên. Thế thì bây giờ chúng ta sẽ lấy ra danh sách các cái `V2` (Vehicle) tức là danh sách các cái phương tiện giao thông dựa trên ba cái giá trị này. Thì thực ra chúng ta cũng cũng có thể dùng một cái lệnh khác là lệnh `columns` để lấy ra cái danh sách này. Mà trong trường hợp này chúng ta đang làm ví dụ thôi. Thì chúng ta sẽ để `v_list` là xác định",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 10,
      "start_timestamp": "00:06:37",
      "end_timestamp": "0:07:23"
    }
  },
  {
    "page_content": "dụ thôi. Thì chúng ta sẽ để `v_list` là xác định tĩnh luôn là bằng `Car`, `Motorbike` và `Bus`. Rồi và chúng ta sẽ tạo ra thêm một cái cột nữa đó là `Used_V2_Vehicle` đúng không hay không? `Used_V2_Vehicle` hay không? Tức là chỉ là `yes`/`no` thôi, `0`/`1` thôi. Rồi thì Chúng ta sẽ chạy và cái cột mới này nó sẽ được cái `dataframe` đúng không? Truyền cái `V2_Vehicle` vào đây. Tức là chúng ta sẽ lấy ra từng cột sau đó chúng ta thực hiện cái lệnh là đếm xem ờ đếm xem giá trị lớn nhất của mình là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 11,
      "start_timestamp": "0:07:17",
      "end_timestamp": "0:08:06"
    }
  },
  {
    "page_content": "là đếm xem ờ đếm xem giá trị lớn nhất của mình là bao nhiêu. Nếu như trên cái hàng đó mà giá trị lớn nhất của mình bằng 0, ví dụ ở đây nè, thì cái giá trị mà mình sẽ điền vào `Used_Vehicle` sẽ là bằng 0. Còn trên cái dòng này chúng ta thấy là ta sẽ điền nó vào đây đó. Thì đây là một cái kỹ thuật mà tương tác trên nhiều cột. Và để định nghĩa những cái cột nào mà mình sẽ tương tác thì mình sẽ có thêm một cái biến `list` chứa danh sách các cái cột mà mình tương tác với các cái cột đó. Chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 12,
      "start_timestamp": "00:08:00",
      "end_timestamp": "0:08:43"
    }
  },
  {
    "page_content": "mà mình tương tác với các cái cột đó. Chúng ta sẽ thực hiện các cái phương thức ở đây là chúng ta sử dụng phương thức là tìm giá trị lớn nhất. Rồi Tiếp theo, kỹ thuật thứ tư đó là chúng ta có thể phân rã cái đặc trưng từ chuỗi có cấu trúc. Thì trong cái cấu trúc `dataframe` có nhiều cái tình huống đó là dữ liệu của mình nó đã được `format` theo một cái định dạng nhất định. Lấy ví dụ ở đây, chúng ta có một cái `dataframe` là thông tin về hệ điều hành ha, là `operating system info`. Thì ở đây cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 13,
      "start_timestamp": "00:08:37",
      "end_timestamp": "0:09:37"
    }
  },
  {
    "page_content": "ha, là `operating system info`. Thì ở đây cái chuỗi của mình nó là cái dạng như thế này đó. Thì ở đây chúng ta thấy là nó đi theo một cái quy luật. Đầu tiên đó là tên của cái hãng, tên của cái hãng. Cái thứ hai đó là cái hệ điều hành đúng không? Cái hệ điều hành của mình đó. Ví dụ ở đây Microsoft Windows 11. Rồi Ở đây là thiếu ha. Microsoft Windows, Apple Mac OS X 10.5. Thì ở đây chúng ta có thể `split` cái dòng đầu tiên, cái cái ký tự khoảng trắng đầu tiên để tách nó ra làm hai là lấy tên của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 14,
      "start_timestamp": "0:09:32",
      "end_timestamp": "0:10:22"
    }
  },
  {
    "page_content": "đầu tiên để tách nó ra làm hai là lấy tên của nhà sản xuất và cái `model` của hệ điều hành của mình. Rồi Ở đây nếu mà mình viết sai mình có thể sửa là Microsoft ha. Rồi đây cũng vậy Microsoft. Và chúng ta sẽ `split` nó ra. Chúng ta sẽ ép về cái kiểu chuỗi và `split` nó ra. Sau đó chúng ta sẽ lấy cái phần tử đầu tiên tách nó ra. Rồi và chúng ta sẽ dùng cái thông số `expand` là bằng `true` ha. Thì khi đó chúng ta đã tách nó ra thêm được hai cột. Tức là từ một cái cột này chúng ta tách nó ra làm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 15,
      "start_timestamp": "0:10:14",
      "end_timestamp": "0:10:59"
    }
  },
  {
    "page_content": "Tức là từ một cái cột này chúng ta tách nó ra làm hai cột là cột 0 và cột 1. Thì 0 là tương ứng là cái hãng và 1 tương ứng là cái `model` của mình. 1 tương ứng là cái `model` của mình. Rồi sau khi chúng ta đã xử lý xong, đã tách ra xong thì chúng ta sẽ truyền vào đó thay đổi cái tên, `rename` cái tên. Thì cái cột 0 của mình nó sẽ được `rename`. 0 sẽ được `rename` thành `Company` và 1 thì tương ứng đó sẽ là cái hệ điều hành của mình, cái mã số của hệ điều hành của mình. Rồi sau đó chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 16,
      "start_timestamp": "0:10:55",
      "end_timestamp": "0:10:59"
    }
  },
  {
    "page_content": "của hệ điều hành của mình. Rồi sau đó chúng ta sẽ `join` nó lại đúng không? `join` nó lại là `df.join` nó sẽ `join` cái `dataframe` cũ với lại cái `dataframe` mới được tách ra từ hai cái thông số này. Như vậy từ một cái thông số là `OS info` nó đã cho chúng ta thêm hai cái `feature` nữa, tương ứng là hai cái tên của hãng.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=jEWheFdYryo",
      "filename": "jEWheFdYryo",
      "title": "[CS116 - Buổi 4] Part 6",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cuối cùng đó là kỹ thuật boosting thì đây là một trong những cái kỹ thuật rất là quan trọng của ensemble model à boosting nó sẽ huấn luyện một cách tuần tự nếu như cái thuật toán bagging á là các cái Model được thực hiện một cách là song song và độc lập với nhau thì boosting nó sẽ thực hiện một cách tuần tự và mô hình sau mô hình sau sẽ được train dựa theo cái kết quả của cái mô hình trước và nhiệm vụ của nó đó là cố gắng đi sửa sai đi đi sửa sai nhưng mà cái sai này là những cái sai còn lại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:45"
    }
  },
  {
    "page_content": "sai nhưng mà cái sai này là những cái sai còn lại thôi cái sai của các cái mô hình trước đó nó đã nó đã đã hình thành và càng lúc về sau nó sẽ càng giảm xuống và cứ thêm một cái mô hình mới thì cái sai số của mình nó sẽ càng lúc càng giảm thì cái hình bên phải minh họa cái ý tưởng của thuật toán boosting đầu tiên đó là chúng ta sẽ có một cái tập dữ liệu à gốc và tập dữ liệu này thì cũng tương tự nó sẽ chia ra làm các cái data 1 2 3 cho đến data thứ N. Ta sẽ thực hiện cái thao tác là chia ra và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:00:39",
      "end_timestamp": "0:04:59"
    }
  },
  {
    "page_content": "thứ N. Ta sẽ thực hiện cái thao tác là chia ra và chúng ta sẽ tiến hành huấn luyện trên cái model số 1 trước rồi sau đó Cái model số 1 này chúng ta sẽ thực hiện trên cái data chúng ta sẽ tiến hành đi predict trên cái data số 2 và chúng ta sẽ ra được cái sai số với cái sai số này thì chúng ta sẽ tiếp tục khai thác cái sai số đó để mà đi train trên cái model số 2 Model số 2 sau khi đã được train xong sẽ đi predict trên cái dữ liệu số 3 và chúng ta sẽ ra được cái sai số và dựa trên cái sai số của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:04:53",
      "end_timestamp": "0:05:35"
    }
  },
  {
    "page_content": "sẽ ra được cái sai số và dựa trên cái sai số của model số 3 chúng ta sẽ tiếp tục đi train cho cái model số 3 rồi lại tiếp tục cứ như vậy cho đến data thứ N và chúng ta sẽ train cái model thứ N và N cái model này sẽ được tổng hợp lại với một cái kỹ thuật ensemble thì ensemble này có thể là những kỹ thuật cơ bản như là voting averaging hoặc bản thân cái phương pháp ensemble này nó được xuất phát từ cái thuật toán của mình tức là cái thuật toán kết hợp giữa Model số 1 Model số 2 Model số 3 với",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:05:30",
      "end_timestamp": "0:06:08"
    }
  },
  {
    "page_content": "kết hợp giữa Model số 1 Model số 2 Model số 3 với những cái trọng số mà mô hình của mình nó đã được học trong cái quá trình boosting thì để hiểu rõ hơn về kỹ thuật Boosting thì chúng ta sẽ lấy một cái thuật toán đại diện đó chính là thuật toán Gradient Boost và Gradient Boost ý tưởng của nó đó là nó sẽ xây dựng một cái chuỗi một cái chuỗi các cái cây quyết định liên tiếp với nhau thì nếu như bagging nó chỉ nói chung chung là một cái mô hình thì trong trường hợp này chúng ta sẽ sử dụng là cây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:06:04",
      "end_timestamp": "0:06:45"
    }
  },
  {
    "page_content": "trong trường hợp này chúng ta sẽ sử dụng là cây quyết định là một cái mô hình cụ thể và kế thừa cái ý tưởng của bagging trong cái thuật toán bagging thì nó sẽ có cái random Forest và random Forest thì cái model thành phần của mình là họ cũng sử dụng cây quyết định decision tree thì boosting nó cũng sẽ sử dụng cái mô hình thành phần là decision tree, cây quyết định và nhiệm vụ đó là cái cây sau sẽ cố gắng làm giảm cái sai số dự đoán của các cái cây trước đó ví dụ như chúng ta thấy ở đây là có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:06:39",
      "end_timestamp": "0:07:22"
    }
  },
  {
    "page_content": "cây trước đó ví dụ như chúng ta thấy ở đây là có cái cột là residual tức là cái sai số dự đoán nếu như với với cái kết quả khởi tạo cái cây đầu tiên là thật ra nó cũng không phải là cây đó là cái giá trị trung bình của cái cột giá trị dự đoán thì sai số nếu như chúng ta sử dụng cái giá trị trung bình này như là một cái giá trị dự đoán thì sai số của mình sẽ là cái cái giá trị ở trên cái cột thứ nhất nhưng nếu như chúng ta kết hợp với lại cái cây thứ hai và với một cái hệ số kết hợp thì cái sai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:07:16",
      "end_timestamp": "0:08:01"
    }
  },
  {
    "page_content": "thứ hai và với một cái hệ số kết hợp thì cái sai số của mình nó giảm từ 16.8 xuống còn 15.1 từ 4.8 xuống còn 4.3 từ -15.2 xuống còn - 13.7 Và khi chúng ta kết hợp thêm với cái cây thứ ba thì cái cái sai số mình nó đã giảm từ 15 xuống còn 13 từ 4.3 xuống còn 3.9 từ - 13.7 xuống còn -12.1. thì cái hình này nó lấy từ cái nguồn video với cái đường dẫn như sau và bên phải đó là một cái hình hình ảnh minh họa khác sử dụng animation đó thì cái đường màu xanh chính là cái hàm đúng của mình còn cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:07:55",
      "end_timestamp": "0:08:38"
    }
  },
  {
    "page_content": "màu xanh chính là cái hàm đúng của mình còn cái đường màu đỏ chính là cái đường mà do thuật toán boosting tạo lập ra thì chúng ta thấy đó là tại những cái bước đầu tiên thì cái đường màu đỏ nó sẽ rất là cách xa nhưng mà sau khi huấn luyện xong thì cái đường màu đỏ nó đã xấp xỉ với cái đường màu màu xanh đó thì đây chính là cái hình ảnh à minh họa cho cái thuật toán đó. V như chúng ta thấy ở đây mới vòng lặp đầu tiên thì cái đường của mình nó rất là thô và nó sẽ đi ra không có giống lắm Nó sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:08:33",
      "end_timestamp": "0:10:25"
    }
  },
  {
    "page_content": "là thô và nó sẽ đi ra không có giống lắm Nó sẽ không có mô phỏng giống lắm cái đường mà xanh nhưng mà càng chạy thì cái đường Zig zắc này sẽ càng lúc nó càng mịn hơn và nó sẽ càng tiến sát hơn đến cái đường màu xanh của mình thì để có thể hiểu rõ hơn và trực quan hơn cho cái thuật toán Gradient Boost thì chúng ta sẽ cùng theo dõi cái video ở YouTube như sau chúng ta sẽ có một cái bảng dữ liệu ba cái cột đầu tiên sẽ là ba cái cột đặc trưng đầu vào và cái cột khối lượng cái cột khối lượng cuối",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:10:19",
      "end_timestamp": "0:11:00"
    }
  },
  {
    "page_content": "vào và cái cột khối lượng cái cột khối lượng cuối cùng chính là cái cột mà mình cần phải dự đoán thì thuật toán Gradient Boost sẽ chạy lên cái cột này để giá trị của cái cột khối lượng này thì bước đầu tiên đó là chúng ta sẽ đoán cái giá trị trung bình à chúng ta sẽ đoán bằng cách đó là lấy một cái giá trị trung bình thì tất cả những cái mẫu nào mà đưa vào chúng ta cũng sẽ đưa ra cái Phán đoán là cái giá trị mà khối lượng trung bình này đó là 71.2 và đương nhiên là cái việc sử dụng giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:10:54",
      "end_timestamp": "0:11:48"
    }
  },
  {
    "page_content": "71.2 và đương nhiên là cái việc sử dụng giá trị trung bình này nó sẽ dẫn đến là cái sai số nó sẽ dẫn đến cái sai số thì với cái sai số này á thì chúng ta sẽ tiếp tục chỉnh sửa lại à Ví dụ như ở đây chúng ta có cái mẫu dữ liệu đầu tiên ha mẫu cái cái dòng đầu tiên cái dòng dữ liệu đầu tiên khi chúng ta lấy cái Ờ giá trị Dự đoán mà sử dụng cái giá trị trung bình là 71.2 này thì khi chúng ta Trừ lấy cái giá trị thực là y là ở đây là 88 trừ cho cái giá trị trung bình mà mình dự đoán là 71.2 thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:11:42",
      "end_timestamp": "0:12:34"
    }
  },
  {
    "page_content": "giá trị trung bình mà mình dự đoán là 71.2 thì chúng ta sẽ ra được cái sai số là 16.8 và cứ tương tự như vậy thì chúng ta sẽ ra được cái nguyên cái sai số này đó là 4.8 76 trừ cho giá trị là 71.2 ấy chúng ta sẽ ra là 4.8 rồi sai số là -15.2 vân vân và bây giờ chúng ta sẽ không còn quan tâm chúng ta sẽ không còn quan tâm đến cái cái cột khối lượng ban đầu này nữa mà cái cột mà chúng ta cần phải dự đoán tiếp theo đó chính là cái cột sai số này và với input feature nó vẫn là ba cái cột đầu tiên và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:12:28",
      "end_timestamp": "0:13:37"
    }
  },
  {
    "page_content": "input feature nó vẫn là ba cái cột đầu tiên và sau khi xây dựng cái thuật toán decision tree trên cái cột dữ liệu mới này thì chúng ta sẽ ra được một cái cây quyết định chúng ta sẽ ra một cái cây quyết định và chúng ta sẽ không sử dụng cái cây quyết định này một cách trọn vẹn 100% mà chúng ta sẽ phải sử dụng kết hợp có tham số đó nó gọi là hệ số learning rate bình thường cái hệ số này là 1 nhưng mà cứ mỗi một cái vòng lặp thì cái cái cái cái cái mức độ mà chúng ta khai thác cái cây mới nó chỉ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 13,
      "start_timestamp": "0:13:31",
      "end_timestamp": "0:14:14"
    }
  },
  {
    "page_content": "mức độ mà chúng ta khai thác cái cây mới nó chỉ là một cái hệ số dưới một thôi tức là chúng ta sẽ à cộng với lại một cái hệ số tương đối nhỏ để cho cái quá trình này của mình nó sẽ cập nhật dần dần và đương nhiên cái hệ số learning rate càng nhỏ thì cái số cây mà mình tạo ra nó cũng sẽ càng nhiều cũng sẽ càng lớn để khắc phục cái sai sót do cái quá trình dự đoán thì trong trường hợp này chúng ta sẽ sử dụng à Đó là cái trọng số là 0.1 như vậy thì với một cái mẫu dữ liệu là đầu tiên là cái hàng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 14,
      "start_timestamp": "0:14:06",
      "end_timestamp": "0:15:08"
    }
  },
  {
    "page_content": "với một cái mẫu dữ liệu là đầu tiên là cái hàng đầu tiên thì cái giá trị dự đoán của mình nó sẽ là bằng 71.2 Tức là cái giá trị trung bình đầu tiên ở cái bước đầu tiên cộng cho cộng cho giả sử như với cái đặc trưng là height, color và gender này nó đi theo cái con đường này nó ra cái giá trị dự đoán của cái sai số là 16.8 nhưng 16.8 này nó phải nhân với hệ số learning rate là 0.1 Tức là nó chỉ cộng với một cái tỉ lệ là 10% cái thông tin từ cái cây quyết định này ra thôi như vậy thì 71.2 cộng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 15,
      "start_timestamp": "0:15:01",
      "end_timestamp": "0:15:55"
    }
  },
  {
    "page_content": "cây quyết định này ra thôi như vậy thì 71.2 cộng cho 0.1 nhân cho 16.8 nó ra là 71 72.9 chúng ta sẽ lấy cái tính cái sai số tiếp theo chúng ta sẽ tính cái sai số tiếp theo rồi cái sai số tiếp theo nó sẽ được tính bằng cách đó là nó vẫn sẽ lấy cái giá trị trọng khối lượng gốc ban đầu là 88 trừ cho cái giá trị Dự đoán khi đã có sự kết hợp của giá trị trung bình ở đây với lại cái cây mà chúng ta đã tạo ra ở cái lớp trước đó Cái biến đổi trước đó thì 88 trừ cho cái giá trị Dự đoán mới này thì nó sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 16,
      "start_timestamp": "0:15:51",
      "end_timestamp": "0:16:33"
    }
  },
  {
    "page_content": "88 trừ cho cái giá trị Dự đoán mới này thì nó sẽ ra cái sai số của mình là 15.1 và chúng ta thực hiện tương tự như vậy cho tất cả các cái dòng dữ liệu còn lại rồi và sau khi chúng ta đã thực hiện thì chúng ta đã có một cái giá trị độ lỗi mới nó khác so với lại cái độ lỗi ở cái bước tính là chỉ có mỗi cái giá trị trung bình thôi thì với cái cây mới này chúng ta có một cái giá trị độ lỗi mới và lặp lại À cái việc cái cái cái quá trình thực hiện này chúng ta lại đi tiếp tục huấn luyện à chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 17,
      "start_timestamp": "0:16:28",
      "end_timestamp": "0:17:22"
    }
  },
  {
    "page_content": "chúng ta lại đi tiếp tục huấn luyện à chúng ta sẽ tiếp tục đi huấn luyện cho cái residual mới này và chúng ta tạo ra được một cái cây mới Cứ lập đi lặp lại như vậy chúng ta sẽ tạo ra được một cái cây mới Và cái cây mới này sẽ được kết hợp nó sẽ được kết hợp với lại hai cái cây trước đó đó là cái cây ở đây và cái giá trị trung bình ở đây và cách mà chúng ta kết hợp là chúng ta vẫn phải phải nhân với một cái hệ số learning rate là 0.1 tức là chúng ta chỉ lấy khoảng 10% cái giá trị Dự đoán mà thôi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 18,
      "start_timestamp": "0:17:12",
      "end_timestamp": "0:18:01"
    }
  },
  {
    "page_content": "ta chỉ lấy khoảng 10% cái giá trị Dự đoán mà thôi rồi và ở đây thì chúng ta sẽ có cái ba cái residual tương ứng cho ba cái lần mà chúng ta học cái mô hình của mình ở cái lần đầu tiên với chỉ có duy nhất một cái giá trị trung bình là 71.2 thì chúng ta thấy là cái độ lỗi của mình nó là 16.8 nhưng khi có cái sự kết hợp 0.1 tức là 10% của cái cây thứ hai thì độ lỗi của mình là nó rớt xuống còn 15.1 và khi kết hợp với lại cái cây thứ ba thì cái độ lỗi của mình nó sẽ giảm xuống Khoảng 13.6 Và cứ như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 19,
      "start_timestamp": "0:17:52",
      "end_timestamp": "0:18:37"
    }
  },
  {
    "page_content": "của mình nó sẽ giảm xuống Khoảng 13.6 Và cứ như vậy chúng ta cứ tạo ra thêm nhiều cái cây và khi tạo ra một cái cây mới thì chúng ta lại tạo ra một cái residual mới một cái sai số mới cái cột sai số mới Và cái cây huấn luyện nó sẽ được huấn luyện trên cái cột sai số mới chứ không phải là dựa trên cái À cái cái cái cột mà Weight Tức là cái cột khối lượng ban đầu đó thì cứ như vậy thì thuật toán của mình nó sẽ chạy thì đây chính là cái ý tưởng của ờ thuật toán Gradient Boost và quay trở lại cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 20,
      "start_timestamp": "0:18:33",
      "end_timestamp": "0:14:12"
    }
  },
  {
    "page_content": "ờ thuật toán Gradient Boost và quay trở lại cái kỹ thuật boosting thì bên cạnh thuật toán Gradient Boost thì chúng ta sẽ có rất nhiều những cái thuật toán boosting nổi tiếng khác đó chính là adaboost rồi XGBoost, LightGBM và CatBoost và tất cả những cái thuật toán này đều là những cái thuật toán mà rất là nổi tiếng và đạt được những cái giải cao trong cuộc thi Kaggle trong đó nổi tiếng nhất đó chính là ba cái cái thuật toán này: L GBM, LightGBM và CatBoost. Đây là ba cái thuật toán mà được sử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 21,
      "start_timestamp": "0:14:05",
      "end_timestamp": "0:14:46"
    }
  },
  {
    "page_content": "và CatBoost. Đây là ba cái thuật toán mà được sử dụng rất là nhiều trong các cái cuộc thi Kaggle và đạt được thứ hạng rất là cao trong đó XGBoost là một cái cải tiến của Gradient Boost. CatBoost cũng là cải tiến. LightGBM thì nghe cái từ Light thôi là chúng ta đã biết là mục tiêu của nó là làm gì rồi đúng không? Tức là chúng ta đang tăng cái tốc độ liên quan đến cái yếu tố về mặt tốc độ đó thì trong cái thuật toán Gradient Boost chúng ta thấy là có cái hệ số gọi là learning rate thì nếu như cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 22,
      "start_timestamp": "0:14:40",
      "end_timestamp": "0:15:18"
    }
  },
  {
    "page_content": "có cái hệ số gọi là learning rate thì nếu như cái hệ số learning rate này mà càng nhỏ thì dẫn đến là cái số lượng cây của mình sẽ càng tăng và như vậy thì cái chi phí tính toán của mình rồi khi chúng ta huấn luyện cũng như là chi phí khi chúng ta inference tức là khi chúng ta dự đoán nó cũng rất là cao thì LightGBM nó sẽ giúp cho chúng ta giải quyết vấn đề này. Như vậy, tóm lại, ensemble learning Đó là một cái kỹ thuật quan trọng để cho mình có thể giúp mô hình để mô hình của mình nó có thể",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 23,
      "start_timestamp": "0:15:10",
      "end_timestamp": "0:15:53"
    }
  },
  {
    "page_content": "có thể giúp mô hình để mô hình của mình nó có thể tổng quát hóa được thì mô hình của mình là nó sẽ được học trên rất nhiều những cái loại dữ liệu khác nhau cũng như là khai thác được những cái điểm mạnh của từng cái mô hình thành phần và bổ trợ cho nhau để giải quyết những cái điểm yếu của từng cái mô hình đó thì mô hình của mình nó sẽ nhiều cái mô hình yếu nó tạo ra thành một cái mô hình mạnh hay nói cách khác đó là mô hình của mình nó càng tổng quát và trong số những cái kỹ thuật về ensemble",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "quát và trong số những cái kỹ thuật về ensemble learning thì bagging và Boosting là hai cái kỹ thuật cho cái tính hiệu quả rất là cao và nó là những cái hai cái hướng tiếp cận mà được các cái cuộc thi trên Kaggle là họ sử dụng rất là nhiều và lưu ý đó là trong cái quá trình mà sử dụng thì tất cả cái mô hình này nó đều có những cái siêu tham số và chúng ta sẽ phải chọn các cái siêu tham số làm sao cho nó phù hợp bằng cái phương pháp gọi là phương pháp tinh chỉnh tham số là cái này nó nằm trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "pháp tinh chỉnh tham số là cái này nó nằm trong cái bài gọi là parameter tuning. À này là nằm trong cái bài là parameter tuning. đó là sẽ tìm xem cái bộ siêu tham số nào mà tối ưu cho các cái thuật toán của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=K9YoXQq0TjI",
      "filename": "K9YoXQq0TjI",
      "title": "[CS116 - Buổi 13] Part 4",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng tìm hiểu một số mô hình gong nhóm à nổi tiếng hiện nay đó là camin và DB scan thì khái niệm về gom nhóm dữ liệu thì đây là một cái bài toán mà chúng ta sẽ gom các cái đối tượng theo từng cụm sao cho các cái đối tượng mà trong cùng một cụm thì có cái sự tương đồng với nhau và cái sự tường Đồng sự tương đồng này nó sẽ lớn hơn hơn so với lại những cái đối tượng thuộc các cái nhóm khác tức là những cái điểm nào mà nằm trong cùng một cụng có sự tuên đồng lớn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:40"
    }
  },
  {
    "page_content": "mà nằm trong cùng một cụng có sự tuên đồng lớn nhưng mà so với lại những cái điểm ở những cái cụm khác thì có cái sự Tuân đầu thấp hơn thì ở trong cái ví dụ trước chúng ta đã từng xét đến điểm Toán điểm vă của các bạn học sinh trong một lớp học thì những bạn học sinh mà trong cùng một cái cụm như thế này thì đều có sự tương đồng đó là gì đó là điểm Toán thì cao nhưng điểm Văn thì thấp và nó sẽ trái ngược so với lại những cái bạn mà nằm ở trong cái cụng khác ví dụ như ở đây có bạn ở trong cụm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:35",
      "end_timestamp": "0:01:18"
    }
  },
  {
    "page_content": "cái cụng khác ví dụ như ở đây có bạn ở trong cụm này thì là điểm Toán thì thấp điểm văng thì cao còn những bạn ở đây trong cái cụm này thì đều có cái sự tương đồng đó là điểm Toán và Văn đều cao đó thì cái sự tương đồng của mình nó thể hiện ở chỗ đó và ở đây đó là một cái hình ảnh động minh họa cho các cái bước chạy của thuật toán camin thì trong phần tiếp theo chúng ta sẽ tìm hiểu kỹ hơn cái ý tưởng của thuộc toán camin các cái thuộc toán nhóm dữ liệu thì nó sẽ có rất nhiều những cái thuộc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:13",
      "end_timestamp": "0:01:55"
    }
  },
  {
    "page_content": "dữ liệu thì nó sẽ có rất nhiều những cái thuộc toán khác nhau và ở đây thì chúng ta sẽ có camin và DB scan sẽ là hai cái thuật toán mà chúng ta sẽ tìm hiểu kỹ trong cái bài học ngày hôm nay còn các cái thật toán như là hierarchical clustering spectral clustering thì đây là những cái thập toán cũng nổi tiếng nhưng mà nó sẽ nằm ngoài cái phạm vi của buổi học ngày hôm nay hai cái thực toán camin và DB scan là hai thực Toán điển hình có đi theo hai cái hướng tiếp cận khác nhau đối với thực Toán",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:01:50",
      "end_timestamp": "0:02:34"
    }
  },
  {
    "page_content": "cái hướng tiếp cận khác nhau đối với thực Toán camin thì nó sẽ gom nhóm khi biết trước cái số lượng K là cái số lượng cụng mà mình sẽ phân loại trong khi đó DD scan thì chúng ta sẽ không biết trước cái số lượng K này DB scan sẽ gom nhóm các cái cụm dựa trên các cái tiêu chí về mậc độ tức là những cái khu vực nào có cái mực độ lớn thì nó sẽ tách ra thành một cụm đó chứ nó không có dựa trên cái số lượng K chỉ định ban đầu tại vì cái việc chỉ định số lượng K này nó sẽ bị cái vấn đề đó là chủ Quang",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:28",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "lượng K này nó sẽ bị cái vấn đề đó là chủ Quang và trong các cái thuộc toán ở đây thì mỗi phương pháp thì đều có những cái Ưu điểm và quyết điểm riêng và cái việc sử dụng cái phương pháp nào á thì nó sẽ tùy thuộc vào cái tính chất dữ liệu cũng như là mục tiêu của cái việc mà mình đang muốn hướng tới ví dụ nếu như cái dữ liệu của mình có cái số lượng lớn số lập tập dữ liệu của mình cái số điểm trong cái không gian của mình nó lớn hoặc là cái số chiều của đặc trưng của mình nó lớn thì khi đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:03:01",
      "end_timestamp": "0:03:38"
    }
  },
  {
    "page_content": "số chiều của đặc trưng của mình nó lớn thì khi đó chúng ta phải chọn những cái thuật toán nào có cái độ phức tạp thấp thì camin là một trong những thuật toán của độ phức tạp thấp còn những thuật toán mà có độ phức tạp cao ví dụ như là DV scan hoặc là g mure Model thì khi đó nó lại không phù hợp cho những cái trường hợp mà dữ liệu của mình có cái khối lượng dữ liệu lớn hoặc là có cái đặc trưng của nó lớn và tùy theo cái mục tiêu cụ thể nếu như chúng ta cần giải quyết cái bài toán mang tính chất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:03:33",
      "end_timestamp": "0:04:08"
    }
  },
  {
    "page_content": "ta cần giải quyết cái bài toán mang tính chất là tương đối chúng ta sẽ gom những cái điểm nào nó gần gần với nhau gom lại và sau đó thì chúng ta sẽ phục vụ cho cái việc là gán giãn dữ liệu hoặc là Nén dữ liệu thì khi đó ch chúng ta có thể sử dụng thuộc toán camin nhưng nếu như chúng ta cần biết chính xác là các cái Cụm nào nó đi theo những cái phân bố nào và các cái phân bố này phải có cái sự cô đặt có cái mực độ mà dày đặt nhất định thì chúng ta mới tạo ra một cùm còn những cái điểm mà rời rạt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:04:02",
      "end_timestamp": "0:04:41"
    }
  },
  {
    "page_content": "mới tạo ra một cùm còn những cái điểm mà rời rạt à những cái điểm lẻ và nhiễu không có nằm chung với lại những cái phân cụm khác thì chúng ta xem nó như là những cái out layer chúng ta sẽ loại bỏ nó ra ngoài chúng ta sẽ không còn xem xét đến nữa thì khi đó chúng ta sẽ chọn DB scan đó thì như vậy thì tùy vào tính chất và mục tiêu cụ thể mà chúng ta sẽ chọn cái thực toán tương ứng và tiếp theo thì chúng ta sẽ đến với mô hình camin thuộc toán caom nhóm camin thì ý tưởng của thuộc toán camin này á",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:04:34",
      "end_timestamp": "0:05:16"
    }
  },
  {
    "page_content": "nhóm camin thì ý tưởng của thuộc toán camin này á đó là chúng ta sẽ khởi tạo ngẫu nhiên ca cái tâm cụng ban đầu trong cái tập điểm này đó nó sẽ khởi tạo ngẫu nhiên tại những cái vị trí bất kỳ trong cái điểm D dệt của mình rồi sau đó chúng ta sẽ lặp đi lặp lại cái quá trình mà Cập nhật cái tâm cụng và cái cách thức mà mình lặp đi lặp lại đó chính là chúng ta sẽ gán giãn à các cái điểm dữ liệu của mình vào cái trọng tâm gần nhất vào cái trọng tâm gần nhất rồi sau đó chúng ta sẽ cập nhật lại cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:05:10",
      "end_timestamp": "0:05:44"
    }
  },
  {
    "page_content": "gần nhất rồi sau đó chúng ta sẽ cập nhật lại cái trọng tâm chúng ta sẽ cập nhật lại cái trọng tâm rồi sau đó chúng ta lại tiếp tục gán nhãn cho các cái điểm dữ liệu vào cái trọng tâm gần nhất và quá trình này sẽ được lặp đi lặp lại cho đến khi các cái trọng tâm của mình nó không còn thay đổi nữa đó thì trong cái mô phỏng ở đây chúng ta thấy ban đầu nè nó tách ra và khi chúng ta cập nhật sang cái tâm cụn mới thì nó sẽ cập nhật lại đó chúng ta sẽ cập nhật lại các cái điểm mới và Càng về sau chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:05:40",
      "end_timestamp": "0:06:19"
    }
  },
  {
    "page_content": "nhật lại các cái điểm mới và Càng về sau chúng ta thấy là số điểm mà mình Cập nhật cái tâm cập nhật lại cái cái nhãn cụm của nó nó càng ít tại những thời điểm đầu chúng ta thấy nè cái khu vực này nó cập nhật rất là nhiều Đúng không cho cái điểm màu đỏ nhưng mà sà đến cái những cái phòng đật cuối cùng thì các cái điểm dưng liệu này nó không còn cập nhật nhiều nữa rồi và thuật toán sẽ dừng khi tâm cụm không di chuyển hoặc là các cái điểm dữ liệu của mình nó không có cái sự thay đổi trạng thái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:06:15",
      "end_timestamp": "0:06:56"
    }
  },
  {
    "page_content": "của mình nó không có cái sự thay đổi trạng thái hoặc là thay đổi trạng thái rất ít thì khi đó chúng ta sẽ dùng và để nhận xét cho cái thuật toán gom nhóm camin thì chúng ta cũng sẽ cùng xem xét ở hai cái góc độ đó là Ưu điểm và khuyết điểm về ưu điểm thì rõ ràng à Đây là một trong những cái tục toán đơn giản và dễ cài đặt và nó hiệu quả cho những cái dữ liệu lớn Tuy nhiên cái hiệu quả cho cái dữ liệu lớn này thì nó cũng tùy theo mức độ ví dụ nếu cái số mẫu dữ liệu của mình lên đến hàng triệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:06:52",
      "end_timestamp": "0:07:37"
    }
  },
  {
    "page_content": "cái số mẫu dữ liệu của mình lên đến hàng triệu mẫu thì khi đó Cái thuộc toán camam của mình nó cũng bắt đầu nó chậm đi và nó cũng không còn hiệu quả nữa thì khi đó chúng ta sẽ có những cái biến thể của camin để mà có thể thực hiện được trên cái tập dữ liệu lớn đó chính là thuộc toán aamin aamin K Tứ A này á đó chính là approximate tức là xắp sỉ thì ở đây nó sẽ có các cái thuật toán để tìm ca cái giá trị gần nhất mà theo kiểu là xấp xỉ thì khi đó thuật toán của mình nó sẽ được chạy nhanh hơn và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 13,
      "start_timestamp": "0:07:32",
      "end_timestamp": "0:08:10"
    }
  },
  {
    "page_content": "thuật toán của mình nó sẽ được chạy nhanh hơn và có thể làm việc được trên trên cái cái tập dữ liệu mà lên đến hàng triệu mẫu thậm chí là hàng trăm triệu mẫu thì nó vẫn có thể thực hiện được với aamin và khuyết điểm của cái thuật toán gom nhóm camin đó chính là nó cần phải biết trước cái số lượng cụm K thì trong nhiều tình huống chúng ta sẽ không thể biết trước được cái số cộm K này là gì Tại vì chúng ta không hề có nhãng dữ liệu này chúng ta không có giãng Do đó thì chúng ta sẽ không biết là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 14,
      "start_timestamp": "0:08:04",
      "end_timestamp": "0:08:53"
    }
  },
  {
    "page_content": "có giãng Do đó thì chúng ta sẽ không biết là cái tập dữ liệu của mình có bao nhiêu cái cụng bên trong đó thì khi đó là cái k của mình Nếu như mình chọn không đúng thì dẫn đến là Thục toán của mình nó sẽ chạy không có hiệu quả đó và điều tiếp theo đó là cái Thục toán này nó rất là dễ rơi vào cái cực tiểu cục bộ và nó sẽ phụ thuộc cái việc này nó sẽ phụ thuộc rất nhiều vào cái việc khởi tạo C cực Ban đầu nếu như chúng ta rải đều các cái tâm cụm này rải ra đều ra thì khi đó Hy vọng rằng là nó sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 15,
      "start_timestamp": "0:08:48",
      "end_timestamp": "0:09:26"
    }
  },
  {
    "page_content": "rải ra đều ra thì khi đó Hy vọng rằng là nó sẽ không bị bị dừng hoặc là bị không có cập nhật nữa Còn nếu như cái k cộng này mà chúng ta khởi tạo không tốt thì nó sẽ có dẫn đến cái tình huống đó là khi thuộc toán chạy đến một mức độ nào đó nó sẽ bị dừng không có cập nhật đi được thêm nữa Nhưng mặc dù lúc đó là cái số cụng của mình nó không có đảm bảo được là cái các cái tiêu chí về mực Độ và một trong những cái điểm yếu Tiếp theo và cũng khá là quan trọng của camin đó chính là nó phụ thuộc vào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 16,
      "start_timestamp": "0:09:21",
      "end_timestamp": "0:09:57"
    }
  },
  {
    "page_content": "quan trọng của camin đó chính là nó phụ thuộc vào cái việc khởi tạo tâm cụm thì đây chính là cái nguyên nhân cái nguyên nhân gây ra cái tình trạng gọi là rơi vào cực tiểu cục bộ nó không thoát ra khỏi cái cái cách thức phân cụm tại một thời điểm nào đó thì cái việc phụ thuộc này là sau này nó cũng sẽ có một số cái thuật toán một số cái chiến thuật để chúng ta khởi tạo cái tâm cụng sao cho nó hiệu quả hơn và ở đây là một cái ví dụ đ chúng ta thấy là sau rất nhiều cái vòng lập thì cái tâm cụng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 17,
      "start_timestamp": "0:09:53",
      "end_timestamp": "0:10:27"
    }
  },
  {
    "page_content": "là sau rất nhiều cái vòng lập thì cái tâm cụng của mình nó cũng gần như không di chuyển đến cái vòng lập thứ 18 19 nó vẫn gần như không di chuyển nhưng mà mãi cho đến những cái vòng lập mà từng thứ 20 trở về sau thì mới bắt đầu thoát ra được khỏi cái cực tiểu cực bộ đó thì đó là lý do là vì cái cái cái tâm cụng hình tròn này nè là ban đầu nó được khởi tạo ở đây đó nó khởi tạo ngay vị trí này thì nó sẽ tốn rất là nhiều thời gian để mà nó thoát nó nhảy ra và nó thoát ra khỏi cái cụm bên đây để",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 18,
      "start_timestamp": "0:10:24",
      "end_timestamp": "0:11:01"
    }
  },
  {
    "page_content": "nó nhảy ra và nó thoát ra khỏi cái cụm bên đây để sang cái cụm bên đây đó Còn nếu như cái điểm hình tròn này nè nếu như chúng ta khởi tạo tốt tức là chúng ta khởi tạo mà nằm trong những cái khu vực bên đây thì cái việc cập nhật sẽ cực kỳ nhanh nó không phải tốn một cái thời gian lớn để mà có thể thoát ra khỏi cái chỗ này và trong nhiều tình huống nếu như cái dữ liệu của mình mà phân bố không tốt á thậm chí là nó sẽ dừng ở bên đây nó không thể thoát ra khỏi khu vực bên đây được và cuối cùng đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 19,
      "start_timestamp": "0:10:55",
      "end_timestamp": "0:11:34"
    }
  },
  {
    "page_content": "ra khỏi khu vực bên đây được và cuối cùng đó là cái Thục toán camin này của mình nó chỉ hoạt độc tốt với những cái dữ liệu ờ có cái dạng hình cầu có cái dạng hình cầu thì nó sẽ hoạt động rất là tốt Còn những cái dữ liệu của mình mà không có dạng phân bố hình cầu mà nó có cái dạng phức tạp thì nó sẽ không còn thực hiện tốt nữa ta lấy ví dụ như lẽ ra ở đây là một cái hình vui ha Nó sẽ là hình mặt người mà đang cười thì lẽ ra ở đây sẽ phải là một cụm ở đây sẽ là một cụm rồi Ở đây sẽ là một cụn Tuy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 20,
      "start_timestamp": "0:11:29",
      "end_timestamp": "0:12:04"
    }
  },
  {
    "page_content": "ở đây sẽ là một cụm rồi Ở đây sẽ là một cụn Tuy nhiên kỹ thuật toán của mình nó đã không học được theo cái mậc độ mà nó chỉ đơn giản đó là nó đi theo cái dạng cập nhật các cái tâm cụng cho cái vị trí gần nhất và nó đi xuyên qua cái khoản không Lấy ví dụ như tại một cái trạng thái cập nhật này chúng ta thấy rõ ràng tâm cụm của mình nó sẽ nằm ngoài cái phân bố dữ liệu đúng không ở đây là tâm cụm nó nằm ngoài phân bố dễn liệu trong khi đó nếu tâm cụm của mình nằm trong khu vực này nằm trong khu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cụm của mình nằm trong khu vực này nằm trong khu vực này nằm trong khu vực này thì nó sẽ hợp lý hơn đó còn ở đây là tâm chụ tâm cụm nó lại nằm nó ở nằm ở trong cái khu vực mà không hề có cái mẫu dữ liệu nào thì điều đó chính là cái điểm yếu của thực toán camin nó chỉ phù hợp với những cái dạng dữ liệu mà có cái dạng hình cầu như thế này tức là phân bố tròn phân bố tròn tỏa ra còn nếu như dữ liệu của mình nó sẽ là những cái cụng rải rác giống như cái hình mặt cười ở đây đây thì thuộc toán camin",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cái hình mặt cười ở đây đây thì thuộc toán camin sẽ không có chạy tốt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KBu_8C3KULg",
      "filename": "KBu_8C3KULg",
      "title": "[CS116 - Buổi 6] Part 2",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tiếp theo thì chúng ta sẽ cùng à Tìm hiểu về các cái phương pháp để phát hiện và xử lý dữ liệu ngoại lệ thì để phát hiện dữ liệu ngoại lệ thì chúng ta sẽ có hai cái cách tiếp cận cách tiếp cận đầu tiên đó là dựa trên cái phương pháp thống kê và cách tiếp cận thứ hai đó là chúng ta sẽ tự động phát hiện các cái giá trị ngoại lệ dựa trên một số cái phương pháp và ở đây chúng ta có để một số cái đường link và các cái phương pháp này thì cũng đều được cài đặt bởi s kit lên và ngoài ra à Ngoài bốn cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:35"
    }
  },
  {
    "page_content": "cài đặt bởi s kit lên và ngoài ra à Ngoài bốn cái phương pháp mà phát hiện tự động này thì chúng ta còn có những cái công cụ tự động khác mà không được phát triển bởi s kit l ví dụ như là clean LB rồi odod rồi phát hiện các cái vấn đề của dữ liệu Tức là bên cạnh những cái dữ liệu ngoại lệ thì chúng ta còn phát hiện rất nhiều những cái vấn đề khác nữa chứ không phải là vấn đề về Ờ về về về chứ không phải là chỉ vấn đề về bị thiếu dữ liệu hoặc là vấn đề dữ liệu bị ngoài cái phân bố out of",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:30",
      "end_timestamp": "0:01:13"
    }
  },
  {
    "page_content": "là vấn đề dữ liệu bị ngoài cái phân bố out of distribution Ví dụ như dữ liệu nó không có cái sự đồng nhất giá trị của mình Nó có thể là nằm trong cái distribution nhưng mà nó sẽ tiền hậu bất nhất ví dụ như cũng cái record đó nhưng mà ở trước thì nó lại là giá trị là a Nhưng mà ở sau đó thì giá trị của mình lại là b thì đó là cái sự bất nhất trong cái dữ liệu à Ở hiếng tiết cận đầu tiên thì chúng ta nh nhắc lại cái phương pháp thống kê với edi ở đây thì chúng ta có thể là sử dụng phương pháp để",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:07",
      "end_timestamp": "0:01:43"
    }
  },
  {
    "page_content": "đây thì chúng ta có thể là sử dụng phương pháp để tính trung bình và độ lịch chuẩn để xác định Xem các cái giá trị ngoại lệ của mình Ví dụ như trong cái sơ đồ ở đây chúng ta có được cái giá trị là trung bình là ở đây và với cái độ lệch chuẩn thì chúng ta sẽ có là mi trừ Sigma rồi mi -2 Sigma và Mi - 3 Sigma thì chúng ta thấy là với cái khoảng giá trị là mi trừ Sigma -3 Sigma trở về trước và ng c 3 Sigma trở về sau thì nó chỉ chiếm cái tỉ lệ rất là thấp và chúng ta Giả định rằng là tại đây đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:01:39",
      "end_timestamp": "0:02:20"
    }
  },
  {
    "page_content": "là thấp và chúng ta Giả định rằng là tại đây đó chính là những cái dữ liệu out layer thì khi đó nếu như cái giá trị của mình mà nằm ngoài cái khoảng là từ mu trừ 2 Sigma cho đến mi c 2 Sigma thì chúng ta xem đó chính là những cái giá trị ngoại lệ một cái phương pháp khác đó chính là phương pháp inter Range IQ để xác định các giá trị ngoại lệ với cái dữ liệu phân bối không với lại cái phân phối không phải là g CN thì ở đây nó cũng tương tự như vậy chúng ta sẽ xét đến các cái ngưỡng thì cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:15",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "vậy chúng ta sẽ xét đến các cái ngưỡng thì cái ngưỡng tại đây đó là ngưỡng Q1 trừ cho 1,5 iqa thì iqa nó sẽ là cái khoảng giá trị từ Q1 cho đến q3 trong đó Q1 tương ứng là cái vị trí Mà nó có 25 cái dữ liệu của mình tức là nếu từ đây đến đây đó thì tất cả những cái số lượng các cái giá trị mà từ đây đến cái ngưỡng q3 Q1 Thì đó sẽ là 25 ph số lượng phần tử và q3 là tương ứng là 75 ph số phần tử tức là từ q3 trở về sau thì nó sẽ chiếm là 25 ph số phần tử và từ đây đến đây là 25 ph số phươ tử như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:03:01",
      "end_timestamp": "0:03:48"
    }
  },
  {
    "page_content": "phần tử và từ đây đến đây là 25 ph số phươ tử như vậy thì cái chúng ta sẽ có hai cái ngưỡng Q1 và q3 Thì nguyên cái khoảng từ Q1 cho đến q3 nó gọi là iqr và với cái giá trị iqr này thì à chúng ta sẽ có các cái ngưỡng để tính giá trị ngoại lệ Đó là tại đây thì cái ngưỡng này nó sẽ có công thức tính là Q1 tức là tại đây trừ cho 1,5 cái khoảng iqa này và tương tự như vậy cái chặn trên cho cái ngưỡng ngoại lệ đó chính là maximum ha Nó sẽ là bằng q3 à nó sẽ là bằng q3 cộng cho 1,5 lần cái ia Tức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:03:42",
      "end_timestamp": "0:04:25"
    }
  },
  {
    "page_content": "à nó sẽ là bằng q3 cộng cho 1,5 lần cái ia Tức là cái khoảng này thì nếu như cái giá trị nào mà nằm ngoài cái khoảng minimum và maximum này thì chúng ta sẽ xem đó là điểm ngoại lệ thì đây là cái phương pháp để xác định km điểm ngoại lệ đối với những cái phân bố mà nó không có cái dạng là gaan còn phương pháp bên đây là mu cộng trừ 2 Sigma đó là cho cái phương pháp mà đối với cái dữ liệu nó tuân theo phân bố g và để xử lý những cái dữ liệu ngoại lệ này thì chúng ta cũng làm tương tự như dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:04:19",
      "end_timestamp": "0:05:05"
    }
  },
  {
    "page_content": "lệ này thì chúng ta cũng làm tương tự như dữ liệu bị thiếu đó là chúng ta có cái phương pháp là loại bỏ phương pháp thay thế đơn giản Ví dụ thay thế bằng các cái giá trị Hào số hoặc là thay thế bởi các cái giá trị thống kê đơn biến ví dụ như là Min rồi median Mode hoặc là cái giá trị mà có cái tầng suất xuất hiện nhiều nhất rồi chúng ta có thể sử dụng các cái mô hình dự đoán đó là các cái mô hình máy học Ví dụ như các cái thực toán về K near neighbor rồi thực toán về linear regression Tức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:04:59",
      "end_timestamp": "0:05:43"
    }
  },
  {
    "page_content": "rồi thực toán về linear regression Tức là phương pháp hồn ngy hoặc là sử dụng các cái mô hình phi tuyến tính khác đó thì đây chính là cái hướng tiếp cận cho xử lý ngoại lệ Ngoài ra thì chúng ta còn có thể thực hiện một số cái thao tác làm sạch khác cho cái dữ liệu của mình lưu ý chúng ta dùng cái từ khóa đó là dữ liệu nghĩa là chúng ta chưa đến cái giai đoạn rút trích đặc trưng thì một số cái thao tác để làm sạch dữ liệu khác ví dụ như là chúng ta sẽ reindexing thực rất phương pháp này cái cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:05:38",
      "end_timestamp": "0:06:28"
    }
  },
  {
    "page_content": "ta sẽ reindexing thực rất phương pháp này cái cái cái thao tác này là nó không làm thay đổi cái giá trị của mình mà nó chỉ làm đánh lại cái chỉ mục đánh lại cái chỉ mục cho các cái cột dữ liệu thì cái cái việc này nó sẽ giúp cho cái việc truy cập về sau truy cập dữ liệu được nhanh hơn đấy thì nó sẽ hỗ trợ cho cái thao tác tính toán về sau reformatting trước đây Nếu như các cái dữ liệu của mình nó ở dạng nan thì nó có thể là ở những cái dạng là không phải số học không phải dạng số thì chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:06:22",
      "end_timestamp": "0:07:04"
    }
  },
  {
    "page_content": "không phải số học không phải dạng số thì chúng ta có thể là phải reformat nó để từ một cái dạng không nó là dạng số về cái dạng là số nguyên hoặc là số thực để mà có thể xử lý tính toán được như vậy chúng ta sẽ phải đổi kiểu dữ liệu rồi ngoài ra chúng ta có thể thay đổi bằng cách đó là thay những cái giá trị mà nó không có cái tính gọi là nhất quán chúng ta sẽ thay những cái giá trị cũ bằng một cái giá trị mới nếu như cái giá trị cũ này là nó vi phạm những cái tính chất nhất quán của dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:07:00",
      "end_timestamp": "0:07:35"
    }
  },
  {
    "page_content": "vi phạm những cái tính chất nhất quán của dữ liệu rồi chúng ta có thể à thay đi gọi là loại bỏ những cái dữ liệu bị trùng lắp tức là nếu như dữ liệu của mình trùng lắp quá nhiều thì nó cũng ảnh hưởng đến cái hiệu năng của à cái mô hình học máy và chúng ta sẽ drop duplicate chúng ta sẽ loại bỏ đi những cái dữ liệu à Để trùng r đó rồi thay bỏ loại bỏ những cái cột dữ liệu không cần thiết chúng ta lấy ví dụ như có những cái cột dữ liệu mà chúng ta biết trước là nó sẽ không liên quan đến cái việc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:07:30",
      "end_timestamp": "0:08:12"
    }
  },
  {
    "page_content": "biết trước là nó sẽ không liên quan đến cái việc mà đưa ra cái dự đoán ờ output cuối cùng Ví dụ như cái cột số thứ tự hoặc là cái cột mã nhân viên thì đây là thường là những cái giá trị ngỗ nhiên nó không có đóng góp nhiều cho cái việc mà huấn luyện nên chúng ta có thể lại bỏ đi các cái cột này rồi ngoài ra thì chúng ta cũng có thể là lại bỏ đi những cái dòng dữ liệu mà nó thoi mãn một số cái tính chất nào đó thì chúng ta có thể dùng cái lệnh để mà lọc lại những cái dòng dữ liệu thì đây là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 13,
      "start_timestamp": "0:08:07",
      "end_timestamp": "0:08:12"
    }
  },
  {
    "page_content": "để mà lọc lại những cái dòng dữ liệu thì đây là những cái phương pháp làm sạch dữ liệu khác bên cạnh hai cái phương pháp chính đó là loại bỏ những cái dữ liệu bị thiếu hoặc là lại bỏ những cái dữ liệu nhiễu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=KgNMHIB8Aoc",
      "filename": "KgNMHIB8Aoc",
      "title": "[CS116 - Buổi 4] Part 2",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "để mà có thể gọi được cái phương thức distance này thì tương tự như vậy chúng ta cũng sẽ có một cái bước gọi là khởi tạo một cái thực thể và cái instance này nó được đặt tên là là C rồi chúng ta sẽ khởi tạo thêm một cái origin hay là một cái Zero ở đây trong trường hợp này thì chúng ta đặt tên là Zero chúng ta đổi tên biến chúng ta sẽ khởi tạo một cái Điểm Khác một cái instance khác rồi sau đó chúng ta sẽ gọi đến cái phương thức chúng ta sẽ gọi đến các phương thức thông qua cái đối tượng chấm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:04",
      "end_timestamp": "0:00:52"
    }
  },
  {
    "page_content": "đến các phương thức thông qua cái đối tượng chấm này chấm distance và nó sẽ lấy cái biến C nó sẽ lấy cái Xin lỗi Nó sẽ lấy cái đối tượng C và tính distance đến cái thực thể là Zero thì đây chính là cái object để gọi hàm và đây là cái phương thức đây chính là cái phương thức để mình gọi hàm và đây chính là cái tham số là nó không bao gồm cái `self` cái tham số này nó không bao gồm `self` lưu ý là lúc chúng ta định nghĩa thì chúng ta sẽ có cái `self` ở đây nhưng đến lúc mà chúng ta gọi hàm thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:47",
      "end_timestamp": "0:01:26"
    }
  },
  {
    "page_content": "ở đây nhưng đến lúc mà chúng ta gọi hàm thì chúng ta sẽ không truyền cái tham số `self` mà chúng ta chỉ chúng ta chỉ truyền cái tham số ngay phía sau `self` ví dụ sau `self` nó có những tham số nào thì chúng ta sẽ truyền vào danh sách các tham số đó `self` thì nó sẽ ám chỉ đến cái object là một cái tính chất quan trọng khác của Lập trình hướng đối tượng chính là kế thừa thì mục tiêu của kế thừa là để giúp chúng ta chúng ta tái sử dụng tái sử dụng lại cái mã nguồn một cách hiệu quả Ví dụ như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:21",
      "end_timestamp": "0:02:06"
    }
  },
  {
    "page_content": "dụng lại cái mã nguồn một cách hiệu quả Ví dụ như chúng ta sẽ có những cái lớp cha ở đây là một cái hình ảnh minh họa thôi Ví dụ như ở đây chúng ta sẽ có cái lớp là Person đó là lớp cha là gồm tập hợp tất cả những cái người tham gia trong cái buổi chụp hình ở đây còn trong đó thì chúng ta sẽ có những người là giảng viên có những người là sinh viên student thì student sẽ được hiểu là một cái tập con của Person student sẽ được hiểu là một lớp con rất là chung hay còn gọi là trong cái ví dụ này sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:00",
      "end_timestamp": "0:02:47"
    }
  },
  {
    "page_content": "là chung hay còn gọi là trong cái ví dụ này sẽ có các tập con Ví dụ là student ví dụ như là Lecturer sẽ được xem là kế thừa với lại cái đối tượng cha là Person Tức là trong Person trong cái lớp tổng quát này nè Nó sẽ có những cái phương thức hoặc là có những cái thuộc tính nào phương thức hay thuộc tính nào mà cái lớp student này có thể tái sử dụng được thì chúng ta sẽ tái sử dụng và không cần phải cài đặt lại còn cái lớp Animal ở đây thì chúng ta sẽ có hai cái đối tượng hai cái đối tượng con",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 4,
      "start_timestamp": "0:02:43",
      "end_timestamp": "0:03:23"
    }
  },
  {
    "page_content": "ta sẽ có hai cái đối tượng hai cái đối tượng con hai cái lớp đối tượng con đó chính là Cat và Rabbit Tức là mèo và thỏ thì ở đây chúng ta sẽ xuất hiện hai cái khái niệm là lớp cha và lớp con lớp cha còn gọi là parent class ở lớp con thì còn gọi là child class hay là subclass subclass và cái việc kế thừa thì sẽ giúp cho chúng ta là kế thừa tất cả các cái thuộc tính của dữ liệu và hành vi cũng như là phương thức của lớp cha đó và nó có thể định nghĩa thêm những cái thuộc tính mới và phương thức",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 5,
      "start_timestamp": "0:03:18",
      "end_timestamp": "0:03:51"
    }
  },
  {
    "page_content": "thêm những cái thuộc tính mới và phương thức mới đồng thời đồng thời nếu như chúng ta không kế thừa chúng ta có thể ghi đè cái phương thức cũ của lớp cha Tức là những cái phương thức cũ của cha mình cũng sẽ có những cái phương thức tên y chang như vậy nhưng mà cái cách hành vi cái cách hành xử nó không giống thì chúng ta sẽ viết lại nó gọi là ghi đè lên override lên đó thì ở đây chúng ta sẽ có một cái ví dụ minh họa thì Animal là cái lớp cha nhất hay còn gọi là lớp ông nội đó dưới đó thì sẽ có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 6,
      "start_timestamp": "0:03:46",
      "end_timestamp": "0:04:30"
    }
  },
  {
    "page_content": "hay còn gọi là lớp ông nội đó dưới đó thì sẽ có cái lớp Person, Cat và Rabbit đều là kế thừa của Animal trong cái Person này chúng ta lại có một cái tập con khác đó chính là student student thì là một tập con của Person và Person Cat và Rabbit của Animal thì đây là một cái cấu trúc cây để giúp cho chúng ta hình dung cái cấu trúc về kế thừa của các lớp đối tượng và đây là một cái ví dụ để minh họa cho cái lớp cha hay còn gọi parent class là lớp Animal những cái phương thức nào những cái thuộc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 7,
      "start_timestamp": "0:04:25",
      "end_timestamp": "0:05:19"
    }
  },
  {
    "page_content": "Animal những cái phương thức nào những cái thuộc tính nào mà chung nhất thuộc tính hoặc là phương thức tức là được tái sử dụng nhiều nhất thì chúng ta sẽ viết vào và chúng ta sẽ, xin lỗi, chúng ta sẽ được viết và cài đặt vào bên trong cái lớp cha ví dụ tính tuổi tất cả các cái Animal nó đều có tuổi do đó thì chúng ta sẽ phải viết một cái phương thức là để tính tuổi rồi gán tuổi rồi gán name tức là gán cái tên thì đây chỉ là cái phương thức mà bất cứ Animal nào nó đều có và print ở đây tức là để",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 8,
      "start_timestamp": "0:05:11",
      "end_timestamp": "0:05:59"
    }
  },
  {
    "page_content": "cứ Animal nào nó đều có và print ở đây tức là để in ra Ví dụ nếu chúng ta gọi cái lệnh là print cái cái Animal của mình Ví dụ như một cái một cái con Cat thì nó sẽ gọi cái lệnh này thì đây là một cái ví dụ về kế thừa trong đó thì chúng ta sẽ cài đặt cái lớp cha tiếp theo thì chúng ta sẽ cài đặt cái lớp con thì đây chính là con là lớp đối tượng Cat class là con của Animal do đó thì chúng ta sẽ kế thừa chúng ta sẽ có cái cú pháp đó là `class` và để tên cha Ở Đây Rồi Cat nó sẽ có những cái thuộc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 9,
      "start_timestamp": "0:05:54",
      "end_timestamp": "0:06:38"
    }
  },
  {
    "page_content": "để tên cha Ở Đây Rồi Cat nó sẽ có những cái thuộc tính và có những cái phương thức riêng và không phải cái lớp cha nào cũng có ví dụ như Cat thì nó sẽ có cái phương thức gọi là speak thì nó sẽ in ra cái câu là meo và đồng thời là chúng ta sẽ ghi đè chúng ta sẽ ghi đè cái phương thức là print này chúng ta sẽ ghi đè thì nếu như cái Lớp con nó có những cái hành vi nào đó khác thì chúng ta sẽ phải viết lại cái hàm đó ví dụ ở đây Cat thì chúng ta sẽ ghi là Cat hai chấm tên và tuổi còn nếu như đối",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 10,
      "start_timestamp": "0:06:32",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "ghi là Cat hai chấm tên và tuổi còn nếu như đối tượng nói chung thì chúng ta sẽ để là Animal hai chấm tên tuổi còn đối với Cat thì ở đây chúng ta sẽ không còn để cái Animal nữa mà chúng ta sẽ để tên là Cat rồi thì cái phương thức mới thêm cái phương thức mới là phương thức speak cho instance của cái lớp Cat thì sẽ được sử dụng và do đó thì chỉ có lớp con Tức là lớp instance của lớp Animal thì không thể gọi được tại vì cái phương thức speak này là chỉ có ở lớp con là Cat và không có trong lớp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 11,
      "start_timestamp": "0:07:18",
      "end_timestamp": "0:07:58"
    }
  },
  {
    "page_content": "là chỉ có ở lớp con là Cat và không có trong lớp cha rồi Như vậy thì chúng ta đã cùng lướt qua một số cái ôn tập cho các cái nội dung về lập trình trong Python ví dụ như là chúng ta được ôn về kiểu dữ liệu các toán tử cấu trúc rẽ nhánh cấu trúc lập rồi hàm rồi Lập trình hướng đối tượng thì đây là những cái thành phần cơ bản nhất khi chúng ta học về lập trình Python tiếp theo thì chúng ta sẽ cùng làm các cái bài quiz và có cái phần hỏi đáp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Khz_kSZ-91M",
      "filename": "Khz_kSZ-91M",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.6.2: Lập trình Python - Hướng đối tượng (P2)",
      "chunk_id": 12,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Hôm nay chúng ta sẽ cùng đến với cái nội dung tiếp theo đó là học có giám sát và tên tiếng Anh đó chính là supervised learning và mô hình đầu tiên mà chúng ta sẽ tiếp cận trong ngày hôm nay đó là mô hình hồi quy trong những bài tiếp theo thì chúng ta sẽ tiếp cận đến mô hình phân lớp. Về vị trí của cái bài học ngày hôm nay thì học có giám sát nó sẽ nằm ở trong cái bài là trong cái Machine Learning pipeline đó là ở bước Model Training hay còn gọi đó là xây dựng và huấn luyện mô hình. Thì học có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kJnJszwQlz8",
      "filename": "kJnJszwQlz8",
      "title": "[CS116 - Buổi 7] Part 0",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:51"
    }
  },
  {
    "page_content": "đó là xây dựng và huấn luyện mô hình. Thì học có giám sát là gì? Tên tiếng Anh của học có giám sát chính là supervised learning, đó là một nhánh của lĩnh vực máy học và mục tiêu của nó đó là nhằm dự đoán cái giá trị đầu ra từ cái đặc trưng đầu vào, từ một cái đặc trưng đầu vào và cái đặc trưng này là một cái đặc trưng mới. Thế thì để có thể đưa ra được cái dự đoán này nó sẽ phải dựa trên các cái dữ liệu huấn luyện trước đó. Nó phải dựa trên các cái dữ liệu huấn luyện trước đó thì cái dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kJnJszwQlz8",
      "filename": "kJnJszwQlz8",
      "title": "[CS116 - Buổi 7] Part 0",
      "chunk_id": 1,
      "start_timestamp": "0:00:45",
      "end_timestamp": "0:01:25"
    }
  },
  {
    "page_content": "cái dữ liệu huấn luyện trước đó thì cái dữ liệu huấn luyện của mình á nó sẽ bao gồm các cái cặp đặc trưng đầu vào và đặc trưng đầu ra mình mong muốn, mình mong muốn thì ký hiệu là x và y, trong đó x chính là cái đặc trưng đầu vào và y chính là cái giá trị đầu ra mong muốn của mô hình của mình. Và trong cái biểu đồ ở dưới đây thì chúng ta thấy dữ liệu X của mình nó sẽ là đầu vào cho cái mô hình máy học được ký hiệu bởi một cái hàm f(x; θ), trong đó f là một cái dạng hàm tuyến tính nếu như đây là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kJnJszwQlz8",
      "filename": "kJnJszwQlz8",
      "title": "[CS116 - Buổi 7] Part 0",
      "chunk_id": 2,
      "start_timestamp": "0:01:19",
      "end_timestamp": "0:01:57"
    }
  },
  {
    "page_content": "f là một cái dạng hàm tuyến tính nếu như đây là một cái dữ liệu có mối quan hệ tuyến tính, và f sẽ là một cái hàm phi tuyến nếu như đây là một cái mối quan hệ phi tuyến. Và trong cái hàm này thì nó sẽ có cái tham số của mô hình và mục tiêu của cái huấn luyện của một cái mô hình máy học đó chính là chúng ta đi tìm cái tham số theta này. Và với cái hàm mô hình máy học f(x; θ) chúng ta sẽ ra được cái giá trị dự đoán y và ở đây chúng ta sẽ ký hiệu là y mũ, tức là giá trị chúng ta dự đoán thôi. Và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kJnJszwQlz8",
      "filename": "kJnJszwQlz8",
      "title": "[CS116 - Buổi 7] Part 0",
      "chunk_id": 3,
      "start_timestamp": "0:01:52",
      "end_timestamp": "0:02:28"
    }
  },
  {
    "page_content": "là y mũ, tức là giá trị chúng ta dự đoán thôi. Và chúng ta luôn mong muốn cái giá trị này xấp xỉ với lại cái giá trị mong muốn y. Thì cái cặp dữ liệu x và y ở đây chính là cái cặp dữ liệu à huấn luyện của mình, đó là cái dữ liệu huấn luyện của mình. Và chúng ta sẽ có hai cái giá trị y mũ và y này xấp xỉ với nhau khi chúng ta có được một cái hàm hàm mất mát hay còn gọi là hàm loss. Và hàm loss này á thì cái biến số của mình nó chính là theta, và x và y của mình nó sẽ đóng vai trò như là dữ liệu.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kJnJszwQlz8",
      "filename": "kJnJszwQlz8",
      "title": "[CS116 - Buổi 7] Part 0",
      "chunk_id": 4,
      "start_timestamp": "0:02:23",
      "end_timestamp": "0:03:10"
    }
  },
  {
    "page_content": "và y của mình nó sẽ đóng vai trò như là dữ liệu. Đây chính là cái dữ liệu huấn luyện, đây chính là dữ liệu huấn luyện. Và mình sẽ phải tìm tham số theta này sao cho cái hàm này đạt được cái giá trị là nhỏ nhất. Và chúng ta sẽ có hai cái loại bài toán chính, đó chính là bài toán hồi quy và bài toán phân lớp. Bài toán hồi quy thì chúng ta sẽ dựa trên cái đặc điểm của cái giá trị đầu ra mong muốn của mình. Nếu y của mình là một cái giá trị liên tục thì đó chính là bài toán hồi quy. Và cái khái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kJnJszwQlz8",
      "filename": "kJnJszwQlz8",
      "title": "[CS116 - Buổi 7] Part 0",
      "chunk_id": 5,
      "start_timestamp": "0:03:04",
      "end_timestamp": "0:03:42"
    }
  },
  {
    "page_content": "tục thì đó chính là bài toán hồi quy. Và cái khái niệm liên tục này á thì chúng ta phải hiểu đó là cái khái niệm cái tính thứ tự của cái y của mình thể hiện qua việc là nếu như hai cái giá trị y1 và y2 bất kỳ của mình trong cái giá trị đầu ra, nếu như chúng ta có thể thực hiện được cái thao tác so sánh lớn, bé, bằng hoặc là khác thì đó chính là bài toán hồi quy. Ngược lại đối với bài toán phân lớp thì y của mình nó sẽ thuộc một cái tập C là bao gồm C1, C2,..., C_k và cái tập này nó sẽ là một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kJnJszwQlz8",
      "filename": "kJnJszwQlz8",
      "title": "[CS116 - Buổi 7] Part 0",
      "chunk_id": 6,
      "start_timestamp": "0:03:37",
      "end_timestamp": "0:04:19"
    }
  },
  {
    "page_content": "gồm C1, C2,..., C_k và cái tập này nó sẽ là một cái tập rời rạc. Nhưng mà định nghĩa thế nào gọi là rời rạc thì chúng ta sẽ phải xét đến cái yếu tố là hai giá trị y1 và y2 bất kỳ ở trong cái tập C này thì chúng ta chỉ có thể thực hiện được cái thao tác là bằng hoặc khác mà thôi, còn chúng ta không thể thực hiện được cái thao tác so sánh lớn, bé thì khi đó nó gọi là bài toán phân lớp.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kJnJszwQlz8",
      "filename": "kJnJszwQlz8",
      "title": "[CS116 - Buổi 7] Part 0",
      "chunk_id": 7,
      "start_timestamp": "0:04:13",
      "end_timestamp": "0:04:19"
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với bài học tiếp theo đó là machine learning pipeline và phân tích dữ liệu thì tên tiếng Việt của machine learning pipeline đó chính là quy trình xây dựng cái mô hình máy học và đây có lẽ là một trong những cái bài học quan trọng vì nó đi xuyên suốt trong toàn bộ cái môn học này machine learning pipeline nó sẽ cho chúng ta biết được cái quy trình thực hiện bao gồm những cái bước nào và trong cái quá trình thực hiện thì chúng ta biết được cái vai trò của từng cái bước trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:50"
    }
  },
  {
    "page_content": "ta biết được cái vai trò của từng cái bước trong machine learning pipeline là gì thì nội dung ngày hôm nay đó là chúng ta sẽ giới thiệu về khái niệm machine learning pipeline và vai trò của nó tại sao chúng ta cần phải thực hiện một cái quy trình máy học và trong phần thứ hai thì chúng ta sẽ cùng tìm hiểu về một số cái thành phần chính của machine learning pipeline và cuối cùng thì chúng ta sẽ đến với một trong những cái bước đầu tiên của cái quy trình đó chính là phân tích dữ liệu hay là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:44",
      "end_timestamp": "0:01:30"
    }
  },
  {
    "page_content": "quy trình đó chính là phân tích dữ liệu hay là exploratory data analysis hay viết tắt đó là EDA đến với khái niệm về machine learning pipeline thì đây là một chuỗi các cái bước xử lý và xây dựng cái mô hình của mình được liệt kê được liên kết với nhau để chuẩn hóa tối ưu cái quá trình xây dựng và huấn luyện đồng thời là đánh giá cũng như là triển khai mô hình máy học đến với thực tế thì ở trên đây chúng ta thấy là một cái sơ đồ gồm các cái bước trong machine learning pipeline và chúng ta lưu ý",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:24",
      "end_timestamp": "0:02:05"
    }
  },
  {
    "page_content": "trong machine learning pipeline và chúng ta lưu ý rằng là cái sơ đồ này thì có nhiều cái phiên bản khác nhau và đây là một cái sơ đồ điển hình có thể là một số cái một số cái tác giả khác có thể là chọn những cái quan điểm thiết kế một cái pipeline khác nhau tuy nhiên thì đâu đó nó cũng sẽ bao gồm các cái bước cơ bản như trên và tại sao chúng ta cần phải thực hiện cái quy trình máy học này đầu tiên đó là chúng ta phải nói đến cái tính hiệu quả Cái quy trình này nó sẽ giúp cho chúng ta Ờ quy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:02:00",
      "end_timestamp": "0:02:38"
    }
  },
  {
    "page_content": "Cái quy trình này nó sẽ giúp cho chúng ta Ờ quy trình hóa tức là chúng ta module hóa ờ các cái bước cần phải thực hiện khi chúng ta xây dựng một cái mô hình máy học và đồng thời nếu như chúng ta làm tốt thì chúng ta cũng có khả năng tự động hóa cái việc cái mô hình máy học nó vận hành triển khai từ cái khâu là thu thập dữ liệu kiểm định dữ liệu cho đến các cái bước là huấn luyện mô hình Và thậm chí là đến được các bước triển khai đến cái người dùng cuối thì nếu mà chúng ta thực hiện tốt thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:33",
      "end_timestamp": "0:03:13"
    }
  },
  {
    "page_content": "dùng cuối thì nếu mà chúng ta thực hiện tốt thì chúng ta có thể tự động hóa được luôn và cái tính hiệu quả này nó còn thể hiện ở chỗ đó là nó giúp cho chúng ta tiết kiệm được thời gian và nguồn lực thời gian thì bao gồm là các cái công đoạn trong quá trình mà xây dựng một mô hình máy học nếu như chúng ta làm mà không có quy trình và không có cái sự liên kết giữa các cái module với nhau thì đâu đó chúng ta sẽ phải tốn thời gian trong cái việc là triển khai cái mô hình trong thực tế về nguồn lực",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:03:09",
      "end_timestamp": "0:03:43"
    }
  },
  {
    "page_content": "triển khai cái mô hình trong thực tế về nguồn lực thì nó tương ứng đó là chúng ta phải tốn những những cái nhân sự hơn để mà xây dựng cái mô hình này có thể triển khai được đến người dùng cuối cũng như là bảo trì rồi cập nhật nâng cấp cái mô hình máy học của mình thì cái tính hiệu quả là nó thể hiện ở những yếu tố như vậy về khả năng tái lập tức là reproducibility là chúng ta có khả năng lặp lại được những cái kết quả đã thực hiện được trước đó hay không khi chúng ta thử nghiệm ở nhiều môi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:03:38",
      "end_timestamp": "0:04:16"
    }
  },
  {
    "page_content": "đó hay không khi chúng ta thử nghiệm ở nhiều môi trường khác nhau và từ cái giai đoạn gọi là phát triển thử nghiệm ở trong phòng thí nghiệm đến những cái bước mà chúng ta thực hiện và triển khai cho người dùng cuối sử dụng thì liệu là từ trong cái giai đoạn ở phòng thí nghiệm cho đến lúc mà triển khai cho người dùng cuối cái mô hình của mình có được bảo trì có được đảm bảo rằng là đang thực hiện trên cùng một cái phiên bản hay không đó Thì đó chính là cái tính lặp lại được tính ờ triển khai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:04:11",
      "end_timestamp": "0:04:51"
    }
  },
  {
    "page_content": "chính là cái tính lặp lại được tính ờ triển khai trong thực tế nó phải giống nhau giữa phòng thí nghiệm và trong cái môi trường triển khai đơn giản hóa cái việc triển khai thì mô hình của mình triển khai luôn được sẵn sàng chuyển giao từ thí nghiệm sang thực thế nghĩa là trong suốt cái quá trình mà chúng ta phát triển các cái mô hình thì chúng ta có thể triển khai ngay được một cái mô hình nào đó ở trong phòng thí nghiệm sang cái môi trường thực tế mà không gặp phải những cái rủi ro về dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:04:46",
      "end_timestamp": "0:05:26"
    }
  },
  {
    "page_content": "tế mà không gặp phải những cái rủi ro về dữ liệu rủi ro về độ chính xác rủi ro về hiệu năng của hệ thống cái tính khả năng tái sử dụng reusable là các cái mã nguồn rồi những cái module trong cái Ờ quy trình thực hiện thì có được tái sử dụng cho những cái dự án khác hay không thì đó là cái tính tái sử dụng cái tính dễ kiểm soát tức là chúng ta có thể biết được rằng là cái hệ thống hiện tại đang được vận hành Ờ khi triển khai thực tế là đang phiên bản thứ bao nhiêu rồi cái phiên bản trong phòng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:05:21",
      "end_timestamp": "0:05:58"
    }
  },
  {
    "page_content": "bản thứ bao nhiêu rồi cái phiên bản trong phòng thí nghiệm đang thực hiện đang thử nghiệm thì nó đang là ở phiên bản bao nhiêu và chúng ta liệu có đảm bảo được rằng là cái phiên bản hiện tại mà chúng ta đang phát triển hoặc là đang triển khai trong thực tế đó có phải là phiên bản mới nhất hay không thì đó chính là cái tính dễ kiểm soát và cuối cùng đó chính là cái tính dễ cộng tác Tức là khi chúng ta mô hình hóa quy trình hóa cái Machine Learning, cái việc xây dựng cái mô hình máy học thì chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 10,
      "start_timestamp": "0:05:54",
      "end_timestamp": "0:06:22"
    }
  },
  {
    "page_content": "cái việc xây dựng cái mô hình máy học thì chúng ta sẽ có thể dễ dàng phân chia nó ra cho nhiều người quản lý và mỗi người sẽ handle hoặc là mỗi nhóm sẽ handle cho một cái module và các cái module đó thì có thể song song hóa được với nhau hay không thì chúng ta sẽ có thể cho cái công việc của mình nó thực hiện một cách đồng thời thì đó chính là cái tính dễ cộng tác khi chúng ta xây dựng cái machine learning pipeline",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kuDPIIsl2_8",
      "filename": "kuDPIIsl2_8",
      "title": "[CS116 - Buổi 3] Part 1",
      "chunk_id": 11,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và sau đây thì chúng ta sẽ nói về một cái khái niệm cũng rất là quan trọng khi chúng ta triển khai một cái mô hình máy học vào thực tế đó chính là technical debt. Technical debt khi mà triển khai một cái ứng dụng thì ý nghĩa của nó là gì? Ý nghĩa của một cái technical debt tức là nó là một cái khái niệm trong cái lĩnh vực công nghệ phần mềm và công nghệ thông tin. Nó mô tả là những cái công việc nào thì cần phải làm trong tương lai do các cái yếu tố quyết định thì được đưa ra để đẩy nhanh cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:40"
    }
  },
  {
    "page_content": "tố quyết định thì được đưa ra để đẩy nhanh cái tốc độ hiện tại á thì chúng ta đôi khi chúng ta sẽ bỏ sót bỏ qua. Tức là vì cái yếu tố về tính cấp thiết cho cái việc triển khai một cái tính năng máy học để có thể đưa ra được sớm đến với người dùng thì đôi khi là cái người phát triển, cái đội ngũ phát triển họ đã phải hy sinh để giảm bớt một số cái công đoạn. Những cái công việc hy sinh đó nó sẽ khiến cho chúng ta tiềm ẩn, nó sẽ tiềm ẩn những cái rủi ro khi chúng ta triển khai cái mô hình về sau.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 1,
      "start_timestamp": "0:00:35",
      "end_timestamp": "0:01:17"
    }
  },
  {
    "page_content": "ro khi chúng ta triển khai cái mô hình về sau. Nó có thể phát sinh ra những cái bug, nó sẽ có phát sinh ra những cái vấn đề khác. Thế thì trong nguyên một cái pipeline của cái việc mà chúng ta triển khai một cái mô hình máy học thì chúng ta thấy nè là cái machine learning code á là cái phần màu đen ở đây nó chiếm một cái tỷ trọng rất là bé. Nó chiếm một cái tỷ trọng rất là bé trong toàn bộ một cái hệ thống máy học. Nếu so cái lượng code của mô hình máy học với những cái phần như là cấu hình cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 2,
      "start_timestamp": "0:01:11",
      "end_timestamp": "0:01:56"
    }
  },
  {
    "page_content": "máy học với những cái phần như là cấu hình cái hệ thống nè, như là thu thập dữ liệu nè, như là gọi là kiểm tra cái tính xác thực của dữ liệu nè, rồi trích xuất đặc trưng nè, rồi các cái công cụ như là quản lý tài nguyên nè, rồi quản lý hạ tầng nè vân vân, rồi giám sát mô hình. Thì cái phần này cái tỷ trọng của cái phần code machine learning của chúng ta rất là bé. Và chúng ta thấy rằng là thậm chí các cái framework của chúng ta đã hỗ trợ cho chúng ta rất là nhiều nên cái việc code các cái mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 3,
      "start_timestamp": "0:01:50",
      "end_timestamp": "0:02:28"
    }
  },
  {
    "page_content": "ta rất là nhiều nên cái việc code các cái mô hình máy học gần đây nó đã tiết giảm rất là nhiều cái số dòng code. Đúng! Chúng ta chỉ cần gọi một số cái hàm, một số cái phương thức thôi. Như vậy thì nói như vậy để thấy rằng điều gì? Là cái khối lượng của cái mô hình máy học của mình á nó rất là ít và để mà mô hình của mình nó có thể triển khai được thành ứng dụng nó sẽ phải phụ thuộc vào rất nhiều những cái yếu tố khác. Và chính vì phụ thuộc rất nhiều vào những yếu tố khác nó sẽ gây ra cái vấn đề",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 4,
      "start_timestamp": "0:02:25",
      "end_timestamp": "0:02:59"
    }
  },
  {
    "page_content": "vào những yếu tố khác nó sẽ gây ra cái vấn đề về technical debt đó. Ví dụ như cái vấn đề xác thực của dữ liệu, liệu dữ liệu của mình nó đã sạch chưa? Nó đã phản ánh đúng được cái môi trường trong thực tế hay chưa? Đôi khi chúng ta thu thập dữ liệu nhưng mà chúng ta thu thập gọi là vừa đủ hoặc là chúng ta thu thập để đủ mô hình có thể chạy được ngay thì chúng ta đã bỏ qua cái yếu tố là cái phân bố của dữ liệu của mình nó phải sát với thực tế thì chúng ta bỏ qua mất cái chuyện đó. Thì đó là một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 5,
      "start_timestamp": "0:02:53",
      "end_timestamp": "0:03:29"
    }
  },
  {
    "page_content": "chúng ta bỏ qua mất cái chuyện đó. Thì đó là một cái technical debt rồi. Chúng ta huấn luyện cái mô hình code cho nó để có thể chạy được với cái hiệu năng cao đúng không? Với cái độ chính xác rất là cao nhưng mà chúng ta lại bỏ qua cái yếu tố về mặt resource tức là yếu tố về mặt tài nguyên thì dẫn đến là cái mô hình của mình sau này khi triển khai với những cái trang thiết bị phần cứng yếu hoặc là không đủ thì dẫn đến là nó không có thể thực thi được, không thể đáp ứng được khi đưa cái ứng dụng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 6,
      "start_timestamp": "0:03:24",
      "end_timestamp": "0:04:06"
    }
  },
  {
    "page_content": "được, không thể đáp ứng được khi đưa cái ứng dụng của mình vào bên trong thực tế. Thì đó là một số cái technical debt rất là phổ biến. Và không những vậy thì khi chúng ta triển khai cái mô hình máy học vào bên trong thực tế đó thì nó sẽ còn rất rất nhiều những cái công nghệ khác có liên quan chứ không phải là chỉ có các cái thư viện máy học mà chúng ta đã học trong phạm vi của môn học này. Ví dụ như trong phạm vi môn học này thì chúng ta sử dụng nhiều nhất đó chính là ờ các cái công cụ như là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 7,
      "start_timestamp": "0:04:02",
      "end_timestamp": "0:04:40"
    }
  },
  {
    "page_content": "nhiều nhất đó chính là ờ các cái công cụ như là Scikit-learn nè, rồi PyTorch và TensorFlow ví dụ vậy. Nhưng mà chúng ta sẽ còn rất nhiều những cái công nghệ khác mà giúp cho cái việc là triển khai mô hình trong thực tế nó được thực hiện một cách trơn tru hơn. Lấy ví dụ như đối với cái nền tảng dữ liệu lớn thì có rất nhiều những cái công nghệ ở đây nhưng mà có thể nói hai cái công nghệ mà nổi tiếng nhất mà mình được từng được trải nghiệm qua đó chính là Hadoop và Spark. Thì Hadoop và Spark đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 8,
      "start_timestamp": "0:04:34",
      "end_timestamp": "0:05:18"
    }
  },
  {
    "page_content": "là Hadoop và Spark. Thì Hadoop và Spark đó là các cái công nghệ mà liên quan đến dữ liệu lớn nó sẽ giúp cho chúng ta quản lý dữ liệu tốt hơn, rồi phân tán dữ liệu, rồi xử lý song song và làm sao để quản lý các cái tác vụ khi mà chúng ta có một cái lượng lớn dữ liệu. Ví dụ như nếu như cái chương trình của chúng ta chỉ thực thi cho một người dùng thì rất là dễ. Nhưng mà sau này khi cái ứng dụng của chúng ta triển khai lên trên các cái mạng xã hội số lượng người dùng có thể lên đến hàng trăm ngàn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 9,
      "start_timestamp": "0:05:13",
      "end_timestamp": "0:05:48"
    }
  },
  {
    "page_content": "số lượng người dùng có thể lên đến hàng trăm ngàn người, thậm chí là hàng triệu người, thậm chí là đối với các cái mạng xã hội như là Facebook thì có thể lên đến hàng tỷ người thì lúc đó là đòi hỏi cần phải có những cái công nghệ để có thể mà quản lý được cái nền tảng dữ liệu lớn đó. Và các cái nền tảng dữ liệu lớn này nó sẽ tương tác với các cái mô hình của mình như thế nào để sao cho nó hiệu quả nhất tránh cái việc đó là cái hệ thống của mình bị tắt nghẽn, bị chết. Đó. Và nó ngoài cái nền",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 10,
      "start_timestamp": "0:05:42",
      "end_timestamp": "0:06:22"
    }
  },
  {
    "page_content": "bị tắt nghẽn, bị chết. Đó. Và nó ngoài cái nền tảng dữ liệu lớn thì chúng ta còn có cái hạ tầng để đóng gói đó. Ví dụ như ở đây là có Kubernetes và Docker là hai cái hạ tầng rất là nổi tiếng. Docker thì giúp cho chúng ta đóng gói toàn bộ cái mô hình của mình, các cái thư viện của mình, các cái phần cấu hình thư viện để mà liên kết với các phần cứng vân vân vào bên trong cái Docker để sau này chúng ta dùng các cái Docker này kết hợp với cái công cụ Kubernetes để mà triển khai hàng loạt trên các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 11,
      "start_timestamp": "0:06:16",
      "end_timestamp": "0:06:53"
    }
  },
  {
    "page_content": "cụ Kubernetes để mà triển khai hàng loạt trên các cái hệ thống máy chủ khác nhau. Ví dụ như sau này khi cái lượng người dùng của mình lớn lên thì nó sẽ tự động nhân rộng nó sẽ tạo ra các cái cluster mới và chúng ta sẽ triển khai các cái mô hình của mình đến các cái cluster đó một cách nhanh chóng. Và khi đến cái thời điểm thấp điểm khi mà cái số lượng người dùng của mình nó ít đi thì chúng ta có thể thu hẹp các cái cluster đó lại. Thì đó là cái tác dụng của các cái hạ tầng đóng gói này nó giúp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 12,
      "start_timestamp": "0:06:49",
      "end_timestamp": "0:07:28"
    }
  },
  {
    "page_content": "tác dụng của các cái hạ tầng đóng gói này nó giúp cho chúng ta triển khai mô hình, nhân rộng cái mô hình nhanh hơn hoặc là thu hẹp cái mô hình của mình nhanh hơn. Rồi nó có các cái nền tảng kết hợp thì ở đây có một cái nền tảng cũng rất là nổi tiếng đó là Airflow. Tức là nền tảng này là tích hợp đóng gói, tích hợp tất cả những cái bước trong cái quy trình từ cái khâu mà xây dựng dữ liệu, quản lý dữ liệu, cho đến vận hành mô hình máy học cho đến giám sát mô hình vân vân thì nó sẽ tích hợp lại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 13,
      "start_timestamp": "0:07:24",
      "end_timestamp": "0:07:41"
    }
  },
  {
    "page_content": "giám sát mô hình vân vân thì nó sẽ tích hợp lại thành một cái flow quy trình đó. Thì trên đây là một vài cái công nghệ thôi có liên quan đến cái việc triển khai mô hình và bên cạnh cái phần chính mà chúng ta đã học trong các cái tuần trước là Scikit-learn, PyTorch và TensorFlow thì chúng ta sẽ còn có các cái công nghệ này cần phải tìm hiểu.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=kylIGUKrEsA",
      "filename": "kylIGUKrEsA",
      "title": "[CS116 - Buổi 14] Part 1_2",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng tìm hiểu về các cái thành phần của một cái machine learning pipeline đầu tiên đó chính là Raw data Raw data hay còn gọi là dữ liệu thô dữ liệu ban đầu của cái mô hình của mình thì Raw data đó là cái gì đó là tổng hợp cái dữ liệu mà chúng ta tổng hợp từ nhiều nguồn khác nhau ví dụ như là trong log của các cái hệ thống hoặc là trong các cái hệ quản trị cơ sở dữ liệu của các cái hệ thống mà đang được triển khai ứng dụng nào đó mà chúng ta đang muốn xây dựng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:40"
    }
  },
  {
    "page_content": "ứng dụng nào đó mà chúng ta đang muốn xây dựng để chuẩn bị sắp tới là chúng ta tích hợp các cái tính năng về ai các cái tính năng về máy học trong cái việc là dự đoán xu hướng của người dùng chẳng hạn rồi Nó có thể là những cái dữ liệu mà đã được survey của khách hàng cách gọi là trực tiếp hoặc là gián tiếp thì đây chính là những cái nguồn dữ liệu mà giúp cho chúng ta có thể tổng hợp những cái dữ liệu thành các cái liệu thô để đưa vào cho máy có thể huấn luyện được và ngoài ra thì chúng ta cũng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:34",
      "end_timestamp": "0:01:10"
    }
  },
  {
    "page_content": "thể huấn luyện được và ngoài ra thì chúng ta cũng có thể có rất nhiều những cái dữ liệu khác nhau Ví dụ như dữ liệu này là đến từ nguồn internet chúng ta có thể cw ở chúng ta có thể cw dữ liệu từ trên các cái trang mạng xã hội để lấy các cái dữ liệu đó về tổng hợp thành một cái kho dữ liệu thô ở đây và dữ liệu này thì hoàn toàn có thể là chưa được kiểm tra hoặc là tiền xử lý nghĩa là cái dữ liệu này đâu đ đó chúng ta vẫn có khả năng là có chứa những cái dữ liệu nhiễu ở trong đó hoặc là cái dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:06",
      "end_timestamp": "0:01:45"
    }
  },
  {
    "page_content": "những cái dữ liệu nhiễu ở trong đó hoặc là cái dữ liệu này đâu đó là nó ở cái dạng thức mà mô hình máy học nó chưa có khả năng thực hiện tính toán được và dữ liệu này thì nó cũng có khả năng đó là không đầy đủ và có chứa nhiễu bên trong cũng như là chứa những cái thông tin nhạy cảm thế thì tại sao chúng ta cần phải quan tâm đến những vấn đề này Tại vì khi chúng ta xây dựng các cái mô hình máy học thì nó rất dễ bị ảnh hưởng bởi cái yếu tố không đầy đủ và cái yếu tố về nhiễu nếu như dữ liệu của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:01:39",
      "end_timestamp": "0:02:17"
    }
  },
  {
    "page_content": "đầy đủ và cái yếu tố về nhiễu nếu như dữ liệu của mình có chứa quá nhiều những cái giá trị đn gây nhiễu Tức là những cái giá trị nó không đúng thì dẫn đến là cái máy học của mình nó sẽ dự đoán sai và nó sẽ có độ chính xác không cao còn chứa thông tin nhạy cảm tức là nếu như cái mô hình của mình nó bằng cách nào đó nó vẫn nhớ được những cái thông tin ở bên trong cái dữ liệu thô này thì khi chúng ta triển khai ra dụng có khả năng nó sẽ gây ra hiện tượng là LCK dữ liệu rò rỉ dữ liệu thì nếu như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:11",
      "end_timestamp": "0:02:48"
    }
  },
  {
    "page_content": "tượng là LCK dữ liệu rò rỉ dữ liệu thì nếu như chứa những cái thông tin nhạy cảm này thì cái mô hình của mình nó cũng khó mà có thể triển khai trong thực tế chưa kể đó là nếu chứa những cái thông tin nhạy cảm thì cái đội ngũ phát triển họ cũng có thể tiếp cận được những cái nguồn thông tin này thì họ có thể thấy được các cái thông tin nhạy cảm liên quan đến yếu tố về cá nhân nào đó của cái hệ thống của mình và bước thứ hai trong cái cái machine learning pipeline đó chính là data validation thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:02:44",
      "end_timestamp": "0:03:23"
    }
  },
  {
    "page_content": "learning pipeline đó chính là data validation thì Data validation là một cái bước thực hiện rất là quan trọng nó rất là quan trọng trong cái quy trình xây dựng mô hình máy học nó đảm bảo được là cái dữ liệu đầu vào của mình nó phù hợp nó phù hợp với cái bài toán mà mình đang ốn tới và nó đảm bảo được cái chất lượng thì cái bước kiểm định dữ liệu này nè Giống như là một cái bước sàn lọc đầu tiên để kiểm tra xem là data này có đủ tiêu chuẩn để có thể đưa vào cho cái mô hình máy học có thể huấn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:03:18",
      "end_timestamp": "0:03:53"
    }
  },
  {
    "page_content": "thể đưa vào cho cái mô hình máy học có thể huấn luyện được hay không và cái bước data validation này á thì nó sẽ thực hiện các cái công việc ví dụ như là kiểm tra cái tính nhất quán của dữ liệu tránh cái việc đó là cũng là nói về một cái đối tượng nhưng mà ở cái dòng dữ liệu trước thì nó nó lại có thể hiện là các cái đặc trưng khác nhưng mà sang cái dòng dữ liệu sau cũng là nói về cái đối tượng đó nhưng nó lại có một cái tên khác ví dụ như tên của một công ty lúc thì nó ở dạng là viết tắt lúc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:03:49",
      "end_timestamp": "0:04:26"
    }
  },
  {
    "page_content": "của một công ty lúc thì nó ở dạng là viết tắt lúc thì nó nó là ở dạng viết à đầy đủ Lúc thì nó ở dạng viết hoa đó thì đó là cái tính nhất quán của dữ liệu cái tính đầy đủ của dữ liệu đó là trong toàn bộ các cái đặc trưng của dữ liệu thì liệu nó có bị thiếu thông tin nào hay không nó thiếu này thì là thiếu do có chủ đích hay là thiếu do sự vô tình rồi dữ liệu của mình nó có bị ngoại lệ hay không Tức là sẽ có những cái tình huống dữ liệu của mình à có đầy đủ đó nhưng mà cái giá trị của mình nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:04:21",
      "end_timestamp": "0:04:58"
    }
  },
  {
    "page_content": "à có đầy đủ đó nhưng mà cái giá trị của mình nó không có hợp lý hoặc là cái giá trị của mình nó nằm ngoài cái khoảng giá trị mà phổ biến thì nó sẽ gây ra cái hiện tượng gọi là nhiễu nhiễu cho cái mô hình của mình khi mà huấn luyện rồi và cái bước data validation này thì thường được thực hiện với cái bước là edi tức là phân tích dữ liệu thì đây có thể nói là một trong những cái bước tiền đề đầu tiên khi chúng ta làm với bất cứ bất cứ một cái mô hình máy học nào một cái bước tiếp theo đó chính là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:04:54",
      "end_timestamp": "0:05:31"
    }
  },
  {
    "page_content": "máy học nào một cái bước tiếp theo đó chính là tiền xử lý dữ liệu data reprocessing thì trong cái bước tiền xử lý dữ liệu chúng ta sẽ phải thực hiện các cái công việc sau đó là chúng ta dựa trên những cái phân tích và kiểm định dữ liệu ở cái bước trước đó chúng ta sẽ tiến hành làm sạch dữ liệu và chuẩn hóa dữ liệu của mình rồi chúng ta sẽ phải xử lý những cái dữ liệu bị thiếu à chúng ta sẽ phải xử lý những cái dữ liệu ngoại lệ dữ liệu đ thiếu nghĩa là những dữ liệu mà trong cái dòng đặc trưng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:05:26",
      "end_timestamp": "0:06:07"
    }
  },
  {
    "page_content": "là những dữ liệu mà trong cái dòng đặc trưng của mình nó sẽ có những cái giá trị Ví dụ như là nan Tức là không xác định thì làm sao chúng ta phải điền được cho các cái giá trị đầy đủ này một cách gọi là khoa học và hợp lý nhất rồi xử lý dữ liệu ngoài lệ đó là trong trường hợp à Có cái số liệu ở đây ví dụ như đây là một cái số là thể hiện là cái độ tuổi của một người nào đó thì ví dụ như tuổi ở đây chúng ta để là 100 thì liệu là các cái trường thông tin trước đó nó có đảm bảo được là cái tuổi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:06:02",
      "end_timestamp": "0:06:38"
    }
  },
  {
    "page_content": "thông tin trước đó nó có đảm bảo được là cái tuổi của mình ở đây là 100 là một cái con số nhiễu hay không hay thực sự người đó là ịch đó đó 100 tuổi Tại vì đây là một cái giá trị mà nó nằm trong cái khoảng rất là đặc biệt của độ tuổi của mình đúng không ở Do đó thì chúng ta phải kiểm tra xem là cái dữ liệu này nó có thực sự là nhiễu hay không Và khi mà nó không phải là nhiễu thì chúng ta sẽ để nguyên Nhưng mà nếu nó là nhiễu thì chúng ta sẽ tìm cách xác định xem cái giá trị thực của nó đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:06:33",
      "end_timestamp": "0:07:14"
    }
  },
  {
    "page_content": "cách xác định xem cái giá trị thực của nó đó là giá trị gì hoặc là chúng ta làm giảm cái vai trò của cái dòng dữ liệu này đi thông qua một số cái phương pháp chuẩn hóa rồi tạo mới đặc trưng feature instruction và transformation cái bước tạo mới đặc trưng này thì nó có thể là tạo ra thêm những cái cái cột dữ liệu thêm cái cái đặc trưng từ những cái đặc trưng trước đó rồi chúng ta có thể biến đổi cái dữ liệu của mình sang một cái dạng thích mà cái mô hình máy học nó có thể xử lý dễ dàng hoặc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 13,
      "start_timestamp": "0:07:09",
      "end_timestamp": "0:07:46"
    }
  },
  {
    "page_content": "mô hình máy học nó có thể xử lý dễ dàng hoặc là nó huấn luyện hiệu quả nhanh hơn chọn lựa đặc trưng thì nếu như trong cái bảng dữ liệu của mình nó có quá nhiều nó có quá nhiều đặc trưng Ví dụ như đây là đặc trưng X và đây là cái đặc trưng y thì X của mình nó bao gồm nhiều cột và không phải tất cả các cột trong đây nó đều đóng góp cho cái việc mà đưa ra cái dự đoán output cuối cùng đó không phải là cái cột thông tin nào nó cũng có cái vai trò hoặc là có cái tầm quan trọng thì chúng ta phải làm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 14,
      "start_timestamp": "0:07:42",
      "end_timestamp": "0:08:25"
    }
  },
  {
    "page_content": "là có cái tầm quan trọng thì chúng ta phải làm sao xác định được Cột nào là cái cột quan trọng nhất chúng ta sẽ đưa vào cho mô hình máy học Hóa học Cột nào mà không liên quan hoặc là ít quan trọng thì chúng ta có thể loại bỏ đi để tránh gây nhễu cho cái mô hình về sau trong cái bước Model Training thì nó sẽ bao gồm cái bước là chúng ta xây dựng cái mô hình và huấn luyện cái mô hình từ cái dữ liệu mà đã tiền xử lý trước đó thì đầu tiên đó là chúng ta sẽ phải khởi tạo mô hình với các cái tham số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 15,
      "start_timestamp": "0:08:19",
      "end_timestamp": "0:09:01"
    }
  },
  {
    "page_content": "ta sẽ phải khởi tạo mô hình với các cái tham số đầu tiên và có một số mô hình thì nó không có tham số do đó ở đây chúng ta sẽ để là nếu có ví dụ như một số mô hình như là kis neighbor thì nó không có cái tham số nhưng mà nó có siêu tham số là k hoặc là đối với cái mô hình như là n bys thì nó sẽ không có nó sẽ không có tham số thì khi đó mô hình của chúng ta chỉ đơn thuần đó là ờ thiết kế xây dựng và tạo ra một cái cơ sở dữ liệu hoặc là tạo ra một cái cấu trúc bản dữ liệu để chuẩn bị đưa vô cho",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 16,
      "start_timestamp": "0:08:54",
      "end_timestamp": "0:09:30"
    }
  },
  {
    "page_content": "cái cấu trúc bản dữ liệu để chuẩn bị đưa vô cho mô hình nó huấn luyện huấn luyện mô hình với cái dữ liệu hoặc là cái đặc trưng đã chuẩn bị trước đó tức là chúng ta sẽ truyền các cái dữ liệu đã được chuẩn hóa đã được tiền xử lý đã được lựa chọn đặc trưng vào bên trong cái mô hình để mô mình có thể tìm ra được những cái tham số phù hợp và Bước tiếp theo thì chúng ta sẽ đánh giá cái mô hình thì đây có thể nói là một trong những bước rất là quan trọng Tại vì nếu như chúng ta không đánh giá được cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 17,
      "start_timestamp": "0:09:24",
      "end_timestamp": "0:10:03"
    }
  },
  {
    "page_content": "Tại vì nếu như chúng ta không đánh giá được cái mô hình thì chúng ta sẽ không thể biết trước à không thể biết được là cái mô hình này nó có đủ hiệu quả để có thể triển khai ra thực tế hay không và cái model Evaluation này á thì chúng ta phải dựa vào những cái độ đo may tính chất định lượng chúng ta không thể nào mà dựa vào cái cảm quan là à Chúng ta thử với một vài mẫu và cảm giác là mô hình nó chạy tốt chúng ta phải có một cái độ đo đánh giá trên một cái quy trình khách quan và hoàn thiện thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 18,
      "start_timestamp": "0:09:57",
      "end_timestamp": "0:10:38"
    }
  },
  {
    "page_content": "một cái quy trình khách quan và hoàn thiện thì ở đây chúng ta sẽ phải sử dụng những cái bộ dữ liệu khách quan thế nào là một cái bộ dữ liệu khách quan bộ dữ liệu khách quan phải là bộ dữ liệu mà chưa được thấy trước đó kh Nếu mà chúng ta đánh giá trên chính cái bộ dữ liệu mà mình huấn luyện thì khi đó cái độ chính xác của mình nó cũng chỉ mang tính chất tương đối không có thể hiện được cái tính hiệu quả của mô hình của mình chúng ta sẽ phải dùng những cái độ đo hoặc là metric rất là cụ thể thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 19,
      "start_timestamp": "0:10:33",
      "end_timestamp": "0:11:15"
    }
  },
  {
    "page_content": "những cái độ đo hoặc là metric rất là cụ thể thì cái độ đo ở đây thì hàm ý đó là phải là độ đo định lượng tức là nó phải ra các cái con số và nếu như cái kết quả tốt thì chúng ta sẽ qua cái Bước tiếp theo là cái bước kiểm định mô hình đây là cái bước mà quan trọng để mà chuẩn bị triển khai cho thực tế còn nếu như cái mô hình này của mình nó chưa tốt thì khi đó chúng ta sẽ quay ngược trở lại và khi quay ngược trở lại thì cũng tùy vào tình huống chúng ta có thể quay ngược đến cái bước đầu tiên đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 20,
      "start_timestamp": "0:11:09",
      "end_timestamp": "0:11:43"
    }
  },
  {
    "page_content": "ta có thể quay ngược đến cái bước đầu tiên đó là cái bước tiền xử lý dữ liệu bao gồm là các cái bước như là chọn lựa đặc trưng tạo thêm đặc trưng hoặc là chuyển đổi đặc trưng hoặc chúng ta chỉ chuyển quay ngược trở lại đến cái mô hình Training tức là chúng ta tạo ra một cái mô hình khác hoặc là chúng ta huấn luyện lại cái mô hình với cái bộ siêu tham số khác Chẳng hạn và cuối cùng đó là nếu như cái mô hình không tốt thì ở đây chúng ta đã nói rồi Ha tức là nếu không có đạt được cái mức cái chuẩn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 21,
      "start_timestamp": "0:11:39",
      "end_timestamp": "0:12:16"
    }
  },
  {
    "page_content": "Ha tức là nếu không có đạt được cái mức cái chuẩn thì chúng ta sẽ phải quay lại các cái bước trước và đến cái bước tiếp theo đó chính là Model validation kiểm định mô hình thì đây là cái bước tiến hành kiểm định mô hình mang tính chất hệ thống Tức là không phải chúng ta chỉ đánh giá ở cái góc độ là độ chính xác mà chúng ta phải kiểm tra xem mô hình của mình có đủ để có thể triển khai ra đến cái người dùng cuối hay không à thì nó sẽ bao gồm rất nhiều những cái yếu tố khác chứ không phải là yếu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 22,
      "start_timestamp": "0:12:13",
      "end_timestamp": "0:13:02"
    }
  },
  {
    "page_content": "nhiều những cái yếu tố khác chứ không phải là yếu tố về mặt Đội chính xác đó thì đây là một cái quá trình thường được thực hiện một cách độc lập với cái đội ngũ phát triển Tức là ở hàng trên là chúng ta sẽ có một cái đội ngũ data Engineer kết hợp với lại machine learning Engineer hoặc là ai Engineer để thực hiện Nhưng mà sang cái hàng thứ hai thì do đó sẽ là những cái đội ngũ khác độc lập thực hiện một cách độc lập thì cái model validation này thì có thể thực kiểm định các cái vấn đề ngoài cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 23,
      "start_timestamp": "0:12:57",
      "end_timestamp": "0:13:35"
    }
  },
  {
    "page_content": "có thể thực kiểm định các cái vấn đề ngoài cái vấn đề về độ độ chính xác tức là độ chính xác nó vẫn sẽ thực hiện lại thực được thực hiện một cách khách quan bởi một cái đội ngũ mới thì chúng ta có thể thực hiện các cái vấn đề như là về tốc độ liệu là cái mô hình này có đảm bảo được là triển khai trong thời gian thực hay không rồi chúng ta sẽ kiểm định xem cái m đồ này nó có rò rỉ dữ liệu hay không Tức là đâu đó nó sẽ làm gây ra cái việc là làm lộ những cái dữ liệu thô ban đầu hay không rồi mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 24,
      "start_timestamp": "0:13:31",
      "end_timestamp": "0:14:19"
    }
  },
  {
    "page_content": "lộ những cái dữ liệu thô ban đầu hay không rồi mô hình này có đủ để mà có thể lưu trữ được bên trên các cái hệ thống mà cái cái hệ thống mà đang có hay không Ví dụ như mô hình này Gi sử như là một cái mô hình học sâu đi giả sử Vậy thì nó phải tốn rất nhiều cái bộ nhớ và đòi hỏi rất nhiều cái tài nguyên tính toán thì liệu là có thể đáp ứng được với cái hạ tầng hệ thống hiện tại hay không đó thì đó là những cái vấn đề mà chúng ta phải triển khai phải kiểm kiểm định trước khi mà triển khai chính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 25,
      "start_timestamp": "0:14:12",
      "end_timestamp": "0:14:56"
    }
  },
  {
    "page_content": "phải kiểm kiểm định trước khi mà triển khai chính thức rồi à có chính xác trên cái dữ liệu chưa từng thấy hay không thì đây sẽ là có một cái độ ngũ khác họ đánh giá lại một lần nữa về độ chính xác tốc độ thực thi có R R R dữ liệu hay không vân vân và sang cái bước tiếp theo đó chính là Model deployment Thì cái này nó thường liên quan đến một cái nhân sự trong cái hệ thống của mình đó gọi là ml up thì cái người kỹ sư ml up nó sẽ triển khai cái mô hình của mình trên cái môi trường thực tế như là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 26,
      "start_timestamp": "0:14:51",
      "end_timestamp": "0:15:29"
    }
  },
  {
    "page_content": "hình của mình trên cái môi trường thực tế như là đóng gói mô hình chuyển giao mô hình thì đây là một cái bước mà gần nhất để mà có thể đưa cái mô hình của mình đến với cái người sử dụng cuối cuối cùng đó chính là Model feedback Model feedback tức là chúng ta sẽ theo dõi cái phản hồi về mô hình và ở đây chúng ta có hai cách để theo dõi cái phản hồi này một đó là cái phản hồi mang tính chất chủ quan chúng ta sẽ đưa ra những cái đánh giá à xếp hạng cho người dùng và người dùng họ sẽ chủ động họ sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 27,
      "start_timestamp": "0:15:24",
      "end_timestamp": "0:15:35"
    }
  },
  {
    "page_content": "cho người dùng và người dùng họ sẽ chủ động họ sẽ chủ động đưa ra những cái nhận xét đưa ra những cái rating đánh giá xem là à cái tính năng mới này là một sao hai sao hay là nă sao rồi đưa ra những cái comment những cái nhận xét Ờ mang tính chúc chủ quan của từng người dùng để xem coi là cái tính năng mới này có đáp ứng được những cái nhu cầu của hỏi không phản hồi khách quan tức là chúng ta sẽ dựa Vào các cái chỉ báo trung gian Tức là ở đây chúng ta sẽ không có để người dùng đánh giá một cách",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ta sẽ không có để người dùng đánh giá một cách trực tiếp mà chúng ta sẽ theo dõi cái hành vi của người dùng có thay đổi hay không Ví dụ để mà thực hiện được một cái chức năng nào đó thì trước đây họ tốn hết ba giây Nhưng nhờ cái tính năng mới này thì nó đã giúp cho họ giảm xuống thực hiện chỉ còn trong vòng là 1 giây thôi đó thì chúng ta có một số cái công cụ để theo dõi cái phần mềm đo lường xem là họ thực hiện một cái tính năng nào đó có tiện hơn hay không có nhanh hơn hay không thì đó chính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "hơn hay không có nhanh hơn hay không thì đó chính là cái phản hồi Khách quen",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lG95Eg3Hv7c",
      "filename": "lG95Eg3Hv7c",
      "title": "[CS116 - Buổi 3] Part 2",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Hôm nay chúng ta sẽ đến với bài học thứ tư đó là tiền xử lý dữ liệu thì về vị trí của bài học này đó là nó nằm ở cái bước gọi là data preprocessing. Đây là một cái bước mà trước khi chúng ta tiến hành huấn luyện cái mô hình. Đây có thể nói là một trong những cái bước cực kỳ quan trọng, tại vì chúng ta có cái câu đó là Garbage in, garbage out. Tức là tất cả các cái mô hình máy học của mình nếu như chúng ta đưa những cái dữ liệu rác vào bên trong cái mô hình thì cho dù cái mô hình của mình có tốt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:48"
    }
  },
  {
    "page_content": "mô hình thì cho dù cái mô hình của mình có tốt như thế nào đi chăng nữa thì cái hiệu suất của nó cũng sẽ bị giảm nếu như cái dữ liệu của mình đưa vào không được tiền xử lý cẩn thận. Và cái nội dung chính của chúng ta sẽ bao gồm năm phần sau đây. Ở hai phần đầu tiên thì nó liên quan đến cái việc là chúng ta làm sạch dữ liệu trên cái dữ liệu thô đầu vào của mình sau khi đã thực hiện xong cái bước là data validation. Thì chúng ta sẽ phải phát hiện và xử lý những cái dữ liệu mà bị thiếu. Rồi chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:44",
      "end_timestamp": "0:01:21"
    }
  },
  {
    "page_content": "và xử lý những cái dữ liệu mà bị thiếu. Rồi chúng ta sẽ phát hiện và xử lý những cái trường hợp dữ liệu bị ngoại lệ. Dữ liệu ngoại lệ thì nó sẽ khác với lại dữ liệu bị thiếu ở chỗ đó là các cái giá trị của mình nó vẫn được điền đầy đủ. Tuy nhiên, nếu xét trong cái phân bố của cái dữ liệu của mình thì các cái giá trị này nó có những cái đặc điểm là nó nằm bên ngoài cái phạm vi tập trung, tập trung dày đặc của dữ liệu. Tức là nó nằm ngoài cái phạm vi của dữ liệu của mình rất là nhiều. Đó thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:16",
      "end_timestamp": "0:01:52"
    }
  },
  {
    "page_content": "phạm vi của dữ liệu của mình rất là nhiều. Đó thì chúng ta sẽ tìm cách phát hiện và xử lý cho những cái loại giá trị như vậy. Và ba bước cuối thì nó liên quan đến một cái từ khóa đó là đặc trưng: tạo đặc trưng, biến đổi đặc trưng và lựa chọn đặc trưng. Thì ở đây cái khái niệm đặc trưng nó cũng chính là dữ liệu của mình, tuy nhiên nó ở cái cấp độ cao hơn và nó là những cái mà chúng ta chuẩn bị để đưa vào cho mô hình máy học. Thì ba cái bước cuối cùng chính là ba bước chúng ta thao tác trên đặc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:01:46",
      "end_timestamp": "0:02:31"
    }
  },
  {
    "page_content": "cùng chính là ba bước chúng ta thao tác trên đặc trưng để chuẩn bị đưa vào cho một cái mô hình máy học. Đầu tiên thì chúng ta sẽ đến với phần xác định và xử lý những cái dữ liệu bị thiếu. Nhắc lại đó là để phát hiện những cái dữ liệu bị thiếu ở trong phần EDA, tức là cái phần mà phân tích dữ liệu, thì chúng ta biết rằng là trong pandas, trong cái thư viện pandas thì nó đã có cung cấp các cái hàm để giúp cho mình phát hiện cái dữ liệu bị thiếu đó là hàm isnull hoặc là hàm isna. Thì chúng ta có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:25",
      "end_timestamp": "0:03:04"
    }
  },
  {
    "page_content": "là hàm isnull hoặc là hàm isna. Thì chúng ta có thể sử dụng cả hai hàm này để kiểm tra xem bảng hoặc là cột hoặc là cái dòng dữ liệu của mình có bị thiếu dữ liệu hay không. Và ở bên trái đó là chúng ta sẽ có một cái mẫu dữ liệu ha. Thì ở đây chúng ta sẽ thấy là các cái dữ liệu NaN nó nằm ở đây và khi chúng ta kiểm tra thì nó sẽ ra là hai cái giá trị true ở đây, tức là chúng ta sẽ có những cái vị trí mà giá trị của mình nó bằng NaN, tức là không phải là một cái giá trị xác định. Thì sau khi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:02:59",
      "end_timestamp": "0:03:42"
    }
  },
  {
    "page_content": "phải là một cái giá trị xác định. Thì sau khi chúng ta đã phát hiện xong thì chúng ta sẽ tiến hành xử lý các cái dữ liệu bị thiếu này. Thì chúng ta sẽ có ba cái cách tiếp cận chính. Cách tiếp cận đầu tiên đó chính là chúng ta sẽ loại bỏ. Đây là cách tiếp cận đơn giản nhất, dễ thực hiện nhất. Cứ khi chỗ nào ở trên hàng hoặc là trên cột mà chúng ta thấy là có một cái tỉ lệ dữ liệu bị thiếu mà đủ lớn, ví dụ như là trên 50% dữ liệu của một cột hoặc là trên 50% dữ liệu của một hàng mà có cái giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:03:36",
      "end_timestamp": "0:04:23"
    }
  },
  {
    "page_content": "trên 50% dữ liệu của một hàng mà có cái giá trị là NaN thì chúng ta sẽ loại bỏ nó đi. Thì để thực hiện cái việc loại bỏ này, chúng ta có thể sử dụng cái hàm là dropna hoặc là chúng ta có thể sử dụng cái hàm drop column nếu như chúng ta đặt ra những cái tiêu chí là bao nhiêu phần trăm dữ liệu trở lên mà bị gọi là bị rỗng, bị thiếu thì chúng ta mới loại bỏ đi. Đó và hướng tiếp cận thứ hai đó là hướng tiếp cận thay thế, có thể là thay thế đơn biến, đa biến hoặc là thay thế trên cái dữ liệu theo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:04:18",
      "end_timestamp": "0:04:56"
    }
  },
  {
    "page_content": "đa biến hoặc là thay thế trên cái dữ liệu theo chuỗi thời gian. Và trong thư viện scikit-learn thì chúng ta cũng sẽ có cái API để phục vụ cho cái việc thay thế này đó chính là scikit-learn imputation thì chúng ta có thể tham khảo trong cái đường link ở sau đây. Và cái phương pháp nâng cao hơn đó chính là chúng ta sẽ sử dụng chính những cái mô hình máy học để đưa ra cái dự đoán cái giá trị bị thiếu này. Thì sơ đồ dưới đây đó là chúng ta sẽ có những cái tiếp cận được chia ra thành các cái nhánh.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:04:49",
      "end_timestamp": "0:05:31"
    }
  },
  {
    "page_content": "cái tiếp cận được chia ra thành các cái nhánh. Đầu tiên đó là cái nhánh mà loại bỏ. Và đây thì chúng ta có các cái chiến thuật loại bỏ. Ví dụ như chúng ta sẽ loại bỏ những cái giá trị nào mà bị thiếu thôi, hoặc chúng ta loại bỏ theo hàng hoặc chúng ta sẽ loại bỏ theo cột. Đối với cái hướng tiếp cận thay thế thì chúng ta sẽ có hai hướng đó là cơ bản và nâng cao. Cơ bản thì chúng ta có thể thay thế, ví dụ như thay bằng một cái giá trị hằng số, hoặc là chúng ta có thể thay những cái giá trị mang",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:05:26",
      "end_timestamp": "0:06:04"
    }
  },
  {
    "page_content": "là chúng ta có thể thay những cái giá trị mang tính chất thống kê, ví dụ như là giá trị min, giá trị median, giá trị Mode hoặc là cái giá trị mà có cái số lần xuất hiện là nhiều nhất. Và còn một cái cách tiếp cận tự động nữa đối với dữ liệu mà dạng time series, tức là dữ liệu theo chuỗi thời gian, chúng ta có thể căn cứ dựa trên cái chuỗi thời gian để chúng ta có thể nội suy ra cái giá trị mà mình sẽ điền khuyết vào bên trong. Và ở hướng tiếp cận nâng cao thì đó chính là các cái hướng tiếp cận",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 10,
      "start_timestamp": "0:06:00",
      "end_timestamp": "0:06:38"
    }
  },
  {
    "page_content": "nâng cao thì đó chính là các cái hướng tiếp cận dựa trên mô hình máy học như là K-nearest neighbor hoặc là các cái mô hình máy học khác. Và ngoài ra thì chúng ta sẽ còn một cái hướng tiếp cận khác không được nói chi tiết ở đây đó là chúng ta sẽ tạo ra thêm một cái cột mới. Trong cái cột mới này thì chúng ta sẽ đánh dấu là những cái dòng dữ liệu nào thì bị thiếu và những cái dòng dữ liệu nào là không bị thiếu. Thì đây là những cái hướng tiếp cận chính cho cái việc xử lý dữ liệu bị thiếu của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 11,
      "start_timestamp": "0:06:30",
      "end_timestamp": "0:07:07"
    }
  },
  {
    "page_content": "cận chính cho cái việc xử lý dữ liệu bị thiếu của mình. Ờ trong cái bảng sau thì nó tiến hành đó là so sánh các cái phương pháp, cách thức thực hiện và đặc điểm của từng cái phương pháp. Phương pháp đầu tiên đó là chúng ta thay thế các cái đặc trưng đơn biến. Thì chúng ta có thể thay thế các cái giá trị mang tính chất thống kê như là giá trị trung bình, giá trị trung vị và giá trị Mode. Và cách thực hiện đó là cũng rất là đơn giản đó là thay các cái giá trị còn thiếu bằng những cái giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 12,
      "start_timestamp": "0:07:03",
      "end_timestamp": "0:07:44"
    }
  },
  {
    "page_content": "các cái giá trị còn thiếu bằng những cái giá trị trung bình, trung vị hoặc là những cái giá trị mà xuất hiện thường xuyên nhất của một cái biến nào đó, được thực hiện một cách độc lập. Tức là chúng ta sẽ xét trên một cái biến X_i. Ví dụ ở đây chúng ta có rất nhiều những cái đặc trưng là X1, X2, vân vân, cho đến Xn. Thì chúng ta xét một cái X_i nào đấy, tức là xét một cái cột nào đó và chúng ta sẽ tính cái giá trị trung bình cho những cái phần tử mà có giá trị. Hoặc là chúng ta sẽ tính cái giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 13,
      "start_timestamp": "0:07:38",
      "end_timestamp": "0:08:13"
    }
  },
  {
    "page_content": "mà có giá trị. Hoặc là chúng ta sẽ tính cái giá trị trung vị. Hoặc là chúng ta sẽ đếm những cái giá trị nào có tần suất xuất hiện nhiều nhất. Thì chúng ta sẽ lấy những cái giá trị đại diện đó điền vào những cái vị trí mà có bị rỗng, bị thiếu giá trị. Thì cái phương pháp này nó thứ nhất đó là nó đơn giản, dễ hiểu và dễ thực hiện. Tuy nhiên cái giá trị đại diện này thực sự mà nói nó cũng khó phản ánh đúng được cái giá trị bị thiếu. Rõ ràng là chúng ta không thể nào, à với một cái vị trí bị thiếu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 14,
      "start_timestamp": "0:08:09",
      "end_timestamp": "0:08:50"
    }
  },
  {
    "page_content": "ta không thể nào, à với một cái vị trí bị thiếu chúng ta có thể điền vào duy nhất một cái giá trị đại diện như vậy được. Thì cũng tương tự như vậy, cũng tương tự như cái phương pháp mà thay thế các cái đặc trưng đơn biến, thì chúng ta thay thế bằng một cái hằng số. Hằng số này có thể là một con số rất là lớn, ví dụ như là trừ 999 hoặc là con số à xin lỗi, những cái giá trị rất là nhỏ hoặc là giá trị rất là lớn, ví dụ như -999, +9999 hoặc là con số trung dung, ví dụ như là số 0. Hoặc là cái con",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 15,
      "start_timestamp": "0:08:45",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "số trung dung, ví dụ như là số 0. Hoặc là cái con số mà vừa đại diện cho một cái giá trị mà mang tính chất đại diện ngoại lệ. Ví dụ như các cái biến của mình ở bên trong cái cột dữ liệu X_i đó là những con số dương thì chúng ta có thể điền đó là một con số là -1 để hàm ý rằng là à cái giá trị này nó là một giá trị ngoại lệ nhưng mà nó vẫn có cái dạng là số học để chúng ta có thể xử lý tính toán được. Thì tương tự như cái phương pháp thay thế đặc trưng đơn biến thì cái phương pháp này nó đơn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 16,
      "start_timestamp": "0:09:19",
      "end_timestamp": "0:10:09"
    }
  },
  {
    "page_content": "đặc trưng đơn biến thì cái phương pháp này nó đơn giản và nó cũng khó phản ánh đúng được cái giá trị thực sự mà bị thiếu ở đó là gì. Và những cái tiếp cận sau thì có vẻ là nó sẽ logic hơn, nó có cái căn cứ tốt hơn để giúp cho chúng ta thay thế cái giá trị bị thiếu. Tiếp cận đầu tiên đó là chúng ta sử dụng phương pháp K-nearest neighbor. Ví dụ như à ở đây chúng ta có cái đặc trưng X_i là đặc trưng bị thiếu, thì chúng ta sẽ xây dựng một cái mô hình tìm kiếm k láng giềng gần nhất và nó sẽ dựa trên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 17,
      "start_timestamp": "0:10:03",
      "end_timestamp": "0:10:45"
    }
  },
  {
    "page_content": "tìm kiếm k láng giềng gần nhất và nó sẽ dựa trên các cái đặc trưng đó là X1, X2 cho đến X_i-1 và X_i+1 cho đến Xn, tức là loại bỏ đi cái X_i. Chúng ta sẽ dùng các cái đặc trưng còn lại như là cái đặc trưng của mô hình máy học và chúng ta sẽ xem xét xem là ứng với cái dòng dữ liệu đó thì nó sẽ có những cái giá trị thì chúng ta sẽ điền cái giá trị còn thiếu vào. Thì bản chất của cái phương pháp K-nearest neighbor ở đây đó là chúng ta sẽ thay thế các cái giá trị bị thiếu bằng cái giá trị trung",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 18,
      "start_timestamp": "0:10:39",
      "end_timestamp": "0:11:23"
    }
  },
  {
    "page_content": "các cái giá trị bị thiếu bằng cái giá trị trung bình hoặc là tổng trọng số của k láng giềng trong cái không gian đặc trưng. Và cái không gian đặc trưng ở đây thì được hiểu đó là tất cả các cái đặc trưng mà trừ cái đặc trưng mà đang bị thiếu ở đây là X_i. Thì phương pháp này nó sẽ chính xác hơn và nó có cái tính giải thích được. Tuy nhiên nó cũng sẽ gọi là có thể tốn kém hơn về mặt chi phí tính toán do nó cũng phải thực hiện cái phép so sánh K láng giềng để tìm ra K láng giềng gần nhất trên một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 19,
      "start_timestamp": "0:11:18",
      "end_timestamp": "0:11:59"
    }
  },
  {
    "page_content": "giềng để tìm ra K láng giềng gần nhất trên một cái tập dữ liệu rất là lớn. Và tương tự như phương pháp K-nearest neighbor thì chúng ta sẽ có cái phương pháp gọi là nội suy tuyến tính. Chúng ta sẽ thay thế cái giá trị bị thiếu bằng cái giá trị được nội suy một cách tuyến tính dựa trên các cái điểm dữ liệu mà không bị thiếu lân cận. Tức là chúng ta sẽ thực hiện gọi là cộng trung bình và chúng ta sẽ nội suy ra cái giá trị bị thiếu ở đó. Đó thì phương pháp này nó cũng tương tự như cái phương pháp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 20,
      "start_timestamp": "0:11:52",
      "end_timestamp": "0:12:40"
    }
  },
  {
    "page_content": "pháp này nó cũng tương tự như cái phương pháp K-nearest neighbor ở đây. Và đặc điểm của nó đó là nó sẽ sử dụng cái mối quan hệ tuyến tính giữa các cái điểm dữ liệu. Nó sử dụng ví dụ cái giá trị của mình là tại đây là với cái đặc trưng X thì chúng ta sẽ có cái giá trị tương ứng của nó là A. Thì tại cái vị trí tiếp theo là Y thì chúng ta sẽ có giá trị là B. Và chúng ta sẽ thực hiện cái giá trị bị thiếu ở đây là Z. Thì chúng ta sẽ đoán xem cái giá trị ở đây là gì. Đó thì chúng ta sẽ dựa trên X, Y,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 21,
      "start_timestamp": "0:12:34",
      "end_timestamp": "0:13:07"
    }
  },
  {
    "page_content": "ở đây là gì. Đó thì chúng ta sẽ dựa trên X, Y, A và Z để chúng ta nội suy ra cái giá trị chấm hỏi ở giữa đây. Đó là cái idea của phương pháp là nội suy tuyến tính. Và phương pháp này thì nó có thể phù hợp với mọi cái loại dữ liệu, tức là dữ liệu của mình cho dù là loại dữ liệu gì thì chúng ta cũng có thể thực hiện được. Rồi nâng cấp hơn so với lại hai phương pháp này đó là chúng ta sẽ thay thế bằng phương pháp hồi quy. Thì với cái phương pháp hồi quy này thì bản chất nó cũng là một cái mô hình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 22,
      "start_timestamp": "0:13:02",
      "end_timestamp": "0:13:39"
    }
  },
  {
    "page_content": "quy này thì bản chất nó cũng là một cái mô hình máy học. Trong đó cái thành phần bị thiếu X_i nó sẽ được tính toán dựa trên các cái thành phần đặc trưng còn lại. Và chúng ta giả sử rằng là X_i này nó sẽ phụ thuộc một cách tuyến tính so với lại các cái đặc trưng còn lại. Thì từ đó mình sẽ xây dựng một cái mô hình máy học để dự đoán cái giá trị X_i từ các cái giá trị còn lại này. Thì phương pháp này nó sẽ cho cái kết quả là chính xác hơn so với cái việc là điền các cái giá trị cố định ở đây ha.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 23,
      "start_timestamp": "0:13:34",
      "end_timestamp": "0:14:16"
    }
  },
  {
    "page_content": "việc là điền các cái giá trị cố định ở đây ha. Và tuy nhiên nó có thể gây ra cái hiện tượng đa cộng tuyến tức là hoặc là quá khớp nếu như cái đặc trưng có mối liên quan cao với các cái đặc trưng khác. Nghĩa là nếu như chúng ta giả sử cái yếu tố là đặc trưng X_i nó phụ thuộc một cách tuyến tính so với lại các cái đặc trưng còn lại thì nó sẽ gây ra cái hiện tượng đa cộng tuyến đó. Và trong thực tế thì rõ ràng không phải cái X_i, cái đặc trưng mà đang bị thiếu dữ liệu ở đây ha, nó có cái mối quan",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 24,
      "start_timestamp": "0:14:12",
      "end_timestamp": "0:14:40"
    }
  },
  {
    "page_content": "bị thiếu dữ liệu ở đây ha, nó có cái mối quan hệ tuyến tính. Rõ ràng không phải lúc nào cũng như vậy. Do đó thì để thực hiện được cái phương pháp này chúng ta phải có một cái giả định, phải có một cái giả định. Và cái giả định này thì không phải lúc nào cũng có thể thỏa mãn. Và cuối cùng đó là chúng ta có thể thay thế dựa trên các cái mô hình. Và mô hình này á là những cái mô hình mà phi tuyến. Thì có thể thay thế bằng các cái mô hình dự đoán nâng cao đó và sử dụng các cái mô hình máy học để",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "nâng cao đó và sử dụng các cái mô hình máy học để ước tính các giá trị còn thiếu dựa trên các cái dữ liệu được quan sát. Thì phương pháp này là phương pháp cao nhất và tổng quát nhất tại vì các cái mô hình máy học ở đây thì nó sẽ không có một cái giả định là tuyến tính mà ở đây chúng ta giả định nó là một cái mối quan hệ phi tuyến luôn. Thì như vậy thì phương pháp này nó sẽ cho cái độ chính xác cao hơn. Tuy nhiên nó sẽ gặp cái vấn đề đó là nó có thể phức tạp và tốn kém cho cái quá trình tính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "có thể phức tạp và tốn kém cho cái quá trình tính toán, tại vì các cái mô hình mà phi tuyến á thì thông thường đó là cái chi phí tính toán của nó lớn do nó phải thực hiện cái số phép biến đổi nhiều hơn.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=lIePeARVnH0",
      "filename": "lIePeARVnH0",
      "title": "[CS116 - Buổi 4] Part 1",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "như vậy thì trong bài học ngày hôm nay chúng ta sẽ cùng đến với hai cái thành phần cuối cùng của một cái machine learning pipeline đó chính là triển khai và giám sát mô hình trong đó thì cái giai đoạn triển khai chúng ta làm sao có thể đưa cái mô hình của mình đến với được với cái người dùng cuối và sau khi chúng ta đã đưa cái mô hình của mình đã huấn luyện đến người dùng cuối rồi thì chúng ta sẽ phải giám sát nó thì cái việc giám sát này á đảm bảo rằng là cái mô hình của mình vẫn được hoạt động",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:51"
    }
  },
  {
    "page_content": "rằng là cái mô hình của mình vẫn được hoạt động một cách trơn tru và đúng như những gì chúng ta kỳ vọng và kể cả trong trường hợp mà cái dữ liệu của mình Ờ không đạt được như kỳ vọng thì chúng ta sẽ có những cái điều chỉnh cho kịp thời thế thì chúng ta sẽ đến với những cái nội dung sau đây đầu tiên đó là chúng ta sẽ giới thiệu về triển khai một cái mô hình máy học nó là cái gì sau đó thì chúng ta sẽ tiếp cận một số cái phương pháp triển khai cái mô hình máy học và chúng ta sẽ có hai phần tiếp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:46",
      "end_timestamp": "0:01:29"
    }
  },
  {
    "page_content": "mô hình máy học và chúng ta sẽ có hai phần tiếp theo đó chính là triển khai ứng dụng dưới dạng web và triển khai ứng dụng dưới dạng dịch vụ Đây là hai cái hình thức được sử dụng rất là phổ biến và nó cũng nằm trong cái phạm vi của môn học này chúng ta có thể thực hiện được một cách dễ dàng và cuối cùng đó là chúng ta sẽ tiến hành Giám sát cái mô hình máy học khi triển khai nó sẽ như thế nào thì đầu tiên chúng ta sẽ cùng đến với phần giới thiệu à triển khai mô hình máy học thì như chúng ta cũng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:24",
      "end_timestamp": "0:02:01"
    }
  },
  {
    "page_content": "triển khai mô hình máy học thì như chúng ta cũng đã biết triển khai mô hình máy học đó là chúng ta làm sao để cho mô hình dự đoán có thể tiếp cận được đến cái người dùng cuối đến người dùng cuối và cái người dùng cuối này thì nó có thể là những người dùng trên mạng xã hội Nó có thể là những cái khách hàng sử dụng trên smartphone thì trên cái hình vẽ ở đây chúng ta thấy người dùng cuối sẽ tiếp cận cái mô hình của mình thông qua hai cái công cụ rất là phổ biến một đó là ứng dụng di động và hai đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 3,
      "start_timestamp": "0:01:55",
      "end_timestamp": "0:02:37"
    }
  },
  {
    "page_content": "là phổ biến một đó là ứng dụng di động và hai đó là cái ứng dụng dạng web đây là có thể nói là hai cái nền tảng giúp cho người dùng tiếp cận đến các các cái thành tựu của công nghệ một cách gọi là nhanh chóng và phổ biến nhất và cái việc mà triển khai mô hình máy học nó cũng không chỉ dừng lại ở người dùng cuối mà nó có thể là ở mức độ tương tác với hệ thống khác ví dụ như chúng ta nhiệm vụ của chúng ta đó là chúng ta sẽ phải bàn giao một cái thuật toán cho một cái bên thứ ba thì chúng ta làm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 4,
      "start_timestamp": "0:02:30",
      "end_timestamp": "0:03:12"
    }
  },
  {
    "page_content": "toán cho một cái bên thứ ba thì chúng ta làm sao để có thể bàn giao được cái mô hình này cho cái bên thứ ba thì đó chính là cái ý nghĩa của cái hệ thống khác ví dụ Chúng ta đang muốn làm một cái dịch vụ chứng thực về mặt gương mặt tức là nhận diện Xem cái Gương Mặt Của Người này là ai đúng không định danh của nó là gì thì chúng ta sẽ cung cấp cái dịch vụ chứng thực gương mặt này cho rất nhiều những cái đơn vị ví dụ như là ngân hàng Ví dụ như là các cái trạm ATM ví dụ như là các cái đơn vị phát",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 5,
      "start_timestamp": "0:03:06",
      "end_timestamp": "0:03:46"
    }
  },
  {
    "page_content": "các cái trạm ATM ví dụ như là các cái đơn vị phát triển về dịch vụ công rồi ví dụ như là các cái đối tác mà có sử dụng cái việc xác thực gương mặt để làm những cái công việc tiếp theo đó như vậy thì các cái hệ thống khác nó cũng đóng vai trò như là một cái khách hàng một cái cái người dùng trong ngữ cảnh của mình và sau khi chúng ta triển khai cái mô hình ờ máy học này xong thì chúng ta sẽ tiến hành Ờ feedback tức là chúng ta lấy cái phản hồi của mô hình thì cái việc mà chúng ta lấy phản hồi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 6,
      "start_timestamp": "0:03:39",
      "end_timestamp": "0:04:22"
    }
  },
  {
    "page_content": "của mô hình thì cái việc mà chúng ta lấy phản hồi của mô hình á nó sẽ có hai hình thức hình thức đầu tiên á đó là trực tiếp và hình thức thứ hai đó là gián tiếp thì đối với cái hình thức trực tiếp á thì người dùng sẽ chủ động đưa ra những cái phản hồi chủ động sẽ đưa ra những cái phản hồi cho các cái mô hình máy học mà chúng ta đã triển khai thì chủ động ở đây họ sẽ thể hiện qua việc là họ sẽ đánh giá rating họ sẽ thả like vào các cái tính năng Hoặc là họ thậm chí họ có thể comment comment vào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 7,
      "start_timestamp": "0:04:17",
      "end_timestamp": "0:04:55"
    }
  },
  {
    "page_content": "Hoặc là họ thậm chí họ có thể comment comment vào các cái ứng dụng để cho biết cái cảm nghĩ của họ về cái tính năng của một cái thuật toán máy học nó như thế nào nếu như cái thuật toán của mình vận hành tốt và đáp ứng được những cái Yêu cầu những cái nguyện vọng của họ thì họ sẽ thả những cái điểm số rating hoặc là thả like rất là tốt nhưng mà trong trường hợp mà cái độ chính xác hoặc là cái tính hiệu quả của mô hình nó không cao thì họ có thể góp ý nhận xét về cái tính năng này là chưa tốt hay",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 8,
      "start_timestamp": "0:04:50",
      "end_timestamp": "0:05:34"
    }
  },
  {
    "page_content": "ý nhận xét về cái tính năng này là chưa tốt hay không tốt chưa tốt thì Nếu tốt thì tốt chỗ nào mà chưa tốt thì tốt ở chỗ nào và cái hình thức nữa thì đó chính là gián tiếp tức là có những thứ mô hình của mình nó không có biểu hiện được thế nào gọi là chính xác thế nào gọi là không chính xác mình lấy ví dụ như là hệ thống recommend hệ thống khuyến nghị cho người dùng sẽ mua tiếp những cái sản phẩm nào khi họ đang tìm kiếm một cái sản phẩm trên các cái trang thương mại điện tử thì các cái sản",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 9,
      "start_timestamp": "0:05:28",
      "end_timestamp": "0:06:10"
    }
  },
  {
    "page_content": "các cái trang thương mại điện tử thì các cái sản phẩm mà mình gợi ý cho họ đôi khi nó không có liên quan một cách trực tiếp nhưng có liên quan một cách gián tiếp ví dụ như là chúng ta thấy người dùng đang ờ tìm một cái chiếc điện thoại trên mạng xã hội thì chúng ta có thể biết là cái nhu cầu tiếp theo đó của cái người dùng này có thể họ sẽ là mua những cái ốp lưng hoặc là mua mua những cái sticker để dán kèm theo thì đây là những cái gợi ý nhưng mà nó không liên quan trực tiếp đến cái món đồ mà",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 10,
      "start_timestamp": "0:06:07",
      "end_timestamp": "0:06:44"
    }
  },
  {
    "page_content": "mà nó không liên quan trực tiếp đến cái món đồ mà họ đang muốn tìm kiếm mà nó lại liên quan một cách gián tiếp như vậy thì cái việc mà chúng ta gợi ý cho khách hàng á thì nó sẽ không thể có cái tính gọi là đúng hay sai à nó không thể dùng các yếu tố gọi là nhận diện đúng nhận diện sai mà nó sẽ phải dựa trên những cái yếu tố gián tiếp để đánh giá xem là cái việc gợi ý này là chính xác hay không thông qua việc chúng ta xem cái doanh thu của cái hãng này có tăng hay không rồi cái lợi nhuận của cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 11,
      "start_timestamp": "0:06:41",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "này có tăng hay không rồi cái lợi nhuận của cái hãng này có tăng hay không khi chúng ta triển khai một cái mô hình vào bên trong cái điều kiện thực tế thì trên đây là một số cái giới thiệu về cái việc triển khai một cái mô hình máy học bao gồm là các cái phương thức mà triển khai đến người dùng cuối hoặc là các cái phương thức tương tác lên các cái hệ thống khác thì với cái hệ thống khác này á là chúng ta có phải có thể đưa cái mô hình của mình cho nhiều bên có thể sử dụng hoặc kể cả cho chính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 12,
      "start_timestamp": "0:07:17",
      "end_timestamp": "0:07:58"
    }
  },
  {
    "page_content": "cho nhiều bên có thể sử dụng hoặc kể cả cho chính cái đơn vị của mình sử dụng luôn tức là một cái việc triển khai có thể dùng cho nhiều mục đích khác nhau và sau khi chúng ta triển khai xong thì chúng ta sẽ nhận những cái feedback của mô hình thông qua hai cái hình thức là trực tiếp là gián tiếp đối với hình thức trực tiếp thì người dùng sẽ chủ động họ sẽ chủ động đánh giá cái mô hình của mình là hiệu quả hay không là tốt hay không nhưng nó sẽ có một cái hình thức khác đó là bị động tức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 13,
      "start_timestamp": "0:07:53",
      "end_timestamp": "0:08:33"
    }
  },
  {
    "page_content": "sẽ có một cái hình thức khác đó là bị động tức là chúng ta sẽ dựa trên những cái hành vi những cái số liệu một cách gián tiếp để xem xem là ví dụ như kể từ khi chúng ta triển khai cái mô hình máy học này lên thì cái doanh thu của một cái công ty nào đó mà có sử dụng cái tính năng mới về máy học này nó tăng lên lấy ví dụ như là các cái hãng về bán lẻ đó họ dự báo xem là trong cái ngày hôm nay thì cái số lượng sản phẩm Hoặc là những cái sản phẩm nào mà người ta quan tâm nhiều thì họ sẽ trưng bày",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 14,
      "start_timestamp": "0:08:26",
      "end_timestamp": "0:09:04"
    }
  },
  {
    "page_content": "mà người ta quan tâm nhiều thì họ sẽ trưng bày các cái sản phẩm đó ra nhiều hơn còn những cái sản phẩm mà họ nhắm là trong Nhữ cái ngày hôm nay nó không có cái tính hiệu quả thì họ sẽ không có trưng bày ra nhiều ví dụ như là đến những cái dịp lễ hội chẳng hạn thì chúng ta sẽ dự đoán rằng là à các cái sản phẩm như là đồ ăn nhanh thức ăn nhanh thì tiêu thụ rất là nhanh chúng ta sẽ phải đóng gói chúng ta sẽ phải sản xuất những cái đồ ăn nhanh nhiều hơn hoặc là trong mùa mưa chẳng hạn chúng ta thấy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 15,
      "start_timestamp": "0:08:59",
      "end_timestamp": "0:09:34"
    }
  },
  {
    "page_content": "hơn hoặc là trong mùa mưa chẳng hạn chúng ta thấy là trời mưa thì cái nhu cầu sử dụng các cái dù hoặc là áo mưa nó tăng lên thì chúng ta phải trưng ra những cái sản phẩm đó nhiều hơn và cất đi những cái sản phẩm mà không phù hợp lắm với cái thời tiết của mình mình như vậy và chúng ta thấy rằng là những cái ứng dụng máy học hiện nay á Nó đang xuất hiện ngày càng trở nên phổ biến nó phổ biến đến mức mà có thể là chúng ta còn không biết cái sự tồn tại của nó cái sự tồn tại của nó trong mắt của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 16,
      "start_timestamp": "0:09:29",
      "end_timestamp": "0:10:10"
    }
  },
  {
    "page_content": "tại của nó cái sự tồn tại của nó trong mắt của người dùng thì trong mắt người dùng có khi là Họ sẽ nhận thức được nhưng mà cũng có khi là họ không nhận thức được lấy ví dụ như là các cái hệ thống khuyến nghị Thì thực tế họ cũng không biết rằng đằng sau nó đang có một cái thuật toán máy học đang được thực thi để mà gợi ý những cái sản phẩm cho họ đúng không Nhưng cũng có những cái ứng dụng mà họ có thể nhận thức được lấy ví dụ như là các cái hệ thống về nhận diện giọng nói nè chúng ta có thể sử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 17,
      "start_timestamp": "0:10:05",
      "end_timestamp": "0:10:44"
    }
  },
  {
    "page_content": "về nhận diện giọng nói nè chúng ta có thể sử dụng nhận diện giọng nói để điều khiển một cái thiết bị di động hoặc là sử dụng nhận diện giọng nói để mở một cái chương trình đúng không thay vì chúng ta ngồi gõ bàn phím thì chúng ta có thể sử dụng Siri chúng ta có thể sử dụng giọng nói để mà ra lệnh và gõ các cái nội dung mà chúng ta muốn tìm kiếm vào bên trong máy tính một cách dễ dàng hơn rồi Ví dụ như cái hệ thống xếp hạng tín dụng ở đây thì cái người sử dụng chính là các cái nhân viên của các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 18,
      "start_timestamp": "0:10:39",
      "end_timestamp": "0:11:21"
    }
  },
  {
    "page_content": "người sử dụng chính là các cái nhân viên của các cái ngân hàng hoặc là các cái tổ chức tín dụng thì họ biết rằng là để ra được một cái mức tín dụng tín nhiệm của một cái người cho vay á thì bên dưới nó sẽ là có một cái thuật toán để xác định xem cái xếp hạng của người này là bao nhiêu thì hai cái ứng dụng này là người dùng sẽ nhận thức được nhưng nó sẽ có những cái ứng dụng mà không nhận thức được người dùng Đôi khi họ sẽ không biết là ờ tại sao nó lại có thể thực thi được lấy ví dụ như là ứng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 19,
      "start_timestamp": "0:11:14",
      "end_timestamp": "0:11:54"
    }
  },
  {
    "page_content": "nó lại có thể thực thi được lấy ví dụ như là ứng dụng News Feed của Facebook là trên cái giao diện ứng dụng của mình thì âm thầm nó đã có một cái thuật toán đã chạy cho từng người và nó sẽ đưa những cái tin tức nào mà người ta mà cái thuật toán đó nó nghĩ rằng là người dùng mạng xã hội họ sẽ quan tâm thì họ sẽ đưa những cái tin tức đó lên trên trên đầu tiên còn những cái tin tức nào mà họ nhắm rằng là người dùng người ta sẽ không quan tâm bằng thì nó sẽ để ở xuống dưới cùng và ở trên đây thì là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 20,
      "start_timestamp": "0:11:50",
      "end_timestamp": "0:12:09"
    }
  },
  {
    "page_content": "nó sẽ để ở xuống dưới cùng và ở trên đây thì là một cái ứng dụng về hồi quy tức là chúng ta đo xem là thời gian để di chuyển từ một nơi từ một để điểm đến một địa điểm trên bản đồ Google Maps thì nó tốn cái thời gian là bao nhiêu thì có khi là người dùng Họ sẽ không biết được là tại sao nó ra được cái con số này thì đó chính là cái sự tồn tại của các cái mô hình máy học trong mắt của người dùng nó rất là đa dạng có thể họ nhận thức được hoặc là không nhận thức được nhưng mà nhìn chung chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "không nhận thức được nhưng mà nhìn chung chúng ta thấy là trong 5 năm 10 năm trở lại đây thì các cái ứng dụng máy học nó đang ngày càng trở nên phổ biến hơn và người dùng đang ngày càng quan tâm hơn và họ đang ngày càng nhận thức được các cái ứng dụng này nó đang hiển hiện cho chúng ta ngày càng nhiều hơn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lqxy5wcEi9I",
      "filename": "Lqxy5wcEi9I",
      "title": "[CS116 - Buổi 14] Part 1_1",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Phương pháp Bayesian Optimization cũng là tìm tuần tự để tìm các điểm tối ưu cục bộ, thì phương pháp của Bayesian Optimization là nó có sự kế thừa, nó có sự kế thừa giữa các lần tìm kiếm. Sự tuần tự này không phải là tuần tự độc lập, mà nó sẽ là sự tuần tự có tính kế thừa. Chúng ta sẽ cùng tìm hiểu trong sơ đồ của ý tưởng của giải thuật ở phần phía bên dưới. Mô hình này cực kỳ phù hợp và rất thích hợp cho mô hình ở dạng blackbox. Chúng ta chỉ cho thông tin đầu vào, cấu hình của mô hình của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:01:17"
    }
  },
  {
    "page_content": "thông tin đầu vào, cấu hình của mô hình của mình cho nó dữ liệu Rồi mô hình này sẽ tự động học và trả ra được hiệu năng, độ chính xác Và chúng ta không có quá nhiều, thậm chí là chúng ta không biết gì về trong mô hình Cấu tạo của nó ra sao, ưu khuyết điểm của nó là gì, chi tiết hoạt động như thế nào Chúng ta sẽ không cần quan tâm, chúng ta nhìn mô hình này như một hộp đen Ví dụ tại thời điểm T, T trong trường hợp này là bằng 2, thì chúng ta có được 1 quan sát X. Chúng ta sẽ có 1 quan sát X. Cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:01:10",
      "end_timestamp": "0:01:55"
    }
  },
  {
    "page_content": "1 quan sát X. Chúng ta sẽ có 1 quan sát X. Cái quan sát X này chính là 1 siêu tham số của mình. Cái đường màu gạch ngang chính là hàm mục tiêu của mình. Và đặc biệt ở đây, đó chính là cái đường ở bên dưới, đó là Acquisition Function. Thì cái hàm này sẽ là khai thác cái hàm hữu dụng. Thì cái hàm hữu dụng này là một cái sự cân đối giữa cái yếu tố exploitation, Đó là khai phá, khai thác thông tin của những lần trước đó Với exploration, chúng ta sẽ khám phá ra một bước ngẫu nhiên Tức là những lần",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:01:49",
      "end_timestamp": "0:03:02"
    }
  },
  {
    "page_content": "khám phá ra một bước ngẫu nhiên Tức là những lần thử của mình tiếp theo Nó sẽ có hai yếu tố là exploitation và exploration Exploitation, tức là chúng ta sẽ đi trong sự chừng mực và chúng ta có sử dụng thông tin của lần quá khứ. Thì trong trường hợp này, đây chính là quá khứ thử nghiệm. Chúng ta đã quan sát được siêu tham số tại vị trí này của hàm mục tiêu. Là cái đường này. Sau đó, với quan sát này, chúng ta sẽ cập nhật lại hàm Acquisition Function này, đó là cái hàm đường màu xanh. Và với cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:02:52",
      "end_timestamp": "0:03:43"
    }
  },
  {
    "page_content": "này, đó là cái hàm đường màu xanh. Và với cái đường màu xanh này, chúng ta sẽ thấy là nó sẽ có những cái vị trí để cho cái mức độ hữu dụng cao nhất, chính là tại cái vị trí này. Vị trí này là cho cái acquisition của mình là cao nhất Và ứng với cái vị trí này thì chúng ta sẽ chiếu lên trong cái không gian tham số Thì đây chính là cái vị trí mà chúng ta sẽ thử tiếp theo là quan sát mới Như vậy là cái quan sát mới, tức là cái bộ siêu tham số thử nghiệm tiếp theo của mình Nó sẽ khác so với phương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:03:39",
      "end_timestamp": "0:04:23"
    }
  },
  {
    "page_content": "tiếp theo của mình Nó sẽ khác so với phương pháp Grid Search và Random Search ở chỗ đó là và nó không hề độc lập so với lại cái lần thử trước đó, cái quan sát trước đó mà nó dựa trên cái hàm Acquisition Function này và cái hàm Acquisition Function này là có sự tham gia của những cái lần thử nghiệm trước đó tức là cái lần quan sát trước đó, chứ không phải đó là một cái hàm cố định thì khi chúng ta thử nghiệm cái quan sát mới Thì chúng ta sẽ thấy là cái hàm mục tiêu của mình sẽ giới hạn phạm vi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:04:17",
      "end_timestamp": "0:04:58"
    }
  },
  {
    "page_content": "là cái hàm mục tiêu của mình sẽ giới hạn phạm vi ảnh hưởng của một siêu tham số đã bị thu hẹp. Ví dụ ở đây chúng ta thấy là nó là một cái dải rất là rộng. Thì khi chúng ta thử cái vùng mới, chúng ta thấy là cái khả năng và cái hàm dự đoán, đây chính là cái hàm ước lượng của mình. Đây là hàm ước lượng, đây là hàm thực tế Đây là hàm mà đường liền là đường ước lượng Và nó là không chính xác, nhưng chúng ta sẽ cố gắng làm sao cho đường ước lượng về sát với đường thực tế nhất Thế thì, khi chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:04:50",
      "end_timestamp": "0:05:39"
    }
  },
  {
    "page_content": "sát với đường thực tế nhất Thế thì, khi chúng ta thử nghiệm với 2 mẫu ở đây thôi, ví dụ như mẫu ở đây và mẫu ở đây và mẫu ở đây thì phạm vi của vùng màu tím, tức là nó sẽ cho biết rằng là cái xác suất cái hàm mục tiêu thực sự của mình nó nằm trong khu vực này. Tức là chúng ta đang giới hạn lại, nó sẽ không nằm ở đây, đúng không? Nó sẽ không nằm ở đây, và, nó sẽ không nằm ở trên đây, mà khả năng cao là nó sẽ nằm trong cái khu vực này. Và khi chúng ta thử một cái quan sát mới thì chúng ta thấy là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:05:37",
      "end_timestamp": "0:06:13"
    }
  },
  {
    "page_content": "ta thử một cái quan sát mới thì chúng ta thấy là cái quan sát mới Và cái quan sát cũ của mình, cái quan sát cũ của mình, nó đã góp phần kéo, nó sẽ kéo cái hàm ước lượng, cái đường ước lượng của mình với lại cái hàm thực tế của mình nó về sát với nhau hơn. Vì vậy trong cái dải phạm vi từ đây đến đây là chúng ta gần như là không có sự biến động nhiều. Cái biến động của mình nó sẽ chủ yếu nằm ở trong cái khu vực đây. Khi chúng ta cập nhật phép thử mới, chúng ta cũng cập nhật hàm Acquisition",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:06:10",
      "end_timestamp": "0:06:59"
    }
  },
  {
    "page_content": "thử mới, chúng ta cũng cập nhật hàm Acquisition Function này. Chúng ta thấy ở ban đầu chỉ có hai quan sát này thì nó ra đường này, nhưng khi chúng ta có thêm điểm mới thì nó đã cập nhật lại theo đường này. Và cái đường này thì giá trị Max Acquisition của mình là cái vị trí này thì tương ứng Chúng ta chiếu thẳng xuống thì đây chính là cái quan sát mới của mình Đây chính là cái quan sát mới Và chúng ta sẽ một lần nữa chúng ta thấy là khi có cái quan sát mới thì cái đường của mình nó bắt đầu Cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:06:53",
      "end_timestamp": "0:07:28"
    }
  },
  {
    "page_content": "sát mới thì cái đường của mình nó bắt đầu Cái phạm vi của mình nó sẽ bắt đầu bớt bị biến động hơn nó sẽ càng lúc càng khớp giữa cái hàm phân bố hậu nghiệm với lại cái hàm mục tiêu thực tế. Thì cái khu vực không chắc chắn của mình bây giờ nó chỉ còn là càng lúc càng về sau, nó sẽ càng lúc càng giảm lại. Cái khu vực mà không chắc chắn nó sẽ càng lúc càng giảm lại. Ví dụ như những cái lần thử nghiệm đầu tiên chúng ta thấy là cái không chắc chắn của mình rất là rộng. Các lần thử tiếp theo sẽ mau",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:07:23",
      "end_timestamp": "0:08:12"
    }
  },
  {
    "page_content": "mình rất là rộng. Các lần thử tiếp theo sẽ mau chóng tiến đến khu vực có khả năng có được nghiệm tối ưu nhất. Tóm lại là phương pháp này đã có một điểm mạnh sau khi chúng ta đã bắt đầu, nó sẽ mau chóng tiến đến cái khu vực có khả năng có được cái nghiệm tối ưu nhất. Như vậy thì tóm lại là cái phương pháp này, nó đã có một cái điểm mạnh so với lại hai phương pháp trước đây, đó chính là cái Acquisition Function. Nó sẽ chỉ điểm cho chúng ta biết là chúng ta nên thử chỗ nào mà có khả năng, có khả",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:08:06",
      "end_timestamp": "0:08:52"
    }
  },
  {
    "page_content": "chúng ta nên thử chỗ nào mà có khả năng, có khả năng hướng đến được cái giá trị tối ưu hoặc là hướng đến cái việc là cái hàm ước lượng nó sẽ khớp với lại cái hàm thực tế, cái hàm mục tiêu thực tế nhất. Chúng ta sẽ phân tích đến cái ưu khuyết điểm của phương pháp Bayesian Optimization này. Đó là tính hiệu quả. Đó là nó đã kế thừa được những thông tin của những lần thử trước để cho việc tìm kiếm của mình hiệu quả hơn. Thay vì các lần tìm kiếm độc lập nhau, thì bây giờ giữa các lần thử nghiệm nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:08:38",
      "end_timestamp": "0:09:27"
    }
  },
  {
    "page_content": "lập nhau, thì bây giờ giữa các lần thử nghiệm nó đã có sự liên kết với nhau để khoanh vùng và hướng đến xác suất tìm ra khu vực tốt hơn. Thứ 2 là nó đã giúp chúng ta giảm bớt được số lần thử nghiệm. Trước đây thì chúng ta tìm kiếm quét cạn không gian thử nghiệm cực kỳ lớn chúng ta đã giải quyết bằng cách đó là Random Search Với Random Search thì chúng ta cũng sẽ phải thử rất là nhiều chúng ta cũng phải thử rất nhiều nếu như không gian tìm kiếm của mình nó lớn Và với phương pháp Bayesian",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 13,
      "start_timestamp": "0:09:22",
      "end_timestamp": "0:10:02"
    }
  },
  {
    "page_content": "kiếm của mình nó lớn Và với phương pháp Bayesian Optimization thì chúng ta chỉ cần với rất ít lần thử nghiệm Ví dụ như trong cái ví dụ này chúng ta chỉ cần có thể thử từ 4 cho đến 5 lần thôi thì kết quả của mình càng về sau sẽ càng hướng đến khu vực có khả năng đạt được cái nghiệm toàn cục. Và cái phương pháp này thì rất phù hợp với những mô hình mà có không gian tham số lớn. Thì như đã nói trước đây, nếu không gian tham số lớn, số lượng siêu tham số nhiều, rồi khoảng giá trị lớn, thì rõ ràng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 14,
      "start_timestamp": "0:09:54",
      "end_timestamp": "0:10:41"
    }
  },
  {
    "page_content": "số nhiều, rồi khoảng giá trị lớn, thì rõ ràng Bayesian sẽ hiệu quả hơn với số lần thử nghiệm ít hơn. Và khuyết điểm của phương pháp này là tính phức tạp. Nó sẽ phức tạp hơn so với Random Search và Grid Search. Và việc chọn lựa hàm Acquisition này cũng có rất nhiều cách chọn lựa khác nhau. Và việc chọn lựa hàm Acquisition này cũng ảnh hưởng rất lớn đến tính hiệu quả của phương pháp này. Đó chính là điểm yếu của phương pháp Bayesian Optimization. Sau đây, chúng ta sẽ tiến hành so sánh các phương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 15,
      "start_timestamp": "0:10:36",
      "end_timestamp": "0:11:15"
    }
  },
  {
    "page_content": "Sau đây, chúng ta sẽ tiến hành so sánh các phương pháp ưu khuyết điểm của từng phương pháp. Đối với phương pháp Grid Search, đây là một phương pháp rất đơn giản, dễ cài đặt. Và tương tự như vậy cho Random Search, đây cũng là phương pháp đơn giản, dễ cài đặt. Tuy nhiên, phương pháp Bayesian sẽ phức tạp hơn. sử dụng lý thuyết về xác suất và do đó nó sẽ khó cài đặt hơn. Thì đó chính là cái tính đơn giản và dễ cài đặt. Xét về cái yếu tố toàn diện, tức là cái khả năng mà chúng ta quét hết những khu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 16,
      "start_timestamp": "0:11:12",
      "end_timestamp": "0:11:56"
    }
  },
  {
    "page_content": "là cái khả năng mà chúng ta quét hết những khu vực mà có tham số, cái tính toàn diện của cái việc mà tìm kiếm không gian siêu tham số, thì rõ ràng phương pháp Grid Search nó sẽ có cái lợi thế tốt hơn trong cái việc đó là quét những cái khả năng có khả năng xảy ra của cái siêu tham số của mình. Vì vậy là cái không gian tìm kiếm của mình nó sẽ toàn diện hơn. Trong khi đó, Random Search thì không gian tìm kiếm không có toàn diện. Tức là nó sẽ không có tìm kiếm một cách toàn diện do yếu tố ngẫu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 17,
      "start_timestamp": "0:11:45",
      "end_timestamp": "0:12:39"
    }
  },
  {
    "page_content": "có tìm kiếm một cách toàn diện do yếu tố ngẫu nhiên. Tiếp theo, đó là ưu điểm của phương pháp Random Search. Đó là nó sẽ hiệu quả cho không gian tìm kiếm lớn. Vì chính vì sự tìm kiếm toàn diện này của Grid Search dẫn đến là nó chậm. và nó không hiệu quả thì phương pháp Random Search nó đã hiệu quả hơn do nó đã tiết kiệm được số lần thử nghiệm của mình nhiều hơn Và đối với phương pháp Bayesian Optimization thì tính hiệu quả của nó cao hơn so với lại hai phương pháp trước đó do tính kế thừa Nó kế",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 18,
      "start_timestamp": "0:12:29",
      "end_timestamp": "0:13:07"
    }
  },
  {
    "page_content": "hai phương pháp trước đó do tính kế thừa Nó kế thừa được giữa các lần thử với nhau. Lần thử sau nó dựa trên thông tin của lần thử trước để mà nó hướng đến, tìm đến những khu vực mà nó khả nghi là có cái nghiệm toàn cục của mình. Và chính sự hiệu quả này, chính sự hiệu quả của việc kế thừa này nó dẫn đến việc hiệu quả cho cái không gian tham số lớn. Tức là nếu như những mô hình của mình có nhiều siêu tham số và với mỗi siêu tham số có nhiều khoảng giá trị thì Bayesian là một phương pháp phù hợp.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 19,
      "start_timestamp": "0:12:58",
      "end_timestamp": "0:13:18"
    }
  },
  {
    "page_content": "giá trị thì Bayesian là một phương pháp phù hợp. Và khuyết điểm của phương pháp Grid Search chính là không gian tìm kiếm của mình quá lớn dẫn đến chi phí tính toán lớn và không hiệu quả do không kế thừa các lần thử nghiệm. Thì cái này đã được giải quyết ở cái điểm này của Bayesian Optimization. Cái điểm yếu này cũng chính là điểm yếu của phương pháp Random Search. Bayesian Optimization có yếu tố phức tạp và nó bị phụ thuộc vào việc chọn lựa hàm Acquisition Function. Trên đây là một bảng tóm tắt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 20,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Function. Trên đây là một bảng tóm tắt đánh giá ưu khuyết điểm của ba phương pháp tinh chỉnh tham số phổ biến nhất hiện nay.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Lt0azzH_htk",
      "filename": "Lt0azzH_htk",
      "title": "[CS116 - Buổi 11] Part 4",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "rồi trong những phần trước thì chúng ta đã tìm hiểu qua cái các cái thành phần cấu tạo của một cái mạng CNN rồi sau đó chúng ta đã tiến hành cài đặt cái mạng CNN này với một cái kiến trúc rất là đơn giản đó là kiến trúc LeNet và để mà hiểu rõ hơn cái mạng CNN này thì không cách nào khác đó là chúng ta sẽ phải trực quan trực quan hóa cái mạng CNN Thế thì có rất nhiều cái cách thức để chúng ta có thể trực quan hóa được cái mạng CNN cách đầu tiên đó là chúng ta sẽ hiển thị tất cả các cái feature",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:48"
    }
  },
  {
    "page_content": "đó là chúng ta sẽ hiển thị tất cả các cái feature map mà thực hiện được trong suốt cái quá trình mà mạng CNN thực hiện các cái phép biến đổi như là convolution, pooling, ReLU thì đầu vào chúng ta thấy là có một cái ảnh độ sâu là ba tức là tương ứng ba kênh màu thì cái này là chúng ta trực quan hóa và con người nhìn vô là có thể hiểu một cách dễ dàng sau đó thì chúng ta sẽ tiến hành cái phép biến đổi là convolution thì ở cái phép biến đổi convolution ở cái lớp đầu tiên thì nó sẽ tạo ra một cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 1,
      "start_timestamp": "0:00:42",
      "end_timestamp": "0:01:21"
    }
  },
  {
    "page_content": "ở cái lớp đầu tiên thì nó sẽ tạo ra một cái mà, xin lỗi, nó sẽ tạo ra một cái feature map và cái feature map này có cái độ sâu là D thì chúng ta sẽ trực quan hóa bằng cách đó là cắt ra các cái lát cắt ở D cái độ sâu này và ứng với mỗi cái lát cắt chúng ta sẽ hiển thị nó trên màn hình để xem coi là cái gì Nằm ở bên trong cái lát cắt này thì từ từ trong ra bên ngoài đúng không thì chúng ta sẽ có D cái lát cắt và có bao nhiêu cái lát cắt thì chúng ta sẽ hiển thị lên trên hết cái màn hình đó từ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 2,
      "start_timestamp": "0:01:15",
      "end_timestamp": "0:01:58"
    }
  },
  {
    "page_content": "ta sẽ hiển thị lên trên hết cái màn hình đó từ trong ra ngoài có bao nhiêu cái lát cắt thì chúng ta sẽ hiển thị lên hết thì đây là cái cách trực quan đầu tiên và cách trực quan thứ hai đó là chúng ta khi mà mô hình mạng CNN nó huấn luyện xong thì nó sẽ có các cái filter và filter này là các cái trọng số mà mạng CNN nó đã huấn luyện và tự động nó điền các cái giá trị ở bên trong cái filter này và chúng ta sẽ trực quan hóa cái filter này để xem coi sau khi huấn luyện xong thì các cái filter này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 3,
      "start_timestamp": "0:01:51",
      "end_timestamp": "0:02:36"
    }
  },
  {
    "page_content": "sau khi huấn luyện xong thì các cái filter này nó nhìn như thế nào thì đây là hai cái cách chính để giúp cho chúng ta có thể trực quan hóa một cái mạng CNN rồi thì ở đây có các cái nhà khoa học họ đã tạo ra một cái công cụ đó là Deep Visualization Toolbox thì chúng ta có thể gõ với cái từ khóa là Deep Visualization Toolbox như ở trên và nó sẽ ra cái video đầu tiên với cái video đầu tiên này thì chúng ta sẽ cùng quan sát xem là các cái tác giả họ đã tiến hành trực quan hóa như thế nào thì đây là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 4,
      "start_timestamp": "0:02:30",
      "end_timestamp": "0:03:13"
    }
  },
  {
    "page_content": "đã tiến hành trực quan hóa như thế nào thì đây là tên của cái công trình nghiên cứu của các cái tác giả làm về Deep Visualization Toolbox rồi thì chúng ta sẽ xem qua cái giao diện Chúng ta sẽ cùng Xem qua cái giao diện của cái ứng dụng này ha đầu tiên ở phía trên bên tay trái đó chính là cái tấm ảnh đầu vào của cái mạng CNN đây chính là cái ảnh màu và các tác giả đã thiết kế cái chương trình để cho phép là chúng ta có thể truyền vào cái ảnh tĩnh hoặc là chúng ta có thể truyền vào một cái đoạn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 5,
      "start_timestamp": "00:03:08",
      "end_timestamp": "0:03:48"
    }
  },
  {
    "page_content": "hoặc là chúng ta có thể truyền vào một cái đoạn video thì khi mà chúng ta đưa vào cái video thì chúng ta sẽ quan sát xem cái feature map nó sẽ biến đổi như thế nào trong suốt quá trình mà chúng ta chuyển động ở bên trong cái video rồi ở phía trên thì chúng ta sẽ thấy là có các cái lớp biến đổi ví dụ như là convolution, pooling, normalization, convolution số 2 và convolution số 3, convolution số 5 rồi các cái lớp biến đổi là FC và lớp cuối cùng là softmax để tạo ra các cái phân bố xác suất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 6,
      "start_timestamp": "000:03:41",
      "end_timestamp": "0:04:23"
    }
  },
  {
    "page_content": "là softmax để tạo ra các cái phân bố xác suất probabilities thì ở đây người ta đang focus vào cái lớp convolution số 1 và nhìn vào cái hình này thì các bạn có thể đoán ra xem cái feature map Sau khi thực hiện cái lớp convolution số 1 đó là có độ sâu là bao nhiêu các bạn thử tính toán xem rồi thì chúng ta để ý ha là xét trên hàng nè thì chúng ta có 3 nè 6 nè 9, 10 như vậy là ở trên hàng này có 10 10 cái ô tương ứng là 10 cái lát cắt còn theo chiều dọc thì chúng ta có 3 nè 6 nè 9 như vậy là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 7,
      "start_timestamp": "000:04:15",
      "end_timestamp": "0:05:06"
    }
  },
  {
    "page_content": "chiều dọc thì chúng ta có 3 nè 6 nè 9 như vậy là nguyên cái khối này là có 10 x 9 tức là 90 cái lát cắt cộng thêm 6 cái feature map ở phía cuối nữa Như vậy là tổng chúng ta sẽ có là 96 như vậy là cái lớp feature map đầu tiên cái lớp feature map đầu tiên đó chính là có 96 cái lát cắt rồi và chúng ta sẽ nhìn vô cái hình thù của các cái lát cắt này nó như thế nào ha Thì ở đây chúng ta sẽ nhìn vô đâu đó chúng ta có thể đoán được hình dáng của của cái đối tượng trên ảnh gốc Ví dụ ở đây chúng ta thấy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 8,
      "start_timestamp": "000:05:00",
      "end_timestamp": "0:05:41"
    }
  },
  {
    "page_content": "đối tượng trên ảnh gốc Ví dụ ở đây chúng ta thấy có ngựa vằn thì ở trên cái feature map các bạn cũng có thể thấy đâu đó có cái bóng dáng của cái đối tượng chính của mình đó là cái con ngựa vằn nhưng mà đương nhiên là ở đây mình đoán trước khi mình thấy được cái ảnh đầu vào thôi và khi thay đổi các cái hình này thì cái feature map của mình sẽ thay đổi rồi bây giờ sẽ đến một cái phần rất là quan trọng đó chính là chúng ta sẽ thử nghiệm đưa vào một cái chuỗi video frame ở bên phía trên bên trái ha",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 9,
      "start_timestamp": "000:05:35",
      "end_timestamp": "0:06:14"
    }
  },
  {
    "page_content": "cái chuỗi video frame ở bên phía trên bên trái ha và chúng ta sẽ xem cái feature map ở bên phải nó thay đổi như thế nào thì chúng ta sẽ quan sát là có một số cái feature map có cái độ response hay là cái độ sáng nó rất là sáng so với lại những feature map khác ví dụ như chúng ta thấy ở trung tâm màn hình có hai cái feature map này nó rất là sáng còn các cái feature map này thì chúng ta nhìn thấy có bóng dáng của cái người đang thực hiện cái demo ở đây nhưng mà cái độ sáng nó yếu hơn vậy thì hai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 10,
      "start_timestamp": "000:06:10",
      "end_timestamp": "0:06:58"
    }
  },
  {
    "page_content": "ở đây nhưng mà cái độ sáng nó yếu hơn vậy thì hai cái feature map này nó có cái ý nghĩa là gì Các bạn có thể đoán được hay không Bây giờ chúng ta sẽ có thêm một cái cửa sổ nữa Ở đây đó là cái cửa sổ này đó là phóng to của cái feature map mà chúng ta đang highlight ở đây đó chúng ta nhấp vô chọn ha cái feature map ở đây và bên đây nó sẽ phóng to ra thì các bạn có thể đoán ra được là cái tính chất của cái feature map này đó chính là tạo ra các cái biên cạnh theo chiều dọc tạo ra các biên cạnh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 11,
      "start_timestamp": "000:06:54",
      "end_timestamp": "0:07:33"
    }
  },
  {
    "page_content": "cái biên cạnh theo chiều dọc tạo ra các biên cạnh theo chiều dọc Tuy nhiên các bạn có để ý là cái biên cạnh theo chiều dọc thì cái phần bên phải cái feature map bên phải nó cũng có cái hình thù tương tự như vậy và cũng tạo ra các cái biên cạnh theo chiều dọc tương tự như vậy Vậy thì cái sự khác nhau giữa hai cái feature map này đó là gì rồi bây giờ chúng ta sẽ thử đưa vô một cái tờ giấy đúng không thì các bạn sẽ thấy nè Cái feature map ở bên tay trái là nó sẽ phát sáng lên cái đường biên theo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 12,
      "start_timestamp": "000:07:29",
      "end_timestamp": "0:08:12"
    }
  },
  {
    "page_content": "trái là nó sẽ phát sáng lên cái đường biên theo chiều dọc đúng như cái gì chúng ta dự đoán Nhưng tại sao cũng là đường biên theo chiều dọc nhưng mà cái feature map bên tay phải không phát sáng đó thì ở đây hai cái feature map này đều là feature map để thể hiện cái biên cạnh theo chiều dọc nhưng mà nó sẽ có hai cái ý nghĩa khác nhau cái feature map bên tay trái là nó sẽ phát sáng nó sẽ phản hồi khi bên trái là cái vùng sáng và bên phải nó là vùng tối đó thì nó sẽ respond nó sẽ phản hồi rồi khi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 13,
      "start_timestamp": "000:08:08",
      "end_timestamp": "0:08:45"
    }
  },
  {
    "page_content": "tối đó thì nó sẽ respond nó sẽ phản hồi rồi khi đưa tờ giấy này qua khi đưa cái tờ giấy này qua bên đây thì các bạn sẽ cùng xem cùng theo dõi cái feature map bên tay phải ha Thì chiếu lại lên đây chúng ta thấy là cái feature map bên tay phải cũng là biên cạnh theo chiều dọc và nó mới bắt đầu nó phát sáng trong khi đó Cái feature map bên tay trái nó đã tối nó không còn phát sáng cái biên cạnh nữa thì cái biên cạnh theo chiều dọc này nó có cái ý nghĩa Đó là nó dịch chuyển từ vùng tối sang cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 14,
      "start_timestamp": "000:08:39",
      "end_timestamp": "0:09:21"
    }
  },
  {
    "page_content": "ý nghĩa Đó là nó dịch chuyển từ vùng tối sang cái vùng sáng hơn bên trái chúng ta thấy là cái gương mặt đó là có cái màu nó tối còn bên phải nó là vùng sáng thì nó trái ngược với lại cái loại feature map này ha feature map này là bên trái sáng bên phải tối thì nó sẽ respond còn feature map bên đây thì là bên trái tối bên phải sáng thì nó mới respond thì đó chính là cái ý nghĩa của hai cái feature map này Vậy tương tự như hồi nãy đã đề cập thì hai cái feature map tương ứng ở hai cái vị trí này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 15,
      "start_timestamp": "000:09:16",
      "end_timestamp": "0:09:57"
    }
  },
  {
    "page_content": "cái feature map tương ứng ở hai cái vị trí này thì nó được tạo ra bởi các cái filter khác nhau và ở đây thì chúng ta sẽ cùng trực quan hóa cái filter của hai cái feature map này đối với cái feature map bên tay phải á thì chúng ta sẽ trực quan lên thì chúng ta thấy là à những cái vùng nào mà có giá trị thấp nó sẽ là màu tối và vùng nào có giá trị cao thì nó sẽ là màu sáng thì chúng ta thấy là Ừ đúng như là cái hình minh họa của cái feature map thì đối với cái filter nó cũng có tính chất tương tự",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 16,
      "start_timestamp": "000:09:50",
      "end_timestamp": "0:10:35"
    }
  },
  {
    "page_content": "đối với cái filter nó cũng có tính chất tương tự như vậy filter chúng ta sẽ thấy là bên trái sẽ có vùng tối và bên phải nó sẽ có vùng sáng tương tự cái filter ở bên tay trái bên trái sẽ là vùng sáng và bên phải sẽ là vùng tối đó thì ý nghĩa của hai cái filter này đó chính là lọc các cái biên cạnh theo chiều dọc Nhưng mà bên cái filter này thì sẽ là chuyển từ tối sang sáng còn cái filter này thì chuyển từ sáng từ sáng sang tối rồi sau đó thì chúng ta sẽ tiến hành trực quan hóa các cái lớp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 17,
      "start_timestamp": "0:10:31",
      "end_timestamp": "0:10:35"
    }
  },
  {
    "page_content": "chúng ta sẽ tiến hành trực quan hóa các cái lớp pooling, normalization thì trong cái bài học chúng ta không đề cập đến normalization nhưng mà normalization chính là một cái phép mà để chuẩn hóa cái feature map của mình rồi lớp convolution số 3 thì chúng ta thấy là đến cái lớp convolution số 3 thì cái số lượng feature map của mình nhiều hơn và đồng thời là cái kích thước của nó cũng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=MrCfY40azyU",
      "filename": "MrCfY40azyU",
      "title": "[CS116 - Buổi 10] Part 4_0",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và cuối cùng đó là một cái thuật toán nằm trong cái nhóm Ờ gọi là phân cụm nhưng mà dựa trên yếu tố về mặt mật độ. Ý tưởng của thuật toán này đó chính là chúng ta sẽ phân cụm dựa trên mật độ và gom các cái dữ liệu gần nhau, gom các cái dữ liệu gần nhau, gần nhau. Thì cái khái niệm là thế nào gọi là dữ liệu gần nhau thì chúng ta sẽ định nghĩa đó là những điểm mà có khoảng cách nhỏ hơn một cái ngưỡng epsilon và gần nhau không là chưa đủ mà nó phải có cái sự phân bố dày đặc, tức là các cái điểm này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:36"
    }
  },
  {
    "page_content": "cái sự phân bố dày đặc, tức là các cái điểm này nó phải co cụm, nó phải co cụm lại với nhau. Chứ còn nếu mà gần nhau nhưng mà nó rời rạc và không đủ tạo thành một cái mật độ lớn thì lúc đó chúng ta cũng sẽ không tách ra thành một cụm. Như vậy thì cái yếu tố đầu tiên đó là phải gom các cái điểm gần nhau. Và yếu tố thứ hai đó là phải có mật độ cao. Mật độ cao này thì được định nghĩa bằng số điểm tối thiểu trong cụm, nó phải là Min Point. Tức là chúng ta sẽ tách nó ra một cụm nếu như à cái số điểm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 1,
      "start_timestamp": "0:00:32",
      "end_timestamp": "0:01:04"
    }
  },
  {
    "page_content": "ta sẽ tách nó ra một cụm nếu như à cái số điểm trong cái cụm đó nó nó phải lớn hơn một cái con số tối thiểu là Min Point ở đây. Và các điểm nằm trong cái cụm có mật độ thấp thì được gán nhãn là nhiễu, tức là những cái điểm cũng gần nhau đấy nhưng mà nó không đủ tạo ra cái số lượng, nó không đủ tạo ra cái số lượng không tạo ra được một cái quần thể đủ nhiễu thì nó sẽ được set vào loại đó là nhiễu hay còn gọi là là noise. Và dưới đây là một cái mô phỏng cho cái thuật toán DB scan với các cái cấu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 2,
      "start_timestamp": "0:01:00",
      "end_timestamp": "0:01:37"
    }
  },
  {
    "page_content": "phỏng cho cái thuật toán DB scan với các cái cấu hình tham số epsilon và Min Point khác nhau. Thì trong trường hợp này chúng ta thấy epsilon của mình là bằng bằng 1. Còn bên đây thì epsilon nhỏ hơn đó là bằng 0.6, tức là những cái điểm nào mà phải đủ gần thì nó mới được xem là có cái liên hệ láng giềng với nhau. Còn ở đây những cái điểm mà tương đối xa nó đã gom xem như là láng giềng rồi. Và trong cái trường hợp bên trái thì tám điểm, phải tối thiểu là tám điểm thì chúng ta mới gom lại thành",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 3,
      "start_timestamp": "0:01:32",
      "end_timestamp": "0:02:14"
    }
  },
  {
    "page_content": "thiểu là tám điểm thì chúng ta mới gom lại thành một cái quần thể. Còn bên đây thì chỉ có sáu điểm thôi. Thì chúng ta thấy là rõ ràng với cái thuật toán bên tay phải thì nó đã tách ra thành rất nhiều những cái nhóm nhỏ ở đây sẽ là co cụm và rất nhiều cái nhóm nhỏ. Trong khi bên đây cái tiêu chí nó thoáng hơn. Nó thoáng hơn khoảng cách để mà được xét là một khi hai cái điểm gần nhau là nó cũng lớn hơn số điểm Ờ tối thiểu của mình nó phải là tám điểm thì nó mới tách ra thành một cái cụm. Thì khi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 4,
      "start_timestamp": "0:02:08",
      "end_timestamp": "0:02:55"
    }
  },
  {
    "page_content": "thì nó mới tách ra thành một cái cụm. Thì khi đó là chúng ta thấy nó ở đây nó chỉ gom ra thành bốn cái cụm lớn như thế này thôi. Nó gom ra thành bốn cụm lớn. Còn các cái điểm màu đen như thế này nó sẽ gọi là outlier hay còn gọi là nhiễu. Còn bên phải thì chúng ta thấy nè, nó đã tách ra thành các cái cụm nhỏ, rất nhiều những cái cụm nhỏ. Còn các cái điểm màu đen này thì cũng rất nhiều, đó là các các cái outlier, các cái điểm nhiễu đó. Thì cái việc chọn lựa các cái tham số epsilon và Min Point",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 5,
      "start_timestamp": "0:02:48",
      "end_timestamp": "0:03:26"
    }
  },
  {
    "page_content": "chọn lựa các cái tham số epsilon và Min Point này nó cũng ảnh hưởng đến cái kết quả của mình. Nhưng nhìn chung đó là chúng ta thấy những điểm nào mà gần nhau thì nó sẽ tách ra thành một cái cụm và nó sẽ khắc phục được những cái điểm yếu của thuật toán K-Means. Như vậy thì cái ưu điểm của cái thuật toán này đó là chúng ta không cần phải biết trước cái số cụm. Nếu như trong K-Means chúng ta phải biết trước cái số cụm là K. Còn ở đây chúng ta thấy thuật toán của mình nó sẽ cứ chạy chạy chạy cho",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 6,
      "start_timestamp": "0:03:20",
      "end_timestamp": "0:04:00"
    }
  },
  {
    "page_content": "thuật toán của mình nó sẽ cứ chạy chạy chạy cho đến khi nào mà nó gom được đủ cụm, nó sẽ tách ra nó chạy trên một cái điểm khác rồi lại tiếp tục lan đó. Rồi các các cái điểm ở khu vực này chính là các cái điểm nhiễu vì nó chưa đạt đủ được cái số lượng Min Point là 4 điểm đúng không? Số Min Point nó chưa đạt đủ là số điểm là 4 nên nó sẽ được tính là noise, là nhiễu. Thì rõ ràng là với những cái dữ liệu mà không có dạng tính chất hình cầu, những cái cụm mà không có dạng tính chất như hình cầu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 7,
      "start_timestamp": "0:03:53",
      "end_timestamp": "0:04:37"
    }
  },
  {
    "page_content": "cái cụm mà không có dạng tính chất như hình cầu phân bố giống như hình cầu như thế này đó, thì rõ ràng là DB scan, DB scan thực hiện rất là tốt. Và K-Means thì lúc này nó lại thực hiện không tốt bằng. Rồi, và thuật toán này thì nó còn có một cái ưu điểm nữa đó là hiệu quả với những cái điểm mà có mật độ cao nha. Tức là những cái điểm mà có cái sự đan xen nè, số lượng điểm tập trung khá là dày đặc nè. Ví dụ như khu vực này là dày đặc, khu vực này là dày đặc thì nó là mật độ cao thì nó sẽ rất là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 8,
      "start_timestamp": "0:04:32",
      "end_timestamp": "0:05:09"
    }
  },
  {
    "page_content": "là dày đặc thì nó là mật độ cao thì nó sẽ rất là hiệu quả. Và thực tế thì cũng vậy, nó cũng sẽ có những cái điểm yếu. Thì khuyết điểm của DB scan chính là nó không hiệu quả với những cái dữ liệu có cái mật độ biến động. Thì ở đây chúng ta sẽ có một cái hình ảnh minh họa cho cái việc đó là thế nào gọi là một cái dữ liệu mà có cái mật độ biến động. Ví dụ như chúng ta thấy những điểm mà nằm trong khu vực này đúng không? Thì đây là những điểm mà co cụm lại, các cái điểm của mình có cái khoảng cách",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 9,
      "start_timestamp": "0:05:04",
      "end_timestamp": "0:06:01"
    }
  },
  {
    "page_content": "cụm lại, các cái điểm của mình có cái khoảng cách rất là là nhỏ thì đây là các cái điểm khoảng cách rất là nhỏ, tức là rất gần nhau. Còn các cái điểm ở nằm trong cái khu vực này, chúng ta thấy cái khoảng cách giữa các cái điểm của mình nó thưa hơn rồi. Và những điểm mà nằm trong cái khu vực này, chúng ta thấy cái khoảng cách còn lớn hơn nữa. Nếu so với lại cái vòng tròn màu đỏ ở đây, chúng ta thấy là trong cái bán kính của cái epsilon này ha, cái bán kính epsilon này, thì chúng ta thấy là không",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 10,
      "start_timestamp": "0:05:56",
      "end_timestamp": "0:06:36"
    }
  },
  {
    "page_content": "bán kính epsilon này, thì chúng ta thấy là không có điểm nào nằm trong cái bán kính epsilon này. Thì đây là một cái minh họa cho cái loại dữ liệu mà có mật độ nó biến động, nó không đồng đều. Khu vực này là những điểm rất là dày, những điểm mà rất là gần sát nhau. Khu vực này thì thưa hơn. Và khu vực này thì là rất thưa, khu vực này thì nó rất thưa. Đó, thì đây chính là cái sự biến động của mật độ dữ liệu. Và sở dĩ tại sao thuật toán DB scan nó không có làm tốt trên những cái dữ liệu mà có mật",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 11,
      "start_timestamp": "0:06:30",
      "end_timestamp": "0:07:08"
    }
  },
  {
    "page_content": "không có làm tốt trên những cái dữ liệu mà có mật độ nó biến động là vì các cái tham số epsilon và Min Point của mình, epsilon đó là những con số cố định. Và vì nó cố định nên khi cái mật độ của mình nó có sự biến động, mật độ của mình nó có biến động thì cái giá trị epsilon này nó sẽ không có cập nhật được. Do đó nếu như chúng ta có thể chọn lựa được ờ chúng ta có thể thay đổi được cái thuật toán này thì chúng ta sẽ tìm cách cập nhật các cái epsilon này. Chúng ta sẽ cập nhật các epsilon này có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 12,
      "start_timestamp": "0:07:05",
      "end_timestamp": "0:07:43"
    }
  },
  {
    "page_content": "này. Chúng ta sẽ cập nhật các epsilon này có thể là gia giảm hoặc là nó sẽ thay đổi một cách linh động tùy theo cái bước chạy của cái thuật toán của mình. Tương tự như vậy cho cái Min Point. Nếu như các các tham số này nó có cái tính gọi là adaptive, thích ứng với cái dữ liệu thì khi đó cái thuật toán của mình nó sẽ chạy tốt hơn. Thì đó là cái điểm yếu cuối cùng của thuật toán DB scan. Và sau đây thì chúng ta sẽ cùng so sánh một số cái tình huống khi chúng ta thực hiện trên các cái toy example,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 13,
      "start_timestamp": "0:07:38",
      "end_timestamp": "0:08:12"
    }
  },
  {
    "page_content": "khi chúng ta thực hiện trên các cái toy example, tức là những cái dữ liệu mẫu mà mang tính chất gọi là thí nghiệm thì chúng ta xem coi cái hiệu quả của thuật toán DB scan và thuật toán K-Means như là như thế nào. Thì như đã đề cập, K-Means nó phù hợp với những cái dữ liệu mà phân bố dạng hình cầu. Do đó đối với những cái dữ liệu mà có phân bố lạ. Để không? Ví dụ như đây là hai cái vòng tròn lồng nhau nè. Không phải là dạng hình cầu. Dạng hình cầu là sao? Dạng hình cầu là nó phải co cụm chứ nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 14,
      "start_timestamp": "0:08:07",
      "end_timestamp": "0:08:38"
    }
  },
  {
    "page_content": "là sao? Dạng hình cầu là nó phải co cụm chứ nó tỏa đều ra. Còn ở đây chúng ta thấy là nó sẽ có một cái khoảng hở nó không có tỏa đều ra. Ở khu vực này nó cũng có một cái khoảng hở nó không tỏa đều ra, nó bị ngắt quãng thì nó sẽ không phải là dạng hình cầu. Một số bạn sẽ nghĩ rằng là à hình cầu có nghĩa là nó phải đi theo dạng hình tròn phải không? Thì không nhất thiết. Ừ, nó phải là tỏa đều ra, nó phải tỏa đều ra. Ở đây nó đang có những khoảng không như thế này sẽ khiến cho cái mô hình của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 15,
      "start_timestamp": "0:08:34",
      "end_timestamp": "0:09:13"
    }
  },
  {
    "page_content": "như thế này sẽ khiến cho cái mô hình của mình đó thực hiện không tốt trên thuật toán K-Means. Trong khi đó, đối với thuật toán DB scan thì chúng ta thấy là nó đã tách ra hai cái điểm, hai cái đường nằm trong và nằm ngoài hình tròn, hình vòng tròn nằm bên trong và vòng tròn nằm bên ngoài rất là tốt. Rồi, tương tự như vậy, hai cái đường ờ hai cái nửa đường tròn gọi là lồng với nhau đúng không? Thì ở đây là một cụm đối với K-Means thì nó sẽ ra xem đây là một cụm và cái tâm cụm của mình chắc là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 16,
      "start_timestamp": "0:09:07",
      "end_timestamp": "0:09:49"
    }
  },
  {
    "page_content": "là một cụm và cái tâm cụm của mình chắc là cái điểm nằm ở đây. Còn ở đây là một cụm và cái tâm cụm thì nó nằm ở đây. Rõ ràng là cái tâm cụm của mình nó không nằm trong cái mật độ điểm dày đặc của mình nên nó sẽ cập nhật sai, nó sẽ cập nhật không có hiệu quả. Còn đối với DB scan nó không có cập nhật dựa trên tâm cụm mà nó dựa trên cái sự lan tỏa, lan tỏa. Ban đầu nó sẽ khởi tạo tại đây, sau đó nó sẽ lan dần, lan dần, lan dần cho đến đây. Và tại vị trí này thì cái khoảng cách giữa đây từ cái điểm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 17,
      "start_timestamp": "0:09:44",
      "end_timestamp": "0:10:25"
    }
  },
  {
    "page_content": "trí này thì cái khoảng cách giữa đây từ cái điểm màu cam cho đến điểm màu xanh nó quá xa, nó vượt quá cái Min Point, nó nó vượt quá cái ngưỡng epsilon. Đó, thì dẫn đến là nó sẽ không nhảy qua được cái vùng bên đây. Thì khi chúng ta chọn cái epsilon đủ tốt, đủ nhỏ thì nó sẽ giúp cho chúng ta tách hai cái, hai cái cụm này ra. Và đối với cái mẫu dữ liệu bên đây thì chúng ta thấy là DB scan nó cũng đã gom, đã gom đúng. Thì trong trường hợp này, những cái điểm này á nếu như cái Min Point của mình mà",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 18,
      "start_timestamp": "0:10:20",
      "end_timestamp": "0:11:00"
    }
  },
  {
    "page_content": "cái điểm này á nếu như cái Min Point của mình mà đủ lớn thì nó có thể xem đây là các cái điểm nhiễu luôn. Đây sẽ là các cái điểm nhiễu nếu như chúng ta chọn các cái Min Point à đủ lớn. Rồi, đây là cái tình huống mà ba cụm rất là rời rạc. Thì rõ ràng là DB scan và K-Means nó đều thực hiện tốt. Nhưng mà chúng ta vẫn phải lưu ý là K-Means mà có thể tách cái này ra làm ba cụm được á là do ban đầu cái điểm khởi tạo của mình nó rải ra nằm ở ba cái vị trí khác nhau. Chứ còn nếu ban đầu mà khởi tạo các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 19,
      "start_timestamp": "0:10:55",
      "end_timestamp": "0:11:31"
    }
  },
  {
    "page_content": "khác nhau. Chứ còn nếu ban đầu mà khởi tạo các cái điểm tâm cụm của mình như thế này thì có khi là những cái điểm bên đây nó sẽ gom với lại cái điểm màu xanh lá chứ nó không có không có tách ra làm ba cụm riêng biệt như thế này. Thì K-Means ở đây là có cái cách để đạt được cái kết quả này thì chắc là nó đã may mắn tách ra được các cái điểm random nằm ở ba cái cụm riêng biệt rồi. Còn thuật toán DB scan thì nó không quan tâm. Nó sẽ chạy lan trên từng cụm trước. Nó sẽ chạy hết cái cụm ở đây xong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 20,
      "start_timestamp": "0:11:26",
      "end_timestamp": "0:11:51"
    }
  },
  {
    "page_content": "từng cụm trước. Nó sẽ chạy hết cái cụm ở đây xong rồi nó tách ra nó lại tiếp tục chạy hết những điểm bên đây xong rồi chạy hết những điểm bên đây. Nó không có phụ thuộc vào cái khởi tạo đó, ờ cái tâm cụm giống như là K-Means. Và cái ví dụ cuối cùng thì rõ ràng chúng ta thấy cái DB scan nó sẽ cho cái kết quả nó phù hợp hơn. Tại vì các các điểm ở đây nó co cụm dày đặc như vậy thì nó xứng đáng là tạo ra một cụm thôi. Còn vì K-Means nó đã cố định cái số K là K rồi nên nó buộc nó phải tách cái hình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "số K là K rồi nên nó buộc nó phải tách cái hình vuông này ra làm ba phần mặc dù về mặt hình thức thì chúng ta thấy là cái này nó xứng đáng là để chung trong một cụm. Thì trên đây đó là các cái thuật toán gom cụm kinh điển, nổi tiếng nhất đó là K-Means và DB scan. Còn các thuật toán còn lại thì nó sẽ nằm trong cái phạm vi tìm hiểu hoặc là sử dụng nó như là một cái công cụ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NJ0rjEK0L78",
      "filename": "NJ0rjEK0L78",
      "title": "[CS116 - Buổi 6] Part 2 (tt)",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Một trong những thành phần rất quan trọng của các mô hình máy học là tinh chỉnh siêu tham số. Trong một mô hình máy học, nó sẽ bao gồm hai loại tham số. Tham số đầu tiên là các tham số chính của mô hình dựa trên dữ liệu huấn luyện để tìm ra các bộ tham số tối ưu nhất với các thước đo đã chọn trước. Khi chúng ta xây dựng một mô hình máy học thì chúng ta sẽ có những tham số liên quan đến kiến trúc của mô hình của mình Những tham số này gọi là siêu tham số và những tham số này cũng đóng góp rất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:44"
    }
  },
  {
    "page_content": "tham số và những tham số này cũng đóng góp rất quan trọng đến hiệu năng của hệ thống của mình. Để tinh chỉnh siêu tham số, chúng ta có 3 phương pháp: Grid Search, Random Search và Bayesian Optimization. Để cài đặt phương pháp Bayesian Optimization thì phải cài đặt thêm một module, toolkit, scikit-optimize. Module này sẽ giúp chúng ta khởi tạo scikit-optimize. Scikit-optimize chính là thư viện để phục vụ Bayesian Optimization. Đối với phần Grid Search và Random Search, chúng ta sẽ khai báo đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 1,
      "start_timestamp": "0:00:35",
      "end_timestamp": "0:01:37"
    }
  },
  {
    "page_content": "và Random Search, chúng ta sẽ khai báo đó là scikit-learn.model_selection. là phương pháp chọn lựa mô hình với Grid Search Cross Validation và Random Search Cross Validation. Ở đây có make_classification thì chúng ta sẽ không sử dụng dataset này. Dataset chúng ta sẽ sử dụng là Decision Tree Classifier. Để tạo dataset, chúng ta sẽ sử dụng dataset của Scikit-learn với dataset Titanic. Dataset này, chúng ta sẽ quan sát data.data. Đây chính là dữ liệu gốc của mình, đặc trưng đầu vào. Bao gồm là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 2,
      "start_timestamp": "0:01:36",
      "end_timestamp": "0:02:43"
    }
  },
  {
    "page_content": "liệu gốc của mình, đặc trưng đầu vào. Bao gồm là Pclass, Name, Age, Giới tính, v.v. Nó sẽ có một số trường bị NaN, tức là bị rỗng. Và một số trường, ví dụ như trường Name, chúng ta thấy là tên người nó sẽ không có vai trò trong việc phân loại. Cột Home, địa chỉ nhà, hoặc địa chỉ nơi đến, cũng không có vai trò trong việc đưa ra dự đoán giá trị đầu ra cuối cùng của mình. Do đó các cột như Name hoặc Home Destination thì chúng ta cũng sẽ bỏ đi. Chúng ta chỉ chừa một số thuộc tính, một số đặc trưng,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 3,
      "start_timestamp": "0:02:32",
      "end_timestamp": "0:03:17"
    }
  },
  {
    "page_content": "ta chỉ chừa một số thuộc tính, một số đặc trưng, ví dụ như là Pclass, Giới tính, Age, R, Popup. Thì các thông số nào, các đặc trưng nào chúng ta sử dụng thì sẽ được đề cập trong Codelog tiếp theo. Hai dòng này chúng ta sẽ trích xuất ra. X là đặc trưng đầu vào. data.target chính là đặc trưng cần dự đoán. Chúng ta sẽ chia tập dữ liệu này ra làm hai phần. Test và Train. Test thì chiếm 20% và Train thì 80%. Và chúng ta sẽ làm một thao tác gọi là tiền xử lý. Các giá trị về giới tính chúng ta sẽ map",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 4,
      "start_timestamp": "0:03:10",
      "end_timestamp": "0:04:01"
    }
  },
  {
    "page_content": "xử lý. Các giá trị về giới tính chúng ta sẽ map về các con số 0, 1. Như chúng ta đã biết là chúng ta sẽ sử dụng Decision Tree Classifier. Thì chúng ta sẽ phải convert mọi cái đặc trưng của mình về cái dạng số. Thì giới tính ban đầu sẽ ở dạng category như dạng chuỗi. Thì chúng ta sẽ map nó về các con số là 0 và 1. Ngoài ra thì chúng ta sẽ phải xử lý một số cái tình huống là dữ liệu bị rỗng. Thì chúng ta sẽ fill in nó bằng cách đó là lấy cái giá trị trung bình. Lấy cái giá trị trung bình của cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 5,
      "start_timestamp": "0:03:57",
      "end_timestamp": "0:04:42"
    }
  },
  {
    "page_content": "trung bình. Lấy cái giá trị trung bình của cái cột đó, ví dụ cột Fare. Chúng ta sẽ lấy giá trị trung bình của cột Fare, cột Age, và cột Age. Chúng ta sẽ chọn ra 6 đặc trưng này để phục vụ cho bài toán phân loại. Tương tự như vậy thì cho X_test chúng ta sẽ lấy ra các đặc trưng như vậy. Rồi, chúng ta sẽ khởi tạo mô hình. Grid Search này chạy khá là lâu, tốn hơn 2 phút. Làm sao chúng ta biết là có những tham số nào để chúng ta xét khoảng để mình có thể vét cạn? Thì chúng ta có thể sử dụng cái hàm,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 6,
      "start_timestamp": "0:04:29",
      "end_timestamp": "0:05:34"
    }
  },
  {
    "page_content": "thể vét cạn? Thì chúng ta có thể sử dụng cái hàm, cái phương thức đó là model của Decision Tree.get_params(). Thì trong đây chúng ta sẽ thấy là có rất nhiều những cái tham số. Tuy nhiên chúng ta chỉ xem xét trên một số, cái tham số chính có ảnh hưởng quan trọng đến cái performance, cái hiệu quả của mô hình. Ví dụ như là độ sâu, như chúng ta biết trong Decision Tree. Nếu mà cái cây của mình nó càng sâu thì có khả năng nó sẽ bị overfit. Do đó thì chúng ta cũng không biết cái depth của mình là bao",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 7,
      "start_timestamp": "0:05:29",
      "end_timestamp": "0:06:16"
    }
  },
  {
    "page_content": "ta cũng không biết cái depth của mình là bao nhiêu là đủ. Do đó thì mình cứ cho nó chạy từ 1 cho đến 15. Tương tự như vậy là min_samples_leaf, max_features. Đặc biệt là cái tiêu chí để giúp chúng ta xác định xem Tiêu chí nào là độ hỗn tạp, tiêu chí nào là chia nút, chọn lựa đặc trưng cho phù hợp. Có nhiều thông tin, chúng ta sẽ sử dụng độ đo Gini hoặc là độ Entropy. Rồi Splitter thì chúng ta có thể chọn 'random' or 'best'. Đây là những thông số phổ biến trong thuật toán Decision Tree. Và chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 8,
      "start_timestamp": "0:06:12",
      "end_timestamp": "0:06:51"
    }
  },
  {
    "page_content": "phổ biến trong thuật toán Decision Tree. Và chúng ta sẽ gọi là Grid Search Cross Validation với tham số cross_validation sẽ là 5. Và chúng ta sẽ truyền tham số grid này vào. Và thật ra thì params_grid này nó cũng sẽ được sử dụng chung cho tất cả các param_space hoặc là param_distributions của Random Search. Thì dùng chung để cho có tính công bằng. Rồi thì, Phương thức Grid Search chạy khá lâu, ở đây chúng ta đã chạy sẵn. Khi chúng ta chạy xong, nó sẽ trả về best_parameters, criterion tiêu chí",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 9,
      "start_timestamp": "0:06:45",
      "end_timestamp": "0:07:36"
    }
  },
  {
    "page_content": "nó sẽ trả về best_parameters, criterion tiêu chí để chọn lựa. Mình chọn đặc trưng đó chính là Entropy. max_depth tốt nhất là 5. max_features là 4. min_samples_leaf là bằng 7. random_state là bằng 1. random_state này thì cũng hơi thừa, tại vì chúng ta chỉ có duy nhất một cái option thôi. Vậy đó, cái này cũng thừa. Và cuối cùng là splitter thì 'best'. Và chúng ta sẽ thử chạy với số vòng lặp Random Search với số vòng lặp là 32 thì xem coi là cái kết quả của mình như thế nào. Thì chúng ta thấy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 10,
      "start_timestamp": "0:07:34",
      "end_timestamp": "0:08:43"
    }
  },
  {
    "page_content": "kết quả của mình như thế nào. Thì chúng ta thấy Random Search chạy rất là nhanh. Grid Search chạy rất nhanh. Và cho performance đạt 79%. So với Grid Search là 80%. Như vậy là độ chính xác cũng gần như tương đương. Nhưng tốc độ rất nhanh, ở đây chỉ tốn 2 giây. Trong khi Grid Search ở đây tốn đến hơn 2 phút. Cụ thể là 158 giây. Tức là phải 2 phút rưỡi. Và tương tự như vậy thì Bayesian Optimization. max_depth dự kiến range từ hệ thống. Chúng ta sẽ gặp lỗi ở max_depth. Y membate ear Roger. Nó phải",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 11,
      "start_timestamp": "0:08:42",
      "end_timestamp": "0:09:50"
    }
  },
  {
    "page_content": "gặp lỗi ở max_depth. Y membate ear Roger. Nó phải là số nguyên. Rồi, OK. Như vậy thì Chúng ta sẽ phải dùng Cái integer, đúng không? Chúng ta phải dùng integer. Thay vì là float. Chắc là min_samples_leaf cũng vậy. max_features. max_features của mình cũng phải là integer. min_samples_leaf cũng vậy, chúng ta sẽ dùng integer thay vì số thực. Chúng ta sẽ chạy nhanh hơn rất nhiều do chúng ta sẽ không cần phải tính toán một số các thao tác để chọn lựa ra các thử nghiệm. Chúng ta sẽ không cần phải tính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 12,
      "start_timestamp": "0:09:38",
      "end_timestamp": "0:10:47"
    }
  },
  {
    "page_content": "các thử nghiệm. Chúng ta sẽ không cần phải tính toán một số các thao tác để chọn lựa ra cấu hình tiếp theo để thử nghiệm. Còn phương pháp Bayesian Optimization thì chúng ta sẽ phải tính toán để chọn ra từ phép thử hiện tại. Chúng ta sẽ tìm ra các phép thử tiếp theo thì nó sẽ tốn chi phí tính toán. Và với phương pháp này thì chúng ta thấy tốn thời gian ít hơn so với lại phương pháp Grid Search là 2 phút. Nhưng kết quả của mình cho độ chính xác gần như tương đương, gần 80%. Rõ ràng là phương pháp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 13,
      "start_timestamp": "0:10:41",
      "end_timestamp": "0:11:57"
    }
  },
  {
    "page_content": "như tương đương, gần 80%. Rõ ràng là phương pháp Bayesian Optimization cho thấy sự hiệu quả của mình. Và các tham số của mình trả về bởi Bayesian Optimization cũng tương tự. Tiêu chí criterion cũng là Entropy. max_depth là 5, max_features là 6, min_samples_leaf là 7, min_samples_leaf là 6. Tức là các con số thử nghiệm cũng khá là tương đồng. Và kết quả best_score của mình cũng tương đương với của Grid Search. Vậy trong bài lab này, chúng ta đã cùng tìm hiểu về các cách thức để tune tham số. Lưu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 14,
      "start_timestamp": "0:11:52",
      "end_timestamp": "0:13:11"
    }
  },
  {
    "page_content": "tìm hiểu về các cách thức để tune tham số. Lưu ý là trong quá trình tune, chúng ta phải tách dữ liệu này ra làm hai phần, là Train và Test. Rồi sau đó chúng ta sẽ thực hiện một số thao tác gọi là tiền xử lý dữ liệu. Và chúng ta sẽ phải xác định được mô hình của mình là gì và tham số của mô hình là gì. Sau đó chúng ta sẽ xét khoảng giá trị mà mình sẽ tìm kiếm. Và thực hiện việc tìm kiếm với phương pháp cho phù hợp. Sau đó chúng ta sẽ thử Bayesian Optimization. Nó sẽ có performance trên tập test",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 15,
      "start_timestamp": "0:12:56",
      "end_timestamp": "0:15:36"
    }
  },
  {
    "page_content": "Optimization. Nó sẽ có performance trên tập test như thế nào. Chúng ta sẽ gọi best_estimator. Tức là estimator có độ chính xác cao nhất. Chúng ta sẽ tiến hành là predict. Predict trên tập dữ liệu là X_test. Và đây là các giá trị mà mình đã dự đoán ra. Rồi, y của mình sẽ là các con số, do đó mình sẽ phải ép kiểu. Y_test là thành array. Chúng ta sẽ đi so sánh cái này với giá trị predict ở đây. Chúng ta sẽ phải chạy lại cái này. Sau đó chúng ta sẽ tính sum và chia cho len của predict. Chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 16,
      "start_timestamp": "0:15:24",
      "end_timestamp": "0:16:39"
    }
  },
  {
    "page_content": "tính sum và chia cho len của predict. Chúng ta sẽ ra được Accuracy của Best Model. Chúng ta sẽ đạt trên tập test là 79%. Chúng ta sẽ áp dụng đoạn code này cho estimator ở phía trên. Độ chính xác đạt 79%, phương pháp Random Search. Kết quả Random Search, Best Estimator. Độ chính xác đạt 79%, Bayesian Optimization cao hơn một chút. Và cuối cùng là Grid Search. Kết quả này là Grid Search. Rồi... D welded Key lot dâyeded là điều đáng nói. Discovering parameters cho target given. Và thậm chí là cao",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 17,
      "start_timestamp": "0:16:31",
      "end_timestamp": "0:17:15"
    }
  },
  {
    "page_content": "parameters cho target given. Và thậm chí là cao hơn so với lại cả tập Train. Grid Search luôn luôn là phương pháp tối ưu nhất. Tại vì nó đã vét cạn hết tất cả các khả năng có thể xảy ra. Do đó thì việc độ chính xác của Grid Search trên Test set là chuyện hoàn toàn có thể dễ hiểu. Tuy nhiên, Random Search sẽ rất nhanh và cho performance của mình tương đương. Cho kết quả Random Search là tương đương, 79. Bayesian Optimization cho kết quả cao hơn so với Random Search. Nhưng nó vẫn thua, cái Grid",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "so với Random Search. Nhưng nó vẫn thua, cái Grid Search là 83% thì cái chuyện này cũng hoàn toàn là dễ hiểu. Tại vì cái phương pháp mà tối ưu nhất vẫn là Grid Search. Rồi thì trên đây sẽ là cái bài để minh họa cách thức chúng ta sử dụng 3 cái phương pháp để tune tham số cho một cái mô hình.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=NW8fWHdiAME",
      "filename": "NW8fWHdiAME",
      "title": "[CS116 - Buổi 11] Part 5",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và kỹ thuật tiếp theo mà chúng ta sẽ được tìm hiểu đó chính là t-SNE t-SNE là viết tắt của chữ t-distributed Stochastic Neighbor Embedding thì t-SNE là một cái kỹ thuật giảm chiều mà phi tuyến. Nếu như PCA nó dựa trên các cái công cụ của Đại Số tuyến tính, các cái phép biến đổi tuyến tính thì t-SNE là cái thuật toán, là cái kỹ thuật mà khi mà chúng ta làm việc trên cái loại dữ liệu có tính chất là phi tuyến, nó không có một cái sự gọi là thể hiện cái mối quan hệ tuyến tính nào hết đó, thì thì đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:44"
    }
  },
  {
    "page_content": "cái mối quan hệ tuyến tính nào hết đó, thì thì đó là cái mối quan hệ phi tuyến. Và mục tiêu của nó đó là để trực quan hóa cái dữ liệu của mình. Đây chính là cái nhiệm vụ chính của mình để trực quan hóa dữ liệu của mình cho cái dữ liệu đa chiều. Tức là cái dữ liệu của mình ban đầu là một cái dữ liệu đa chiều thì chúng ta sẽ đưa nó về cái số chiều thấp hơn, số chiều thấp hơn. Và thông thường để mà có thể trực quan với các cái công cụ vẽ hiện nay thì chúng ta sẽ sử dụng là à không gian hai chiều",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 1,
      "start_timestamp": "0:00:39",
      "end_timestamp": "0:01:17"
    }
  },
  {
    "page_content": "thì chúng ta sẽ sử dụng là à không gian hai chiều hoặc là không gian ba chiều. Và ý tưởng của nó đó là nó sẽ tạo ra một cái phân bố xác suất à nó sẽ tạo ra một cái phân bố xác suất mới nó tương tự nó tương tự trong cái không gian có cái số chiều thấp hơn. Tức là thay vì không gian là 10 chiều thì nó tạo ra một cái phân bố trong cái không gian hai chiều trong cái không gian hai chiều. Và các cái tính chất về phân bố của mình nó sẽ được bảo toàn. Ví dụ các cái điểm nào mà gần nhau ở trong không",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 2,
      "start_timestamp": "00:01:12",
      "end_timestamp": "0:01:49"
    }
  },
  {
    "page_content": "Ví dụ các cái điểm nào mà gần nhau ở trong không gian nhiều chiều thì khi chiếu xuống trong không gian nhiều chiều, Khi chiếu xuống không gian hai chiều thì các cái điểm đó các cái đặc trưng đó nó vẫn phải gần nhau. Đó chính là cái tính chất và ràng buộc khi chúng ta dùng t-SNE. Và đây là một cái minh họa cho cái ý tưởng đó đó. Ví dụ như các cái điểm ở đây là những cái ảnh của cái tập dữ liệu là MNIST. Và cái tập dữ liệu MNIST này thì các bạn biết rồi đó là những cái ảnh có kích thước là 28 x",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 3,
      "start_timestamp": "00:01:45",
      "end_timestamp": "0:02:28"
    }
  },
  {
    "page_content": "rồi đó là những cái ảnh có kích thước là 28 x 28. Tức là nếu như chúng ta trải nó ra thành cái vector thì đây là các cái vector 784 chiều, tức là 28 x 28 là 784 chiều. Đây là một cái không gian rất là lớn và rất khó để có thể trực quan hóa được. Nhưng nhờ cái thuật toán, cái kỹ thuật t-SNE, chúng ta chiếu nó về cái không gian hai chiều là các cái điểm ở đây thì chúng ta vẽ lên và chúng ta thấy nó vẫn giữ được những cái tính chất nhất định. Ví dụ những cái điểm màu xanh ở đây chúng ta thấy những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 4,
      "start_timestamp": "00:02:24",
      "end_timestamp": "0:03:08"
    }
  },
  {
    "page_content": "những cái điểm màu xanh ở đây chúng ta thấy những cái điểm co cụm ở đây nó đều là những cái điểm mà tạo bởi cái ảnh của con số 1. Rồi những cái cụm điểm ở đây chúng ta thấy là khi chúng ta giảm chiều dữ liệu xong thì những cái điểm là số 0 nó sẽ nằm ở gần đây. Rồi những cái ảnh mà tạo những cái ảnh của cái chữ số 6 thì nó cũng sẽ nằm co cụm ở đây, nó sẽ nằm phân bố như như trên đây đó. Đây là những cái vùng điểm số 7. Và đương nhiên đâu đó chúng ta sẽ thấy có những cái điểm nhiễu, có những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 5,
      "start_timestamp": "00:03:01",
      "end_timestamp": "0:03:41"
    }
  },
  {
    "page_content": "ta sẽ thấy có những cái điểm nhiễu, có những cái điểm nhiễu do cái thao tác à chiếu từ không gian nhiều chiều xuống không gian thấp chiều lấy ví dụ như ở đây chúng ta thấy là những cái điểm thuộc cái chữ số 4 đúng không, là màu xanh ngọc ở đây nè là số 4. Nhưng đâu đó nó lại lọt những cái điểm màu xanh dương, tức là tương ứng cái con số 1 ở đây thì đó là những cái điểm nhiễu. Rồi, và như vậy thì chúng ta sẽ tiến hành so sánh các cái thuật toán PCA và thuật toán t-SNE. Thì ưu về ưu điểm, thuật",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 6,
      "start_timestamp": "00:03:36",
      "end_timestamp": "0:04:19"
    }
  },
  {
    "page_content": "PCA và thuật toán t-SNE. Thì ưu về ưu điểm, thuật toán PCA nó nhanh và nó hiệu rất là hiệu quả với lại những cái dữ liệu lớn. Và do là nó phải nó chỉ thực hiện với các cái phép biến đổi tuyến tính. Ở đây là mình ghi nhầm ha, đây là những cái phép biến đổi là tuyến tính. Các cái thao tác biến đổi của PCA thì tất cả đều thực hiện các cái phép biến đổi tuyến tính nên cái tốc độ của nó nó rất là nhanh, nó rất là hiệu quả. Và nó giữ lại được các cái thành phần chính với những cái phương sai lớn,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 7,
      "start_timestamp": "00:04:15",
      "end_timestamp": "0:04:57"
    }
  },
  {
    "page_content": "thành phần chính với những cái phương sai lớn, phương sai lớn hay là cái độ biến động, độ lệch hoặc là biến động lớn. Tại sao? Tại vì những cái điểm mà có cái độ lệch độ biến động lớn thì nó sẽ chứa nhiều thông tin. Còn những cái thành phần nào mà có độ lệch độ biến động ít á, tức là nó ít có thông tin. Và ưu điểm cho t-SNE đó chính là nó có khả năng nắm bắt được cái cấu trúc phi tuyến của dữ liệu. PCA thì rất là phù hợp cho những cái dữ liệu nào mà dạng tuyến tính, còn t-SNE thì nó sẽ giúp cho",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 8,
      "start_timestamp": "00:04:50",
      "end_timestamp": "0:05:30"
    }
  },
  {
    "page_content": "mà dạng tuyến tính, còn t-SNE thì nó sẽ giúp cho mình nắm bắt được những cái cấu trúc phi tuyến tính, và thường được sử dụng trong cái việc là trực quan hóa dữ liệu thôi. PCA thì thường được sử dụng cho cái việc là giảm chiều dữ liệu và lấy cái dữ liệu đó như là một cái vector đặc trưng, đó như là một cái vector đặc trưng để mà phục vụ cho cái công đoạn phía sau, ví dụ như là dự đoán cái kết quả cho bài toán hồi quy hoặc là phân lớp. Còn t-SNE thì thông thường được sử dụng cho cái vấn đề là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 9,
      "start_timestamp": "00:05:26",
      "end_timestamp": "0:06:06"
    }
  },
  {
    "page_content": "thì thông thường được sử dụng cho cái vấn đề là trực quan hóa dữ liệu gốc ban đầu là cái dữ liệu đa chiều thì chúng ta sẽ giảm nó xuống còn hai cho đến ba chiều để vẽ được trong cái không gian đó. Và khuyết điểm của PCA đó chính là nó có khả năng à nó không có cái khả năng à bắt được những cái cấu trúc phi tuyến, hay nói cách khác đó là khả năng mà bắt cái cấu trúc phi tuyến của nó là kém. Thì đó chính là cái sự đối ngẫu với t-SNE. t-SNE có khả năng bắt được cấu trúc phi tuyến thì PCA nó cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 10,
      "start_timestamp": "00:06:00",
      "end_timestamp": "0:06:36"
    }
  },
  {
    "page_content": "năng bắt được cấu trúc phi tuyến thì PCA nó cái cái việc mà bắt được cấu trúc phi tuyến của nó rất là kém. Và nó dễ bị ảnh hưởng bởi cái nhiễu hay là các cái outlier. Tức là trong mẫu dữ liệu của mình nếu có những cái đặc trưng nào mà là đặc trưng nhiễu thì nó sẽ gây ảnh hưởng lớn đến cái kết quả phân tích của mình. Và t-SNE thì nó sẽ không ổn định do có cái yếu tố ngẫu nhiên. Trong cái thuật toán của t-SNE thì nó sẽ có cái yếu tố là đưa về cái phân bố ngẫu nhiên thì có cái yếu tố ngẫu nhiên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 11,
      "start_timestamp": "00:06:32",
      "end_timestamp": "0:07:10"
    }
  },
  {
    "page_content": "phân bố ngẫu nhiên thì có cái yếu tố ngẫu nhiên nên cái tính không ổn định của t-SNE. Và nó có cái độ phức tạp cao do nó phải thực hiện các cái thao tác biến đổi trong cái không gian phi tuyến. Rồi, và nó sẽ khó có cái tính giải thích. Tức là cái tính giải thích của nó nó sẽ không cao so với lại PCA. Tại vì PCA chúng ta thực hiện trên cái thao tác là tuyến tính mà tuyến tính thì chúng ta sẽ dễ hình dung dễ hiểu hơn. Còn phi tuyến thì nó sẽ khó hiểu khó giải thích hơn. Thì trên đây đó chính là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 12,
      "start_timestamp": "00:07:04",
      "end_timestamp": "0:07:10"
    }
  },
  {
    "page_content": "hiểu khó giải thích hơn. Thì trên đây đó chính là chúng ta đã so sánh các cái phương pháp về giảm chiều dữ liệu nổi tiếng nhất đó chính là PCA và t-SNE.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=Oc2dKYMWUx0",
      "filename": "Oc2dKYMWUx0",
      "title": "[CS116 - Buổi 6] Part  3 (tt)",
      "chunk_id": 13,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Hôm nay thì chúng ta sẽ cùng đến với bài số hai đó là lập trình với các cái thư viện nổi tiếng của Python được sử dụng và trong cái môn học này đó là thư viện NumPy thì đây là thư viện mà giúp cho chúng ta thực hiện các cái tính toán trên số học và trên đại số tuyến tính. Matplotlib là cái thư viện để giúp cho chúng ta trực quan hóa dữ liệu và pandas là cái thư viện để giúp cho chúng ta có thể xử lý trên cái dữ liệu dạng bảng. Giúp cho chúng ta xử lý như các cái dữ liệu mà ở dạng bảng đó. Thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:58"
    }
  },
  {
    "page_content": "xử lý như các cái dữ liệu mà ở dạng bảng đó. Thì trong bài học ngày hôm nay chúng ta sẽ cùng tìm hiểu về ba cái thư viện này. Đầu tiên đó là thư viện NumPy. Thì thư viện NumPy là một cái thư viện tính toán khoa học mà nó có cái hiệu năng rất là cao. Tức là nếu như chúng ta sử dụng các cái hàm của NumPy để thực hiện các cái thao tác tính toán trên ma trận, trên vectơ hoặc là trên tensor thì cái tốc độ của nó cực kỳ nhanh. Tại vì NumPy nó bên dưới, ngầm bên dưới của nó đã được cài đặt bằng các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:51",
      "end_timestamp": "0:01:34"
    }
  },
  {
    "page_content": "ngầm bên dưới của nó đã được cài đặt bằng các cái ngôn ngữ cấp thấp nên cái tốc độ tính toán của nó rất là nhanh. Nếu như chúng ta cố gắng cài đặt lại các cái thao tác cộng trừ nhân chia ma trận mà bằng các cái vòng For bình thường của Python á thì chắc chắn luôn là cái tốc độ của mình nó sẽ thấp hơn rất là nhiều so với cái việc là chúng ta sử dụng các cái hàm trong thư viện NumPy này. Đó thì đây là một cái thư viện rất là phổ biến trong Python. Có thể nói là một trong những thư viện phổ biến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:29",
      "end_timestamp": "0:02:06"
    }
  },
  {
    "page_content": "Có thể nói là một trong những thư viện phổ biến nhất. Tại vì khi nói về lập trình với Python thì chúng ta sẽ phải lập trình với à xử lý các cái số liệu rất là nhiều. Và trong các cái xử lý số liệu thì xử lý trên các cái đối tượng là đại số tuyến tính như là vectơ, ma trận và tensor là những cái loại dữ liệu mà được sử dụng sử dụng rất là phổ biến. Và một số cái chủ đề chính trong cái thư viện NumPy đó chính là về array hay là indexing hoặc là slicing array. Tức là chúng ta sẽ khởi tạo ra một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:01:59",
      "end_timestamp": "0:02:43"
    }
  },
  {
    "page_content": "slicing array. Tức là chúng ta sẽ khởi tạo ra một cái đối tượng à Ví dụ như đối tượng dạng số học 7 3 7 - 5. Chúng ta chúng ta tạo ra một cái vector như thế nào hoặc là chúng ta tạo ra một cái ma trận như thế nào. Rồi và chúng ta sẽ tìm hiểu về cái cơ chế đánh chỉ mục trong cái NumPy nó có khác gì so với cái chỉ mục của Python hay không? Thì cái cách đánh chỉ mục của nó nó cũng tương tự như trong Python đó là là chỉ mục của mình là chỉ mục dạng số nguyên và chỉ số của mình nó sẽ bắt đầu từ 0.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:38",
      "end_timestamp": "0:03:25"
    }
  },
  {
    "page_content": "số nguyên và chỉ số của mình nó sẽ bắt đầu từ 0. Thì ví dụ ở đây là theo cột thì đây là cột thứ 0, cột thứ một, cột thứ hai. Còn đây là dòng thứ không, dòng thứ một. Thì đó là indexing à đánh chỉ mục. Slicing là cái cơ chế để cho phép chúng ta trích ra trong cái vector hoặc là trích ra trong cái ma trận các cái vector con và ma trận con. Ví dụ chúng ta muốn lấy ra hai cái giá trị cuối ở bên trong cái vector này thì chúng ta sẽ lấy ra như thế nào. Chúng ta lấy ra hai cái giá trị cuối này để xử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:03:19",
      "end_timestamp": "0:04:03"
    }
  },
  {
    "page_content": "Chúng ta lấy ra hai cái giá trị cuối này để xử lý. Hoặc là chúng ta muốn lấy ra bốn cái giá trị cuối cùng này thì chúng ta sẽ lấy ra như thế nào bằng cái cơ chế slicing. Rồi kiểu dữ liệu thì trong NumPy nó có hỗ trợ các cái kiểu dữ liệu nào khi chúng ta xây dựng một cái array đúng không? Thì ở trong cái array thì nó sẽ phải thỏa mãn một tính chất đó là tất cả các cái giá trị trong cùng một cái array nó phải cùng một cái kiểu dữ liệu. Thế thì cái kiểu dữ liệu mà NumPy array nó hỗ trợ đó là những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:03:58",
      "end_timestamp": "0:04:43"
    }
  },
  {
    "page_content": "kiểu dữ liệu mà NumPy array nó hỗ trợ đó là những cái dữ liệu gì? Ví dụ như NumPy array sẽ hỗ trợ dữ liệu là kiểu số nguyên hoặc là số thực hoặc là boolean. Và ngoài những kiểu này ra thì còn những kiểu nào hay không? Rồi NumPy còn hỗ trợ các cái thao tác là copy và view dữ liệu. Copy tức là chúng ta sẽ tạo một cái đối tượng mới từ một cái array cũ hay là chúng ta clone cái dữ liệu của mình ra như thế nào. Rồi chúng ta sẽ trực quan, chúng ta sẽ xem cái dữ liệu đó hiển thị lên trên màn hình như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:04:35",
      "end_timestamp": "0:05:23"
    }
  },
  {
    "page_content": "xem cái dữ liệu đó hiển thị lên trên màn hình như thế nào. Và một phần cũng rất là quan trọng trong cái thư viện NumPy này và được sử dụng cũng rất là thường xuyên đó chính là array shape và reshape. Array shape là cái cơ chế là cái phương thức để giúp cho chúng ta biết cái array của mình nó có kích thước là bao nhiêu, nó có bao nhiêu chiều và kích thước cho từng chiều là bao nhiêu. Ví dụ đây là một cái array có cái số chiều là 1 nhưng mà cái kích thước cho từng chiều của mình nó là 3. Như vậy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:05:15",
      "end_timestamp": "0:06:01"
    }
  },
  {
    "page_content": "thước cho từng chiều của mình nó là 3. Như vậy nó sẽ là 3. Đối với cái array này thì cái shape của của nó nó sẽ là bao nhiêu đó. Shape ở đây nó sẽ là 2 3. Tức là đây là một cái array có hai chiều. Trong đó thành phần thứ nhất có kích thước đó là 2 và cái chiều thứ hai kích thước của nó là 3. Và nó cho phép cái cơ chế để chuyển đổi à cái array của mình từ cái chiều, từ cái dạng này sang cái dạng khác. Ví dụ đối với cái dữ liệu ma trận nó có thể biến thành dữ liệu dạng vector. Chúng ta sẽ trải",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:05:54",
      "end_timestamp": "0:06:37"
    }
  },
  {
    "page_content": "biến thành dữ liệu dạng vector. Chúng ta sẽ trải các cái giá trị của ma trận này ra thành vector. Thì để mà có thể biến một cái ma trận thành một cái vector chúng ta sẽ phải dùng cái hàm là reshape. Chúng ta sẽ phải dùng cái hàm là reshape. Thì hàm reshape sẽ cho phép chúng ta chuyển đổi dữ liệu một cách linh hoạt chuyển từ các cái kích thước này sang các kích thước khác, từ ma trận thành vector hoặc từ à vector chuyển ngược trở về thành ma trận. Rồi chúng ta sẽ thực hiện cái thao tác lặp ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 10,
      "start_timestamp": "0:06:31",
      "end_timestamp": "0:07:22"
    }
  },
  {
    "page_content": "Rồi chúng ta sẽ thực hiện cái thao tác lặp ở trên cái array như thế nào. Rồi chúng ta sẽ thực hiện cái thao tác là ghép hoặc là tách array. Tức là chúng ta sẽ có hai cái array khác nhau. Ví dụ như là 1 2 3 rồi array là 4 5 6. Chúng ta sẽ ghép hai cái array này lại với nhau theo nhiều cách. Có thể là ghép theo chiều ngang đó là 1 2 3 rồi sau đó là 4 5 6. Hoặc là chúng ta có thể ghép theo chiều dọc đó là 1 2 3 4 5 6 để tạo ra thành một cái ma trận. Đó chúng ta có thể tách. Tương tự như vậy thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 11,
      "start_timestamp": "0:07:19",
      "end_timestamp": "0:07:58"
    }
  },
  {
    "page_content": "Đó chúng ta có thể tách. Tương tự như vậy thì chúng ta sẽ từ một cái ma trận chúng ta sẽ tách ra thành từng hàng như thế nào. Đó hoặc là chúng ta làm trên những cái dữ liệu tensor thì chúng ta sẽ tách ra thành từng cái ma trận như thế nào. Thì đó là ghép và tách. Và trong cái thư viện của NumPy nó cho phép chúng ta có thể thực hiện cái thao tác tìm kiếm. Tìm kiếm trên array tức là chúng ta sẽ xác định xem những cái phần tử thỏa mãn một số cái tính chất tìm kiếm nào đó. Ví dụ ở đây chúng ta muốn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 12,
      "start_timestamp": "0:07:49",
      "end_timestamp": "0:08:40"
    }
  },
  {
    "page_content": "chất tìm kiếm nào đó. Ví dụ ở đây chúng ta muốn tìm những cái phần tử nào có cái giá trị là số chẵn. Thì khi đó với cái array này ha, chúng ta muốn tìm những cái phần tử là dạng số chẵn thì array nó sẽ cho phép mình có cái cơ chế để thực hiện cái việc tìm kiếm với cái hàm là hàm where. Và chúng ta sẽ truyền cái tính chất vô đây ví dụ như nếu chúng ta muốn tìm những số chẵn thì khi chúng ta trả về nó sẽ trả về là False. Rồi hai là chẵn đúng không? Nó sẽ là True. Ba là lẻ nó sẽ trả về là False.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 13,
      "start_timestamp": "0:08:36",
      "end_timestamp": "0:08:50"
    }
  },
  {
    "page_content": "Nó sẽ là True. Ba là lẻ nó sẽ trả về là False. True. True. Đó thì khi chúng ta sử dụng hàm where nó sẽ trả về một cái kiểu array có kích thước tương tự như cái đầu vào và nó sẽ trả về các cái giá trị True False để tương ứng là nó có thỏa mãn cái điều kiện tìm kiếm của mình hay không. Thì toàn bộ những cái nội dung này thì sẽ được trình bày trong cái code tham khảo ở đây.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oXy25Wt6rdE",
      "filename": "oXy25Wt6rdE",
      "title": "[CS116 - Buổi 2] Part 1",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong bài hôm nay thì chúng ta sẽ cùng tìm hiểu về một số cái phương pháp tinh chỉnh tham số hay còn gọi là parameter tuning. Vị trí của bài hôm nay thì đây là cái Machine Learning pipeline mà chúng ta đã biết ở trong những bài đầu tiên và tinh chỉnh tham số thì nó sẽ bao gồm hai cái module đó là model Training và model Evaluation. Nghĩa là chúng ta sẽ phải điều chỉnh các cái tham số của mô hình để làm sao đó cho cái mô hình của mình đạt được những cái độ chính xác cao nhất có thể. Thì nội dung",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oyZngWDeRb4",
      "filename": "oyZngWDeRb4",
      "title": "[CS116 - Buổi 11] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:54"
    }
  },
  {
    "page_content": "cái độ chính xác cao nhất có thể. Thì nội dung của bài hôm nay sẽ gồm các cái phần đó là tại sao chúng ta cần phải tinh chỉnh tham số, một số phương pháp tinh chỉnh tham số phổ biến ví dụ như phương pháp Grid Search Tìm kiếm theo kiểu vét cạn, phương pháp Random Search tức là chúng ta sẽ tìm kiếm theo kiểu ngẫu nhiên và phương pháp Bayesian Optimization tối ưu hóa. Đối với cái phần Tại sao chúng ta cần phải tiến hành gọi là tinh chỉnh tham số thì đầu tiên chúng ta sẽ phải hiểu cái khái niệm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oyZngWDeRb4",
      "filename": "oyZngWDeRb4",
      "title": "[CS116 - Buổi 11] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:49",
      "end_timestamp": "0:01:33"
    }
  },
  {
    "page_content": "thì đầu tiên chúng ta sẽ phải hiểu cái khái niệm tham số trong cái mô hình máy học đó là gì? Tham số trong mô hình đó là tên tiếng Anh là parameter thì đây là các cái biến số mà mô hình học được, mà mô hình học từ dữ liệu. Nó sẽ học được từ dữ liệu huấn luyện. Thế thì chúng ta xét một cái ví dụ là cái mạng Neural Network như sau ha. Chúng ta sẽ xét một cái mạng Neural Network thì trong cái mạng Neural Network thì tham số mô hình, tham số mô hình của mạng Neural Network nó sẽ là các cái trọng số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oyZngWDeRb4",
      "filename": "oyZngWDeRb4",
      "title": "[CS116 - Buổi 11] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:26",
      "end_timestamp": "0:02:13"
    }
  },
  {
    "page_content": "của mạng Neural Network nó sẽ là các cái trọng số của các cái cạnh nối từ cái lớp trước đó cho đến cái lớp hiện tại. Ví dụ trọng số của các cái cạnh nối này sẽ là cái tham số của mô hình và các cái tham số này thì nó sẽ được cập nhật thường xuyên trong cái quá trình huấn luyện và chúng ta sẽ fit cái dữ liệu đầu vào X và chúng ta sẽ so sánh cái này với lại cái dữ liệu thực tế y thì chúng ta sẽ tìm ra được là các cái tham số của mô hình như thế nào để cho nó tối ưu nhất để cho cái giá trị đầu ra",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oyZngWDeRb4",
      "filename": "oyZngWDeRb4",
      "title": "[CS116 - Buổi 11] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:02:05",
      "end_timestamp": "0:02:48"
    }
  },
  {
    "page_content": "để cho nó tối ưu nhất để cho cái giá trị đầu ra của mình nó xấp xỉ với lại cái giá trị dự đoán, cái giá trị dự đoán nó xấp xỉ với lại cái giá trị thực tế nhất. Còn một cái loại tham số nữa đó chính là siêu tham số hay còn gọi là hyper parameter. Thì đây là cái tham số nó quy định cái cấu hình của mô hình trước khi huấn luyện. Nghĩa là sao? Ví dụ trong cái mạng Neural Network thì chúng chúng ta sẽ thấy là có các cái hidden layer tức là các cái lớp ẩn. Thế thì ở đây chúng ta sẽ cấu hình cái mạng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oyZngWDeRb4",
      "filename": "oyZngWDeRb4",
      "title": "[CS116 - Buổi 11] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:41",
      "end_timestamp": "0:03:18"
    }
  },
  {
    "page_content": "ẩn. Thế thì ở đây chúng ta sẽ cấu hình cái mạng này trong cái hình ví dụ này thì chúng ta sẽ cấu hình đó là có các cái layer có bao nhiêu lớp ẩn. Ví dụ như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oyZngWDeRb4",
      "filename": "oyZngWDeRb4",
      "title": "[CS116 - Buổi 11] Part 1",
      "chunk_id": 5,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "dưới đây là những cái hình ảnh minh họa cho các cái dạng thức biểu đồ ở đây các cái biểu đồ dạng thanh chính là cái histogram rồi cái biểu đồ đường này đó là biểu đồ về mật độ và đây chính là box plot rồi về phân tích ví dụ về phân tích đơn biến thì chúng ta sẽ có các cái biểu đồ như sau đó là các cái biểu đồ về đếm số lượng theo cái giá trị của cái room service đó thì chúng ta sẽ thấy là cái biểu đồ này với cái biểu đồ này thì chúng ta sẽ cảm nhận được là dữ liệu của mình nó có cái tính chất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:04:48"
    }
  },
  {
    "page_content": "nhận được là dữ liệu của mình nó có cái tính chất như thế nào Tức là những cái giá trị từ 0 cho đến 10 Hoặc là những cái giá trị đầu tiên chúng ta sẽ thấy là giá trị của mình nó tập trung chủ yếu là trong cái phạm vi này Nhưng mà từ cái vị trí ngưỡng này trở về sau Ví dụ như là từ khoảng 1000 trở về sau thì có xu hướng là giảm rất là đáng kể thì từ cái biểu đồ histogram này thì chúng ta thấy là dữ liệu của mình nó có cái tính thiên lệch nó có cái tính thiên lệch rất là cao tương tự như vậy cho",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 1,
      "start_timestamp": "0:00:43",
      "end_timestamp": "0:01:23"
    }
  },
  {
    "page_content": "tính thiên lệch rất là cao tương tự như vậy cho cái biểu đồ về FoodC đúng không Thì chúng ta thấy là nó bị thiên lệch rất là lớn rồi và khi chúng ta chuyển về cái dạng biểu đồ histogram thông qua một cái phép biến đổi thì chúng ta thấy là cái tính chất cái phân bố của dữ liệu của mình nó cũng đã khác so với lại cái phiên bản ban đầu thì đây chính là cái phân tích đơn biến rồi đối với cái phân tích hai biến thì chúng ta sẽ xác định xem là có tồn tại cái mối liên hệ về thống kê cái mối liên hệ về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 2,
      "start_timestamp": "0:01:17",
      "end_timestamp": "0:01:56"
    }
  },
  {
    "page_content": "cái mối liên hệ về thống kê cái mối liên hệ về thống kê giữa hai cái biến hay không đó thì chúng ta sẽ có ba cái loại chính cái loại đầu tiên đó là phân tích giữa hai cái biến mà đều là cùng ở dạng số (numeric) numeric với numeric rồi phân tích cái dạng là số và cái kiểu phân loại numeric và category và cuối cùng đó là giữa hai cái biến mà có cái kiểu là phân loại và phân loại (category và category) thì đối với cái phân tích dạng số - số thì chúng ta có hai cái biến này cần và được hai cái biến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 3,
      "start_timestamp": "0:01:51",
      "end_timestamp": "0:02:37"
    }
  },
  {
    "page_content": "ta có hai cái biến này cần và được hai cái biến được so sánh với nhau thì nó đều là dữ liệu dạng số ha và chúng ta có một số cái phương pháp để trực quan đó là chúng ta có thể sử dụng cái biểu đồ dạng phân tán scatter plot biểu đồ dạng cặp pair plot hoặc là biểu đồ về cái ma hoặc là về cái ma trận tương quan correlation Matrix và dưới đây là các cái ví dụ biểu đồ phân tán thì chúng ta sẽ vẽ nó dưới dạng là các cái điểm rời rạc trong đó thì điểm rời rạc này nó sẽ được tạo bởi một cặp giá trị là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 4,
      "start_timestamp": "0:02:32",
      "end_timestamp": "0:03:13"
    }
  },
  {
    "page_content": "rời rạc này nó sẽ được tạo bởi một cặp giá trị là trục hoành và trục tung Còn đối với cái ma trận tương quan thì chúng ta sẽ thấy là chúng ta sẽ có một cái ma trận trong đó mỗi một cái ô ví dụ ô ở đây nó sẽ thể hiện cái mối tương quan giữa room service và cái shopping còn các cái giá trị mà trên cái trục đường chéo này thì nó luôn luôn là là một tại vì giữa cái FoodC đúng không Ví dụ ở đây là FoodC với lại FoodC thì độ tương quan của nó luôn luôn là 1 và dựa trên cái biểu đồ cái ma trận tương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 5,
      "start_timestamp": "0:03:07",
      "end_timestamp": "0:03:48"
    }
  },
  {
    "page_content": "là 1 và dựa trên cái biểu đồ cái ma trận tương quan này thì chúng ta sẽ phát hiện ra là những cái cặp dữ liệu nào có cái mối tương quan cao những cái cặp dữ liệu nào có cái mối tương quan thấp thì chúng ta sẽ đi tiến hành phân tích trên những cái cặp dữ liệu đó những cái cặp đặc trưng đó và đối với cái dữ liệu dạng số và phân loại thì một biến sẽ là kiểu số và biến khác thì nó sẽ là kiểu phân loại thì ở đây chúng ta có thể sử dụng cái phương pháp đó là multiple density plots tức là chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 6,
      "start_timestamp": "0:03:43",
      "end_timestamp": "0:04:32"
    }
  },
  {
    "page_content": "đó là multiple density plots tức là chúng ta sẽ có nhiều À cái biểu đồ mật độ trong cùng một cái sơ đồ đó ví dụ như ở đây chúng ta sẽ có cái à chúng ta sẽ sử dụng cái hai cái giá trị là Male và Female thì đây là hai cái giá trị phân loại và ứng với từng cái giá trị phân loại này thì chúng ta sẽ vẽ cái biểu đồ à mật độ tương ứng đó rồi đối với cái boxplot thì chúng ta sẽ phân ra Ví dụ như mỗi một cái box này thì nó tương ứng với lại một cái giá trị của cái kiểu phân loại và cái chiều còn lại cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 7,
      "start_timestamp": "0:04:24",
      "end_timestamp": "0:05:15"
    }
  },
  {
    "page_content": "của cái kiểu phân loại và cái chiều còn lại cái biến còn lại tức là kiểu số thì chúng ta sẽ Ờ vẽ nó dưới dạng là hình là cái box là cái hộp như vậy mỗi một cái box là tương ứng với một cái giá trị của kiểu phân loại và cái giải các cái giá trị min max rồi Q1 q3 và median ở đây thì nó được tổng hợp Nó được thống kê từ cái cột dữ liệu cái đặc trưng mà dạng dạng số thì đó chính là cái cách để mà phân tích dưới dạng là biểu đồ dạng số và phân loại tiếp theo đó là cái dữ liệu dạng phân loại với phân",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 8,
      "start_timestamp": "0:05:10",
      "end_timestamp": "0:05:51"
    }
  },
  {
    "page_content": "theo đó là cái dữ liệu dạng phân loại với phân loại thì cả hai biến đều đó là kiểu dữ liệu phân loại thì chúng ta sẽ có một số cái phương pháp trực quan để có thể sử dụng được trong cái trường hợp này đó là chúng ta có thể sử dụng biểu đồ dạng xếp chồng (stacked bar chart) hoặc là chúng ta có thể sử dụng biểu đồ theo cụm là cluster bar chart thì ở đây là cái biểu đồ theo dạng là nhóm theo cụm Ví dụ như với cái trục hoành đúng không thì chúng ta sẽ thấy là có các cái giá trị đó là các cái giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 9,
      "start_timestamp": "0:05:47",
      "end_timestamp": "0:06:27"
    }
  },
  {
    "page_content": "sẽ thấy là có các cái giá trị đó là các cái giá trị của một cái đặc trưng dữ liệu của mình Ví dụ ở đây là age là tuổi đó thì chúng ta có cái khoảng độ tuổi khác nhau và tương ứng với một cái khoảng độ tuổi thì chúng ta sẽ có ờ một cái trường thuộc tính khác cái trường thuộc tính khác và nó nhận hai cái giá trị hai giá trị là True và False thì đây là hai cái giá trị dạng phân loại luôn đó thì tuổi nó đã được phân loại thành các cái khoảng tuổi và cái thuộc tính thứ hai đó là transported thì nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 10,
      "start_timestamp": "0:06:22",
      "end_timestamp": "0:07:00"
    }
  },
  {
    "page_content": "cái thuộc tính thứ hai đó là transported thì nó cũng là cái giá trị phân loại như vậy thì ở đây có bao nhiêu cái giá trị phân loại này thì chúng ta sẽ có bấy nhiêu cột song hành song song với nhau Ví dụ ở đây sẽ là có hai giá trị là False và True thì ở đây chúng ta sẽ có là hai cái cột thì đây là cái kiểu biểu đồ cột theo cụm hoặc là chúng ta có thể sử dụng biểu đồ cột xếp chồng tức là theo cái trục ngang này thì chúng ta cũng sẽ là các cái giá trị của một cái biến phân loại và nếu như cái biến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 11,
      "start_timestamp": "0:06:53",
      "end_timestamp": "0:07:40"
    }
  },
  {
    "page_content": "của một cái biến phân loại và nếu như cái biến phân loại còn lại của mình nó có nhiều giá trị nó không phải là hai giá trị mà nó có nhiều giá trị này thì chúng ta cũng có thể là mỗi một cái chồng như thế này đó sẽ tương ứng cho một cái giá trị của một cái biến phân loại thì chúng ta có thể sử dụng hai cái loại này một đó là chúng ta xếp ngang song song với nhau cho từng cái giá trị hai đó là chúng ta sẽ chồng lên nhau và phân tích đa biến thì Nếu như à chúng ta phân tích mà có nhiều hơn hai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 12,
      "start_timestamp": "0:07:36",
      "end_timestamp": "0:08:16"
    }
  },
  {
    "page_content": "Nếu như à chúng ta phân tích mà có nhiều hơn hai biến nhiều hơn hai biến cùng một lúc đó thì để trực quan hóa thì chúng ta cần phải sử dụng nhuần nhuyễn các cái loại biểu đồ tương quan à chúng ta sẽ sử dụng các cái loại biểu đồ tương ứng với cái tổ hợp biến đó Tức là nó sẽ tùy vô các cái biến của mình Ví dụ như ở đây chúng ta có ba biến thì số tổ hợp của cái ba biến này nó cũng rất là đa dạng nó có thể vừa là ở dạng số, số và số nó cũng có thể là số, phân loại và phân loại rồi Nó có thể là ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 13,
      "start_timestamp": "0:08:11",
      "end_timestamp": "0:08:49"
    }
  },
  {
    "page_content": "là số, phân loại và phân loại rồi Nó có thể là ở dạng là tất cả ba đều cùng là phân loại thì khi đó chúng ta sẽ phải sử dụng một cách nhuần nhuyễn các cái loại biểu đồ tương ứng với lại các cái Ờ cái tính chất của các cái biến này ví dụ như trong cái sơ đồ này chúng ta thấy đó là trục hoành đúng không Thì là các cái giá trị dạng số và trục tung là các cái giá trị dạng số luôn và từng cái màu ở đây thì chúng ta sẽ thấy là nó có hai màu tương ứng cho cái đặc trưng thứ ba đó là giới tính thì mỗi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 14,
      "start_timestamp": "0:08:44",
      "end_timestamp": "0:09:31"
    }
  },
  {
    "page_content": "cho cái đặc trưng thứ ba đó là giới tính thì mỗi màu này nó sẽ là một. À mỗi màu này tương ứng là một cái giá trị trong cái cột à trong cái đặc trưng dạng phân loại đó tương tự như vậy thì chúng ta có thể sử dụng cái biểu đồ dạng boxplot thì trục hoành đó là biểu tượng biểu tượng cho cái à giá trị đó là cái đặc trưng đó là giới tính và nó nhận hai cái giá trị đó là Male và Female trục tung đó là giá trị dạng số Ờ numeric rồi Trong đó thì với một cái giá trị của cái biến Ờ giới tính thì chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 15,
      "start_timestamp": "0:09:28",
      "end_timestamp": "0:10:11"
    }
  },
  {
    "page_content": "cái giá trị của cái biến Ờ giới tính thì chúng ta lại có hai cái boxplot tương ứng cho cái feature thứ ba đúng không thì đây là cái feature số 1 nè Đây là cái feature số 2 nè Và khi chúng ta chia ra làm hai loại như thế này và mỗi loại là một màu thì nó tương ứng là chúng ta đang phân tích cho cái feature số 3 và để phát hiện cái dữ liệu bị thiếu thì chúng ta có thể sử dụng các cái hàm là isna của dataframe Như vậy thì trong cái slide Từ đây trở về sau thì chúng ta sẽ liên quan đến cái công",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 16,
      "start_timestamp": "0:10:06",
      "end_timestamp": "0:10:49"
    }
  },
  {
    "page_content": "trở về sau thì chúng ta sẽ liên quan đến cái công việc đó là phát hiện ra những cái vấn đề trong cái dữ liệu của mình thì cái vấn đề đầu tiên đó chính là vấn đề dữ liệu bị thiếu chúng ta nhìn vô cái bản dữ liệu đây chúng ta sẽ thấy có một số cái vị trí là dữ liệu của mình nó bị NaN đó thì đây chính là một số cái tình huống dữ liệu bị thiếu và chúng ta có thể loại bỏ các cái giá trị bị thiếu này thông qua cái hàm là drop NA rồi phát hiện dữ liệu bị nhiễu thì chúng ta sẽ dựa trên các cái phương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 17,
      "start_timestamp": "0:10:42",
      "end_timestamp": "0:11:24"
    }
  },
  {
    "page_content": "bị nhiễu thì chúng ta sẽ dựa trên các cái phương pháp đó là thống kê Ví dụ nếu như cái dữ liệu của mình mà nó tuân theo cái phân bố Gaussian hoặc là tương tự như Gaussian thì chúng ta có thể sử dụng các cái giá trị đó là giá trị trung bình (mu) và với cái giá trị ở đây chúng ta sẽ có các cái khoảng giá trị nếu như mu mà trừ 2 Sigma đúng không Chúng ta có giá trị ở đây đó thì nếu như cái giá trị nào mà nhỏ hơn mu trừ 2 Sigma (Tức là nó chỉ chiếm khoảng là 2,1 phần trăm thôi) thì những cái giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 18,
      "start_timestamp": "0:11:18",
      "end_timestamp": "0:12:01"
    }
  },
  {
    "page_content": "khoảng là 2,1 phần trăm thôi) thì những cái giá trị nào mà rớt vào trong cái khoảng này thì chúng ta xem nó là outlier tương tự như vậy cho mu cộng 2 Sigma thì nếu như giá trị của mình mà rớt trong khoảng này thì chúng ta sẽ xem nó là outlier còn đối với những cái dữ liệu mà không có tuân theo phân bố chuẩn không theo không có tuân theo phân bố Gaussian thì chúng ta sẽ dùng cái phương pháp là IQR là Interquartile Range bằng cách đó là chúng ta sẽ xác định các cái giá trị Q1 và Q3 rồi sau đó lấy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 19,
      "start_timestamp": "0:11:58",
      "end_timestamp": "0:12:38"
    }
  },
  {
    "page_content": "xác định các cái giá trị Q1 và Q3 rồi sau đó lấy Q3 - Q1 thì chúng ta sẽ có cái khoảng giá trị là IQR đó (Interquartile Range) và với cái khoảng giá trị này chúng ta lấy Q1 trừ cho 1,5 IQR thì chúng ta ra được cái giá trị này lấy Q3 cộng cho 1,5 IQR thì chúng ta sẽ ra được cái giá trị này và tất cả những cái giá trị nào mà nằm ngoài cái giá trị minimum và maximum trong nháy kép này Tức là ở đây cái giá trị này nó không thực sự là cái giá trị nhỏ nhất và giá trị này nó không thực sự là giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 20,
      "start_timestamp": "0:12:35",
      "end_timestamp": "0:13:16"
    }
  },
  {
    "page_content": "nhất và giá trị này nó không thực sự là giá trị lớn nhất nên mình mới để dấu nháy kép đó thì nếu như cái giá trị nào mà vượt quá cái giá trị này thì nó được gọi là outlier và giá trị nào mà vượt qua cái giá trị ở đây thì nó là outlier thì đây là cái phương pháp các cái phương pháp để mà phân tích và xác định dữ liệu là nhiễu dựa trên thống kê và trong cái phần tiền xử lý dữ liệu thì chúng ta sẽ à xem thêm chúng ta sẽ sử dụng các cái phân tích thống kê này để đưa vào cái quá trình tiền xử lý dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 21,
      "start_timestamp": "0:13:11",
      "end_timestamp": "0:13:55"
    }
  },
  {
    "page_content": "kê này để đưa vào cái quá trình tiền xử lý dữ liệu trong tiền xử lý dữ liệu chúng ta sẽ nhắc lại cái vấn đề này một lần nữa và chúng ta sẽ có các cái giải pháp để xử lý các cái giá trị outlier này như thế nào như vậy thì trong bài Ngày hôm nay chúng ta đã cùng tìm hiểu về Machine Learning Pipeline. Machine Learning Pipeline là một trong những cái nội dung rất là quan trọng Tại vì nó định hình cho chúng ta biết là cái quy trình Chúng ta cần phải xây dựng à Một cái mô hình máy học là như thế nào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 22,
      "start_timestamp": "0:13:50",
      "end_timestamp": "0:13:55"
    }
  },
  {
    "page_content": "xây dựng à Một cái mô hình máy học là như thế nào rồi và đồng thời là vai trò của từng cái bước trong cái mô hình máy học trong cái quy trình xây dựng máy học đó ra sao và chúng ta sẽ tiến hành Ờ phân tích và tìm hiểu các cái phương pháp cho cái bước đầu tiên đó là phân tích dữ liệu các cái phương pháp để mà phân tích dữ liệu đó là gì rồi các cái vấn đề chúng ta sẽ phát hiện các cái vấn đề trong cái dữ liệu của mình ra sao để làm tiền đề cho cái bước là data preprocessing tiền đề cho cái bước",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "bước là data preprocessing tiền đề cho cái bước là tiền xử lý dữ liệu về sau thì đó là các cái phương pháp được gọi là EDA là Exploratory Data Analysis",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=oZa-m3pb1SQ",
      "filename": "oZa-m3pb1SQ",
      "title": "[CS116 - Buổi 3] Part 3 (tt)",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "rồi sau khi chúng ta đã cài đặt xong thì chúng ta sẽ activate cái Streamlit environment và chúng ta sẽ cài đặt scikit learn 1.3.2 scikit-learn rồi thư viện của mình là scikit learn install rồi sau khi cài đặt cái thư viện này thì chúng ta đã hoàn toàn có thể chạy được và để cài đặt cái này thì nó sẽ tốn khoảng 1 cho đến 2 phút rồi Ok như vậy chúng ta sẽ vào cái thư mục là document CD vào thư mục Project và Streamlit để chạy thì chúng ta sẽ chạy là streamlit run và tên của cái file của mình nó sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pB7Y3ytmjZ0",
      "filename": "pB7Y3ytmjZ0",
      "title": "[CS116 - Buổi 14] Part 3_3",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:01:33"
    }
  },
  {
    "page_content": "streamlit run và tên của cái file của mình nó sẽ là Model App Web rồi sau khi chạy Xong thì tự động nó sẽ tạo ra một cái nó sẽ tự động mở cái đường dẫn của trang web của mình và chúng ta sẽ lấy cái port là 8501 và ở đây thì chúng ta sẽ nhập các con số ví dụ như chúng ta sẽ điền vào là 120 và trọng lượng đó là như đây là chúng ta sẽ mở cái file mở một cái file mẫu ha Ví dụ như 110 kích thước là 110 cm và Trọng lượng là 120 kg thì giá của mình là khoảng 500.000đ Thế thì ở đây chúng ta sẽ nhập thử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pB7Y3ytmjZ0",
      "filename": "pB7Y3ytmjZ0",
      "title": "[CS116 - Buổi 14] Part 3_3",
      "chunk_id": 1,
      "start_timestamp": "0:01:27",
      "end_timestamp": "0:02:21"
    }
  },
  {
    "page_content": "500.000đ Thế thì ở đây chúng ta sẽ nhập thử ha 110 giá là một à trọng lượng là 120 và predict Price thì nó sẽ ra là khoảng 509.000 như vậy chúng ta thấy cái con số này nó sai lệch là khoảng 9000 090 đồng so với lại cái giá trị thực đó thì có thể thấy là mô hình của mình nó cũng đã vận hành khá là hiệu quả cuối cùng thì chúng ta sẽ triển khai cái ứng dụng này trên cái trang web thật thì cái trang web thật nó sẽ phải có cái domain và để tạo được cái domain thì nó sẽ có một cái gọi là DNS server",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pB7Y3ytmjZ0",
      "filename": "pB7Y3ytmjZ0",
      "title": "[CS116 - Buổi 14] Part 3_3",
      "chunk_id": 2,
      "start_timestamp": "0:02:16",
      "end_timestamp": "0:02:55"
    }
  },
  {
    "page_content": "cái domain thì nó sẽ có một cái gọi là DNS server chúng ta sẽ cấu hình cái DNS server để có thể trỏ cái đường dẫn đến trỏ cái domain đến cái web server Ví dụ như ở đây có một cái địa chỉ IP là 10.11.12.13 thì chúng ta sẽ sử dụng một cái Nginx web server ở đây là Nginx web server chúng ta sẽ vào cái đường dẫn chứa cái sites available Sau đó chúng ta sẽ chỉnh sửa bằng cái lệnh vim chỉnh sửa cái file default cái file cấu hình này và nếu chúng ta muốn để là domain.com ví dụ vậy đây sẽ là cái domain",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pB7Y3ytmjZ0",
      "filename": "pB7Y3ytmjZ0",
      "title": "[CS116 - Buổi 14] Part 3_3",
      "chunk_id": 3,
      "start_timestamp": "0:02:51",
      "end_timestamp": "0:03:49"
    }
  },
  {
    "page_content": "để là domain.com ví dụ vậy đây sẽ là cái domain name của các bạn SUT demo SUT estimate đó thì chúng ta sẽ cấu hình như sau chúng ta sẽ tạo một cái record tên là location đó rồi và ở đây thì nó sẽ trỏ Nó sẽ trỏ một cái địa chỉ IP thì đây là 20.45 thì đây là cái server để host cái model của mình và port là 8501 thì đây là cái port mặc định của Streamlit thì trên cái con Server này trên cái con server này thì chúng ta sẽ phải cài cái thư viện Streamlit và chúng ta sẽ host cái dịch vụ web với cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pB7Y3ytmjZ0",
      "filename": "pB7Y3ytmjZ0",
      "title": "[CS116 - Buổi 14] Part 3_3",
      "chunk_id": 4,
      "start_timestamp": "0:03:39",
      "end_timestamp": "0:04:21"
    }
  },
  {
    "page_content": "và chúng ta sẽ host cái dịch vụ web với cái port là 8501 thì với cái cách làm này thì nó sẽ giúp cho chúng ta tạo ra được một cái đường dẫn là SUT demo SUT estimate và nó sẽ ra cái giao diện trang web giống như ở dưới đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pB7Y3ytmjZ0",
      "filename": "pB7Y3ytmjZ0",
      "title": "[CS116 - Buổi 14] Part 3_3",
      "chunk_id": 5,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng tìm hiểu về cái thư viện Matplotlib thì đây là một trong những cái thư viện dùng để trực quan hóa rất là nổi tiếng và cái cách khai báo của chúng ta đó là chúng ta sẽ import matplotlib.pyplot Đây là cái module mà được sử dụng nhiều nhất trong cái Tutorial ngày hôm nay và chúng ta sẽ viết tắt nó là bằng chữ plt thì đây là cái quy tắc chung được cộng đồng sử dụng rất là nhiều ha. Thao tác đầu tiên đó là vẽ thì ở đây chúng ta đang khởi tạo ra một cái mảng X",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:38"
    }
  },
  {
    "page_content": "ở đây chúng ta đang khởi tạo ra một cái mảng X gồm có các cái giá trị nè np.arange thì trong cái bài về Numpy á chúng ta biết rồi np.arange là từ 0 cho đến 3 pi bước nhảy của mình là 0.1 và chúng ta sẽ lấy cái X này chúng ta sẽ truyền vào np.sin thì np.sin á nó thực hiện cái thao tác tính giá trị sin trên một cái array đó thì y của mình sẽ là các cái giá trị sin của x rồi và chúng ta sẽ dùng cái hàm là plt.plot(x, y) thì để hiển thị kết quả chúng ta sẽ dùng là plt.style.use rồi chúng ta có thể",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 1,
      "start_timestamp": "0:00:32",
      "end_timestamp": "0:01:38"
    }
  },
  {
    "page_content": "ta sẽ dùng là plt.style.use rồi chúng ta có thể vẽ thay vì chúng ta vẽ một đường như thế này thì trong Matplotlib chúng ta cũng có thể vẽ nhiều đường Ví dụ ở đây chúng ta sẽ có y_sin và y_cos đúng không Rồi chúng ta sẽ gán nhãn label, gán label cho các cái đường này ví dụ như đối với x, y_sin thì chúng ta sẽ gán label cho nó là đường sin và y_cos thì chúng ta sẽ gán nhãn cho nó là cosin và chúng ta có thể chú thích trên các cái trục là trục ngang trục hoành và trục tung là xlabel và ylabel thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 2,
      "start_timestamp": "0:01:33",
      "end_timestamp": "0:02:17"
    }
  },
  {
    "page_content": "trục hoành và trục tung là xlabel và ylabel thì trên trục hoành chúng ta sẽ ghi là x-axis label và trên trục tung là y label và chúng ta có thể đặt tên cho cái biểu đồ của mình thì chúng ta thấy nè cái lệnh legend này nè đó thì nó sẽ lấy cái label là sin và cosin ra đây nó sẽ điền qua đây sin, cosin rồi cái tiêu đề là sin và cosin Đây là cái tiêu đề của tấm hình và chú thích theo trục đó tức là xlabel và ylabel thì nó tương ứng là đây Chú thích theo trục ý nghĩa của trục tung và ý nghĩa của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 3,
      "start_timestamp": "0:02:10",
      "end_timestamp": "0:02:54"
    }
  },
  {
    "page_content": "theo trục ý nghĩa của trục tung và ý nghĩa của trục hoành rồi đây là chúng ta vẽ dưới dạng là đường liên tục nối tiếp nhau chúng ta sẽ có một cái kiểu vẽ đó là scatter, scatter là chúng ta sẽ vẽ dưới dạng những cái điểm rời rạc chúng ta sẽ vẽ những cái điểm rời rạc và không có điểm nào nối với điểm nào tức là các cái điểm nó sẽ độc lập nhau thì x y ở đây là các cái giá trị random gồm 50 các phần tử random thì giá trị random ở đây là từ 0 cho đến 1 ha và cứ mỗi giá trị x và một cặp một cặp giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 4,
      "start_timestamp": "0:02:49",
      "end_timestamp": "0:03:33"
    }
  },
  {
    "page_content": "1 ha và cứ mỗi giá trị x và một cặp một cặp giá trị x và y thì chúng ta sẽ có một cái tọa độ trong không gian hai chiều này rồi chúng ta sẽ chọn các màu của mình cũng random luôn màu random từ 0 cho đến 2 và số lượng cái màu mà mình lấy ra để random đó là 50 cái màu thì là ở đây chúng ta chỉ là từ 0 và 1 hàm ý là chỉ có hai màu thôi tức là 0 hoặc 1 rồi thì colors chúng ta sẽ là plt.scatter(x, y) tức là các cái giá trị theo trục X và giá trị trục y vẽ rời rạc. rạc. nhau rồi thì đây là kiểu vẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 5,
      "start_timestamp": "0:03:26",
      "end_timestamp": "0:04:12"
    }
  },
  {
    "page_content": "y vẽ rời rạc. rạc. nhau rồi thì đây là kiểu vẽ rời rạc trong trường hợp nếu như chúng ta muốn minh họa cái hình ảnh mà dưới dạng nhiều cái phần hoặc là nhiều cái ô khác nhau thì chúng ta có thể dùng subplot ở đây chúng ta sẽ có một cái ví dụ ha là x là một cái giá trị chúng ta lấy từ 0 cho đến 3 pi và chúng ta sẽ có hai cái đường là sin và y_sin. Thế thì chúng ta muốn vẽ hai cái đường sin và y_sin này trên cái ô đầu tiên thì chúng ta sẽ dùng cái lệnh là subplot 211 thì 211 này hàm ý là gì? 211",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 6,
      "start_timestamp": "0:04:06",
      "end_timestamp": "0:05:01"
    }
  },
  {
    "page_content": "lệnh là subplot 211 thì 211 này hàm ý là gì? 211 này là chúng ta sẽ có hai hàng và một cột trong đó, trong đó cái việc vẽ nữa tiếp theo chúng ta sẽ chuẩn bị vẽ là chúng ta sẽ làm chúng ta sẽ thực hiện vẽ trên cái ô đầu tiên tức là ô số 1. Rồi sau đó thì chúng ta sẽ có cái lệnh là subplot và chúng ta sẽ có cái cái ký hiệu là subplot 212 tức là hai hàng hai hàng và một cột. Tuy nhiên chúng ta sẽ vẽ rồi và chúng ta mỗi cái hình sin và hình cos sẽ được vẽ trên một cái ô khác nhau đó thì ở hàng ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 7,
      "start_timestamp": "0:04:53",
      "end_timestamp": "0:05:45"
    }
  },
  {
    "page_content": "được vẽ trên một cái ô khác nhau đó thì ở hàng ở đây chúng ta có hai hàng nè, Một Cột nè. Đây là hàng số 1, đây là hàng số hai và có một cột Thôi thì cái cột đầu tiên cái ô đầu tiên chúng ta sẽ vẽ đường sin. Ô Thứ hai chúng ta sẽ vẽ hình cos thì chi tiết cho cái phần này chúng ta có thể tham khảo thêm trong cái tài liệu ở đây đó là subplot subplot. rồi về các cái loại biểu đồ thì chúng ta có những cái loại biểu đồ rất là phổ biến đó chính là scatter là vẽ dạng rời rạc giống như hồi nãy. Line",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 8,
      "start_timestamp": "0:05:39",
      "end_timestamp": "0:06:30"
    }
  },
  {
    "page_content": "là vẽ dạng rời rạc giống như hồi nãy. Line plot là plot (vẽ dạng đường) thì nó sẽ vẽ ra các cái điểm và nối tiếp nhau bằng các cái đường đường thẳng. Bar chart là vẽ dưới dạng là biểu đồ cột và pie chart tức là vẽ dưới dạng biểu đồ tròn. Ở đây chúng ta sẽ thấy là có bốn cái loại biểu đồ khác nhau tương ứng với lại từng cái ô trong cái subplot của mình. Cái subplot đầu tiên đó là 221 tức là hai hàng hai cột và ô đầu tiên tức là đây. Ô tiếp theo đó là 222 tức là hai hàng hai cột và cái ô thứ hai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 9,
      "start_timestamp": "0:06:21",
      "end_timestamp": "0:07:13"
    }
  },
  {
    "page_content": "là 222 tức là hai hàng hai cột và cái ô thứ hai là cái đó và hai hàng hai cột tức là hai hàng và hai cột và ô thứ ba tức là cái ô này rồi 224 tức là chúng ta sẽ vẽ lên đây thì đây là cái đoạn code minh họa cho cái việc vẽ với rất nhiều những cái ô khác nhau với nhiều những loại biểu đồ khác nhau. Rồi một cái thao tác nữa đó chính là cho phép chúng ta có thể vẽ và đọc và hiển thị hình ảnh thì ở đây chúng ta sẽ có một cái ví dụ là chúng ta sẽ đọc một cái ảnh từ file chúng ta sẽ truyền cái đường",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 10,
      "start_timestamp": "0:07:08",
      "end_timestamp": "0:07:38"
    }
  },
  {
    "page_content": "một cái ảnh từ file chúng ta sẽ truyền cái đường dẫn của cái file ảnh của mình lên và chúng ta sẽ dùng là plt.imread và hiển thị cái cái ảnh của mình đã load lên từ file lên như thế này rồi sau đó là plt.imshow sau khi chúng ta đọc xong là chúng ta sẽ plt.imshow thì trên đây là một số cái hàm phổ biến trong thư viện Matplotlib mà chúng ta sẽ dùng trong phạm vi của môn học này.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pBrGDARCTE8",
      "filename": "pBrGDARCTE8",
      "title": "[CS116 - Buổi 2] Part 5",
      "chunk_id": 11,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "phương pháp tiếp theo mà chúng ta sẽ cùng tìm hiểu đó chính là phương pháp random search hay là tìm kiếm ngẫu nhiên thì ý tưởng của phương pháp này nó cũng rất là đơn giản tương tự như là cái phương pháp trước đó thay vì chúng ta quét cạn trên tất cả các cái không gian tham số ví dụ như chúng ta thử nghiệm ở đây sau đó Chúng ta thử ở đây thử ở đây và thử ở đây thì phương pháp này nó sẽ ngẫu nhiên nó sẽ chọn ngẫu nhiên các cái tổ hợp tham số ờ thay vì là lấy mẫu đều chúng ta duyệt từ trái qua",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:34"
    }
  },
  {
    "page_content": "thay vì là lấy mẫu đều chúng ta duyệt từ trái qua phải từ trên xuống dưới thì chúng ta không làm như vậy nữa mà chúng ta sẽ nhảy đến những cái cấu hình tham số bất kỳ rồi sau đó chúng ta cũng lần lượt thử và chọn ra cái tổ hợp mà cho cái mô hình tốt nhất ví dụ như sau khi chúng ta thử với rất nhiều những cái lần random thì chúng ta thấy là tại đây cho cái độ chính xác của mình là tốt nhất như vậy thì chúng ta sẽ lấy cái siêu tham số này để đi huấn luyện lại trên đầy đủ toàn bộ cái dữ liệu huấn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:31",
      "end_timestamp": "0:01:11"
    }
  },
  {
    "page_content": "luyện lại trên đầy đủ toàn bộ cái dữ liệu huấn luyện của mình và để so sánh cái phương pháp Grid Search với lại cái phương pháp random Search thì chúng ta sẽ có một cái hình ảnh minh họa như sau đối với cái phương pháp Grid Search thì cái không gian tham số của mình là lấy mẫu đều và lấy trên tất cả những cái khả năng mà có thể xảy ra cho từng cái trục của cái siêu tham số đó thì với cái phương pháp lấy mẫu đều thì đâu đó chúng ta vẫn có khả năng là chúng ta bỏ sót những cái điểm mà cho cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:07",
      "end_timestamp": "0:01:47"
    }
  },
  {
    "page_content": "năng là chúng ta bỏ sót những cái điểm mà cho cái hiệu quả của mô hình nó cao nhất còn phương pháp random phương pháp random thì nó sẽ lấy ngẫu nhiên và nó sẽ có cái khả năng là nó tìm thấy cái khu vực mà cho cái độ hiệu quả cao của cái mô hình của mình tuy nhiên nếu như cái không gian tham số của mình nó quá lớn thì rõ ràng là cái việc random này nó cũng không chắc chắn không có gì đảm bảo rằng là nó sẽ đến được điểm tối ưu toàn cục của cái mô hình của mình và một lần nữa thì chúng ta sẽ cùng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:01:41",
      "end_timestamp": "0:02:23"
    }
  },
  {
    "page_content": "hình của mình và một lần nữa thì chúng ta sẽ cùng bình luận về những cái ưu điểm và khuyết điểm của cái mô hình random search này về ưu điểm thì cũng tương tự như Grid Search thì phương pháp này rất là đơn giản dễ cài đặt và nó rất là hiệu quả đối với cái không gian tìm kiếm lớn nếu như đối với cái phương pháp Grid Search số lượng tham số mà nhiều đồng thời đó là các cái giải giá trị mà chúng ta lấy rất là dày thì dẫn đến là số phép thử của mình cực kỳ lớn hay nói cách khác là số cái không gian",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:17",
      "end_timestamp": "0:02:53"
    }
  },
  {
    "page_content": "cực kỳ lớn hay nói cách khác là số cái không gian tìm kiếm của mình rất là lớn còn đối với cái phương pháp random search chúng ta chỉ cần cho nó biết trước cái số lần thử và cứ mỗi lần thử thì chúng ta sẽ random như vậy thì nó không có phụ thuộc vào cái không gian tìm kiếm của mình không gian tìm kiếm lớn như thế nào thì nó cũng chỉ thử với lại cái số lượng tối đa mà mình chấp nhận để có thể thử cho cái việc là tìm kiếm cái siêu tham số này mà thôi và khuyết điểm của mô hình này đó là nếu như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:02:49",
      "end_timestamp": "0:03:24"
    }
  },
  {
    "page_content": "thôi và khuyết điểm của mô hình này đó là nếu như cái không gian tìm kiếm của mình mà nó lớn thì nó khó tìm được cái điểm tối ưu toàn cục rõ ràng rồi chúng ta biết là cái cái cái yếu tố về mặt xác suất rồi đúng không cái điểm tối ưu toàn cục thông thường nó rất là ít trong khi đó nếu không gian tìm kiếm này mà càng phức tạp thì cái xác suất để mà chúng ta tìm ra được với cái phương pháp ngẫu nhiên này đó là gần như là bằng 0 do đó thì cái việc tối ưu này nó sẽ cũng sẽ không hiệu quả khi cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:03:20",
      "end_timestamp": "0:03:54"
    }
  },
  {
    "page_content": "tối ưu này nó sẽ cũng sẽ không hiệu quả khi cái không gian tìm kiếm của mình nó quá lớn và nó còn một cái điểm yếu nữa cũng kế thừa từ cái Grid Search đó chính là các cái lần thử độc lập nó độc lập nhau dẫn đến là nó không kế thừa được thông tin của lần thử trước với thuật toán Grid Search thì cái lần thử tại đây nó không hề cung cấp thêm thông tin bổ ích cho cái lần thử này để mà chúng ta có thể bỏ qua cái bước này để mà nhảy xa hơn để tìm những cái khu vực khác nó hiệu quả hơn và có khả năng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:03:48",
      "end_timestamp": "0:04:31"
    }
  },
  {
    "page_content": "cái khu vực khác nó hiệu quả hơn và có khả năng tìm được cái điểm tối ưu hơn và random search cũng vậy Ví dụ chúng ta tìm ở đây xong sau đó chúng ta sẽ nhảy qua đây thì cái thông tin tại đây và thông tin tại đây nó cũng không có cái sự bổ trợ cho nhau mà nó hoàn toàn là độc lập nhau đó nếu như mà chúng ta tìm thấy một cái giá trị nào đó mà cho cái độ chính xác tăng đột biến thì lẽ ra là chúng ta nên khoanh vùng nó lại và tìm nó sát hơn và tìm nó kỹ hơn trong cái khu vực đó thì biết đâu chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:04:24",
      "end_timestamp": "0:05:06"
    }
  },
  {
    "page_content": "kỹ hơn trong cái khu vực đó thì biết đâu chúng ta tìm ra được một cái Ờ mô hình cho cái độ chính xác tối ưu và do là cái yếu tố random tức là một cái yếu tố ngẫu nhiên đó yếu tố ngẫu nhiên Nên có khả năng là kết quả nó sẽ không nhất quán khi chúng ta thử nghiệm trên những cái lần thử khác nhau nếu như chúng ta thử Ờ ba lần Ờ ở ba cái môi trường khác nhau thì có khả năng là cái độ chính xác của mình cho cái sự sai lệch rất là cao vì cái yếu tố ngẫu nhiên này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=piHxNCYpMLk",
      "filename": "piHxNCYpMLk",
      "title": "[CS116 - Buổi 11] Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:05:02",
      "end_timestamp": "0:05:06"
    }
  },
  {
    "page_content": "tiếp theo thì chúng ta sẽ cùng tìm hiểu về một số cái biến đổi đặc trưng hay còn gọi là feature transformation thì đầu tiên đó là chúng ta sẽ phải trả lời câu hỏi là tại sao chúng ta cần phải biến đổi đặc trưng thì có rất nhiều những cái mô hình máy học nó yêu cầu cái đầu vào cho cái mô hình đó là phải tuân theo một cái loại dữ liệu nhất định lấy ví dụ thuật toán nếu mà làm hiệu quả nhất cho nó thì đó phải là những giá trị dạng rời rạc đó hoặc là một số mô hình như là linear regression hoặc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:46"
    }
  },
  {
    "page_content": "một số mô hình như là linear regression hoặc là Logistic regression thì cái dữ liệu mà hiệu quả nhất cho nó đó là phải ở dạng số học như vậy thì ở đây chúng ta giải thích đó là nhiều mô hình nó bắt buộc nó phải ở một số cái dạng nhất định thì khi đó chúng ta sẽ phải chuyển đổi từ cái dạng không phải là cái yêu cầu của mô hình về cái dạng mà mô hình nó yêu cầu ví dụ chuyển từ dạng phân loại về dạng số hoặc là chuyển từ dạng số về cái dạng phân loại để mà mô hình có thể chạy được thì đó là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:00:39",
      "end_timestamp": "0:01:25"
    }
  },
  {
    "page_content": "loại để mà mô hình có thể chạy được thì đó là cái đáp ứng được cái yêu cầu về loại dữ liệu của mô hình tiếp theo đó là về giả định về cái dữ liệu đầu vào của mô hình nó sẽ tuân theo những cái phân bố nào đó thì nhiều cái mô hình máy học nó đặt cái giả định về phân bố hoặc là cái tỉ lệ của dữ liệu đầu vào một số mô hình thì nó yêu cầu cái dữ liệu đầu vào của mình phải là phân bố chuẩn một số mô hình thì nó yêu cầu cái tỷ lệ của cái dữ liệu của mình nó phải nằm trong cái đoạn là từ 0 cho đến 1",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:01:19",
      "end_timestamp": "0:01:59"
    }
  },
  {
    "page_content": "mình nó phải nằm trong cái đoạn là từ 0 cho đến 1 như vậy thì chúng ta sẽ phải biến đổi những cái đặc trưng đầu vào từ một cái dạng phân bố bất kỳ hoặc là từ một cái tỷ lệ bất kỳ về cái dạng phân bố và tỷ lệ mà và cái mô hình máy học của mình nó yêu cầu để đáp ứng được cái giả định cho cái dữ liệu đầu vào của mô hình tiếp theo đó là về vấn đề dữ liệu bị nhiễu thì có rất nhiều những cái mô hình gọi có rất nhiều những cái tập dữ liệu mà có rất nhiều nhiễu trong đó và cái giá trị nhiễu nó có khả",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:01:53",
      "end_timestamp": "0:02:33"
    }
  },
  {
    "page_content": "nhiễu trong đó và cái giá trị nhiễu nó có khả năng ảnh hưởng lớn đến cái hiệu suất của mô hình Do đó để làm giảm bớt cái vai trò của giá trị nhiễu này thì chúng ta sẽ có thể thực hiện một số cái thao tác biến đổi ví dụ như log transform hoặc là RobustScaler thì đây là hai cái phép biến đổi cho phép là làm giảm cái ảnh hưởng của cái dữ liệu nhiễu Nếu có về cái tính giải thích cái vấn đề về giải thích kết quả thì đặc trưng nó có giá trị liên tục thì thông thường nó sẽ làm cho mô hình khó hiểu và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:02:28",
      "end_timestamp": "0:03:04"
    }
  },
  {
    "page_content": "thông thường nó sẽ làm cho mô hình khó hiểu và khó giải thích trong khi đó Những cái đặc trưng dạng Ờ phân loại thì nó sẽ có cái tính dễ giải thích hơn lấy ví dụ như đối với cái mô hình decision tree thì các cái đặc trưng của mình Nó chia ra làm các cái tình huống như là thời tiết thì thời tiết Nếu mà thời tiết ở ba loại đó là có mây hoặc là có nắng hoặc là trời mưa thời tiết là trời mưa thì cái việc mà đưa ra các cái phân loại như là mây trời nắng hoặc là trời mưa và chúng ta đưa ra một cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:03:00",
      "end_timestamp": "0:03:44"
    }
  },
  {
    "page_content": "nắng hoặc là trời mưa và chúng ta đưa ra một cái quyết định nào đó ví dụ như là có đi chơi hay không đi chơi thì cái việc mà sử dụng cái đặc trưng mà ở dạng phân loại nó sẽ dễ giải thích hơn so với việc là à nếu như chúng ta có một cái thông tin là tuổi mà tuổi của mình là giá trị liên tục đúng không Nếu tuổi mà dưới 8 tuổi rồi nếu tuổi mà từ 8 tuổi cho đến 15 tuổi và tuổi từ 16 tuổi cho đến 90 tuổi ví dụ vậy thì khi chúng ta nhìn cái khoảng giá trị này chúng ta rất khó để mà có thể giải thích",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:03:38",
      "end_timestamp": "0:04:25"
    }
  },
  {
    "page_content": "trị này chúng ta rất khó để mà có thể giải thích được là tại sao nó lại có cái con số là 8 cho đến 15 hoặc là từ 16 cho đến 90 thì như vậy thì chúng ta sẽ tìm cách đó là binning transformation để chia ra thành những cái khoảng giá trị và nếu như chúng ta từ các cái giá trị mà liên tục từ 0 cho đến à Ví dụ như 100 tuổi thì đây là cái các cái giá trị liên tục nó rất khó để cho chúng ta có thể giải thích được do đó thì bằng cái phương pháp là binning transformation chúng ta chia thành cái khoảng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:04:19",
      "end_timestamp": "0:04:55"
    }
  },
  {
    "page_content": "transformation chúng ta chia thành cái khoảng giá trị thì khi chúng ta giải thích cho cái đối tác hoặc là giải thích cho những cái người mà không có nhiều kiến thức về mô hình của mình thì họ sẽ dễ hình dung các cái khoảng giá trị này hơn là khi chúng ta đưa những cái giá trị là ở cái độ tuổi vào và mỗi một cái khoảng độ tuổi này thì nó sẽ có một cái ý nghĩa nhất định như vậy thì cái tính giải thích của mình nó sẽ được đảm bảo và cuối cùng đó là cái vấn đề về cái mối quan hệ phi tuyến giữa các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:04:52",
      "end_timestamp": "0:05:30"
    }
  },
  {
    "page_content": "cái vấn đề về cái mối quan hệ phi tuyến giữa các cái đặc trưng thì các cái quan hệ phi tuyến nó sẽ làm cho cái mô hình của mình Ờ làm cho cái mô hình hóa cũng như là cái việc giải thích trở nên khó khăn hơn đó thì cái việc mà biến đổi cái dữ liệu của mình về cái dạng tuyến tính hoặc là về cái dạng đơn giản hơn đó thì sẽ giúp cho cái mô hình của mình nó dễ học hơn hoặc là sau này chúng ta giải thích cho khách hàng hoặc là đối tác Những người mà không có chuyên môn họ sẽ dễ hơn đó thì ở đây chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:05:26",
      "end_timestamp": "0:06:06"
    }
  },
  {
    "page_content": "có chuyên môn họ sẽ dễ hơn đó thì ở đây chúng ta sẽ có cái công thức là ở dạng hàm mũ có thể à đưa về cái dạng là công thức của tuyến tính đó là ax cộng cho log b thì trong đó log b là một cái hằng số chúng ta đưa về một cái dạng hàm mũ về một cái dạng là hàm tuyến tính thì mô hình của mình huấn luyện nó cũng sẽ dễ hơn và sau này chúng ta giải thích nó cũng sẽ dễ hơn thì đó là lý do những lý do tại sao chúng ta cần phải biến đổi đặc trưng và đối với cái biến đổi đặc trưng thì chúng ta sẽ có hai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:06:00",
      "end_timestamp": "0:06:51"
    }
  },
  {
    "page_content": "với cái biến đổi đặc trưng thì chúng ta sẽ có hai dạng có hai loại dữ liệu đó là dữ liệu dạng số và dữ liệu dạng danh mục hoặc là phân loại thì đối với cái dữ liệu dạng số chúng ta sẽ có một số cái cách biến đổi như sau đầu tiên đó là Min-Max Scaling đó thì chúng ta sẽ có cái công thức là x' sẽ là bằng x trừ cho min chia cho max trừ Min Thì mục tiêu của cái phép Min-Max Scaling này đó là biến các cái đặc trưng của mình từ một cái giải giá trị bất kỳ về cái khoảng là từ 0 cho đến 1 thì như vậy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:06:47",
      "end_timestamp": "0:07:22"
    }
  },
  {
    "page_content": "kỳ về cái khoảng là từ 0 cho đến 1 thì như vậy thì cái đặc trưng khi mà đưa về cái dạng là từ 0 cho đến 1 thì có khả năng là sẽ giúp cho những cái mô hình mà đòi hỏi là cái dạng thức đầu vào của mình tuân theo cái phân bố chuẩn nó có thể hoặc là tuân theo cái phân bố mà dữ liệu phải nằm trong đoạn từ 0 đến 1 nó sẽ thực hiện độ chính xác cao hơn nó thực hiện hiệu quả hơn đồng thời có thể là giúp cho cái quá trình huấn luyện của mình Nó diễn ra với tốc độ là nhanh hơn thì ở đây chúng ta thấy là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:07:17",
      "end_timestamp": "0:07:56"
    }
  },
  {
    "page_content": "tốc độ là nhanh hơn thì ở đây chúng ta thấy là với cái bảng dữ liệu đầu vào thì với từng cái cột dữ liệu này giải giá trị của mình có thể là từ con số 0 cho đến con số rất là lớn như là 300 thì sau khi chúng ta thực hiện Min-Max Scaling thì cái giải giá trị của mình nó đã được đưa về cái khoảng là từ 0 cho đến 1 tương tự như vậy cho tất cả những cái cột dữ liệu còn lại thì nó cũng đều biến đổi về cái khoảng giá trị là từ 0 cho đến 1 cái phép biến đổi đặc trưng thứ hai đó là Standardization tức",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 13,
      "start_timestamp": "0:07:50",
      "end_timestamp": "0:08:34"
    }
  },
  {
    "page_content": "đổi đặc trưng thứ hai đó là Standardization tức là chuẩn hóa đưa hoặc là có một cái tên gọi khác đó là Z-score Scaling thì với cái dữ liệu đầu vào góc ban đầu là x chúng ta sẽ trừ cho cái giá trị trung bình theo từng cột và chia cho độ lệch chuẩn theo từng cột thì với cái phương pháp là chuẩn hóa này thì chúng ta sẽ đưa nó về cái phân bố là normal 0 1 tức là giá trị trung bình sẽ là 0 và độ lệch chuẩn của mình sẽ là 1 như vậy thì với cái giá trị đầu vào là những cái con số rất là lớn và lưu ý",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 14,
      "start_timestamp": "0:08:29",
      "end_timestamp": "0:09:10"
    }
  },
  {
    "page_content": "đầu vào là những cái con số rất là lớn và lưu ý là trong cái cột room service này thì nó có thể nhận những giá trị là lớn hơn một rất là nhiều và à *giá trị* Nó lớn hơn 0 và nhỏ hơn *giá trị* nó là những cái giá trị dương thì sau khi chúng ta thực hiện cái phép là chuẩn hóa thì nó sẽ đưa về có thể đưa về những cái giá trị là âm có cả âm nhưng mà nhìn chung Nó là phân bố theo phân bố chuẩn 01 cái thao tác biến đổi tiếp theo đó là RobustScaler mục tiêu của cái RobustScaler là để giải quyết những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 15,
      "start_timestamp": "0:09:04",
      "end_timestamp": "0:10:19"
    }
  },
  {
    "page_content": "tiêu của cái RobustScaler là để giải quyết những cái tình huống dữ liệu của mình bị bị nhiễu Tức là nó vượt qua những cái khoảng giá trị mà quá khác biệt đó thì ở đây chúng ta sẽ có cái khoảng Q3 trừ cho Q1 thì đây chính là IQR và Median thì cái công thức biến đổi của mình đó là giá trị gốc trừ cho giá trị Median theo từng cột và chia cho cái khoảng IQR thì cái này nó cũng na ná với lại cái công thức của x trừ mu chia cho Sigma thì thay vì là dùng mu và Sigma thì chúng ta dùng là Median và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 16,
      "start_timestamp": "0:10:14",
      "end_timestamp": "0:10:54"
    }
  },
  {
    "page_content": "dùng mu và Sigma thì chúng ta dùng là Median và khoảng IQR rồi đối với cái log transform thì ở bên trái là chúng ta sẽ thấy cái phân bố của cái dữ liệu ờ phân bố của cái dữ liệu gốc thì chúng lệch và nhờ cái phép biến đổi log transform chúng ta tính log theo cái trục trục hoành thì khi đó cái phân bố dữ liệu của mình nó sẽ trải ra thành các cái giá trị nó đều hơn và đâu đó nó sẽ đối xứng hơn thay vì là bị thiên lệch như thế này thì nó sẽ trải đều và nó sẽ đối Nhìn có vẻ nó đối xứng hơn thì đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 17,
      "start_timestamp": "0:10:46",
      "end_timestamp": "0:11:28"
    }
  },
  {
    "page_content": "và nó sẽ đối Nhìn có vẻ nó đối xứng hơn thì đó là giảm bớt được những cái ảnh hưởng của những cái giá trị nằm trong cái khoảng là lớn này và cuối cùng đó chính là thao tác rời rạc hóa hoặc còn gọi là binning thì ở đây chúng ta sẽ có cái dữ liệu là tuổi là một cái giá trị liên tục tuổi là 3924 thì sau khi chúng ta thực hiện binning Chúng ta chia khoảng thì 39 nó sẽ đưa về là khoảng giá trị từ 31 cho đến 50 58 sẽ đưa về khoảng giá trị là 51+ thì đây sẽ là biến một cái giá trị từ dạng số về cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 18,
      "start_timestamp": "0:11:23",
      "end_timestamp": "0:12:09"
    }
  },
  {
    "page_content": "đây sẽ là biến một cái giá trị từ dạng số về cái dạng phân loại thì có một số thuật toán nó đòi hỏi hoặc là nó làm việc hiệu quả trên cái dữ liệu dạng rời rạc như thế này thì chúng ta buộc phải biến đổi những cái giá trị dạng liên tục về cái dạng rời rạc sang cái loại dữ liệu thứ hai đó là dữ liệu dạng danh mục hay là phân loại thì chúng ta sẽ có một số cái phép biến đổi đầu tiên đó là phép biến đổi One-Hot Encoding nếu như cái dữ liệu đầu vào của mình đó là là những cái dạng phân loại ví dụ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 19,
      "start_timestamp": "0:12:03",
      "end_timestamp": "0:12:48"
    }
  },
  {
    "page_content": "của mình đó là là những cái dạng phân loại ví dụ home planet của mình là Europa, Earth đó thì chúng ta sẽ đưa về cái dạng là One-Hot Encoding bằng cách chúng ta sẽ tạo ra thêm ba cái cột dữ liệu mới tạo ra thêm ba thì trong trường hợp này là nếu như ở phía sau ha các cái mẫu dữ liệu 567 nó có thêm cái thông tin à planet của mình đó là Mars thì chúng ta sẽ có thêm cái cột nè thì tương ứng ở đây là Europa thì cái cột Europa của mình nó sẽ bật lên là 1 ở đây là Earth thì cái cột Earth nó sẽ bật",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 20,
      "start_timestamp": "0:12:41",
      "end_timestamp": "0:13:22"
    }
  },
  {
    "page_content": "là 1 ở đây là Earth thì cái cột Earth nó sẽ bật lên là 1 còn các cái trường còn lại sẽ giữ nguyên là 0 thì đây là cái dạng chuyển đổi từ phân loại cái cái cái đặc trưng dạng phân loại về cái dạng đặc trưng dạng số học có thể tính toán được các cái con số 01 này sẽ giúp cho mô hình của mình có thể tính toán được tiếp theo đó là Ordinal Encoding thì đối với một số cái loại dữ liệu Mặc dù là ở dạng phân loại Nhưng nó vẫn có cái tính thứ tự trước sau lớn nhỏ Ví dụ như cái độ tuổi là từ 31 cho đến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 21,
      "start_timestamp": "0:13:17",
      "end_timestamp": "0:14:05"
    }
  },
  {
    "page_content": "lớn nhỏ Ví dụ như cái độ tuổi là từ 31 cho đến 50 thì chúng ta sẽ thấy là nó sẽ lớn hơn cái độ tuổi là age từ 18 cho đến 25 đúng không như vậy nếu như chúng ta biểu diễn các cái cái giá trị phân loại này dưới dạng số thì các cái con số này nó phải là những con số có tính chất thứ tự lớn nhỏ thì cái độ tuổi là từ 31 cho đến 50 Nếu như ở đây chúng ta dùng một số là số 5 thì cái độ tuổi là từ 18 cho đến 25 nó phải được biểu diễn dưới dạng là con số nhưng mà con số này nó phải nhỏ hơn con số số 5.0",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 22,
      "start_timestamp": "0:14:00",
      "end_timestamp": "0:14:42"
    }
  },
  {
    "page_content": "nhưng mà con số này nó phải nhỏ hơn con số số 5.0 này tức là con số 3 tại vì cái độ tuổi của 31 đến 50 Nó lớn hơn độ tuổi của 18 cho đến 25 rồi tương tự như vậy cái độ tuổi là từ 51 trở lên thì nó sẽ biểu diễn là số 6 đội tuổi từ 31 cho đến 50 tức là ngay trước cái độ tuổi ba à Xin gọi là độ tuổi 13 cho đến 17 là nó ngay trước cái độ tuổi 18 cho đến 25 do đó nó sẽ biểu diễn bằng con số 2 hai là cái con số ngay trước con số 3 đây đó và tiếp theo đó là Label Encoding tức là ờ các cái Ờ giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 23,
      "start_timestamp": "0:14:37",
      "end_timestamp": "0:15:27"
    }
  },
  {
    "page_content": "đó là Label Encoding tức là ờ các cái Ờ giá trị phân loại ở đây nó sẽ được biểu diễn dưới dạng là các cái con số và con số này thì không nhất thiết phải có tính thứ tự ví dụ Europa và Earth thì nó không có thể hiện là Europa Nó lớn hơn Earth hay là Europa nó nhỏ hơn nó không có cái tính thứ tự ở đây do đó thì chúng ta có thể biểu diễn nó bằng các cái con số bất kỳ không nhất thiết là những cái con số liên tục như thế này rồi cuối cùng đó chính là Target Encoding thì đây là một trong những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 24,
      "start_timestamp": "0:15:20",
      "end_timestamp": "0:16:12"
    }
  },
  {
    "page_content": "là Target Encoding thì đây là một trong những cái kỹ thuật là khai thác cái đặc trưng của cái dự đoán thì ở trong cái ví dụ này là chúng ta sẽ có cái x là cái home planet và cái y Tức là cái giá trị dự đoán của mình là transported thì cái X này á nó sẽ dựa trên cái transported này để mà nó encode nó tạo ra thêm Ờ một cái dạng encode nữa đó chính là Europa thì sẽ biểu diễn bằng à cái giá trị trung bình khi chúng ta cộng thực hiện tính toán trên cái cột dự đoán này lấy ví dụ Europa ở đây chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 25,
      "start_timestamp": "0:16:06",
      "end_timestamp": "0:16:24"
    }
  },
  {
    "page_content": "cột dự đoán này lấy ví dụ Europa ở đây chúng ta thấy là có ba giá trị có ba giá trị và ba cái lưu ý là ở đây dữ liệu của mình Nó có thể là lên 678 nha nó còn nhiều nữa thì chúng ta sẽ gom nhóm tất cả những cái cột y tương ứng với lại cái Europa này lấy ví dụ như chúng ta có giá trị là 0 nè ở đây là 0 ở đây là 0 và phía dưới nó sẽ còn các giá trị nữa là 1 nè 1 nè rồi 1 nè 1 nè 0 thì chúng ta sẽ lấy các giá trị này cộng lại rồi chia trung bình thì chúng ta sẽ được cái con số là 0.65 Và từ nay tất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chúng ta sẽ được cái con số là 0.65 Và từ nay tất cả các cái trường dữ liệu tất cả các cái đặc trưng mà của cái home planet này mà có cái giá trị là Europa thì sẽ được thêm vô cái dạng Target Encoding của mình đó là 0.65 0.65 0.65 và giá trị 0.65 này được tổng hợp từ cái cột dữ liệu của cái đặc trưng cần phải dự đoán thì nó sẽ có rất nhiều những cái chiến thuật khác nhau cho cái Target Encoding này chúng ta có thể thực hiện là hàm Max hàm trung bình cộng hàm Min hoặc là bất cứ cái chiến thuật",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "bình cộng hàm Min hoặc là bất cứ cái chiến thuật nào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pIuM6XnJjD4",
      "filename": "pIuM6XnJjD4",
      "title": "[CS116 - Buổi 4] Part 4",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "rồi và bây giờ thì chúng ta sẽ qua cái giao diện của cái **Colab**. Đây chính là cái mô hình mà giả sử chúng ta đã huấn luyện xong đúng không. Thì ở đây chúng ta sẽ nói qua cái đoạn code **Colab** này là gì và chúng ta mong muốn đó là chúng ta sẽ đưa cái mô hình mà đã được huấn luyện với cái Google **Colab** để tạo thành một cái **ứng dụng web**. Thì rõ ràng với cái **Colab** này, những người dùng người ta sẽ rất khó để có thể **thiết lập** được những cái đoạn code này khi họ không biết về lập",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:35"
    }
  },
  {
    "page_content": "những cái đoạn code này khi họ không biết về lập trình máy học. Đó, người ta sẽ nhìn vô các cái đoạn code này, người ta sẽ không hiểu là phải nhập vô cái chỗ nào, nhập input, nhập input như thế nào và xem cái output như thế nào. Đó thì ở đây chúng ta sẽ chạy thử ha. Rồi, chúng ta sẽ **load** dữ liệu lên từ file. Thì ở đây cái dữ liệu của mình nó sẽ là bao gồm thuộc tính **đầu vào** là kích thước và khối lượng của một cái món hàng, và output mà mình cần phải dự đoán đó chính là giá, cái giá mà",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 1,
      "start_timestamp": "0:00:32",
      "end_timestamp": "0:01:10"
    }
  },
  {
    "page_content": "mình cần phải dự đoán đó chính là giá, cái giá mà để vận chuyển cái món hàng đó sẽ là bao nhiêu tiền và đơn vị sẽ là Việt Nam đồng. Rồi, chúng ta **load dữ liệu** lên, sau đó là đưa nó vào các cái biến X là **input** **feature** và Y là giá trị dự đoán là **Price**. Sau đó chúng ta sẽ tiến hành chia ra làm hai tập train và tập test với tỉ lệ là 80% train và 20% để test. Sau đó chúng ta sẽ thử nghiệm với một mô hình. Thì với hai mô hình, mô hình đầu tiên đó chính là **Linear Regression**, và mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 2,
      "start_timestamp": "0:01:07",
      "end_timestamp": "0:01:46"
    }
  },
  {
    "page_content": "đầu tiên đó chính là **Linear Regression**, và mô hình này cho cái **sai số** đó là 36.000đ. Sau đó thì chúng ta sẽ thử với lại cái mô hình thứ hai đó là mô hình **Decision Tree**, và chúng ta sẽ thử với phương pháp **Grid Search** để tìm cái **bộ siêu tham số tối ưu**. Thì tất cả những cái kiến thức này chúng ta đều đã học ở trong những cái bài trước đây. Và sau khi mô hình đã **vét cạn** để tìm ra cái bộ siêu tham số lớn nhất thì cái **best estimator** sẽ dự đoán trên cái giá trị **X_test**,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 3,
      "start_timestamp": "0:01:41",
      "end_timestamp": "0:02:20"
    }
  },
  {
    "page_content": "sẽ dự đoán trên cái giá trị **X_test**, và chúng ta sẽ đo coi cái **sai số** trên cái tập test là bao nhiêu. Thì **sai số** trên cái tập test set của mình sẽ là 23. Như vậy là giữa hai mô hình là **Linear Regression** với **sai số** là 36.000 và **Decision Tree** với **sai số** là 23.000 thì chúng ta sẽ quyết định sử dụng **mô hình Decision Tree**. Và sau đó thì chúng ta sẽ tiến hành **trực quan hóa** cái sơ đồ cây này. Thì đây là cái cấu trúc cây của cái mô hình. Tuy nhiên thì đây chỉ là mang",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 4,
      "start_timestamp": "0:02:15",
      "end_timestamp": "0:02:52"
    }
  },
  {
    "page_content": "của cái mô hình. Tuy nhiên thì đây chỉ là mang tính chất gọi là trực quan, chúng ta không có sử dụng cái mô hình này về sau. Xin lỗi, chúng ta không có sử dụng cái hình này về sau. Và để mà có thể sử dụng được cái mô hình này á thì chúng ta sẽ phải lưu cái **best estimator** này xuống dưới file, và sau đó chúng ta sẽ load cái mô hình đó lên từ file để mà tiến hành dự đoán. Thế thì để mà lưu xuống dưới file thì chúng ta sẽ phải dùng một cái thư viện đó là **pickle**. Rồi, cái tên file mà chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 5,
      "start_timestamp": "0:02:45",
      "end_timestamp": "0:03:29"
    }
  },
  {
    "page_content": "viện đó là **pickle**. Rồi, cái tên file mà chúng ta đặt sẽ là **best_model.pickle**. Rồi, sau khi thực thi cái lệnh này xong thì chúng ta thấy là ở bên cửa sổ bên trái nó sẽ hiển thị một cái file tên là **best_model.pickle**. Thì đây, cái cái mô hình mà mình đã huấn luyện nó sẽ nằm trong cái file **best_model.pickle** này. Và bây giờ thì chúng ta sẽ tiến hành **thử nghiệm** xem là cái thư cái cái cái model này sau khi chúng ta load lên từ file á thì nó dự đoán có còn chính xác được hay không.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 6,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:04"
    }
  },
  {
    "page_content": "á thì nó dự đoán có còn chính xác được hay không. Rồi, thì chúng ta thấy là cái mô hình mà được load lên từ file nó cho cái **sai số** là 23.545. Nó trùng khớp với cái con số là 23.545 ở đây. Như vậy thì chúng ta thấy là rõ ràng cái mô hình này đã được load lên từ file đúng rồi đúng không. Bây giờ chúng ta sẽ tải cái **model** này xuống. Rồi sau đó chúng ta sẽ đưa vào cái thư mục mà **dự kiến** chúng ta sẽ làm việc và chúng ta sẽ tạo ra một cái đoạn code để mà có thể đọc cái mô hình này và tạo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 7,
      "start_timestamp": "0:04:00",
      "end_timestamp": "0:04:41"
    }
  },
  {
    "page_content": "đoạn code để mà có thể đọc cái mô hình này và tạo ra một cái file à, xin lỗi, tạo ra một cái trang web. Thế thì để tạo trang web á thì như hồi nãy chúng ta có đề cập, chúng ta có thể sử dụng công cụ Google nhưng mà gần đây chúng ta có một cái công cụ rất là hiệu quả để mà có thể lập, để mà có thể lập trình và tương tác để mà hỏi đáp về lập trình, đó chính là **ChatGPT**. Thì bây giờ chúng ta sẽ hỏi, chúng ta sẽ nhờ cái công cụ **ChatGPT** này xây dựng một cái ứng dụng web **với Streamlit**. Và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 8,
      "start_timestamp": "0:04:36",
      "end_timestamp": "0:05:51"
    }
  },
  {
    "page_content": "dựng một cái ứng dụng web **với Streamlit**. Và cái cách mà chúng ta **prompt** sẽ là như sau: chúng ta sẽ phải mô tả rất là chi tiết ha. Tức là hãy lập trình bằng thư viện **Streamlit** để tạo một ứng dụng web với à cái thông số **bố cục** web để người dùng có thể nhập các cái thông tin như là **size**, kích thước và **trọng lượng** của cái hàng hóa. Sau đó, sau đó người dùng sẽ click vào button có nhãn là **predict**. **Predict** đúng không? Thì ứng dụng web sẽ load mô hình lên từ file, load",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 9,
      "start_timestamp": "0:05:41",
      "end_timestamp": "0:06:31"
    }
  },
  {
    "page_content": "ứng dụng web sẽ load mô hình lên từ file, load cái mô hình lên từ file và dự đoán. Rồi, trả kết quả về được. Thì đây là cái mô tả mà mình mong muốn **ChatGPT** nó viết cho mình. Thì ở đây nó rất là tử tế đúng không? Tức là nó nói là để mà làm được cái việc này thì chúng ta sẽ phải bước một là cài đặt cái thư viện **Streamlit** và các thư viện cần thiết. Và nó dự đoán là chúng ta sẽ cần có cái thư viện **scikit-learn**. lên. Rồi, giả sử chúng ta sẽ có được một cái file mô hình đúng không? Có một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 10,
      "start_timestamp": "0:06:26",
      "end_timestamp": "0:07:05"
    }
  },
  {
    "page_content": "có được một cái file mô hình đúng không? Có một cái file mô hình đã được **huấn luyện** trước đó, đó là **model.pickle**. Thì nó chính là cái **best_model.pickle** của mình. Thì chúng ta sẽ có cái đoạn code như sau. Nó sẽ **open** cái **pickle** này lên. Rồi, sau đó nó sẽ đọc đúng không? **st.number_input** nè, **st.number_input** nè. Nó sẽ trả ra hai cái biến là **size** và **weight**. Rồi sau đó nếu người dùng click vào cái button đó là **predict** thì nó sẽ tiến hành dự đoán. Nó sẽ tiến hành",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 11,
      "start_timestamp": "0:07:00",
      "end_timestamp": "0:07:42"
    }
  },
  {
    "page_content": "thì nó sẽ tiến hành dự đoán. Nó sẽ tiến hành lấy cái **model** đã load ở cái file này. Thì ở đây chúng ta nếu mà chúng ta code, chúng ta sẽ phải sửa lại đúng không? Chúng ta sẽ phải sửa lại. Nhưng mà đầu tiên thì chúng ta sẽ phải **pip install** cái này. Nhưng mà để cài đặt cái này thì chúng ta nên tạo một cái **environment**, tạo một cái **environment** cho đó. Thì là **conda** **create --name**. Thì ở đây là tên của này sẽ là **streamlit**. Cái **environment** sẽ là **Streamlit** và chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 12,
      "start_timestamp": "0:07:36",
      "end_timestamp": "0:08:36"
    }
  },
  {
    "page_content": "**environment** sẽ là **Streamlit** và chúng ta sẽ phải cài hai thư viện này. Tuy nhiên thì cái thư viện **scikit-learn** thì chúng ta sẽ phải sử dụng đúng cái phiên bản mà chúng ta đang dùng ở đây để tránh những cái lỗi về sau. Thế thì chúng ta sẽ xem cái phiên bản của mình là bao nhiêu. Và phiên bản của mình nó sẽ là **1.3.2**. Do đó thì ở đây chúng ta sẽ để là **1.3.2**. Rồi **Streamlit** thì chúng ta sẽ lấy cái phiên bản mới nhất. Còn **Python** thì chúng ta có thể để là phiên bản ờ 3.9.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 13,
      "start_timestamp": "0:08:29",
      "end_timestamp": "0:09:28"
    }
  },
  {
    "page_content": "thì chúng ta có thể để là phiên bản ờ 3.9. Rồi, và chúng ta sẽ chờ một thời gian để cho nó cài đặt các cái thư viện này ha. Rồi, tiếp theo thì chúng ta sẽ copy cái code này và đưa vào **Visual** **Studio**. Thì ở đây chúng ta tạo một cái file. Cái file này sẽ là dạng **Python**. Rồi, rồi ta sẽ lưu lại cái file vào **best_model.py**. Rồi, và ở đây thì chúng ta sẽ sửa lại là **best_model.pickle**. Rồi, sau khi chúng ta lưu lại thì chúng ta sẽ qua đây kiểm tra xem đã cài xong chưa. Thì ở đây nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 14,
      "start_timestamp": "0:09:16",
      "end_timestamp": "0:10:22"
    }
  },
  {
    "page_content": "đây kiểm tra xem đã cài xong chưa. Thì ở đây nó thông báo là **package** **not found**. Tức là cái thư viện **conda** của mình nó không tìm thấy được cái **scikit-learn** phiên bản 1.3.2. Như vậy thì à mình sẽ bỏ đi cái **package** này và mình sẽ cài nó bằng **pip**. **Pip** thì nó sẽ có lưu đủ các cái phiên bản của **Anaconda**. Xin lỗi, nó sẽ lưu đủ hơn các phiên bản so với lại **Anaconda**, ví dụ như là **scikit-learn** phiên bản **1.3.2**. Rồi, và ở đây thì chúng ta sẽ xem. Thì trong quá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 15,
      "start_timestamp": "0:10:15",
      "end_timestamp": "0:11:04"
    }
  },
  {
    "page_content": "Rồi, và ở đây thì chúng ta sẽ xem. Thì trong quá trình mà cài đặt thì nó sẽ tìm tất cả những cái phiên bản thư viện có liên quan đến **Streamlit** cũng như là **Python** phiên bản 3.9 để mà nó bổ sung. Tức là mặc dù chúng ta chỉ cài có **Streamlit**, nhưng mà bên dưới thì nó sẽ cần có thêm những cái đơn những cái cái thư viện của bên thứ ba và **Anaconda** nó sẽ tự động nó cài. Rồi, thì tranh thủ thì chúng ta sẽ cùng xem cái đoạn code này nó có cái ý nghĩa gì. Thì đầu tiên á, là nó sẽ load cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 16,
      "start_timestamp": "0:10:58",
      "end_timestamp": "0:11:39"
    }
  },
  {
    "page_content": "cái ý nghĩa gì. Thì đầu tiên á, là nó sẽ load cái model từ cái thư viện là **pickle**. Thì cái **pickle** này chính là cái mô hình mà chúng ta đã được huấn luyện sử dụng phương pháp **Grid Search** và với cái cấu trúc, với cái thuật toán đó là **Decision Tree**. Và sau khi chúng ta load xong thì cái model này sẽ được sử dụng để **predict**, để dự đoán. Và cái giá trị mà nó dự đoán thì nó sẽ được lấy từ một cái đối tượng tên là **NumPy array**, trong đó bao gồm hai cái thuộc tính là **size** và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 17,
      "start_timestamp": "0:11:33",
      "end_timestamp": "0:12:08"
    }
  },
  {
    "page_content": "đó bao gồm hai cái thuộc tính là **size** và **weight**. **Size** và **weight** sẽ là hai cái thuộc tính đến từ cái **Streamlit number_input**. Thì **st.number_input** chính là cái cửa sổ **textbox** để cho người dùng có thể nhập hai cái thông số là kích thước và cân nặng. Rồi, còn cái **st.title** thì đây chỉ là cái câu thông báo của cái ứng dụng của mình, cái ứng dụng web của mình. Thì tổng thể đó là chúng ta thấy cái code mặc dù là chúng ta code web nhưng mà ờ bằng cái ngôn ngữ **Python**,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "code web nhưng mà ờ bằng cái ngôn ngữ **Python**, và bên dưới thì nó đã tự động nó tạo ra các cái mã **HTML**, **JavaScript** để mà tương tác. Còn thư viện này thì chúng ta chỉ việc code nó dưới dạng là cú pháp của file **Python**, còn ngầm bên dưới thì nó vẫn đã có tạo ra cái **frontend**, **backend** dựa trên các cái **mã nguồn** chuẩn.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=pWrRBwgKqPQ",
      "filename": "pWrRBwgKqPQ",
      "title": "[CS116 - Buổi 14] Part 3_2",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "khi cái người đàn ông này lùi ra xa đúng không? Thì chúng ta thấy cái đốm sáng này nó cũng lùi ra xa theo nghĩa đó là khi cái gương mặt này lùi ra xa thì rõ ràng cái kích thước của cái đốm sáng này nó sẽ nhỏ hơn kích thước của cái đốm sáng này và đồng thời cái đốm sáng này nó tiến về phía trên, góc phía trên của cái khung hình thì cái đốm sáng này nó cũng sẽ tiến về phía trên của cái feature map. Rồi chúng ta cũng để ý thêm là cái tỉ lệ của cái vùng gương mặt này nó bằng một nửa, nó khoảng một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=P_og-OmyL44",
      "filename": "P_og-OmyL44",
      "title": "[CS116 - Buổi 10] Part 4_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:07",
      "end_timestamp": "0:00:42"
    }
  },
  {
    "page_content": "vùng gương mặt này nó bằng một nửa, nó khoảng một nửa so với lại cái gương mặt này thì cái đốm sáng này nó cũng bằng một nửa. Như vậy thì điều này nó thể hiện cái tính chất gì? Nó thể hiện cái tính chất đó là feature map của mình nó sẽ bất biến về cái trình tự không gian. Nó sẽ bất biến về trình tự không gian, nghĩa là khi gương mặt bên tay trái đúng không? Nó nằm bên tay trái cái gương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=P_og-OmyL44",
      "filename": "P_og-OmyL44",
      "title": "[CS116 - Buổi 10] Part 4_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:38",
      "end_timestamp": "0:01:03"
    }
  },
  {
    "page_content": "tiếp theo thì chúng ta sẽ cùng đến với các cái độ đo cho bài toán phân lớp thì tương tự như cho bài toán hồi quy thì đối với bài toán phần lớp thì chúng ta sẽ có một cái hàm là hàm độ lỗi dành cho cái mô hình dành cho cái mô hình khi huấn luyện rồi thì ở đây cũng chúng ta cũng sẽ có các cái biến đầu vào và cái biến phân loại đầu ra thì khác với lại cái bài toán hồi quy đó là đối với cái bài toán phân loại thì đầu ra của mình nó sẽ nhận các cái giá trị phân loại đó thì thông thường thì chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:52"
    }
  },
  {
    "page_content": "trị phân loại đó thì thông thường thì chúng ta sẽ là đặt tên chứ không có dùng số ví dụ bài toán spam hay không spam thì các bạn sẽ để là spam hoặc là not spam đó hoặc là nhưng mà chúng ta sẽ không có sử dụng các cái chuỗi ký tự để chúng ta mã hóa cho cái biến đồ ra mà Thông thường chúng ta sẽ mã hóa nó dưới dạng là các cái con số đó thì tại vì sao chúng ta phải mã hóa nó dới dạy các cái con số để giúp cho cái mô hình có thể thực hiện tính toán cộng trường nhân chia được chứ nếu chúng ta để các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:44",
      "end_timestamp": "0:01:33"
    }
  },
  {
    "page_content": "trường nhân chia được chứ nếu chúng ta để các cái chuỗi ký tự như là spam hoặc là not spam thì dẫn đến là chúng ta không không thể tính toán được đó thì ở đây là bài toán à phân lớp nhị phân thì chúng ta sẽ có cái đầu ra của mình nó chỉ nhận ra chỉ nhận hai giá trị đó là 0 hoặc là 1 và cũng tương tự cho bài toán hội quy thì đối với bài toán phân lớp chúng ta sẽ lấy các cái biến đầu vào X trên tập dữ liệu Trend trên tập dữ liệu Trend Chúng ta đưa vào cái mô hình máy học và chúng ta sẽ ra được",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:25",
      "end_timestamp": "0:02:07"
    }
  },
  {
    "page_content": "vào cái mô hình máy học và chúng ta sẽ ra được cái giá trị Dự đoán y ngã và so sánh cái y Ngã này với cái giá trị thực tế thì liệu chúng ta có sử dụng cái hàm độ lỗi mse tương tự như đối với cái bài toán hồi quy hay không thì Câu trả lời đó là chúng ta sẽ có thể sử dụng được cái độ đo này chúng ta có thể sử dụng được cái độ đo là cái hàm độ lỗi đó là Min Square ra Tuy nhiên cái Min Square ra này á thì nó sẽ có một cái điểm yếu đó là nó sẽ giúp cho cái quá trình huấn luyện nó sẽ làm cho cái quá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:02:00",
      "end_timestamp": "0:02:42"
    }
  },
  {
    "page_content": "cái quá trình huấn luyện nó sẽ làm cho cái quá trình huấn luyện của mình nó TH thự hiện trọng do cái sự trừng phạt khi chúng ta làm đối với cái bài toán hồi quy đó là rất là thấp Tại sao Tại vì các cái giá trị y và y Ngã này nè y và y ngã các bạn sẽ thấy là miền giá trị của nó là chỉ từ 0 cho đến 1 thôi Do đó cái size số này khi mà bình phương lên đó là con số rất là bé mà cái con số size số này bé nó sẽ khiến cho cái hàm mô hình của mình nó sẽ cập nhật rất là chọng nó sẽ cập nhật chọng do đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:36",
      "end_timestamp": "0:03:16"
    }
  },
  {
    "page_content": "cập nhật rất là chọng nó sẽ cập nhật chọng do đó chúng ta sẽ sẽ có cái nhu cầu là muốn thay thế cái hàm lỗi Min Square ER này bằng một cái hàm khác và nó cho cái size số nó lớn hơn cho cái độ dốc của cái hàm Nó lớn hơn thì khi đó hàm của cái cái mô hình của mình nó sẽ huấn luyện nhanh hơn và đối với cái bài toán phân lớp thì thông thường người ta hay sử dụng cái hàm độ lỗi đó là hàm lock loss hàm log loss cho cái trường hợp mà có nhiều class Ví dụ như chúng ta có k class K này không nhất thiết",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:03:12",
      "end_timestamp": "0:03:58"
    }
  },
  {
    "page_content": "dụ như chúng ta có k class K này không nhất thiết là chỉ có hai class như ở đây ha K này có thể là ba class ba class 4 class vân vân thì cái công thức tổng quát cho cái log loss này á đó chính là nó sẽ là bằng trừ của tổng của i i log của y dự đoán và chúng ta sẽ có cái cái hàm độ lỗi như trên và với ở đây nó sẽ có một cái chỉ số k là chạy từ 1 K là chạy từ 1 cho đến k l đó thì ở đây sẽ là k à sử ở đây là sẽ k k thường và chúng ta sẽ phải tính chung bình cộng cho tất cả các cái mẫ y Công thức",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:03:51",
      "end_timestamp": "0:04:52"
    }
  },
  {
    "page_content": "chung bình cộng cho tất cả các cái mẫ y Công thức này sẽ là công thức tính cho một vectơ thôi cho một vectơ Ví dụ nếu như chúng ta dùng cho cái bài toán phân lớp K lớp thì cái vectơ I của mình I của mình nó sẽ là một cái vectơ k chiều đây chính là y ngã thì cái sai số giữa y và y Ngã của mình nó chính là bằng giá trị này nhân cho log của giá trị dự đoán giá trị này nhân log giá trị Dự đoán và cộng lại các cái cái y với lại cái LCK y ngã thì cái thành phần K của mình cái chỉ số chạy K của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:04:46",
      "end_timestamp": "0:05:39"
    }
  },
  {
    "page_content": "thành phần K của mình cái chỉ số chạy K của mình nó sẽ chạy từ từ 1 cho đến 2 cho đến k că a và nó sẽ cứ Lấy từng cái cặp này y y thứ K nhân với lại cái y mũ thứ K cộng lại và lưu ý là chúng ta mới chỉ tính cho cái mẫu dự liệu thứ y thôi Đây là một mẫu một mẫu mẫu này là mẫu thứ mẫu thứ y và chúng ta sẽ phải tính sii số cho trung bình cộng của tất cả các cái mẫu dữ liệu do đó ở đây chúng ta sẽ có một cái tổng nữa là y y chạy từ 1 cho đến n và trung bình cộng thì chúng ta sẽ để là 1 phn rồi và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:05:33",
      "end_timestamp": "0:06:16"
    }
  },
  {
    "page_content": "bình cộng thì chúng ta sẽ để là 1 phn rồi và để thêm cái dấu trừ ở đằng trước thì đây là cái công thức của cái hàm logl Tuy nhiên đối với bài toán phân lớp nhị phân thì chúng ta sẽ có cái công thức log L theo cái kiểu như sau đó là ở cái mẫu dữ liệu thứ y đúng không Ví dụ đây là cái mẫu dữ liệu thứ y đi thì chúng ta sẽ lấy cái y nhân log y ngã cộng cho 1 - y nhân cho log của 1 ph trừ y ngã thì hiểu một cách N ra đây chính là một cái trường hợp đặc biệt của cái n loss cho cái công thức ở trên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:06:12",
      "end_timestamp": "0:06:53"
    }
  },
  {
    "page_content": "đặc biệt của cái n loss cho cái công thức ở trên đây tại vì nếu như chúng ta biểu diễn cái i này dưới dạng vectơ ha thì y này nó sẽ là bao gồm hai thành phần bao gồm ha thành phần cái Thành Phần đầu tiên là cho biết cái xác suất thuộc về cái lớp thứ nhất thành phần thứ hai là cho biết cái xác suất thuộc về lớp thứ hai rồi y ngã tương tự như vậy thì cũng sẽ có hai thành phần Tuy nhiên nếu như ở đây y của mình nó chỉ nhận một cái giá trị từ 0 cho đến 1 thôi từ 0 cho đến 1 thôi thì cái thành phần",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 10,
      "start_timestamp": "0:06:46",
      "end_timestamp": "0:07:30"
    }
  },
  {
    "page_content": "đến 1 thôi từ 0 cho đến 1 thôi thì cái thành phần thứ nhất mà là y thì thành phần thứ hai nó sẽ là 1 - y thành phần thứ hai sẽ là 1 - y thành phần thứ nhất này mà là y ngã thì thành phần thứ hai nó sẽ là 1 - i ngã và lúc này thì mình sẽ không cần dùng cái dạng vector nữa mà mình sẽ dùng một cái giá trị scaler Thành Phần đầu tiên là xác suất thuộc về cái lớp của mình và thành phần thứ hai đó là 1 - y chính là cái xác suất thuộc về cái lớp còn lại do đó thì cái đây là cái công thức loog L cho cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 11,
      "start_timestamp": "0:07:25",
      "end_timestamp": "0:08:08"
    }
  },
  {
    "page_content": "do đó thì cái đây là cái công thức loog L cho cái trường đây là trường hợp đặc biệt so với lại cái công thức ở đây và clock loss thì nó có một cái tính chất đó chính là cái loss của mình càng nhỏ thì độ chính xác nó sẽ càng cao mọi hàm lỗi nó đều có cái tính chất này giá trị loss càng nhỏ thì cái độ chính xác của mình nó sẽ càng cao và tổng tổng của tất cả các cái mẫu dữ liệu thì chúng ta sẽ lấy trung bình cộng chúng ta sẽ lấy trung bình cộng của tất cả các mẫu dữ liệu ha Và đây là chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 12,
      "start_timestamp": "0:08:01",
      "end_timestamp": "0:09:00"
    }
  },
  {
    "page_content": "tất cả các mẫu dữ liệu ha Và đây là chúng ta sẽ có chỉ số y n thì ở đây thì cái cách tính của mình sẽ là lấy cái giá trị y này nè nhân với lại log của n y ngã đây chính là y đây chính là y ngã rồi cộng cho 1 - y nhân cho log của 1 - y ngã thì mình sẽ ra được cái giá trị này tương tự như vậy 1 nhân với lại log của 0.75 cộng cho 1 - 1 nhân cho log của 1 - 075 thì nó sẽ ra cái giá này à lưu ý là chúng ta phải có dấu trừ ở đằng trước có dấu trừ trước thì cái giá trị 1.4 này nó chính là bằng trừ của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 13,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "thì cái giá trị 1.4 này nó chính là bằng trừ của 0 nhân với lại log của 0.96 cộng cho à 1 - 0 tức là 1 nhân cho log của 1 trừ 0.96 thì nó sẽ ra là số này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=QUIZn8fpTpI",
      "filename": "QUIZn8fpTpI",
      "title": "[CS116 - Buổi 5] Part 3",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng đến với cái phần cài đặt mô hình linear regression sử dụng thư viện scikit-learn thì bước đầu tiên đó là chúng ta sẽ cùng tạo sinh ra các cái dữ liệu mẫu thì ở đây chúng ta đã chuẩn bị sẵn một cái chương trình để tạo ra các cái dữ liệu trong đó X sẽ là các cái giá trị lấy mẫu từ 1 cho đến số nhỏ hơn 10 và bước nhảy là 0.5 tức là X sẽ là bằng 1, 1.5, 2, 2.5, vân vân cho đến 9.5 và chúng ta sẽ có thêm một cái đại lượng nữa đó là noise. Thì cái noise này nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:57"
    }
  },
  {
    "page_content": "đại lượng nữa đó là noise. Thì cái noise này nó sẽ có kích thước đúng bằng kích thước của X. Tức là cái số phần tử của X. Ở đây noise này thì nó đại diện cho những cái phần ờ sai số trong quá trình mà chúng ta đo lường cái dữ liệu của mình khi trong thực tế. Và y thì sẽ là có cái công thức ở đây chúng ta sẽ cho trước một cái hàm phương trình là y = -6x + 10 và chúng ta sẽ cộng thêm cho một cái sai số noise theo cái nhiễu à tuân theo cái phân bố đó là phân bố chuẩn. Và sau đó thì chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:51",
      "end_timestamp": "0:01:36"
    }
  },
  {
    "page_content": "bố đó là phân bố chuẩn. Và sau đó thì chúng ta sẽ tiến hành vẽ các cái cặp điểm X và y lên trên cái ờ sơ đồ của mình bằng thư viện plt. Rồi thì chúng ta thấy ở đây là sẽ có các cái điểm là các cái sai số của mình. Thì chúng ta có thể generate ra nhiều lần. Thì muốn cho cái noise này á mà nó có cái sự dao động lớn hơn thì chúng ta có thể tăng cái biên độ này lên. Bình thường chúng ta để là noise là 0.1, bây giờ chúng ta đang có là noise 0.2 và muốn tăng cái sai số này lên chúng ta có thể cho lên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:26",
      "end_timestamp": "0:02:11"
    }
  },
  {
    "page_content": "tăng cái sai số này lên chúng ta có thể cho lên là 5. Đó thì các bạn sẽ thấy là cái sự dao động xung quanh cái đường thẳng y = -6x + 10 nó lớn hơn. Còn nếu như chúng ta cho cái dao động này là bằng 1 cái độ lệch này bằng 1 thì nó sẽ ít dao động hơn. Đó thì để cho mô phỏng gần giống với lại cái sai số trong thực tế thì chúng ta sẽ cho cái nhiễu này nó lớn một chút. Đó thì nó ra cái đường các cái điểm xoay xung quanh cái đường thẳng y bằng -6x + 10. Thì đây là cái phương trình đúng mà mình sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 3,
      "start_timestamp": "0:02:05",
      "end_timestamp": "0:02:47"
    }
  },
  {
    "page_content": "+ 10. Thì đây là cái phương trình đúng mà mình sẽ phải tìm cách để đưa ra được cái dự đoán và chúng ta sẽ sử dụng cái mô hình linear regression để chúng ta đoán xem là các cái tham số tương ứng với lại cái X, cái biến X và cái bias này là bao nhiêu khi chúng ta đưa vào tập các cái mẫu huấn luyện này. Đó thì ở đây chúng ta sẽ xem ha, X của mình `X.shape` rồi. Tức là ở đây chúng ta đang có 18 mẫu tất cả rồi. Tiếp theo thì chúng ta sẽ Build cái model sử dụng thư viện scikit-learn.linear_model. Và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 4,
      "start_timestamp": "0:02:42",
      "end_timestamp": "0:03:23"
    }
  },
  {
    "page_content": "sử dụng thư viện scikit-learn.linear_model. Và chúng ta sẽ sử dụng mô hình là hồi quy tuyến tính linear regression. Và để tạo ra cái đối tượng là linear regression xong rồi chúng ta sẽ fit tức là chúng ta sẽ huấn luyện trên cái dữ liệu X và y. Chúng ta đã train ở đây thì chúng ta sẽ gọi cái lệnh như sau là Reg là viết tắt của regression, linear regression. Rồi `Reg.fit(X, y)`. Chúng ta sẽ chạy thử ha. Rồi thì ở đây nó có một cái thông báo lỗi à expected là 2D array nhưng nó lại got 1D array.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 5,
      "start_timestamp": "0:03:19",
      "end_timestamp": "0:04:08"
    }
  },
  {
    "page_content": "à expected là 2D array nhưng nó lại got 1D array. Tức là mình, cái X này của mình á Bây giờ mình sẽ xem lại ha `X.shape`. OK ở đây thì nó đang nói đó là mình đang chỉ có 1D array trong khi đó cái người ta kỳ vọng đó là 2D. Thì đầu vào của mình á là X sẽ là một tập hợp các cái điểm Ví dụ như X của mình nó sẽ là phải bằng rồi x1, x2 rồi xuống dòng cho cái mẫu dữ liệu thứ hai rồi x2, x1, x2 đó. Thì đây là cái ví dụ của mình. Trong trường hợp này thì chúng ta chỉ có duy nhất một cái mẫu dữ, xin",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 6,
      "start_timestamp": "0:04:04",
      "end_timestamp": "0:05:07"
    }
  },
  {
    "page_content": "thì chúng ta chỉ có duy nhất một cái mẫu dữ, xin lỗi, chúng ta chỉ có duy nhất một chiều thôi. Rồi thì như vậy thì ở đây lẽ ra nó sẽ phải là một cái ma trận. X của mình sẽ lẽ ra là một ma trận thay vì là một vectơ. Do đó thì chúng ta sẽ phải thực hiện một cái thao tác là `reshape`. Như vậy là X sẽ là bằng X chấm `reshape` và chúng ta sẽ thấy là ở đây cái cột của mình á là nó sẽ có một cột đúng không? Tại vì cái X của mình nó là một cái giá trị scalar. Do đó thì nó chỉ có một cột. Trong trường",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 7,
      "start_timestamp": "0:05:02",
      "end_timestamp": "0:05:39"
    }
  },
  {
    "page_content": "scalar. Do đó thì nó chỉ có một cột. Trong trường hợp X của mình là vectơ nhiều chiều thì mình sẽ có nhiều cột hơn. Như vậy thì mình sẽ có là một cột. Còn số dòng thì ở đây mình sẽ không biết cái số dòng là bao nhiêu. Thực ra mình biết nó là 18, mình có thể để là 18, 1 như thế này cũng được. Tuy nhiên mình sẽ để cho Python, thư viện NumPy nó sẽ tự tính cái số dòng là bao nhiêu. Mình chỉ cần biết là à X của mình là từ một cái dạng vectơ chuyển về một cái ma trận với cái số cột của mình là một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 8,
      "start_timestamp": "0:05:36",
      "end_timestamp": "0:06:18"
    }
  },
  {
    "page_content": "về một cái ma trận với cái số cột của mình là một cột rồi. Còn chuyển còn lại là số dòng nó sẽ tự tính. Như vậy thì ở đây mình sẽ để là -1. Rồi rồi và ở đây thì chắc mình sẽ in ra ha, `X.shape` rồi. Như vậy thì nó đã chuyển thành một cái ma trận hai chiều, trong đó cái chiều thứ hai sẽ là có một cột và số dòng tương ứng là cái số mẫu dữ liệu của mình sẽ là 18. Bây giờ mình sẽ fit dữ liệu vào. OK, như vậy sau khi chúng ta fit xong thì chúng ta đã có được cái mô hình và bây giờ thì chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 9,
      "start_timestamp": "0:06:14",
      "end_timestamp": "0:06:55"
    }
  },
  {
    "page_content": "đã có được cái mô hình và bây giờ thì chúng ta sẽ tiến hành Trực Quan Hóa cái mô hình này. Thì khi chúng ta fit xong á thì các cái tham số của cái mô hình của mình nó đã được lưu bên trong cái biến là biến Reg này. Bây giờ chúng ta sẽ cùng quan sát xem cái Reg này các cái biến số của Reg nó sẽ có cái gì ha. `Reg.` thì ở đây chúng ta sẽ có cái thông số đó là `coefficient`. `Coefficient` tức là cho chúng ta biết là cái hệ số của cái biến X này là bao nhiêu, của các cái tham số đầu vào của mình là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 10,
      "start_timestamp": "0:06:50",
      "end_timestamp": "0:07:29"
    }
  },
  {
    "page_content": "nhiêu, của các cái tham số đầu vào của mình là bao nhiêu thì chúng ta sẽ in ra ở đây. Như vậy hệ số của mình là -5.7. Ở đây thì chúng ta sẽ có một cái array, một cái mảng là ở đây nó sẽ để một cách tổng quát là trong trường hợp X của mình á nó có nhiều à nó có nhiều cột. Trong trường hợp này thì X của mình chỉ có duy nhất là một giá trị scalar nhưng mà một cách tổng quát thì X của mình nó có thể là có nhiều cột. Như vậy thì ở đây nó sẽ để là một cái ma trận X, để một cái vectơ và trong cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 11,
      "start_timestamp": "0:07:23",
      "end_timestamp": "0:08:04"
    }
  },
  {
    "page_content": "một cái ma trận X, để một cái vectơ và trong cái vectơ này thì nó chỉ có duy nhất một phần tử. Nếu X của mình có hai cột, ba cột, ví dụ như X có ba cột thì ở đây nó sẽ có ba à ba giá trị tương ứng cái hệ số của từng cột của mình. Rồi thì hệ số của cái X của mình nó chính là `coefficient` là bằng -5.7. Thì chúng ta đối chiếu với lại cái phương trình này chúng ta thấy con số -5.7 nó cũng khá là gần với lại cái con số là hệ số -6 của cái mô hình mà mình cần phải dự đoán ở đây. Rồi bây giờ chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 12,
      "start_timestamp": "0:07:57",
      "end_timestamp": "0:08:42"
    }
  },
  {
    "page_content": "mình cần phải dự đoán ở đây. Rồi bây giờ chúng ta sẽ có thêm một cái thành phần nữa đó là thành phần bias. Thì mình sẽ xem trong mô hình linear regression thì cái bias nó lưu ở đâu. Trong mô hình linear regression thì bias nó lưu ở trong cái biến là `intercept`. Đó thì ở đây là hệ số của mình là 6.9. Chúng ta cũng thấy đó là nó cũng gần với lại cái con số là 10. Sở dĩ là cái con số 6.9 nó vẫn còn thấp hơn con số 10 là vì cái sai số ở đây chúng ta đang cho khá là lớn. Nếu như chúng ta giảm cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 13,
      "start_timestamp": "0:08:35",
      "end_timestamp": "0:09:36"
    }
  },
  {
    "page_content": "ta đang cho khá là lớn. Nếu như chúng ta giảm cái sai số này xuống thì à cái bias của mình nó có thể sẽ gần chính xác hơn. Ví dụ mình cho ở đây là bằng 3 rồi thì chúng ta sẽ thấy là cái lệch, cái sự lệch của nó nó ít hơn và mình sẽ ờ cho chạy lại cái mô hình này. Rồi hệ số của mình hồi nãy đang là - 5.7 đúng không? Rồi thì ở đây là nó vẫn xấp xỉ là -5, -5.3 và `intercept` của mình thì nó là là 6. Ở đây thì vẫn còn lớn ha. Ví dụ như nếu chúng ta cho nó là 1. Đi, đó thì nó tiến tới là -5.9, xấp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 14,
      "start_timestamp": "0:09:32",
      "end_timestamp": "0:10:14"
    }
  },
  {
    "page_content": "cho nó là 1. Đi, đó thì nó tiến tới là -5.9, xấp xỉ -6 và bias của mình là nó tiến đến 9.6. Tức là gần bằng 10, gần bằng 10. Thì nguyên nhân khiến cho các cái hệ số của biến X và bias của mình nó bị lệch đó chính là do cái nhiễu này. Thì bây giờ chúng ta đang giả lập trong cái tình huống là dữ liệu của mình nó bị nhiễu dao động nhiều thì chúng ta cứ để là cái giá trị nhiễu này là một con số khá là để 5 chấm. Rồi bây giờ mình sẽ cho chạy lại hàm fit và xem các cái hệ số này. Rồi thì bây giờ mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 15,
      "start_timestamp": "0:10:08",
      "end_timestamp": "0:11:05"
    }
  },
  {
    "page_content": "và xem các cái hệ số này. Rồi thì bây giờ mình sẽ trực quan hóa, mình sẽ tiến hành Trực Quan Hóa cái mô hình này của mình bằng cách đó là mình sẽ vẽ ra một cái đường thẳng đi xuyên qua các cái điểm này và cái công thức của mình thì vẫn là Y sẽ là bằng cái hệ số nhân với X cộng cho bias rồi. Ờ rồi thì ở đây chúng ta sẽ vẽ lên cái mô hình này bằng cách `plt.plot` thì chúng ta sẽ lấy các cái điểm X và y dự đoán đúng không? X và y dự đoán thì cái X đầu tiên cái điểm đầu tiên của mình nó sẽ bắt đầu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 16,
      "start_timestamp": "0:11:00",
      "end_timestamp": "0:11:42"
    }
  },
  {
    "page_content": "đầu tiên cái điểm đầu tiên của mình nó sẽ bắt đầu tại ở vị trí này đi. Ví dụ chúng ta cho là -1 à xin lỗi, vị trí 1 đi ha, và cái điểm cuối ở bên đây mình sẽ cho đó là 9. Đó thì ở đây chúng ta sẽ có hai điểm là 1 và 9. Rồi tương ứng thì mình sẽ có là mình sẽ lấy cái công thức ở trên đây ha, lấy công thức ở trên đây. Lưu ý là các cái hệ số này mình không có sử dụng cái mô hình gốc ban đầu, mà chúng ta sẽ phải thay cái con số -6 này bằng cái hệ số của mô hình đã huấn luyện được. Rồi, con số 10",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 17,
      "start_timestamp": "0:11:36",
      "end_timestamp": "0:12:20"
    }
  },
  {
    "page_content": "số của mô hình đã huấn luyện được. Rồi, con số 10 (trong phương trình gốc) là bằng `intercept` của mô hình đã huấn luyện được, và bias thì sẽ lấy con số này là `Reg.intercept_`. Rồi, tương tự như vậy, chúng ta sẽ làm cho à X của mình trong trường hợp này là bằng 1 ha, X là bằng 1. Rồi cái giá trị dự đoán tiếp theo thì chúng ta sẽ copy cái công thức ở đây và chúng ta thay cái giá trị của mình đúng không? Thay cái giá trị của mình là 9 này và cái giá trị dự đoán bởi cái mô hình của mình. Nó sẽ có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 18,
      "start_timestamp": "0:12:15",
      "end_timestamp": "0:12:23"
    }
  },
  {
    "page_content": "trị dự đoán bởi cái mô hình của mình. Nó sẽ có công thức là `Reg.coef_[0] * 9 + Reg.intercept_`. giá trị dự đoán bởi mô hình của mình nó sẽ có công thức là `Reg.coef_[0]` nhân với 9 cộng cho `Reg.intercept_`. Rồi. Ok thì ở đây nó đang có một cái lỗi: không có thuộc tính `plot`. Rồi thì chúng ta thấy là cái mô hình của mình nó đi xuyên qua các cái điểm. Như vậy là sau khi huấn luyện xong thì cái mô hình của mình nó khá là khớp với các cái điểm mà đã được generate trước đó.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=sDmzaaAv3Pc",
      "filename": "sDmzaaAv3Pc",
      "title": "[CS116 - Buổi 8] Part 7_1",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và đến với cái phần mà mô hình sau khi đã được huấn luyện xong và chúng ta phải đánh giá cái mô hình của mình nó có tốt hay không thì tại sao chúng ta không sử dụng cái hàm log loss đó nữa để làm một cái độ đo đánh giá tại sao chúng ta không sử dụng cái log loss làm độ đo đánh giá tại vì như chúng ta đã giải thích trước đây á là một cái hàm độ lỗi của cái mô hình khi huấn luyện không nhất thiết nó phải là cái hàm để đánh giá thì trong trường hợp này Tại sao chúng ta không dùng nếu như chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:32"
    }
  },
  {
    "page_content": "này Tại sao chúng ta không dùng nếu như chúng ta sử dụng cái độ đo log loss thì rõ ràng là nó sẽ khó hiểu nó sẽ rất khó hiểu đối với cái người à người sử người mà không có chuyên môn hoặc về machine learning hoặc là đối với khách hàng của mình mà chúng ta phải sử dụng cái độ đo nó dễ hiểu hơn và dễ cảm nhận hơn họ sẽ không hiểu là tại sao chúng ta lại dùng là trừ của y log y tổng Tại sao lại có cái thành phần log này thì nguyên nhân của đó đó là để giúp cho cái quá trình huấn luyện nó sẽ nhanh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 1,
      "start_timestamp": "0:00:27",
      "end_timestamp": "0:01:07"
    }
  },
  {
    "page_content": "để giúp cho cái quá trình huấn luyện nó sẽ nhanh hơn giúp cho cái quá trình huấn luyện nó hiệu quả hơn thì đối với khách hàng hoặc là đối với những người dùng đối với những cái người mà không có cái kiến thức đó về machine learning Họ sẽ không quan tâm lắm Về cái độ đo này mà họ cần có một cái độ đo mà người ta cảm nhận được thì Jaccard Index là một cái độ đo như vậy Giả sử như y là cái tập giá trị thực tế của cái tập test của mình và y ngã là tập các cái giá trị dự đoán thì Jaccard của y và y",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 2,
      "start_timestamp": "0:01:04",
      "end_timestamp": "0:01:54"
    }
  },
  {
    "page_content": "các cái giá trị dự đoán thì Jaccard của y và y ngã thì nó sẽ được tính là bằng phần giao y và y ngã so với lại cái phần hợp của y và y ngã thì giả sử như là chúng ta có cái y của mình là 11 10 1 rồi y ngã của mình sẽ là 11 10 10 thì khi đó cái phần giao của hai cái y và y ngã của mình nó sẽ là năm phần tử tại sao ở đây là giống nè Ở đây là giống nè Giống giống V à x rồi đây không dấu đây là dấu như vậy thì có tất cả là năm phần tử giống và trên tổng số phần tử của mình đó là có bảy phần tử như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 3,
      "start_timestamp": "0:01:48",
      "end_timestamp": "0:02:49"
    }
  },
  {
    "page_content": "tổng số phần tử của mình đó là có bảy phần tử như vậy thì cái Jaccard của mình đó sẽ là bằng 5 mẫu đúng trên tổng số mẫu của mình là 7 mẫu cộng cho 7 - 5 cho 7 - 5 thì dựa trên cái công thức này y là tổng số mẫu nè y ngã là tổng số mẫu dự đoán nè trong tổng số mẫu dự đoán còn y là tổng số mẫu thực tế trừ cho trừ cho cái thành phần mà giao của hai cái thằng này đi Tức là đây là những cái chúng ta dự đoán đúng đúng không Và đây là cái mà trừ này ra thì nó sẽ là loại bỏ đi cái thành phần dự đoán",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 4,
      "start_timestamp": "0:02:42",
      "end_timestamp": "0:03:37"
    }
  },
  {
    "page_content": "ra thì nó sẽ là loại bỏ đi cái thành phần dự đoán đúng này đi Tức là những cái thành phần mà chúng ta dự đoán sai thì đó chính là cái diện tích của cái phần này cái phần mẫu số của mình nó sẽ là diện tích của cái phần này chúng ta sẽ lấy y là toàn bộ cái tập này cộng cho Y ngã là tập này chúng ta sẽ trừ đi cái thành phần giao y và y ngã thì nó sẽ ra được cái thành phần là phần hợp mà y giao với y ngã Tức là những cái thành phần mà chúng ta dự đoán đúng như vậy thì với cái độ đo Jaccard thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 5,
      "start_timestamp": "0:03:30",
      "end_timestamp": "0:04:13"
    }
  },
  {
    "page_content": "đoán đúng như vậy thì với cái độ đo Jaccard thì chúng ta sẽ thấy được rằng là tổng số mẫu đúng chia cho tổng số mẫu mà thuộc cái phần hợp này thì nó sẽ ra là 0.41 và với cái độ đo này thì chúng ta sẽ thấy rằng là trong trường hợp mà hoàn hảo nhất tức là hai cái tập y và y ngã này trùng khớp với nhau hoàn toàn giá trị trên với giá trị dưới nó khớp nhau hoàn toàn tức là chúng ta đang có hai cái vòng tròn đúng không Chúng ta sẽ có hai vòng tròn chồng lên nhau y đồng thời chính là y ngã thì khi đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 6,
      "start_timestamp": "0:04:09",
      "end_timestamp": "0:05:00"
    }
  },
  {
    "page_content": "lên nhau y đồng thời chính là y ngã thì khi đó phần giao của y và y ngã nó chính là tổng số phần tử của của mình luôn đó chính là tổng số phần tử thì giao với y ngã thì nó cũng chính là bằng cái lực lượng của tập y này luôn và y cộng cho Y ngã trừ cho phần giao của y và y ngã thì nó cũng chính là bằng y cộng cho Y tại vì y và y ngã giống nhau đúng không y cộng cho Y trừ cho cái phần này là giống là 1y luôn như vậy là bỏ như vậy là tử số là lực lượng của tập y và mẫu số là lực lượng của tập y do",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 7,
      "start_timestamp": "0:04:54",
      "end_timestamp": "0:05:49"
    }
  },
  {
    "page_content": "của tập y và mẫu số là lực lượng của tập y do đó thì trong cái trường hợp này nó sẽ ra là 1 tức là 100 phần trăm còn trong tình huống tệ nhất đó là không có giao thì hai cái đường tròn này không giao nhau như vậy là cái phần tử số là y giao với lại y ngã thì nó sẽ là bằng 0 0 chia cho bao nhiêu cũng bằng 0 thì với cái cách sử dụng cái độ đo Jaccard này thì nó sẽ cho chúng ta cảm nhận được cái ý nghĩa của cái phép tính Jaccard của mình ngoài ra thì chúng ta cũng có thể sử dụng các cái độ đo về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 8,
      "start_timestamp": "0:05:39",
      "end_timestamp": "0:06:24"
    }
  },
  {
    "page_content": "thì chúng ta cũng có thể sử dụng các cái độ đo về precision, recall và F1-score. Precision là thể hiện số mẫu mà mình dự đoán đúng. Tức là trong số những cái kết quả mà mình dự đoán, dự đoán thì số mẫu mà mình dự đoán đúng chia cho tổng số mẫu chia cho tổng số mẫu mà mình đưa ra cái phán đoán. Ví dụ ở đây precision nó sẽ được tính bằng công thức là true positive chia cho true positive cộng cho false positive. True positive tức là nếu như mình nói đó là positive và nó thực sự là positive còn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 9,
      "start_timestamp": "0:06:17",
      "end_timestamp": "0:07:04"
    }
  },
  {
    "page_content": "nói đó là positive và nó thực sự là positive còn false positive tức là nếu như mình nói nó là positive nhưng mà nó sai nó không đúng thì bây giờ chúng ta sẽ có cái F1-score và tương tự như precision và recall thì nó cũng sẽ thỏa mãn là tính chất đó là độ chính xác mà càng cao thì nó sẽ càng cao. À nó khác so với lại cái độ đo hàm độ lỗi. Đối với hàm độ lỗi như là log loss thì loss mà càng thấp thì càng tốt. Thì F1-score, F1-score độ chính xác nó sẽ càng tiến về 1, độ chính xác càng cao thì thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 10,
      "start_timestamp": "0:06:59",
      "end_timestamp": "0:07:48"
    }
  },
  {
    "page_content": "sẽ càng tiến về 1, độ chính xác càng cao thì thì thì cái giá trị F1-score nó sẽ càng tiến về 1. Tương tự như vậy vì precision, precision và recall thì nó sẽ càng chính xác nếu như nó càng tiến về 1. Recall thì nó là bằng tập hợp true positive chia cho true positive cộng cho false negative. F1-score thì đây là công thức trung bình điều hòa. Trung bình điều hòa. Rồi, cả F1-score lẫn là precision hoặc là recall thì đều thỏa mãn tính chất đó là càng tiến đến 1 thì độ chính xác càng cao chứ không",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 11,
      "start_timestamp": "0:07:43",
      "end_timestamp": "0:08:28"
    }
  },
  {
    "page_content": "tiến đến 1 thì độ chính xác càng cao chứ không phải là chỉ có F1-score Và bây giờ thì chúng ta sẽ tính toán thử tính toán thử. Đầu tiên đó là với cái phán đoán là đây là đoán nha, đây là đoán nè, là nhãn mà bằng 0 thì precision, recall và F1-score là bao nhiêu? Thì chúng ta phải xem. Chúng ta sẽ xét trên cái cột dự đoán nè, nhãn bằng 0 tức là chúng ta đang muốn nói đến nguyên cái cột này, chúng ta đang muốn nói đến nguyên cái cột này. À thì nhãn bằng 0 có nghĩa là ở đây chúng ta quên hết công",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 12,
      "start_timestamp": "0:08:21",
      "end_timestamp": "0:09:16"
    }
  },
  {
    "page_content": "bằng 0 có nghĩa là ở đây chúng ta quên hết công thức này đi, chúng ta sẽ hiểu cái ý nghĩa của công thức để chúng ta ráp số vào. À đối với nhãn bằng 0, tức là tổng số mẫu mà tôi dự đoán đó chính là 24 cộng 9 mẫu. 24 cộng 9 mẫu và trong số 24 cộng 9 mẫu này thì những cái thằng mà tôi đoán đúng, tức là true negative, tức là 24. Như vậy thì precision cho cái nhãn bằng 0 tương ứng nó sẽ là đoán negative đúng không? Mình đang nhãn là bằng 0, tức là negative. Đoán negative là 24. À đoán mà đoán đúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 13,
      "start_timestamp": "0:09:10",
      "end_timestamp": "0:09:55"
    }
  },
  {
    "page_content": "Đoán negative là 24. À đoán mà đoán đúng nha, chia cho tổng cái số mà tôi đoán negative tức là 24 cộng cho 9. Chín thằng này là tôi đoán sai. Tôi đoán sai. Còn 24 thằng này là tôi đoán đúng rồi. Và chúng ta sẽ dùng máy tính chúng ta sẽ tính ra được cái con số ở đây. Recall nó sẽ là bằng 24 chia cho tổng số mẫu mà lẽ ra lẽ ra tôi phải thực sự có đúng không? Thì chúng ta sẽ tính trên cái cột này, à xin lỗi tính trên cái hàng này. 24 này là cái chúng ta đã phát hiện ra được nhưng mà chúng ta đã bỏ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 14,
      "start_timestamp": "0:09:50",
      "end_timestamp": "0:13:30"
    }
  },
  {
    "page_content": "ta đã phát hiện ra được nhưng mà chúng ta đã bỏ sót một cái false positive, tức là bỏ sót một mẫu nó thực sự là negative. Như vậy thì ở đây nó sẽ là bằng 24 chia cho 24 cộng 1. Và F1-score thì nó sẽ là bằng trung bình điều hòa dựa trên cái công thức này, chúng ta sẽ tính ra cái giá trị ở đây đó. Thì có cái công thức này rồi thì khá là dễ tính rồi. Nhãn bằng à 1 thì lúc này chúng ta sẽ xét đến cái dự đoán của mình là nhãn 1, tức là chúng ta sẽ xét đến cái cột này. Chúng ta đang xét đến giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 15,
      "start_timestamp": "0:10:31",
      "end_timestamp": "0:11:03"
    }
  },
  {
    "page_content": "đến cái cột này. Chúng ta đang xét đến giá trị dự đoán và sáu cái cái cái dự đoán của mình là đúng là true positive. Thì đây là cái công thức dành cho cái việc dự đoán nhãn là bằng 1 rồi. Thì chúng ta sẽ có sáu mẫu dự đoán đúng trên tổng số mẫu ở đây mà chúng ta đoán đó là 6 + 1 tức là 6/7. Và recall tương ứng của mình nó sẽ là bằng 6 6 mẫu chia cho tổng số mẫu mà lẽ ra mình phải trả về. Đây là thực tế nè, thực tế nhãn bằng 1 thì nó sẽ 1 tức là 6/7 và recall tương ứng của mình nó sẽ là bằng 6 6",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 16,
      "start_timestamp": "0:10:58",
      "end_timestamp": "0:11:41"
    }
  },
  {
    "page_content": "và recall tương ứng của mình nó sẽ là bằng 6 6 mẫu chia cho tổng số mẫu mà Lẽ ra mình phải trả về đây là thực tế nè thực tế nhãn bằng 1 thì nó sẽ là có 15 mẫu. Trong đó Sáu mẫu đã được thuật toán của mình nó phát hiện ra. Chín mẫu thì bỏ sót. Như vậy ở đây sẽ là 6 + 9. Và như vậy thì hai cái giá trị này thực hiện trung bình điều hòa chúng ta sẽ ra được cái giá trị ở đây. Rồi, và một cách trung bình thì chúng ta sẽ lấy trung bình cộng của precision này với precision này sẽ ra được trung bình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 17,
      "start_timestamp": "0:11:32",
      "end_timestamp": "0:12:38"
    }
  },
  {
    "page_content": "này với precision này sẽ ra được trung bình cộng này. Recall này với recall này chúng ta sẽ ra giá trị trung bình. Và F1-score, F1-score ở đây cho hai trường hợp là nhãn bằng 0 và nhãn bằng 1 thì chúng ta sẽ cộng lại chia đôi chúng ta sẽ ra cái giá trị ở đây. Thì đó là cái cách chúng ta tính toán trên cái độ đo đánh giá là precision, recall và F1-score. Và nhận xét đó là các cái độ đo đánh giá, rồi hàm độ lỗi trên đó là các cái cách tính trung bình. Thực tế thì chúng ta có thể có cái cách tính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 18,
      "start_timestamp": "0:12:34",
      "end_timestamp": "0:13:18"
    }
  },
  {
    "page_content": "Thực tế thì chúng ta có thể có cái cách tính nó thiên lệch, nghĩa là sao? Khi chúng ta không biết cái cái nhãn nào thực sự là quan trọng. Lấy ví dụ như à cái nhãn bằng 0 với lại cái nhãn bằng 1 thì trong thực tế nếu như chúng ta dự đoán nhãn bằng 0 nó có cái vai trò có cái tầm ảnh hưởng lớn hơn thì như vậy nó sẽ có cái trọng số nó sẽ có cái trọng số là à lớn hơn. Đó trọng số lớn hơn, còn nhãn bằng 1 thì cái trọng số của mình nhỏ hơn. Thì lúc đó chúng ta sẽ không cộng trung bình mà chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 19,
      "start_timestamp": "0:13:14",
      "end_timestamp": "0:13:51"
    }
  },
  {
    "page_content": "chúng ta sẽ không cộng trung bình mà chúng ta sẽ lấy cái F1-score của cái tình huống đó là nhãn bằng 0 chúng ta sẽ cho nó trọng số là ví dụ như là 0.8. Sau đó chúng ta sẽ cộng cho 0.2 của cái F1-score nhưng mà với nhãn là bằng 1. Thì tùy vào cái tình huống thực tế của mình chúng ta sẽ có thể có trọng số nó khác nhau chứ không nhất thiết chúng ta là cộng trung bình. Rồi, tương tự như vậy đến cái cấp độ là mẫu dữ liệu. Đến cái cấp độ mẫu dữ liệu thì bình thường là chúng ta sử dụng công thức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 20,
      "start_timestamp": "0:13:47",
      "end_timestamp": "0:14:30"
    }
  },
  {
    "page_content": "thì bình thường là chúng ta sử dụng công thức là trung bình cộng nhưng mà trong thực tế thì chúng ta có thể là sử dụng công thức là trung bình trọng số. Rồi, một số độ đo thì nó có thể bắt nguồn từ cái yếu tố thực tiễn. Ở đây tất cả tất cả các độ đo này thì chúng ta dựa trên cái sự sai số, sai biệt hoặc là đếm chỉ đơn giản là đếm số phần tử đúng chia cho tổng số mẫu đó. Nhưng trong thực tế thì cái hàm độ đo của mình, hàm độ lỗi hoặc là cái độ đo đánh giá của mình nó có thể là các cái độ đo liên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 21,
      "start_timestamp": "0:14:26",
      "end_timestamp": "0:15:03"
    }
  },
  {
    "page_content": "đánh giá của mình nó có thể là các cái độ đo liên quan đến yếu tố về doanh thu, có thể là yếu tố về mặt lợi nhuận, lợi nhuận biên hoặc là thiệt hại kinh tế như là một cái hàm loss. Thì các cái độ đo đó nó hoàn toàn có thể được sử dụng như là một cái hàm để cho mô hình nó học, để cho tối ưu cái mô hình của mình. Rồi, một số cái hàm độ lỗi thì lấy trực tiếp từ cái độ đo đánh giá. Tức là ok, bình thường mình phân biệt đó là hàm độ lỗi và hàm đánh giá. À cái độ đo đánh giá đó là hai cái con số khác",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 22,
      "start_timestamp": "0:14:59",
      "end_timestamp": "0:15:29"
    }
  },
  {
    "page_content": "À cái độ đo đánh giá đó là hai cái con số khác nhau. Nhưng mà trong một số tình huống người ta lấy trực tiếp, tức là chúng ta sẽ dùng hàm độ lỗi này như là một cái hàm đánh giá luôn. Thì khi sau này chúng ta đánh giá thì cái cái cái cái giá trị đánh giá của mình đúng không, là nó sẽ đạt được cái hiệu suất cao. Nhưng mà như mình có nói trước đó, tức là trong nhiều tình huống người ta sử dụng cái độ lỗi là một cái hàm nó khác với hàm đánh giá. Tức là một cách tổng quát thì độ lỗi của mình nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 23,
      "start_timestamp": "0:15:25",
      "end_timestamp": "0:15:33"
    }
  },
  {
    "page_content": "Tức là một cách tổng quát thì độ lỗi của mình nó không nhất thiết phải giống cái hàm đánh giá. Tại vì cái việc thiết kế hàm độ lỗi nó còn phục vụ cho cái mô hình của mình đó huấn luyện nhanh hơn. Thì khi đó người ta sẽ có những cái thủ thuật, có những cái mẹo trong toán học để làm sao cho sử dụng cái hàm độ lỗi này thì cái mô hình của mình huấn luyện rất là nhanh đó. Nhưng có thể là mô hình nó huấn luyện nhanh nhưng mà khi chúng ta đánh giá thì nó sẽ không được như chúng ta mong muốn. Do đó thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "sẽ không được như chúng ta mong muốn. Do đó thì người ta muốn đạt được cái độ đo đánh giá sau khi chúng ta đã huấn luyện xong, chúng ta muốn cái mô hình của mình có cái sự đánh giá tốt thì chúng ta sử dụng trực tiếp cái hàm độ lỗi này là cái hàm đánh giá luôn.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=tEV-Ie0kCsc",
      "filename": "tEV-Ie0kCsc",
      "title": "[CS116 - Buổi 5] Part 3 (tt)",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tiếp theo đó là cấu trúc dữ liệu touble thì đây là một cái đối tượng dùng để lưu trữ tập hợp các các đối tượng khác nhau và touble thì nó không thể nó không thể thực hiện nó không thể thực hiện cái thao tác thêm bớt Thay đổi cái giá trị thay đổi các giá trị của cái touble thì đây là một cái đặc tính mà khiến cho toppo nó ít được sử dụng nhất Tuy nhiên nó vẫn có cái giá trị nhất định Vì túc hồ không được phép thay đổi giá trị do đó thì tốc độ thường được sử dụng để làm cái kết quả trả về của một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:37"
    }
  },
  {
    "page_content": "được sử dụng để làm cái kết quả trả về của một cái hàm số nó thường được dùng để đóng gói các cái kết quả trả về của một hàm số để đảm bảo là trong quá trình mà trẻ Tri Tôn Các kết quả về thì nó sẽ không bị thay đổi ở trong cái quá trình mà chuyển đổi dữ liệu từ cái hàm ra bên ngoài hàng từ trong hẻm ra bên ngoài hẹp và cái cú pháp của touble đó chính là chúng ta sẽ dùng cái dấu cặp dấu mở ngoặc và đóng ngoặc tròn này và chúng ta sẽ điền các quay trở lại và các giá trị giá trị 1 2 ở đây thì nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 1,
      "start_timestamp": "0:00:32",
      "end_timestamp": "0:01:12"
    }
  },
  {
    "page_content": "trở lại và các giá trị giá trị 1 2 ở đây thì nó có thể thuộc các cái kiểu dữ liệu khác nhau thì vì chính touble nó không có thể thực hiện được các cái thao tác thêm bớt thay đổi giá trị nó chỉ có nhiệm vụ là đóng gói các cái những gì giá trị lại chính vì vậy nên cái bộ nhớ được sử dụng cho Oppo nó thường sẽ nhỏ hơn list Tại vì nó không có hỗ trợ các cái thao tác thêm xóa sửa và đồng thời thì cái touble có nó sẽ có cái tốc độ xử lý nhanh hơn so với list Chính vì nó ít hỗ trợ các cái thao tác kia",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 2,
      "start_timestamp": "0:01:06",
      "end_timestamp": "0:01:40"
    }
  },
  {
    "page_content": "list Chính vì nó ít hỗ trợ các cái thao tác kia nên nó đơn giản hơn list nên tốc độ xử lý của nó sẽ nhanh hơn và một trong những cái cấu trúc dữ liệu khác cũng được sử dụng không có quá phổ biến bằng đó chính là tập hợp đó là xét thì xét nó có một cái đặc tính đó là nó không chứa nó không chứa nó không thể chứa các cái phần tử trùng nhau tại vì trong Toán học chúng ta biết rồi nguyên tắc của tập hợp đó là các cái phần tử trong tập hợp nó không được phép cùng nhau Do đó nếu chúng ta khai báo tập",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 3,
      "start_timestamp": "0:01:36",
      "end_timestamp": "0:02:22"
    }
  },
  {
    "page_content": "phép cùng nhau Do đó nếu chúng ta khai báo tập hợp là bao gồm số 1 số 3 rồi lại số 1 số 5 đổi lại số 3 ví dụ vậy thì nó sẽ tự động nó sẽ tự động ép về đó là chúng ta chỉ có các giá trị là 1 3 và 5 mà thôi đương nhiên cái thứ tự 135 này thì ở đây mình chọn là như vậy nhưng mà trong tùy vào cái ngôn ngữ lập trình Python trong quá trình thực thi nó có thể thứ tự nó đã đảo lại mình không biết được và trong cái tập hợp trong cái set nó còn một cái tính chất nữa đó là nó không thể truy theo chỉ số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 4,
      "start_timestamp": "0:02:16",
      "end_timestamp": "0:02:55"
    }
  },
  {
    "page_content": "tính chất nữa đó là nó không thể truy theo chỉ số tại vì cái thứ tự 135 nó có thể lúc thì nó sẽ lưu là 3 1 5 nên chính vì vậy chúng ta không thể lấy theo cái chỉ số được vậy thì xét nó sẽ có các cái thao tác gì xét nó sẽ có các cái toán tử có các thao tác trên các cái phép ví dụ như là phép giao phép hiệu phép Phần bù hoặc là phép hợp Ví dụ và cuối cùng đó là một cái cấu trúc dữ liệu cũng rất là hay được sử dụng và nó cũng gần gũi với một cái kiểu một cái loại file mà các bạn thấy rất là phổ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 5,
      "start_timestamp": "0:02:49",
      "end_timestamp": "0:03:39"
    }
  },
  {
    "page_content": "kiểu một cái loại file mà các bạn thấy rất là phổ biến hiện nay đó là file jasonic để lưu trữ đó là file là gì đó là một danh sách các cái phần tử trong đó thì mỗi phần tử sẽ là một cái cặp khóa và giá trị tức là khi khi là khóa và nó sẽ ánh xạ đến một cái value là giá trị này nó sẽ bao gồm một tập hợp các cái cây và lưu này và mỗi khóa nó phải đảm bảo cái tính chất đó là duy nhất là không được trùng thì cái Nissan nary này thì các bạn nghe cái tên thì chắc các bạn cũng có thể đoán ra được là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 6,
      "start_timestamp": "0:03:34",
      "end_timestamp": "0:04:13"
    }
  },
  {
    "page_content": "tên thì chắc các bạn cũng có thể đoán ra được là nó có thể dùng để làm cái cái ứng dụng gì rồi đúng không nó chính là làm từ điển nó có thể ánh xạ từ một cái từ tiếng Anh sang một từ tiếng Việt ví dụ vậy và cái cú pháp nó chúng ta lưu ý là khi cú pháp nó cũng sẽ sử dụng các cái cặp dấu là mở ngoặc nhọn và đóng ngoặc nhọn Tuy nhiên cái việc khai báo từng cái phần tử trong đây nó sẽ phải tuân theo cái cú pháp đó là khóa 1 giá trị 1 và 2 200 giá trị 2 Còn nếu chúng ta chỉ để là giá trị giá trị giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 7,
      "start_timestamp": "0:04:09",
      "end_timestamp": "0:05:19"
    }
  },
  {
    "page_content": "2 Còn nếu chúng ta chỉ để là giá trị giá trị giá trị thì nó sẽ được hiểu là xét Rồi ví dụ như chúng ta khai báo một cái từ điển Anh Việt như sau rồi chúng ta sẽ có cái từ là Hello thì nó sẽ made in sang cái từ là xin chào và cái từ word thì nó sẽ mát sang cái từ là thế giới chúng ta sẽ dùng không dấu như vậy thì chúng ta sẽ truy cập vô cái giá trị của cái từ hello thì chúng ta sẽ để là mở ngoặc vuông để truy xuất vô cái cái là Hello thì chúng ta sẽ để nằm ngủ mở ngoặc vuông và truyền cái kia",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 8,
      "start_timestamp": "0:05:13",
      "end_timestamp": "0:06:03"
    }
  },
  {
    "page_content": "ta sẽ để nằm ngủ mở ngoặc vuông và truyền cái kia vào ví dụ như Hello thì chúng ta sẽ hiểu rằng kết quả của cái thao tác nắp bên này nó chính là từ xin chào và chúng ta sẽ lấy ra ký tự rồi thì vậy Kết quả của cái phép này thì chúng ta sẽ có một cái câu đó là xin chào thế giới thay vì là Hero World nó sẽ dịch sang tiếng Việt đó là xin chào thế giới Xin chào thế giới thì ở đây để cho nó đẹp thì chúng ta sẽ thêm vô một cái con rắn nữa và thêm vô một cái câu thông báo ví dụ như là nghĩa tiếng Việt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 9,
      "start_timestamp": "0:05:59",
      "end_timestamp": "0:07:10"
    }
  },
  {
    "page_content": "cái câu thông báo ví dụ như là nghĩa tiếng Việt của hello thì ở đây chúng ta dùng cái dấu là nháy đơn ở bên trong cái cụm từ hello hello nên nó sẽ bị nhầm lẫn với lại cái dấu nháy bên ngoài do đó để có thể đóng gói được một cái ký hiệu là dấu nháy thì chúng ta bên ngoài chúng ta sẽ dùng là giá đôi và bên trong thì chúng ta sẽ dùng dây kép như vậy là nghĩa tiếng Việt của hello world chính là xin chào thế giới để tóm tắt cho các cấu trúc dữ liệu cơ bản trong bài thơ thì chúng ta sẽ có một cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 10,
      "start_timestamp": "0:07:05",
      "end_timestamp": "0:07:43"
    }
  },
  {
    "page_content": "cơ bản trong bài thơ thì chúng ta sẽ có một cái bảng như thế này đầu tiên đó là kiểu dữ liệu list thì nó có thể chứa bất kỳ cái kiểu dữ liệu nào và có tính thứ tự có tính thứ tự tức là chúng ta khai báo phụ nữ nào ở trước thì nó sẽ xuất hiện trước và khai báo phụ nữ nào sau thì nó sẽ xuất hiện sau và có các giá trị này thì có thể thay đổi có thứ tự và có thể thay đổi các giá trị còn tốt rồi thì sao tour thì các cái giá trị không thể thay đổi và Tuy nhiên nó vẫn có cái tính thứ tự tức là phần tử",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 11,
      "start_timestamp": "0:07:38",
      "end_timestamp": "0:08:22"
    }
  },
  {
    "page_content": "nhiên nó vẫn có cái tính thứ tự tức là phần tử nào khai báo trước thì nó sẽ được có thể lấy trước phần tử nào khai báo sau thì có thể lấy ra sau và không thể thay đổi giá trị còn đối với xét Tức là nó sẽ chứa các giá trị không trùng lặp nhau và xét thì có thể có thứ tự và có thể thay đổi được các cái nội dung bên trong cái xác Thì theo cái cơ chế là khóa 72 chấm Giá trị tức là ánh xạ từ khóa sang giá trị và nó sẽ các cái khóa này thì không được phép trùng lặp nhau lưu ý là trong dictionary thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 12,
      "start_timestamp": "0:08:15",
      "end_timestamp": "0:08:55"
    }
  },
  {
    "page_content": "phép trùng lặp nhau lưu ý là trong dictionary thì một cái khóa là duy nhất và về cú pháp thì đối với list chúng ta sẽ sử dụng cặp dấu mở ngoặc vuông toppo mở ngoặc tròn xác cảm mở ngoặc nhỏ và discory nằm ở mục nhỏ nhưng mà nó sẽ có cái cấu trúc đó là khóa hai chấm Giá trị và thường thì cái mục đích của list dùng để lưu trữ các danh sách còn của Total thì chúng ta sẽ lưu tập hợp không thay đổi cái giá trị và đòi hỏi cái tốc độ đòi hỏi cái tốc độ xử lý nhanh và set thì thường sử dụng cho biểu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 13,
      "start_timestamp": "0:08:49",
      "end_timestamp": "0:08:57"
    }
  },
  {
    "page_content": "độ xử lý nhanh và set thì thường sử dụng cho biểu diễn các khái niệm tập hợp trong Toán học và dictionary thì đường sẽ sử dụng cái để lưu trữ các dữ liệu có cấu trúc và nó sẽ ánh xạ từ một cái cây sang một cái ba lô nào đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=TqORZBSitQU",
      "filename": "TqORZBSitQU",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.3: Lập trình Python - Biến và kiểu dữ liệu (P3)",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến phần cuối cùng của học có giám sát đó chính là mô hình phân lớp classification thì vị trí của cái bài học này đó là chúng ta sẽ nội dung của cái bài học có giám sát và mô hình hồi quy cũng như là mô hình phân lớp thì đều nằm trong cái bước gọi là model Training tức là chúng ta sẽ tiến hành xây dựng và huấn luyện cái mô hình của mình từ cái tập dữ liệu đã được chuẩn bị ở cái bước trước đó thì đối với cái mô hình hồi quy hoặc là mô hình phân lớp thì đều mục tiêu đó là chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:40"
    }
  },
  {
    "page_content": "mô hình phân lớp thì đều mục tiêu đó là chúng ta sẽ phải ước lượng cái hàm FX sao cho nó đưa ra được cái giá trị dự đoán y và giá trị này thì chúng ta mong muốn đó là nó sẽ xấp xỉ với lại cái giá trị Ờ thực tế thì đó là mục tiêu của học có giám sát và như vậy Để có thể học ra được cái hàm f này chúng ta cần phải có các cái cặp giá trị là xy bao gồm là x là đặc trưng đầu vào và y là cái nhãn đầu ra thì đối với cái mô hình về phân loại thì chúng ta sẽ học về mô hình Logistic Regression và một số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 1,
      "start_timestamp": "000:00:33",
      "end_timestamp": "0:01:18"
    }
  },
  {
    "page_content": "sẽ học về mô hình Logistic Regression và một số mô hình cho cái loại dữ liệu có quan hệ Phi tuyến đối với mô hình Logistic Regression thì đây là một cái mô hình để giải quyết cho cái trường hợp mà dữ liệu y của mình nó sẽ có một cái mối quan hệ tuyến tính F của mình trong trường hợp này đó là một cái hàm tuyến tính Còn trong trường hợp F là một cái hàm Phi tuyến thì chúng ta phải sử dụng những cái mô hình phức tạp hơn đầu tiên đó là mô hình Logistic thì chúng ta xét hai cái tập điểm là màu xanh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 2,
      "start_timestamp": "000:01:13",
      "end_timestamp": "0:01:56"
    }
  },
  {
    "page_content": "thì chúng ta xét hai cái tập điểm là màu xanh và màu cam Nếu như chúng ta sử dụng Ờ hai cái chuỗi ký tự là xanh và cam này để đưa vào mô hình học á thì rõ ràng là mô hình nó sẽ không học được do hai cái giá trị này nó không phải là cái con số do đó thì chúng ta sẽ biểu diễn bằng cách đó là màu xanh thì chúng ta sẽ biểu diễn bằng y là bằng 1 và màu cam thì chúng ta sẽ biểu diễn bằng số 0 đó tương ứng là như trên cái biểu đồ như sau và ở đây ở trong cái không gian hai chiều này thì hai cái thành",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 3,
      "start_timestamp": "000:01:51",
      "end_timestamp": "0:02:32"
    }
  },
  {
    "page_content": "cái không gian hai chiều này thì hai cái thành phần x1 và x2 chính là cái đặc trưng của cái dữ liệu của mình đó là đặc trưng của cái dữ liệu của mình và chúng ta sẽ có cái à mô hình dự đoán y_hat sẽ là bằng sigmoid của beta x trong đó hai cái tập điểm màu xanh và màu cam này nè thì nó sẽ được chia cắt bởi một cái đường thẳng thì đây chính là cái tính chất tuyến tính của cái bài toán của mình tức là các cái tập điểm có thể được chia cách bởi một cái đường thẳng tuyến tính. Một cái đường thẳng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 4,
      "start_timestamp": "000:02:25",
      "end_timestamp": "0:03:08"
    }
  },
  {
    "page_content": "cái đường thẳng tuyến tính. Một cái đường thẳng thì nó gọi là bài toán tuyến tính cho bài toán phân loại và trên cái đường thẳng này thì nó sẽ có cái phương trình là beta x là bằng 0 và những cái điểm nào mà màu xanh và tất cả những cái điểm nào mà nằm về một nửa phía cùng phía với màu xanh chứ không nhất thiết là những điểm màu xanh ha ví dụ cái điểm ở đây cũng được thì khi chúng ta thế nó vào thế cái tọa độ nó vào cái công thức beta x thì nó sẽ cho cái giá trị là lớn hơn 0 và cái giá trị này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 5,
      "start_timestamp": "000:03:05",
      "end_timestamp": "0:03:41"
    }
  },
  {
    "page_content": "cho cái giá trị là lớn hơn 0 và cái giá trị này nó có thể là tiến đến vô cùng cộng vô cùng và tương tự như vậy Những cái điểm nào mà nằm về cùng một phía với cái điểm màu cam Ví dụ như điểm này đó thì khi chúng ta thế cái tọa độ nó vào đây thì cũng chúng ta cũng sẽ ra một cái giá trị là bé hơn 0 và miền giá trị của beta X này nó có thể tiến đến trừ vô cùng nhưng ở đây chúng ta đã biểu diễn các cái giá trị y và các cái giá trị tương ứng với lại hai cái phân lớp là xanh và cam của mình là bởi hai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 6,
      "start_timestamp": "000:03:33",
      "end_timestamp": "0:04:16"
    }
  },
  {
    "page_content": "cái phân lớp là xanh và cam của mình là bởi hai cái giá trị là 1 và 0 do đó thì chúng ta sẽ phải tìm cách để ép cái miền giá trị của beta x về cái đoạn là từ 0 cho đến 1 đó thì may quá chúng ta sẽ có một cái hàm sigmoid hàm sigmoid này sẽ giúp cho chúng ta ép cái miền giá trị của beta x từ trừ vô cùng cộng vô cùng nó sẽ đưa về cái miền giá trị là từ 0 cho đến 1 và nếu như nó chạm được đến cái giá trị là 0 tức là chúng ta đang đưa ra cái quyết định phân loại đó là màu cam và nếu như nó chạm đến",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 7,
      "start_timestamp": "000:04:10",
      "end_timestamp": "0:04:51"
    }
  },
  {
    "page_content": "phân loại đó là màu cam và nếu như nó chạm đến cái giá trị là 1 tức là chúng ta đang ờ xác định cái nhãn của nó chính là màu xanh Thì đó chính là cái mô hình Logistic Regression và với mô hình Logistic Regression thì chúng ta sẽ có cái hàm độ lỗi hàm độ lỗi này là thể hiện cái sai số giữa giá trị dự đoán và giá trị thực tế thì công thức của hàm độ lỗi này đó chính là Binary Cross Entropy Binary Cross Entropy này đó là một cái công thức đặc biệt cho cái trường hợp tổng quát của cái công thức Log",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 8,
      "start_timestamp": "000:04:44",
      "end_timestamp": "0:05:42"
    }
  },
  {
    "page_content": "cái trường hợp tổng quát của cái công thức Log Loss thì cái công thức Log Loss này á đó là bằng tổng của i à log y_hat với k là chạy từ 1 cho đến K trong đó y và y_hat ở đây y và y_hat đều là một cái vectơ có k chiều Ví dụ như chúng ta đang cần phân lớp Ờ ba lớp thì cái k này của mình nó sẽ là bằng 3 vậy Lúc đó I của mình nó sẽ là một cái vectơ ba thành phần nếu như chúng ta phân lớp cho cái bài toán mà 10 lớp thì K của mình bằng 10 và đây sẽ là vectơ có k chiều là 10 còn trong trường hợp phân",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 9,
      "start_timestamp": "000:05:36",
      "end_timestamp": "0:06:17"
    }
  },
  {
    "page_content": "vectơ có k chiều là 10 còn trong trường hợp phân tích nhị phân thì chúng ta không cần phải tạo ra I là y và y_hat là vectơ cái k là bằng 2 tức là vectơ hai chiều Tại vì ở đây chúng ta chỉ cần một giá trị đầu ra thôi thì giá trị này nó sẽ nhận giá trị trên cái đoạn là từ 0 cho đến 1 tương ứng nó sẽ là cái hai cái trạng thái của cái giá trị đầu ra của mình rồi do đó thì không nhất thiết mình phải dùng một cái vector hai chiều mà mình chỉ cần dùng duy nhất một cái giá trị output Tại vì output nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 10,
      "start_timestamp": "000:06:12",
      "end_timestamp": "0:07:01"
    }
  },
  {
    "page_content": "duy nhất một cái giá trị output Tại vì output nó sẽ có hai trạng thái là 0 và 1 thì nó tương ứng với hai cái lớp rồi rồi và công thức của mình cho cái trường hợp mà nó có nhiều lớp thì ở đây nếu mà Đúng là chúng ta nên có cái trung bình cộng chúng ta sẽ để cái trừ đằng trước tức là trung bình cộng đó rồi y log y_hat rồi cộng cho 1 - y log 1 - y thì cái công thức này nó sẽ thỏa mãn đó là nếu như cái giá trị dự đoán mà đoán trúng đó thì cái log của cái loss của mình nó sẽ tiến về 0 Còn trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 11,
      "start_timestamp": "000:06:50",
      "end_timestamp": "0:07:30"
    }
  },
  {
    "page_content": "của cái loss của mình nó sẽ tiến về 0 Còn trong trường hợp mà chúng ta đoán sai Ví dụ như y = 1 mà y_hat của mình mà bằng 0 á thì cái loss này của mình nó sẽ tiến đến cộng vô cùng tức là sai số rất là lớn thì điều này nó sẽ ép cho cái mô hình nó học sẽ nhanh hơn như vậy thì cái mô hình Logistic Regression nó cũng sẽ có những cái đặc điểm về ưu điểm và khuyết điểm thứ nhất đó là mô hình này cũng tương đối là đơn giản và dễ cài đặt Và thậm chí trong scikit-learn thì chúng ta cũng đã có cái module",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 12,
      "start_timestamp": "000:07:26",
      "end_timestamp": "0:08:01"
    }
  },
  {
    "page_content": "scikit-learn thì chúng ta cũng đã có cái module tên là Logistic Regression luôn chúng ta đã có cái cái cài đặt sẵn trong thư viện scikit-learn rồi và chúng ta hoàn toàn có thể dễ dàng mở rộng mô hình Logistic Regression này cho các cái bài toán phân loại nhiều lớp bằng cách thay vì chúng ta sử dụng cái y là bằng sigmoid của beta x chúng ta thay cái hàm này bằng một cái hàm softmax và với cái hàm softmax này thì cái output của mình nó không nhất thiết là ra một giá trị từ 0 đến 1 mà nó có thể ra",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 13,
      "start_timestamp": "000:07:56",
      "end_timestamp": "0:08:37"
    }
  },
  {
    "page_content": "là ra một giá trị từ 0 đến 1 mà nó có thể ra một cái vectơ ở dạng là One-hot để giúp cho chúng ta có thể giải quyết được cái bài toán là phân lớp nhiều lớp và khuyết điểm của mô hình này đó chính là nó không giải quyết được những cái trường hợp là dữ liệu nó phức tạp nghĩa là dữ liệu của mình nó có mối quan hệ Phi tuyến và nó rất dễ bị ảnh hưởng bởi những cái điểm nhiễu bởi những cái dữ liệu nhiễu. Điều gì xảy ra nếu như trong cái tập dữ liệu của mình đó ở đây chúng ta sẽ có những cái điểm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 14,
      "start_timestamp": "000:08:31",
      "end_timestamp": "0:08:48"
    }
  },
  {
    "page_content": "của mình đó ở đây chúng ta sẽ có những cái điểm nhiễu là những cái điểm mà nằm ở đây thì nó sẽ kéo cái mô hình của mình lệch về phía này dẫn đến là mất đi cái tính tổng quát. Mô hình của mình nó sẽ bị mất đi cái tính tổng quát trong khi đó lẽ ra cái mô hình đúng của mình nó nên là cái đường như thế này thì nó sẽ trung dung hơn và thuật toán SVM là một trong những thuật toán nó giúp cho mình loại bỏ được những cái điểm nhiễu tốt hơn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=UCmTraNX7QA",
      "filename": "UCmTraNX7QA",
      "title": "[CS116 - Buổi 8] Part 5",
      "chunk_id": 15,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "về cấu tạo của một cái mạng Convolutional Neural Network thì nó sẽ có những cái thành phần chính sau đây. Thế thì nếu như chúng ta tra cứu trên mạng Internet chúng ta thấy là khi mà người ta vẽ một cái kiến trúc mạng CNN á, thì nó hay sử dụng cái dạng là hình khối ảnh đầu vào ví dụ ở đây là ảnh một chiếc xe rồi nó sẽ biến đổi thành một cái khối. Thì cái khối này á nó gọi là đặc trưng và nó được thực hiện bởi cái phép convolution, đây là phép convolution và ngay sau phép convolution nó sẽ thực",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:38"
    }
  },
  {
    "page_content": "và ngay sau phép convolution nó sẽ thực hiện cái phép ReLU. Rồi khi tạo ra cái feature này xong, chúng ta sẽ thực hiện cái phép pooling để mà giảm cái kích thước của tấm hình này lại, giảm kích thước của cái đặc trưng này lại. Và cứ như vậy. Tuy nhiên thì khi chúng ta mới bắt đầu tìm hiểu cái kiến trúc này á thì chúng ta sẽ hơi bị rối. Do đó thì ở đây chúng ta sẽ phân loại ra bốn cái phép biến đổi chính mà cái mạng CNN được sử dụng xuyên suốt trong toàn bộ cái cái kiến trúc này. Bốn cái phép",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 1,
      "start_timestamp": "0:00:33",
      "end_timestamp": "0:01:11"
    }
  },
  {
    "page_content": "trong toàn bộ cái cái kiến trúc này. Bốn cái phép biến đổi đó chính là phép convolution, phép activation (tức là cái tương ứng là cái hàm kích hoạt, tầng kích hoạt), rồi cái tầng pooling và cái tầng Fully Connected. Thì đây chính là bốn cái phép bốn cái tầng biến đổi chính. Và chúng ta sẽ phối hợp, phối hợp như thế nào? Thông thường tất cả các cái tầng convolution và activation (tầng kích hoạt) nó sẽ đi chung với nhau thành một cặp. Tức là ngay sau convolution nó sẽ là cái tầng activation và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 2,
      "start_timestamp": "0:01:05",
      "end_timestamp": "0:01:44"
    }
  },
  {
    "page_content": "sau convolution nó sẽ là cái tầng activation và tầng activation này thì thường người ta sử dụng cái hàm đó là hàm ReLU. Và như vậy nó sẽ đi theo cặp với nhau. Và cái cặp biến đổi convolution activation này nó sẽ được thực hiện K lần. Thì lâu lâu nó sẽ chọt vào một cái tầng pooling, chọt vào cái tầng pooling. Mục tiêu của cái tầng pooling này nó để giảm cái kích thước của cái feature, giảm kích thước của cái feature. Và khi giảm cái kích thước của cái feature thì sau này ở cái tầng Fully",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 3,
      "start_timestamp": "0:01:39",
      "end_timestamp": "0:02:18"
    }
  },
  {
    "page_content": "của cái feature thì sau này ở cái tầng Fully Connected thì nó sẽ giảm cái số lượng tham số. À khi việc giảm cái số lượng tham số này thì nó sẽ có tác dụng gì thì chúng ta sẽ bàn luận sau. Và phối hợp các cái cặp convolution, activation và pooling này thì chúng ta sẽ lặp N lần và cứ thực hiện đi thực hiện lại. Thì hết cái giai đoạn này á thì nó sẽ gọi là rút trích đặc trưng, nó sẽ gọi là rút trích đặc trưng. Và khi kết thúc cái giai đoạn rút trích đặc trưng này, nó sẽ đến cái tầng gọi là tầng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 4,
      "start_timestamp": "0:02:11",
      "end_timestamp": "0:02:55"
    }
  },
  {
    "page_content": "đặc trưng này, nó sẽ đến cái tầng gọi là tầng Fully Connected. Thì ở đây sẽ là tầng thực hiện cái công việc đó là phân lớp, phân lớp đặc trưng. Các cái đặc trưng mà đã được thực hiện bởi ba cái tầng trước thì qua đến cái tầng Fully Connected này, tầng này thực ra nó chính là cái mạng neural Network đó, chính là cái mạng neural Network của mình rồi. Và cái tầng neural Network này nhiệm vụ của nó sẽ là đi phân loại cái đặc trưng. Thì ở đây chúng ta sẽ có một cái sơ đồ ha. Đó là một cái ảnh một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 5,
      "start_timestamp": "0:02:51",
      "end_timestamp": "0:03:29"
    }
  },
  {
    "page_content": "ta sẽ có một cái sơ đồ ha. Đó là một cái ảnh một chiếc xe nó thực hiện phép convolution rồi lại ReLU và convolution, ReLU, sau đó lại pooling rồi sau đó convolution ReLU, convolution ReLU rồi lại pooling. Thì ở đây tương ứng với lại cái cái tham số K và N ở đây. Thì K của mình trong trường hợp này nó chính là 2. Là sao? Chúng ta thực hiện hai lần cái cặp biến đổi convolution ReLU, convolution ReLU. N này là bằng 3 có nghĩa là sao? Nguyên một cái bộ này chúng ta sẽ thực hiện ba lần đó:",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 6,
      "start_timestamp": "0:03:23",
      "end_timestamp": "0:04:10"
    }
  },
  {
    "page_content": "một cái bộ này chúng ta sẽ thực hiện ba lần đó: convolution ReLU, convolution ReLU và pooling. Đây là một bộ. Rồi một bộ nữa và một bộ nữa. Như vậy là N trong trường hợp này là bằng 3. Và khi thực hiện xong thì nó sẽ đến cái tầng FC để thực hiện cái phân lớp và cái output của mình, đầu ra kỳ vọng nó sẽ ra một cái à xác suất, cái phân bố xác suất, trong đó cái phần K (tức là chiếc xe) nó cho cái phân bố cao nhất. Thì đây chính là một cái kiến trúc mạng CNN phổ dụng. Thế thì bây giờ tiếp theo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 7,
      "start_timestamp": "0:04:04",
      "end_timestamp": "0:04:45"
    }
  },
  {
    "page_content": "trúc mạng CNN phổ dụng. Thế thì bây giờ tiếp theo chúng ta sẽ đến với cái ờ cái cái cái công thức biến đổi của từng cái lớp biến đổi này. Đầu tiên đó chính là tầng convolution, tầng convolution. Như đã giới thiệu cho trong phần một thì bản chất của cái phép biến đổi convolution tức là chúng ta sẽ có một cái filter, một cái filter và chúng ta sẽ trượt lên trên toàn bộ cái tấm ảnh này. Đó. Và ảnh đây lưu ý là ảnh Xám. Đó, ảnh ở đây là ảnh Xám. Và khi chúng ta biến đổi xong thì chúng ta sẽ tạo ra",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 8,
      "start_timestamp": "0:04:39",
      "end_timestamp": "0:05:19"
    }
  },
  {
    "page_content": "khi chúng ta biến đổi xong thì chúng ta sẽ tạo ra một cái feature. Ở đây không phải là feature map hay là feature nha, feature tức là chúng ta mới có một cái đặc trưng thôi. Rồi, kết quả của cái phép biến đổi X với cái phép biến đổi convolution trên cái filter W thì nó sẽ tạo ra một cái feature. Thì đây là phép biến đổi convolution. Và điều gì xảy ra nếu như chúng ta thực hiện cái phép biến đổi convolution nhưng mà trên cái ảnh ba cái màu là Red, Green, Blue? Như vậy ở đây một cách tổng quát nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 9,
      "start_timestamp": "0:05:13",
      "end_timestamp": "0:05:58"
    }
  },
  {
    "page_content": "Green, Blue? Như vậy ở đây một cách tổng quát nó có thể là có cái độ sâu. Độ sâu trong trường hợp này nó sẽ là bằng 3 do là có ba kênh màu. Thì ở đây chúng ta sẽ sử dụng một cái cái filter, chúng ta sẽ sử dụng một cái filter nó sẽ có cái độ sâu tương ứng bằng với lại cái độ sâu của cái input. Thì đây chính là cái dữ liệu đầu vào, còn đây là cái filter. Và cái filter này nó sẽ có độ sâu đúng bằng với lại cái độ sâu của cái input. Và khi chúng ta tưởng tượng cái filter này nó giống như là một cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 10,
      "start_timestamp": "0:05:51",
      "end_timestamp": "0:06:25"
    }
  },
  {
    "page_content": "tượng cái filter này nó giống như là một cái cục Rubik, chúng ta cũng sẽ trượt. Đó, chúng ta sẽ trượt lên trên toàn bộ cái dữ liệu đầu vào này, cái feature map đầu vào này thì chúng ta sẽ tại một cái vị trí này chúng ta sẽ tính ra được một giá trị. Đó, dịch chuyển tiếp thì chúng ta sẽ lại tính một giá trị tiếp theo. Dịch chuyển tiếp chúng ta sẽ dịch chuyển đến một cái vị trí mới, chúng ta sẽ tính ra một cái giá trị. Đó, cứ như vậy chúng ta sẽ tạo ra một cái feature. Đó. Như vậy đối với cái phép",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 11,
      "start_timestamp": "0:06:20",
      "end_timestamp": "0:07:02"
    }
  },
  {
    "page_content": "ra một cái feature. Đó. Như vậy đối với cái phép convolution nhưng mà trên cái dữ liệu đầu vào thay vì là ảnh xám mà là ảnh Red, Green, Blue thì cái độ sâu của cái filter của mình nó phải đúng bằng cái độ sâu của cái ảnh đầu vào. Và như vậy thì kết quả ở đây chúng ta sẽ có là cái kết quả cho một cái đặc trưng, tức là một cái filter, một cái filter thì chúng ta sẽ ra một cái đặc trưng. Giống như hồi nãy trong cái slide minh họa cho cái lọc Sobel thì cái đặc trưng của lọc Sobel nó tương ứng là nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 12,
      "start_timestamp": "0:06:56",
      "end_timestamp": "0:07:37"
    }
  },
  {
    "page_content": "cái đặc trưng của lọc Sobel nó tương ứng là nó sẽ tìm ra cái cạnh theo cái chiều thẳng đứng, theo cái chiều dọc. Vậy thì à với mỗi filter chúng ta sẽ có một đặc trưng. Và nhiều filter à? Nhiều filter chúng ta sẽ tạo ra nhiều đặc trưng. Thì ở đây với cái ảnh đầu vào nhân với lại filter màu vàng chúng ta sẽ tạo ra đặc trưng vàng. Với cái filter màu xanh đúng không? Chúng ta sẽ tạo ra đặc trưng xanh. Và cứ như vậy. Ở đây chúng ta có bốn cái filter thì tương ứng chúng ta sẽ có bốn cái đặc trưng. Và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 13,
      "start_timestamp": "0:07:27",
      "end_timestamp": "0:08:15"
    }
  },
  {
    "page_content": "tương ứng chúng ta sẽ có bốn cái đặc trưng. Và chúng ta sẽ chồng lớp bốn cái đặc trưng này lại với nhau thì nó sẽ tạo ra thành một cái tensor output. Sẽ tạo ra một cái tensor output. Và chồng các cái feature này thì chúng ta sẽ tạo ra một cái khối 3D. Khối 3D này nó chính nó được gọi chính là tensor. Và tên của nó nó gọi là feature map. Trong cái slide trước, trong slide trước thì cái này nó gọi là feature, còn tập hợp các cái feature thì người ta sẽ gọi nó là feature map. Thì nếu như cái ảnh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 14,
      "start_timestamp": "0:08:10",
      "end_timestamp": "0:08:50"
    }
  },
  {
    "page_content": "ta sẽ gọi nó là feature map. Thì nếu như cái ảnh đầu vào của mình kích thước là 28 thì ảnh đầu ra kích thước nó sẽ còn 24. Là tại vì sao? Tại vì khi chúng ta áp khi chúng ta áp cái filter chúng ta trượt lên đây đúng không? Thì không thể nào khi mà chúng ta áp lên cái biên của cái tấm ảnh rồi chúng ta trượt đến đây và chúng ta sẽ chạm đến cái biên này và nó sẽ không lố ra bên ngoài, nó sẽ không lố ra bên ngoài. Do đó nó sẽ bị thất thoát, sẽ bị mất đi, giảm từ 28 xuống còn 24. Thì đó là lý do tại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 15,
      "start_timestamp": "0:08:43",
      "end_timestamp": "0:09:29"
    }
  },
  {
    "page_content": "đi, giảm từ 28 xuống còn 24. Thì đó là lý do tại sao nó giảm xuống. Và ở đây thì chúng ta chỉ cần nhớ đến một cái công thức liên quan đến cái việc kích thước của cái filter ha. Nếu như cái ảnh đầu vào, ảnh đầu vào trong trường hợp này có cái độ sâu là D (D trong trường hợp này bằng 3 ha). Thì cái filter của mình nó sẽ có cái độ sâu đúng bằng D luôn, đúng bằng D luôn, tức là bằng 3. Và ở đây nếu như cái số lượng filter của mình, số lượng filter của mình là K tổng quát là K (trong trường hợp này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 16,
      "start_timestamp": "0:09:22",
      "end_timestamp": "0:10:06"
    }
  },
  {
    "page_content": "mình là K tổng quát là K (trong trường hợp này K là bằng 4), thì cái độ sâu của cái tensor output của mình nó cũng chính là bằng K. Có bao nhiêu filter thì ở đây nó sẽ có bấy nhiêu cái độ sâu. Thì đây là một cái quy luật chúng ta ráng nhớ cái công thức của nó. Và ở đây chúng ta sẽ có cái ví dụ tính toán số học. Ở đây chúng ta sẽ có cái phép biến đổi là convolution với cái dữ liệu ảnh đầu vào là ảnh 5x5. Đó, với cái giá trị như trên. Khi chúng ta áp cái filter 3x3 lên đây thì chúng ta sẽ lần",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 17,
      "start_timestamp": "0:10:00",
      "end_timestamp": "0:10:47"
    }
  },
  {
    "page_content": "ta áp cái filter 3x3 lên đây thì chúng ta sẽ lần lượt lấy các cái giá trị này nhân với lại các phần tử ở đây. Thì 0 nhân với -1 nó sẽ ra là 0 và cứ như vậy 0 nhân với 25 nó sẽ ra 0. Và cứ nhân vô thì chúng ta sẽ có được cái kết quả như thế này. Và chúng ta sẽ lưu ý là phải thực hiện thêm một cái thao tác nữa là tổng tất cả các cái phần tử trên cái đây trên cái ma trận này đúng không? Thì 75 + 80 + 80 + 0 thì nó sẽ ra là 235. Như vậy thì tại cái vị trí này, tại cái vị trí này khi nhân với lại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 18,
      "start_timestamp": "0:10:43",
      "end_timestamp": "0:11:21"
    }
  },
  {
    "page_content": "vị trí này, tại cái vị trí này khi nhân với lại cái filter 3x3 này thì nó sẽ tạo ra một cái giá trị đó là 235. Và chúng ta sẽ lần lượt trượt từ trái sang phải. Thì tương ứng ở đây chúng ta sẽ điền các cái giá trị ở đây. Và chúng ta sẽ có một cái animation để minh họa cho cái phép trượt này ha. Ảnh đầu vào sẽ là ảnh 5x5 và filter của mình là 3x 3. Thì chúng ta sẽ cho cái filter này trượt lên trên cái vị trí đầu tiên. Và chúng ta sẽ thấy rằng là cái ý nghĩa của cái filter này nó chính là những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 19,
      "start_timestamp": "0:11:17",
      "end_timestamp": "0:12:09"
    }
  },
  {
    "page_content": "cái ý nghĩa của cái filter này nó chính là những cái con số 0 này khi nhân với các cái giá trị trên cái điểm ảnh gốc thì nó sẽ triệt tiêu. 0 này sẽ là triệt tiêu, chỉ còn lại các cái số 1 này. Như vậy ý nghĩa của cái filter này đó chính là tổng tất cả các cái giá trị màu của ảnh đầu vào theo cái trục dọc này. Thì ở đây chúng ta thấy là 0 này cộng 0 này cộng 1 này tương ứng nó sẽ là 1. Vậy thì các bạn sẽ thử tự điền vào các cái giá trị này xem nó là bao nhiêu. Khi trượt qua đây đúng không? Thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 20,
      "start_timestamp": "0:12:03",
      "end_timestamp": "0:12:38"
    }
  },
  {
    "page_content": "là bao nhiêu. Khi trượt qua đây đúng không? Thì nó tương ứng sẽ là 3 + 4 + 1. Cái ý nghĩa của filter này nó là cộng các cái thành phần ở trên cột ở giữa. 3 + 4 + 1 nó sẽ ra là 8. 0 + 2 + 0 nó sẽ ra là 2. Rồi trượt xuống dưới 0 + 1 + 0 nó ra 1. Cứ như vậy nó sẽ lấp đầy. Và lưu ý là ở đây ảnh đầu vào của mình là 5x5 nhưng mà khi chúng ta tính với cái cái filter này xong thì nó chỉ còn lại cái feature là kích thước là 3x3 thôi. Đầu vào là 5x5 thì output của mình chỉ là 3x3 thôi. Rồi, ở đây chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 21,
      "start_timestamp": "0:12:34",
      "end_timestamp": "0:13:21"
    }
  },
  {
    "page_content": "output của mình chỉ là 3x3 thôi. Rồi, ở đây chúng ta sẽ có thêm một cái tham số nữa đó là stride, tức là cái độ dài của cái bước trượt filter. Thì ở đây nếu bình thường chúng ta sẽ trượt một đơn vị đúng không? Thì ở đây chúng ta sẽ có cái stride trong trường hợp này chúng ta sẽ cho stride là bằng bằng 2, tức là chúng ta sẽ nhảy cóc. Rồi ở trong trường hợp này ha, cái ví dụ mà chúng ta đã làm trong slide trước thì stride là bằng 1. Nhưng mà bây giờ chúng ta sẽ làm thử với stride bằng 2 ha. Với",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 22,
      "start_timestamp": "0:13:16",
      "end_timestamp": "0:14:06"
    }
  },
  {
    "page_content": "giờ chúng ta sẽ làm thử với stride bằng 2 ha. Với stride bằng 2 thì các cái giá trị ở đây là bao nhiêu? Thì cái mẹo để chúng ta có thể tính nhanh đó chính là chúng ta sẽ lấy các cái giá trị này chúng ta điền xuống và nhảy cóc bỏ qua cái này rồi chúng ta lấy giá trị này chúng ta điền xuống, nhảy cóc bỏ qua và điền xuống, nhảy cóc bỏ cái thằng này điền xuống. Như vậy khi chúng ta trượt, rồi. Như vậy thì khi chúng ta trượt đó thì cái giá trị khi mà với cái bước nhảy stride bằng 2 nó sẽ là 1, 2, 2,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 23,
      "start_timestamp": "0:14:02",
      "end_timestamp": "0:14:34"
    }
  },
  {
    "page_content": "với cái bước nhảy stride bằng 2 nó sẽ là 1, 2, 2, 5. Và giá trị này hiểu một cách nôm na đó là nó copy từ cái feature map ở phía dưới copy xuống nhưng mà nó bỏ qua hàng và cột này, tức là nó đang làm giảm, nó đang làm giảm cái độ phân giải của feature map của đặc trưng với cái bước nhảy là stride là bằng 2. Và chúng ta sẽ giảm khoảng một nửa. Rồi, tiếp theo đó chính là padding. Thì hồi nãy chúng ta đã nói rồi với một cái ảnh 5x5 sau khi nhân với lại cái filter 3x3 thì nó sẽ giảm xuống là còn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 24,
      "start_timestamp": "0:14:29",
      "end_timestamp": "0:15:08"
    }
  },
  {
    "page_content": "lại cái filter 3x3 thì nó sẽ giảm xuống là còn 3x3. Nhưng mà chúng ta mong muốn là giữ nguyên cái thông tin của cái đặc trưng đầu vào đó, giữ nguyên cái thông tin của đặc trưng đầu vào. Thì thay vì là giảm xuống còn 3x3, chúng ta mong muốn là không, nó vẫn giữ nguyên cái kích thước gốc đầu vào là 5x5. Đó. Thì ở đây chúng ta lấy một cái ví dụ nhỏ hơn, chúng ta lấy một cái ví dụ nhỏ hơn để dễ tính. Ảnh đầu vào nếu như kích thước là 3x3 thì khi chúng ta lấy cái filter 3x3 chúng ta chồng lên đây,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 25,
      "start_timestamp": "0:15:07",
      "end_timestamp": "0:15:46"
    }
  },
  {
    "page_content": "ta lấy cái filter 3x3 chúng ta chồng lên đây, chúng ta thực hiện cái phép tính tổng ở đây đúng không? Rồi tổng theo cái cột ở giữa nè. Thì 4 + 1 + 4 nó sẽ ra là 9. Và kết thúc cái quá trình nhân Convolution đó. Và cái kích thước của mình nó giảm xuống chỉ còn là 1x1 thì mình không muốn cái điều này. Mình muốn là giữ nguyên cái kích thước đầu vào. Mình muốn giữ nguyên kích thước đầu vào. Thì nếu như ở đây ảnh của mình là 3x3, mình sẽ chèn thêm các cái giá trị ở bên ngoài vào đó thì nó sẽ tạo ra",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 26,
      "start_timestamp": "0:15:41",
      "end_timestamp": "0:16:20"
    }
  },
  {
    "page_content": "cái giá trị ở bên ngoài vào đó thì nó sẽ tạo ra thành một cái ảnh là 5x5 với các cái giá trị padding ở đây. Và lấy cái ảnh 5x5 này nhân với filter 3x3 thì nó sẽ tạo ra cái feature map là 3x3. Như vậy là 3x3 đầu vào và đầu ra của mình nó vẫn giữ nguyên là 3x3. Thì cái giá trị ở đây đó chính là cái giá trị padding, cái giá trị padding. Và mình có rất nhiều cái chiến thuật. Thì trong trường hợp này chúng ta đang chèn thêm cái số 0 vào viền của cái tấm ảnh. Nó sẽ có một số cái chiến thuật khác. Thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 27,
      "start_timestamp": "0:16:13",
      "end_timestamp": "0:16:43"
    }
  },
  {
    "page_content": "ảnh. Nó sẽ có một số cái chiến thuật khác. Thì thực ra theo quan điểm của mình, cái chiến thuật các bạn chọn padding kiểu nào thì nó cũng không ảnh hưởng nhiều lắm đến cái kết quả cuối cùng. Tại vì sao? Tại vì cái tấm ảnh của các bạn đó là một cái tấm ảnh rất là lớn và cái object của các bạn á trong cái tấm hình này cũng là những cái object rất là lớn. Và cái việc đưa ra cái quyết định phân loại cái nội dung của tấm ảnh này nó sẽ dựa trên cái phần ruột của tấm ảnh chứ còn cái phần biên của tấm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ruột của tấm ảnh chứ còn cái phần biên của tấm ảnh này thì nó sẽ không đóng góp nhiều trong cái việc là đưa ra cái thông tin để mình phân loại cái dữ liệu bên trong này. Do đó cái phần ngoài biên này nó không quá quan trọng, nó sẽ không quan trọng. Do đó các bạn dùng chiến thuật padding nào cũng được. Zero-padding chèn số 0 hoặc là padding theo mỗi chiều nó sẽ có kích thước khác nhau. Ví dụ như chèn ờ bên chiều phía trên là hai nhưng mà bên chiều dọc thì nó lại chỉ chèn có một. Đó. Ở đây là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "dọc thì nó lại chỉ chèn có một. Đó. Ở đây là chèn theo kiểu đó là lấy cái giá trị gần nhất để copy ra. Ví dụ như ở đây số 1 đúng không? Thì nó nó sẽ copy ra đây. Đó, số 9 thì nó sẽ copy ra đây. Thì các cái chiến thuật chèn này thì theo mình đó là nó cũng không ảnh hưởng nhiều đến cái kết quả nhận diện cuối cùng.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=uhwita1uhlA",
      "filename": "uhwita1uhlA",
      "title": "[CS116 - Buổi 9] Part 2_0",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "bây giờ chúng ta sẽ tiến hành train chúng ta sẽ truyền vào hai tham số đó là X_train và y_train. Tuy nhiên y_train nó phải ở dạng là one-hot rồi thì cái việc train này đâu đó nó có thể tốn. Ồ, ở đây chúng ta quên mất một cái việc đó là sau này để mà có thể vẽ được cái hàm loss, vẽ được cái giá trị loss theo các epochs, chúng ta sẽ phải gán vào một cái biến là history. Rồi sau đó thì ở đây chúng ta mới có thể thực hiện được cái việc trực quan hóa. này. Rồi để trực quan hóa cho cái mô hình thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:50"
    }
  },
  {
    "page_content": "này. Rồi để trực quan hóa cho cái mô hình thì chúng ta sẽ phải lấy ra các cái filter đó. Thì ở đây chúng ta sẽ lấy ra filter ở cái lớp đầu tiên, đó chính là CNN get_weights. get_weights ở đây chúng ta sẽ để cái layer số 1, tại vì layer số 0 chính là cái input. Rồi layer số 1 chính là cái phép convolution. Rồi chúng ta sẽ cùng quan sát nhưng mà đương nhiên là phải chờ cái mô hình này nó huấn luyện xong thì chúng ta mới có thể thấy được cái hàm loss này nó chạy như thế nào. Ở đây thì chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:44",
      "end_timestamp": "0:01:30"
    }
  },
  {
    "page_content": "loss này nó chạy như thế nào. Ở đây thì chúng ta quan sát thấy là cái loss của mình nó đã giảm từ 0.18 trong cái epoch đầu tiên giảm xuống còn 0.13, giảm xuống còn 0.10 và đến cái epoch thứ 25, 26 thì giảm xuống còn 0.01. Và hi vọng rằng là đến cái epoch số 30 thì cái loss của mình nó đã giảm xuống còn 0.007 và accuracy cho cái tập dữ liệu train nó đã lên đến 98, 99.85 %. Rồi và chúng ta quan sát thấy cái loss giảm rất là tốt. Chúng ta quan sát cái train loss này giảm rất là tốt. Rồi bây giờ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:22",
      "end_timestamp": "0:02:09"
    }
  },
  {
    "page_content": "cái train loss này giảm rất là tốt. Rồi bây giờ chúng ta sẽ xem xem cái ma trận W này có cái giá trị là bao nhiêu. Thì ở đây chúng ta sẽ thấy là cái W này nó sẽ là một cái array. Nó là một cái list bao gồm hai phần tử. Thì cái phần tử đầu tiên chính là cái số trọng số, cái số filter của cái phép biến đổi convolution đầu tiên. Và cái thành phần thứ hai đó chính là cái bias. Tại vì chúng ta có sử dụng bias, W0 chính là cái trọng số của mình đó. Rồi để xem coi cái trọng số này có kích thước bao",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 3,
      "start_timestamp": "0:02:04",
      "end_timestamp": "0:02:49"
    }
  },
  {
    "page_content": "Rồi để xem coi cái trọng số này có kích thước bao nhiêu thì chúng ta là chấm shape. Thì trong đó 3, 3, 1, 6 thì 3, 3 chính là cái kích thước của cái kernel và 1 chính là cái input dimension của input của đầu vào của mình. Nó chỉ có một channel thôi, nó sẽ là 1. Và output của mình sẽ là 6, sáu cái filter. Như vậy thì để trực quan chúng ta sẽ có số filter là 6. Rồi chúng ta sẽ duyệt qua y từ 0 cho đến 5 để truyền vô đây. Rồi đây là W0 nè. W0.shape chính là 3, 3, 1, 6. Thì chúng ta sẽ lấy cái chỉ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 4,
      "start_timestamp": "0:02:43",
      "end_timestamp": "0:03:25"
    }
  },
  {
    "page_content": "chính là 3, 3, 1, 6. Thì chúng ta sẽ lấy cái chỉ số y chạy ở đây trước rồi sau đó lấy chỉ số J chạy ở đây. Thì ở đây một cách tổng quát, trong cái lớp convolution số 2 thì cái số 1 này nó sẽ khi nó chuyển thành là số 16. Do đó thì ở đây chúng ta sẽ để là y là chạy cho một cái range. Range này thì ở đây là chúng ta để là 1 nhưng mà sắp tới có thể để là 16. Rồi. đây chính là sáu cái filter ở cái lớp đầu tiên. Thì chúng ta có thể hiểu à cái ý nghĩa của cái filter này đó chính là chúng ta lấy cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 5,
      "start_timestamp": "0:03:20",
      "end_timestamp": "0:04:01"
    }
  },
  {
    "page_content": "của cái filter này đó chính là chúng ta lấy cái sai số, cái sự chênh lệch của cái vùng phía bên phải, phía dưới so với lại cái vùng ở phía trái bên trên. Ý nghĩa của filter này đó là lấy cái sự chênh lệch giữa cái hàng ở giữa so với lại hai cái hàng ở phía trên và phía dưới. Thì mỗi một cái filter này nó sẽ thể hiện một cái đặc trưng nào đó. Rồi. Tiếp theo là chúng ta sẽ tiến hành à thí nghiệm với một số cái biến thể khác nhau. Nhưng mà trước khi qua thử nghiệm một số biến thể khác nhau thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 6,
      "start_timestamp": "0:03:56",
      "end_timestamp": "0:04:48"
    }
  },
  {
    "page_content": "khi qua thử nghiệm một số biến thể khác nhau thì chúng ta sẽ thử cái hàm predict ha, cái hàm predict thì CNN. predict. Rồi thì chúng ta sẽ truyền vào cái X_test và mẫu dữ liệu thứ, ví dụ như là mẫu dữ liệu thứ 300. Rồi. Ok. Ở đây thì hàm predict chúng ta sẽ xem lại cái hàm predict của mình truyền vào X_test, reshape. Ok. Bây giờ chúng ta sẽ xem tiếp cái X_test của mình đã được load rồi và đã được chuẩn hóa rồi đúng không? Rồi. Ok. Bây giờ chúng ta sẽ thử truyền vào như thế này. Rồi chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 7,
      "start_timestamp": "0:04:40",
      "end_timestamp": "0:06:03"
    }
  },
  {
    "page_content": "ta sẽ thử truyền vào như thế này. Rồi chúng ta sẽ xem cái X_test của mình. Thôi rồi. À X_test của mình nó là cái mảng kích thước là 28x28. Do đó thì chúng ta phải reshape, chúng ta phải reshape nó về cái dạng là 28, 28 nhân với 1. Rồi sau đó chúng ta mới đưa vào để cho cái mô hình của mình có thể predict được. CNN. predict. Rồi. Ồ, cũng chưa được. Nào. Rồi à ở đây cái số này sẽ phải phải để lên trước đúng không? Cái cái cái này nó sẽ phải để lên trước. Vậy là 1, 28. Ok được rồi. Tức là nó sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 8,
      "start_timestamp": "0:05:54",
      "end_timestamp": "0:06:56"
    }
  },
  {
    "page_content": "trước. Vậy là 1, 28. Ok được rồi. Tức là nó sẽ phải để cái chỉ số của cái ờ thứ tự ờ lên trước. Nó hơi ngược, nó hơi ngược. Rồi bây giờ chúng ta sẽ thử xem cái nhãn này nó sẽ ra cái giá trị là bao nhiêu. Ừm. Tại vì ở đây nó chỉ trả ra một cái vector one-hot. Chúng ta sẽ phải có thêm một cái hàm nữa đó là argmax là np.argmax. Rồi nó sẽ là 4. Và bây giờ chúng ta sẽ xem coi cái mẫu thứ 300 này. y_test của mình thứ 300 nó là bằng bao nhiêu? Nó là 4. Rồi bây giờ chúng ta sẽ thử những cái mẫu khác",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 9,
      "start_timestamp": "0:06:51",
      "end_timestamp": "0:08:01"
    }
  },
  {
    "page_content": "4. Rồi bây giờ chúng ta sẽ thử những cái mẫu khác ha. Chúng ta sẽ thử những cái mẫu khác. Ở đây chúng ta sẽ để là predict, nhãn dự đoán là y_pred. Rồi còn ở đây sẽ là nhãn thực tế. Và ở đây cái chỉ số này chúng ta sẽ tham số hóa nó là idx là bằng 100 ví dụ vậy. Và chúng ta sẽ để đây là idx. Rồi đó thì đại đa số chúng ta thấy là cái độ chính xác rất là cao. Chúng ta thử rất nhiều những cái nhãn khác nhau ha. Đó thì nó đều ra là dự đoán và thực tế khớp với nhau. Bây giờ trong cái mô hình thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 10,
      "start_timestamp": "0:07:55",
      "end_timestamp": "0:08:36"
    }
  },
  {
    "page_content": "tế khớp với nhau. Bây giờ trong cái mô hình thì chúng ta thấy nó có rất nhiều những cái module khác nhau. Và tại thời điểm hiện tại thì chúng ta sẽ chưa hiểu rõ cái vai trò của từng module này. Do đó thì chúng ta sẽ làm một cái thí nghiệm nó gọi là ablation study với các cái biến thể khác nhau bằng cách đó là chúng ta sẽ lần lượt thay đổi một số cái cấu hình của cái cái chương trình của mình. Chúng ta sẽ thay đổi một số cái cấu hình. Thì cái phiên bản, cái biến thể đầu tiên đó là chúng ta sẽ bỏ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 11,
      "start_timestamp": "0:08:29",
      "end_timestamp": "0:09:21"
    }
  },
  {
    "page_content": "bản, cái biến thể đầu tiên đó là chúng ta sẽ bỏ đi cái, thay cái hàm sigmoid bằng ReLU. Chúng ta sẽ thay cái sigmoid bằng ReLU. Như vậy thì chúng ta sẽ copy cái code ở đây đem xuống. Rồi chúng ta sẽ đem cái đó lên hàm này thay cái sigmoid bằng ReLU. Ok. Như vậy thì bản chất là ờ cái biến thể này chúng ta không cần phải cài đặt lại. Biến thể này chúng ta không cần phải cài đặt lại mà chúng ta chỉ sửa cái cái tham số của mình thôi. Chúng ta chỉ sửa cái tham số khi ờ gọi cái hàm build thôi. Rồi và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 12,
      "start_timestamp": "0:09:15",
      "end_timestamp": "0:10:28"
    }
  },
  {
    "page_content": "cái tham số khi ờ gọi cái hàm build thôi. Rồi và đây là ReLU, đây là ReLU. Rồi sau đó thì chúng ta sẽ tiến hành là CNN.train và X_ train rồi y_train. Ồ và lưu ý ở đây chúng ta sẽ để cái history là history số 2. Rồi bây giờ chúng ta sẽ tiến hành build cái này ha. Và tranh thủ trong thời gian chờ đợi thì chúng ta sẽ thử ờ viết code trước cho cái phần vẽ cái giá trị loss. Chúng ta sẽ thêm một cái đường nữa đó là history số 2. Rồi và ở đây sẽ là train loss V1. À đây sẽ là train loss V2. Trong đó V2",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 13,
      "start_timestamp": "0:10:19",
      "end_timestamp": "0:11:09"
    }
  },
  {
    "page_content": "loss V1. À đây sẽ là train loss V2. Trong đó V2 đó là dùng ReLU, dùng ReLU. Rồi tương tự như vậy. Bây giờ chúng ta sẽ chờ đợi chúng ta sẽ ờ viết trước cái code cho các cái biến thể tiếp theo. Biến thể về bỏ hết các cái lớp pooling. Thì chúng ta làm cũng rất là nhanh. Pooling đúng không? Thì chúng ta sẽ bỏ nè, xóa đi, xóa đi. Và lưu ý đó là phải để gối đầu các cái các cái biến. Ví dụ như ở đây C1 thì sẽ được truyền trực tiếp sang đây. Rồi C3 thì sẽ truyền trực tiếp sang đây. Như vậy là chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 14,
      "start_timestamp": "0:11:03",
      "end_timestamp": "0:11:58"
    }
  },
  {
    "page_content": "sẽ truyền trực tiếp sang đây. Như vậy là chúng ta đã xong cái biến thể số 3. Chúng ta sẽ để là CNN_V3. Rồi bây giờ chúng ta sẽ cài cho cái biến thể cuối cùng. Ok. Ở đây khi bỏ cái ReLU thì chúng ta thấy là nó đã chạy xong rồi ha. Nó đã chạy xong. Và chúng ta sẽ quan sát thử. Ờ. Ok, chúng ta sẽ vẽ. Thì nhìn vào cái sơ đồ này. À. Ok. Ở đây chúng ta sẽ phải gom nó lại, gom hai cái legend này lại. Rồi gom lại. Rồi chúng ta sẽ thấy là cái ReLU phiên bản số 2 nó giảm rất là nhanh đúng không? Nó giảm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 15,
      "start_timestamp": "0:11:53",
      "end_timestamp": "0:12:30"
    }
  },
  {
    "page_content": "bản số 2 nó giảm rất là nhanh đúng không? Nó giảm rất là nhanh. Nó nằm bên dưới cái đường màu xanh. Thì điều đó có nghĩa là gì? Điều đó đó là ví dụ tại cái epoch số 5 thì cái phương pháp V2, tức là khi sử dụng ReLU nó cho cái loss thấp hơn so với cái phiên bản số 1, tức là dùng sigmoid. Tức là nó đã giúp cho mình hội tụ nhanh hơn. Nhưng mà đương nhiên khi mà cái số epochs càng lớn thì cả hai thằng nó cũng sẽ tiệm cận về. Nhưng mà nó sẽ tốn thời gian hơn. Thì tập MNIST là một cái tập rất là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 16,
      "start_timestamp": "0:12:25",
      "end_timestamp": "0:13:02"
    }
  },
  {
    "page_content": "gian hơn. Thì tập MNIST là một cái tập rất là tuyến tính, rất là dễ, rất là đơn giản. Nó sẽ không thể nào thể hiện được cái sự khuyếch đại, cái cái cái cái tốc độ mà train của ReLU nó nhanh hơn so với sigmoid như thế nào. Khi mà chúng ta train với tập dữ liệu lớn như là ImageNet thì chúng ta sẽ thấy rõ là ReLU nó hiệu quả hơn rất là nhiều. Loss sẽ giảm xuống, chúng ta sẽ thấy là cái cái cái cái sự sụp giảm về loss của nó rất là nhanh. Thì đó chính là cái ý nghĩa của cái biến thể đầu tiên đó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 17,
      "start_timestamp": "0:12:57",
      "end_timestamp": "0:14:20"
    }
  },
  {
    "page_content": "là cái ý nghĩa của cái biến thể đầu tiên đó là bỏ cái sigmoid và thay thế là bằng ReLU. Thì tốc độ hội tụ của nó sẽ nhanh hơn. Còn về độ chính xác theo thời gian dài đâu đó nó vẫn sẽ xấp xỉ với lại sigmoid. Nhưng mà với cái thời gian mà mình có thể chờ đợi được để mà có thể huấn luyện thì việc dùng sigmoid nó sẽ chậm hơn rất là nhiều. Rồi tiếp theo đó là chúng ta sẽ bỏ hết các cái lớp pooling. Rồi chúng ta đã cài đặt rồi. Và bây giờ chúng ta sẽ sử dụng, chúng ta sẽ sử dụng nó. Rồi ở đây chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 18,
      "start_timestamp": "0:14:14",
      "end_timestamp": "0:14:55"
    }
  },
  {
    "page_content": "sử dụng, chúng ta sẽ sử dụng nó. Rồi ở đây chúng ta sẽ để là CNN_V3 và history ở đây sẽ là history số 3. Rồi ở đây chúng ta sẽ khôi phục ngược trở lại ha. Chúng ta sẽ khôi phục ngược trở lại là sigmoid. Rồi chạy. Rồi bây giờ chúng ta sẽ vẽ cái hàm loss khi có đồng thời cả ba cái history. 1, 2, 3. Rồi V3 thì ở đây sẽ là V3: Không có Pooling. Rồi chúng ta có thể thu gọn lại chút xíu. Rồi. Ờ tranh thủ trong khi chờ đợi thì chúng ta sẽ cài luôn cái phiên bản thứ tư. Cái phiên bản này đó chính là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 19,
      "start_timestamp": "0:14:49",
      "end_timestamp": "0:15:41"
    }
  },
  {
    "page_content": "phiên bản thứ tư. Cái phiên bản này đó chính là chúng ta bỏ hết các cái lớp convolution. Một điều rất là thú vị đó là chúng ta đặt cái sự nghi ngờ rằng là cái mạng convolution thì ờ cái vai trò của convolution rõ ràng rất là lớn. Nhưng bây giờ chúng ta sẽ làm một thí nghiệm đó là bỏ hết cái convolution thì xem điều gì sẽ xảy ra. Đó thì đó chính là cái ý nghĩa của cái phiên bản số 4. Rồi bây giờ may quá cái phiên bản số 3 nó đã chạy xong. Và chúng ta sẽ xem thử. Rồi chúng ta thấy là nếu như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 20,
      "start_timestamp": "0:15:34",
      "end_timestamp": "0:17:03"
    }
  },
  {
    "page_content": "chúng ta sẽ xem thử. Rồi chúng ta thấy là nếu như không có nếu như không có pooling thì cái loss của mình gần như không giảm, nó cứ giữ nguyên. Loss gần như không giảm, duy trì. Thì rõ ràng là cái vai trò của pooling cũng rất là quan trọng. Nếu không có pooling thì cái loss của mình gần như là đi ngang, gần như đi ngang. Nó không giúp cho mình giảm xuống. Rồi ok. Bây giờ chúng ta sẽ qua cái phiên bản tiếp theo đó là không có cái lớp convolution. Rồi ở đây chúng ta phải sử dụng cái biến thể đầu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 21,
      "start_timestamp": "0:16:59",
      "end_timestamp": "0:17:36"
    }
  },
  {
    "page_content": "Rồi ở đây chúng ta phải sử dụng cái biến thể đầu tiên để mình code chứ nếu không là sẽ nhầm lẫn. Rồi không có convolution chúng ta sẽ bỏ đi lớp này, bỏ đi lớp này. Rồi và ở đây chúng ta sẽ truyền vào input C2 sẽ truyền vô đây. Tức là chúng ta sẽ giảm kích thước liên tiếp hai lần ha. Rồi ok ở đây sẽ là CNN_V 4. Rồi bây giờ chúng ta sẽ gọi cái hàm này khởi tạo để là V4, history là 4. Ok. Run. Và tương tự như vậy chúng ta sẽ vẽ cái sơ đồ ở đây. Rồi chúng ta sẽ có history là 4. train loss ở đây sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 22,
      "start_timestamp": "0:01:32",
      "end_timestamp": "0:18:05"
    }
  },
  {
    "page_content": "chúng ta sẽ có history là 4. train loss ở đây sẽ là V4: Không có Convolution. convolution. Rồi chúng ta thấy là cái loss của mình cũng có giảm. Tuy nhiên cái tốc độ giảm của nó khá là chậm, tốc độ giảm khá chậm. Thì điều này cũng minh chứng cho cái việc đó là cái convolution của mình nó đã giúp cho cái việc huấn luyện nó nhanh hơn. Mặc dù accuracy thì nó cũng có xu hướng là nó càng lúc càng tăng đúng không? Nó có xu hướng càng tăng nhưng với cùng cái số epochs thì không có convolution, tốc độ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cái số epochs thì không có convolution, tốc độ nó sẽ chậm hơn rất là nhiều. Và cái đường màu đậm là Version 4 thì chúng ta thấy là nó nằm ở phía trên. Nếu không có convolution nó sẽ nằm phía trên. Như vậy cái phiên bản mà hoàn thiện nhất của chúng ta chính là cái phiên bản màu cam ở đây là đường nằm ở dưới cùng, là tương ứng phiên bản số 2 là thay cái sigmoid bằng ReLU. Trong đó vẫn phải giữ vừa có pooling và vừa có convolution. Như vậy thì đây chính là cái cái bài tập, cái tutorial để giúp cho",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "là cái cái bài tập, cái tutorial để giúp cho chúng ta hiểu được cái vai trò của từng cái phép biến đổi ở bên trong cái mạng CNN.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=usMgo0mKV3A",
      "filename": "usMgo0mKV3A",
      "title": "[CS116 - Buổi 10] Part 3_1",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "rồi trong phần tiếp theo thì chúng ta sẽ tiếp cận một số cái cách triển khai mô hình trong thực tế thì ở đây chúng ta sẽ xét đến hai cái yếu tố đó là local và remote local tức là tại cái máy của người dùng cuối hay còn gọi là client và remote Tức là cái server của mình được phục vụ tức là từ xa để mà cho chúng ta có thể cung cấp các cái dịch vụ đến với cái người dùng cuối thì thì ở đây chúng ta sẽ có hai cái khái niệm là local và remote và ở đây chúng ta sẽ có hai cái mũi tên nét liền và nét đứt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:02",
      "end_timestamp": "0:00:47"
    }
  },
  {
    "page_content": "ta sẽ có hai cái mũi tên nét liền và nét đứt thì nét liền á chính là chúng ta sẽ gọi cái request Gọi cái yêu cầu và nét đứt chính là cái phản hồi thì ba cái khái niệm đó chính là client server và database thì đối với cái cách triển khai đầu tiên á đó là gọi là batch prediction tức là chúng ta sẽ dự đoán chúng ta sẽ sử dụng cái mô hình của mình dự đoán trên toàn bộ cái khối dữ liệu ờ của người dùng và chúng ta sẽ tương tác và trực tiếp đưa cái kết quả dự đoán của mình vào bên trong database để",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:40",
      "end_timestamp": "0:01:28"
    }
  },
  {
    "page_content": "quả dự đoán của mình vào bên trong database để lưu trữ đó thì đây là cái cách tiếp cận đầu tiên và cách tiếp cận này thì nó sẽ định kỳ à nó sẽ định kỳ chạy cái mô hình của mình trên những cái dữ liệu mới và lưu vào vùng đệm cache Ờ cái kết quả dự đoán vào trong database này và khi chúng ta đưa nó vào bên trong database thì khi người dùng người ta request người ta gọi cái request thì nó sẽ lấy từ trong database nó trả ra chứ nó không có đưa cái mô hình chạy lại cái việc dự đoán nên mô hình của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:22",
      "end_timestamp": "0:02:04"
    }
  },
  {
    "page_content": "mô hình chạy lại cái việc dự đoán nên mô hình của mình nó thường sẽ không có bị độ trễ ở chỗ này tức là nó trực tiếp vấn vào trong database với những cái kết quả đã được xử lý sẵn đã được xử lý trước đó và cái việc xử lý này thì nó được thực hiện một cách là định kỳ định kỳ chứ nó không phải là khi có cái request của người dùng thì nó mới chạy do đó thì cái cách làm mà batch prediction này á thì nó chỉ khả thi khi chúng ta cái toàn bộ cái dữ liệu mà chúng ta cần phải chạy á thì nó đủ nhỏ nó vừa",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 3,
      "start_timestamp": "0:01:59",
      "end_timestamp": "0:02:39"
    }
  },
  {
    "page_content": "mà chúng ta cần phải chạy á thì nó đủ nhỏ nó vừa đủ nhỏ thôi chứ còn Nếu mà cái việc mà thực thi này mà cái bộ dữ liệu mà chúng ta cần phải chạy nó quá lớn thì cái việc này nó cũng không có phù hợp lắm thì ở đây thế nào được gọi là một cái bộ dữ liệu nhỏ thì ở đây ví dụ như chúng ta sẽ có một dự đoán cho một user lấy ví dụ khi người dùng đăng ký một cái tài khoản lên trên cái mạng xã hội của mình dựa trên các cái thông tin mà họ khai báo thì chúng ta có thể dự đoán được cái độ tuổi hoặc là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 4,
      "start_timestamp": "0:02:35",
      "end_timestamp": "0:03:14"
    }
  },
  {
    "page_content": "chúng ta có thể dự đoán được cái độ tuổi hoặc là chúng ta có thể dự đoán được cái sở thích của người này ngay cái lần đăng ký đầu tiên đó và cái việc này thì chúng ta chỉ thực hiện cái việc dự đoán một lần và một lần duy nhất thì khi đó cái cái dữ liệu mà chúng ta cần chạy nó sẽ là đủ nhỏ nó sẽ không phù hợp nếu như cái cái cái sở thích của người dùng này thay đổi liên tục thay đổi theo ngày thì dẫn đến là cứ vài vài giờ vài ngày là chúng ta lại phải đi thực hiện cái dự đoán cái sở thích này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 5,
      "start_timestamp": "0:03:10",
      "end_timestamp": "0:03:44"
    }
  },
  {
    "page_content": "phải đi thực hiện cái dự đoán cái sở thích này trên người dùng một lần nữa thì cái việc này nó không phù hợp nếu như chúng ta giả định rằng là cái sở thích của người dùng là cố định trong một khoảng thời gian đủ lớn thì chúng ta mới thực thi cái phương pháp là batch prediction này đó thì đây là một cái Ờ cái giới thiệu cho cái ý nghĩa của cái batch prediction Khi nào thì chúng ta cần phải thực hiện cái batch prediction thì batch prediction á là nó sẽ có một cái ưu điểm và khuyết điểm đầu tiên á",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 6,
      "start_timestamp": "0:03:41",
      "end_timestamp": "0:04:21"
    }
  },
  {
    "page_content": "sẽ có một cái ưu điểm và khuyết điểm đầu tiên á đó là dễ thực hiện tại sao tại vì chúng ta chỉ cần lấy cái mô hình này của mình đóng gói nó lại và thực thi theo một cái chu kỳ thời gian ví dụ mỗi tháng chúng ta sẽ chạy một lần hoặc là mỗi ngày chúng ta chạy một lần ví dụ vậy thì nó rất là dễ thực hiện và nó sẽ không cần phải quan tâm nhiều những cái yếu tố khác liên quan đến cái việc là scale của hệ thống khi mà cái lượng người dùng mà tại một thời điểm mà nhiều lên thì chúng ta sẽ phải chạy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 7,
      "start_timestamp": "0:04:19",
      "end_timestamp": "0:04:52"
    }
  },
  {
    "page_content": "thời điểm mà nhiều lên thì chúng ta sẽ phải chạy nhiều nhưng mà thời điểm mà cái lượng người dùng mà ít thì chúng ta sẽ chạy chúng ta sẽ không bị cái vấn đề scale cái vấn đề mở rộng của mô hình mà ở đây là chúng ta cứ thực hiện theo một cái chu kỳ thời gian do đó thì cái cách thực hiện của chúng ta nó dễ thực hiện và nó độ trễ thấp đối với người dùng tại sao nó lại có độ trễ thấp đối với người dùng tại khi cái người dùng của mình á họ gọi cái request lên trên cái server thì cái server của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 8,
      "start_timestamp": "0:04:47",
      "end_timestamp": "0:05:37"
    }
  },
  {
    "page_content": "lên trên cái server thì cái server của mình lúc này nó sẽ không có gọi cái mô hình máy học để mà nó dự đoán mà nó sẽ gọi trực tiếp vào bên trong cái database trong cái database này nó đã chứa sẵn cái kết quả dự đoán rồi do đó thì nó sẽ trả kết quả về ngay lập tức tại vì cái chúng ta biết rằng là cái việc truy vấn trong cái database nó thực hiện rất là nhanh nó thực hiện gần như tức thì chưa kể là các cái cơ chế về vùng đệm caching thì nó nó sẽ còn nhanh hơn nữa và khuyết điểm của mô hình này đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 9,
      "start_timestamp": "0:05:30",
      "end_timestamp": "0:06:10"
    }
  },
  {
    "page_content": "nhanh hơn nữa và khuyết điểm của mô hình này đó là cái dữ liệu mà phức tạp á thì có thể khiến cho cái mô hình của mình nó tăng cái quy mô tính toán lên lấy ví dụ nếu cái thuật toán của mình nó chỉ đơn giản là những cái mô hình gọi là các cái mô hình như linear regression Logistic regression những cái mô hình mà tốc độ tính toán rất là nhanh với những cái dữ liệu rất là gọn gàng như là các cái vectơ biểu diễn của một cái người dùng thì lúc đó vấn đề nó sẽ không nảy sinh nhưng nếu như cái dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 10,
      "start_timestamp": "0:06:04",
      "end_timestamp": "0:06:43"
    }
  },
  {
    "page_content": "đề nó sẽ không nảy sinh nhưng nếu như cái dữ liệu của mình nó phức tạp Ví dụ như chúng ta sẽ cần phải Ờ thực thi cái mô hình của mình trên một cái kho dữ liệu video của người dùng và kho dữ liệu video của người dùng nó có thể từ vài GB cho đến vài trăm GB thì lúc đó là cái mô hình của mình nó rất là nặng chạy rất là lâu và nó phải chạy cho hết tất cả các cái user trong cái ứng dụng của mình đó thì rõ ràng là cái việc này nó sẽ không phù hợp do đó thì cái phương pháp này nó nó đối với những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 11,
      "start_timestamp": "0:06:36",
      "end_timestamp": "0:07:19"
    }
  },
  {
    "page_content": "thì cái phương pháp này nó nó đối với những cái dữ liệu phức tạp thì nó sẽ không có phù hợp lắm và dữ liệu dự đoán thì nó sẽ không có cái yếu tố cập nhật nó sẽ không có yếu tố cập nhật tại vì cái việc chúng ta chạy là chúng ta phải chạy định kỳ nên cái mô hình cái model của mình nó sẽ được thực thi trên cái dữ liệu của người dùng nhưng mà cái dữ liệu đó là cách đây một vài ngày Đúng không Nó không phải là cái thời điểm last update cái thời điểm mới nhất của người dùng tại cái thời điểm mà người",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 12,
      "start_timestamp": "0:07:14",
      "end_timestamp": "0:07:51"
    }
  },
  {
    "page_content": "nhất của người dùng tại cái thời điểm mà người ta đang request mà cái cái cái kết quả dự đoán của mình nó được thực thi trên cái dữ liệu của người dùng đã có từ cách đây Ờ khá là lâu rồi do đó thì cái dữ liệu dự đoán của mình nó sẽ không có yếu tố cập nhật đó và yếu tố thứ ba cái khuyết điểm thứ ba đó là mô hình của mình nó thường sẽ dần trở nên lỗi thời thì cũng đúng thôi tại vì cái mô hình của mình thì nó sẽ được huấn luyện trên dữ liệu mà cái dữ liệu của mình thì nó lại được thực hiện ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 13,
      "start_timestamp": "0:07:47",
      "end_timestamp": "0:08:14"
    }
  },
  {
    "page_content": "cái dữ liệu của mình thì nó lại được thực hiện ở trong một cái dữ liệu của quá khứ rất là lâu rồi do đó thì cái mô hình của mình nó sẽ không có cái yếu tố để cập nhật trên cái dữ liệu mới do đó thì nó sẽ có cái hiện tượng là Model của mình bị lỗi thời thì trên đây đó là những cái khuyết điểm của cái cách tiếp cận mô hình batch prediction tức là dự đoán nó chạy cái việc thực thi mô hình theo khối trên toàn bộ cái dữ liệu của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WSGSbmgzO3M",
      "filename": "WSGSbmgzO3M",
      "title": "[CS116 - Buổi 14] Part 2_1",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Cuối cùng thì chúng ta sẽ tiến hành giám sát mô hình sau khi đã triển khai thì sau khi mô hình đã triển khai Thì liệu rằng cái độ chính xác của mô hình có có còn được đảm bảo nữa hay không biết rằng là cái mô hình của mình khi chúng ta đánh giá trên cái tập dữ liệu validation á thì cái kết quả nó rất là tốt nhưng mà trong cái quá trình triển khai thì liệu có những cái rủi ro gì khiến cho cái mô hình của mình bị giảm cái độ chính xác một cách đột ngột hoặc là không còn chính xác một cách gọi là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:39"
    }
  },
  {
    "page_content": "ngột hoặc là không còn chính xác một cách gọi là xuất sắc như ban đầu hay không thì một số cái khả năng nó có khả năng xảy ra đầu tiên đó là do cái phân bố của cái dữ liệu trong cái quá trình mà triển khai á thì nó đã bị thay đổi Tức là cái này nó đơn thuần là liên quan đến cái dữ liệu yếu tố thứ hai đó là do cái mô hình tức khi mà mình dự đoán trong thực tế và là dữ liệu thì vẫn ổn nhưng mà cái mô hình của mình á thì nó bị thay đổi trong cái quá trình mà vận hành đó thì ở đây chính là hai cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 1,
      "start_timestamp": "0:00:34",
      "end_timestamp": "0:01:18"
    }
  },
  {
    "page_content": "trình mà vận hành đó thì ở đây chính là hai cái lý do chính cái lý do liên quan đến cái dữ liệu mình đưa vào mô hình và cái lý do liên quan đến bản thân cái mô hình của mình nó cũng bị biến động. Có một số cái cách, có một số cái cách triển khai đó là mô hình của mình nó sẽ cập nhật theo thời gian cứ sau một khoảng thời gian thì nó sẽ update thì cái mô hình của mình nó cũng sẽ bị biến đổi theo thì đây Có thể là một số cái khả năng và ờ dưới đây là một cái số cái loại thay đổi của cái dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 2,
      "start_timestamp": "0:01:14",
      "end_timestamp": "0:01:51"
    }
  },
  {
    "page_content": "là một cái số cái loại thay đổi của cái dữ liệu ha. Đầu tiên mình sẽ bàn về cái yếu tố về dữ liệu. Đây là cái trục thời gian Đây là cái trục thời gian từ quá khứ cho đến hiện tại và đến tương lai và đây là cái giá trị, cái trục giá trị của mình. Thế thì cái giá trị này nó có thể là cái sở thích của người dùng. Nó có thể là cái kết quả kinh doanh vân vân. Thế thì mình sẽ kỳ vọng rằng là theo cái chuỗi thời gian thì cái trục giá trị của mình nó sẽ không có biến động, nó sẽ đi đứng yên như thế này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 3,
      "start_timestamp": "0:01:45",
      "end_timestamp": "0:02:28"
    }
  },
  {
    "page_content": "không có biến động, nó sẽ đi đứng yên như thế này thì đây là trường hợp hoàn hảo nhất. Tuy nhiên thực tế thì dữ liệu của mình nó sẽ bị biến động theo thời gian và dưới đây là một số cái dạng thay đổi của dữ liệu theo thời gian. Ví dụ như chúng ta thấy ở đây Từ Quá Khứ cho đến hiện tại đúng không, Thì nó đi ngang như thế này, sau đó nó đã đột ngột, nó đã đột ngột hay là tức thì dịch chuyển lên một cái mức độ khác, nó lên một cái giải giá trị khác thì cái này nó gọi là dữ liệu bị dịch chuyển tức",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 4,
      "start_timestamp": "0:02:22",
      "end_timestamp": "0:03:13"
    }
  },
  {
    "page_content": "thì cái này nó gọi là dữ liệu bị dịch chuyển tức thì hay còn gọi là instantaneous drift. Thì cái này nó có khả năng đó là do cái môi trường của mình nó bị áp dụng nó khác. Ví dụ như cái dữ liệu của mình trước đây thì mình áp dụng cho dữ liệu của một cái lĩnh vực là lĩnh vực về kinh tế nhưng mà sau đó thì chúng ta lại đi áp dụng nó trong một cái lĩnh vực khác hoàn toàn. Ví dụ như trong lĩnh vực về ờ quảng cáo về Marketing thì đó là hai cái domain khác hoàn toàn dẫn đến là đây là cái tình huống",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 5,
      "start_timestamp": "0:03:06",
      "end_timestamp": "0:03:56"
    }
  },
  {
    "page_content": "khác hoàn toàn dẫn đến là đây là cái tình huống mà chúng ta train nó là một cái domain Còn đây là trong cái tình huống thực tế nè thì nó lại là một domain khác đó thì nó sẽ có cái sự phân bố bị chênh lệch về môi trường áp dụng và một cái lý do nữa đó là do có cái sự biến động đột ngột của dữ liệu thì ở đây chúng ta có thể thấy lấy một cái ví dụ mà kinh điển nhất đó chính là đại dịch COVID. Chúng ta thấy là khi mà đại dịch COVID diễn ra thì cái hành vi của con người là thay đổi đột ngột rất là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 6,
      "start_timestamp": "0:03:52",
      "end_timestamp": "0:04:32"
    }
  },
  {
    "page_content": "hành vi của con người là thay đổi đột ngột rất là đột ngột do là cái chính sách gọi là cách ly xã hội đúng không? Thì cái hành vi của chúng ta cũng bị biến đổi một cách đột ngột. Nếu như trước đây, trước cái đại dịch á, cái cách mà chúng ta sử dụng tiền, cách mà chúng ta tiêu dùng và mua bán là chúng ta sẽ gọi là khác hoàn toàn so với lại khi đại dịch nó diễn ra. Ví dụ khi chúng ta mua bán trao đổi các cái giao dịch thì trước đại dịch chúng ta thường mua bán trực tiếp. Nhưng mà kể từ khi đại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 7,
      "start_timestamp": "0:04:25",
      "end_timestamp": "0:05:07"
    }
  },
  {
    "page_content": "thường mua bán trực tiếp. Nhưng mà kể từ khi đại dịch nó diễn ra, các cái chính phủ họ tiến hành gọi là cách ly xã hội á thì giao dịch đã chuyển hoàn toàn sang cái môi trường ảo đó. Tức là chúng ta sẽ mua bán thanh toán qua các cái tài khoản Ờ tài khoản ảo ở trên internet thay vì chúng ta sẽ cầm tiền trực tiếp. Thì đó chính là một cái ví dụ cho cái việc là hành vi của người dùng thay đổi một cách đột ngột. Và khi cái hành vi của người dùng thay đổi đột ngột như vậy thì nó sẽ dẫn đến là cái dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 8,
      "start_timestamp": "0:05:02",
      "end_timestamp": "0:05:43"
    }
  },
  {
    "page_content": "đổi đột ngột như vậy thì nó sẽ dẫn đến là cái dữ liệu của mình nó không còn phù hợp với lại cái mô hình của mình nữa đúng không? Thì khi đó chúng ta buộc sẽ phải thay đổi cái mô hình của mình sao cho nó thích ứng với lại cái dữ liệu mới của mình đó. Thì đây là một cái tình huống mà đầu tiên đó là dữ liệu của mình thay đổi một cách tức thì, thay đổi một cách đột ngột. Tình huống thứ hai đó là dữ liệu của mình nó dịch chuyển một cách gọi là dần dần trái với lại cái lần đó, trái với cái trường hợp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 9,
      "start_timestamp": "0:05:35",
      "end_timestamp": "0:06:17"
    }
  },
  {
    "page_content": "trái với lại cái lần đó, trái với cái trường hợp đầu tiên đó là dữ liệu của mình nó di chuyển một cách gọi là đột ngột và tức thì thì ở trong cái dạng thứ hai, dữ liệu của mình Chúng ta thấy nè. Nó di chuyển lên từ từ từ từ từ từ đó chứ nó không có cái sự đột ngột như vậy. Thì Cái này à Có thể một số cái nguyên nhân dẫn đến cái việc mà dữ liệu của mình nó gây ra như vậy. Đầu tiên đó là theo dòng thời gian. Theo dòng thời gian thì cái sở thích của con người đúng không? Cái nhu cầu, cái sự quan",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 10,
      "start_timestamp": "0:06:13",
      "end_timestamp": "0:06:52"
    }
  },
  {
    "page_content": "con người đúng không? Cái nhu cầu, cái sự quan tâm của con người nó cũng thay đổi dần. Ví dụ như khi còn trẻ chúng ta sẽ có những cái sở thích khác mà khi lớn tuổi thì chúng ta lại có cái sở thích tiêu dùng khác. Ví dụ như khi còn trẻ chúng ta thích sử dụng những cái sản phẩm là công nghệ Hoặc là những cái sản phẩm mang cái tính chất là sáng tạo đột phá. Nhưng mà khi chúng ta dần dần chuyển sang cái độ tuổi trưởng thành và lớn tuổi hơn thì cái cái gu sử dụng sản phẩm của chúng ta nó tiến đến là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 11,
      "start_timestamp": "0:06:45",
      "end_timestamp": "0:07:38"
    }
  },
  {
    "page_content": "gu sử dụng sản phẩm của chúng ta nó tiến đến là sử dụng những sản phẩm chất lượng hơn rồi tốt cho sức khỏe hơn đó và thuận tiện hơn. Thì đó chính là cái sự thay đổi sở thích của con người theo cái dòng thời gian thì đó là một cái sự dịch chuyển. Rồi các cái khái niệm của mình nó cũng sẽ thay đổi dần theo thời gian. Ví dụ như cách đây 20 năm, cách đây 20 năm thì khi chúng ta nói về mạng xã hội, khi chúng ta nói về internet thì chúng ta sẽ nghĩ đến các cái trang web Hoặc là các cái trang blog với",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 12,
      "start_timestamp": "0:07:33",
      "end_timestamp": "0:08:13"
    }
  },
  {
    "page_content": "các cái trang web Hoặc là các cái trang blog với dạng là chữ là hình ảnh rất là phổ biến khi mà trong cái giai đoạn đầu của internet. Nhưng mà trong thời gian là 5 năm trở lại đây chúng ta thấy là với các cái concept mới xuất hiện ví dụ như chúng ta sẽ không có cái khái niệm là blog mà nó sẽ có khái niệm là vlog tức là video blog. Rồi chúng ta sẽ không có sử dụng những cái mạng truyền thống đơn thuần ví dụ như là Facebook hoặc là Twitter mà chúng ta sẽ có những cái dạng vlog, chúng ta có những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 13,
      "start_timestamp": "0:08:08",
      "end_timestamp": "0:08:46"
    }
  },
  {
    "page_content": "ta sẽ có những cái dạng vlog, chúng ta có những cái mạng xã hội mà video với cái thời gian ngắn ví dụ như là TikTok dạ. Và trước đây thì chúng ta mua bán hàng chúng ta sẽ bán hàng giao dịch trực tiếp hoặc là thông qua các cái trang thương mại điện tử truyền thống. Thì bây giờ với cái sự phát triển của TikTok đúng không? Thì chúng ta có thể bán hàng ngay trên chính cái trang mạng xã hội này đó gọi là TikTok Shop. Thì đây là những cái khái niệm mới xuất hiện trong thời gian là 5 năm trở lại đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 14,
      "start_timestamp": "0:08:42",
      "end_timestamp": "0:09:17"
    }
  },
  {
    "page_content": "xuất hiện trong thời gian là 5 năm trở lại đây và chúng ta cũng sẽ không biết được là trong 5 năm tiếp theo với cái sự phát triển của tiến bộ của khoa học công nghệ của trí tuệ nhân tạo hoặc là với cái sự phát triển của xã hội loài người thì chúng ta sẽ không biết là nó sẽ có những cái khái niệm mới gì đó. Thì mỗi một cái chu kỳ phát triển của con người nó sẽ đẻ ra thêm một cái khái niệm mới. Thì chính những cái sự thay đổi về khái niệm theo thời gian, chính cái sự thay đổi về sở thích của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 15,
      "start_timestamp": "0:09:12",
      "end_timestamp": "0:10:08"
    }
  },
  {
    "page_content": "thời gian, chính cái sự thay đổi về sở thích của người dùng theo thời gian nó sẽ tạo ra cái sự dịch chuyển. Và cái sự dịch chuyển này nó sẽ không đột ngột, nó sẽ đi từ từ thì nó gọi là gradual drift. Và một cái loại nữa đó là cái sự dịch chuyển theo chu kỳ. Thì cái chu kỳ này nó có thể là chu kỳ theo mùa ví dụ như là mùa xuân, hạ, thu đông. Nó có thể là theo thời gian chu kỳ 10 năm ví dụ như chu kỳ của khủng hoảng chẳng hạn, khủng hoảng kinh tế hoặc là chu kỳ theo múi giờ. Thì đây là những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 16,
      "start_timestamp": "0:10:04",
      "end_timestamp": "0:10:38"
    }
  },
  {
    "page_content": "hoặc là chu kỳ theo múi giờ. Thì đây là những cái yếu tố về mặt chu kỳ thời gian thì sở thích của con người cũng thay đổi theo cái chu kỳ thời gian à theo chu kỳ. Ví dụ khi mùa đông đúng không thì chúng ta sẽ có cái xu gọi là để giữ ấm. Nhưng mà khi mùa hè thì hướng là chọn những cái sản phẩm chúng ta sẽ chọn những cái sản phẩm mát rồi những cái sản phẩm mang tính chất gọi là giải nhiệt. Thì đó chính là những cái sở thích của con người nó thay đổi theo theo mùa. Do đó thì cái mô hình của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 17,
      "start_timestamp": "0:10:33",
      "end_timestamp": "0:11:18"
    }
  },
  {
    "page_content": "đổi theo theo mùa. Do đó thì cái mô hình của mình nó không thể đúng được khi áp dụng cho những cái mùa khác nhau. Ví dụ mô hình của chúng ta được huấn luyện trên cái dữ liệu về mùa đông thì khi chúng ta chuyển sang cái mùa hạ thì cái mô hình của mình nó sẽ không còn đúng nữa. Do đó khi chúng ta xây dựng cái mô hình của mình khi chúng ta lấy mẫu dữ liệu chúng ta cũng cần phải chú ý đến cái yếu tố về cái tính chu kỳ này để làm sao cho cái dữ liệu của mình nó đảm bảo được cái yếu tố về sự thay đổi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 18,
      "start_timestamp": "0:11:12",
      "end_timestamp": "0:11:49"
    }
  },
  {
    "page_content": "mình nó đảm bảo được cái yếu tố về sự thay đổi theo thời gian có tính chu kỳ. Và một cái loại biến động nữa đó chính là sự dịch chuyển tạm thời. Sự dịch chuyển tạm thời này nó sẽ hơi khác so với lại cái sự dịch chuyển đột ngột đó chính là khi ở đây chúng ta đi ngang đúng không, sau đó đột ngột dịch chuyển lên, thay đổi cái cách sử dụng dữ liệu. Sau đó chúng ta lại trở lại về cái dạng ban đầu. Thì đây là cái sự dịch chuyển trong ngắn hạn đó. Sự dịch chuyển trong ngắn hạn và cái sự dịch chuyển",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 19,
      "start_timestamp": "0:11:42",
      "end_timestamp": "0:12:20"
    }
  },
  {
    "page_content": "dịch chuyển trong ngắn hạn và cái sự dịch chuyển này thì thường là do một số nguyên nhân sau. Ví dụ như do người dùng độc hại tấn công, tức là sẽ có những cái ví dụ như mình có những cái đợt tấn công mạng trong một cái khoảng thời gian ngắn thì cái traffic, cái lượng truy cập của người dùng trong nó sẽ tăng lên một cách đột ngột trong một cái khoảng thời gian ngắn rồi sau đó nó sẽ trở lại trạng thái bình thường khi chúng ta đã phát hiện ra cái hệ thống của mình bị tấn công thì cái dữ liệu của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 20,
      "start_timestamp": "0:12:14",
      "end_timestamp": "0:12:56"
    }
  },
  {
    "page_content": "hệ thống của mình bị tấn công thì cái dữ liệu của mình nó cũng sẽ bị thay đổi theo trong cái giai đoạn mà chúng ta bị tấn công. Hoặc là khi có những cái người dùng họ muốn thử nghiệm à những cái mô hình của mình. Ví dụ như khi ChatGPT mới ra ra đời thì có rất nhiều người tìm cách để là tìm ra những cái lỗ hổng của ChatGPT. Nên chúng ta tìm cách là chat với cái cái mô hình và mình nhồi những cái dữ liệu xấu cho mô hình để khiến cho tìm cách bẫy cái mô hình để khiến cho nó có khả năng là trả lời",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 21,
      "start_timestamp": "0:12:50",
      "end_timestamp": "0:13:09"
    }
  },
  {
    "page_content": "mô hình để khiến cho nó có khả năng là trả lời những cái câu hỏi không có được đúng đó. Thì đó là nhưng mà cái việc đó thì nó chỉ diễn ra trong một cái khoảng thời gian rất là ngắn mà thôi. Và khi chúng ta có cái sự tham gia của một cái nhóm đối tượng mới hoàn toàn. Trước đây là chúng ta sẽ lấy cái dữ liệu trên một cái nhóm người cho trước và nằm trong một cái tập demography là do chúng ta lấy mẫu nhưng khi chúng ta tiến hành triển khai cái mô hình của mình trong thực tế thì nó sẽ xuất hiện",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "hình của mình trong thực tế thì nó sẽ xuất hiện những cái nhóm đối tượng và đối tượng này chưa từng được lấy mẫu, nó gọi là mới hoàn toàn. Thì cũng có khả năng đó là xuất hiện những cái đối tượng như vậy trong cái khoảng thời gian ngắn hạn khiến cho cái dữ liệu của mình nó bị biến động. Và cái sự biến động này thì có thể là chỉ biến động tạm thời mà thôi.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=WWRZF5x7Hqo",
      "filename": "WWRZF5x7Hqo",
      "title": "[CS116 - Buổi 14] Part 5_1",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cùng cài đặt hai mô hình rất là quan trọng đó là mô hình Logistic Regression và mô hình Neural Network trong đó Mô hình Logistic Regression thì mô hình này thường được sử dụng cho dữ liệu của mình ở dạng có thể phân chia được bởi một đường thẳng tuyến tính thì ở bên đây dưới đây chúng ta sẽ có một cái hình ảnh minh họa cho cái dữ liệu mà chúng ta sẽ làm việc tiếp theo ở đây chúng ta sẽ thấy là có hai tập điểm màu xanh và màu đỏ thì hai tập điểm này chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=X--mLc-PW-o",
      "filename": "X--mLc-PW-o",
      "title": "[CS116 - Buổi 8] Part 8",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:34"
    }
  },
  {
    "page_content": "màu xanh và màu đỏ thì hai tập điểm này chúng ta có thể chia tách nó ra được làm hai phần à bằng một cái đường thẳng chia ra làm hai thì đây là dữ liệu và có thể phân chia được một cách tuyến tính và mô hình Logistic Regression thì rất là phù hợp đối với lại của mình là bằng 2 thì ở đây chúng ta sẽ thấy có một số trường hợp sai số lớn nó sẽ kéo cái điểm màu đỏ lại đây luôn nhưng mà đây là cái tình huống mà chúng ta không muốn rồi Ok Nếu vậy thì chúng ta sẽ giảm cái sai số này xuống còn là 1.5",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=X--mLc-PW-o",
      "filename": "X--mLc-PW-o",
      "title": "[CS116 - Buổi 8] Part 8",
      "chunk_id": 1,
      "start_timestamp": "0:00:29",
      "end_timestamp": "0:04:41"
    }
  },
  {
    "page_content": "chúng ta sẽ giảm cái sai số này xuống còn là 1.5 rồi Như vậy thì chúng ta thấy là hai tập điểm này đã được tách biệt nhau ra và chúng ta sẽ tạo hai cái X là dữ liệu train thì cái dữ liệu train của mình sẽ bao gồm cả hai cái tập xanh và đỏ này do đó thì chúng ta sẽ dùng là np. concatenate và sẽ truyền vào hai biến X_Red và à Xin lỗi X_Blue rồi và Y của mình trong trường hợp này sẽ là bằng các cái giá trị là 0 giả sử như màu đỏ màu đỏ của mình là 0 ha và màu xanh của mình là 1 rồi thì ở đây sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=X--mLc-PW-o",
      "filename": "X--mLc-PW-o",
      "title": "[CS116 - Buổi 8] Part 8",
      "chunk_id": 2,
      "start_timestamp": "0:04:34",
      "end_timestamp": "0:05:39"
    }
  },
  {
    "page_content": "0 ha và màu xanh của mình là 1 rồi thì ở đây sẽ nhân cho số samples cộng cho 1 nhân cho số samples rồi rồi bây giờ chúng ta sẽ cùng in ra thử ha X đó, X của mình là các cái là một cái mảng hai chiều trong đó thì có hai cột cột đầu tiên tương ứng là đặc trưng x1 và cột thứ hai tương ứng là đặc trưng X2",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=X--mLc-PW-o",
      "filename": "X--mLc-PW-o",
      "title": "[CS116 - Buổi 8] Part 8",
      "chunk_id": 3,
      "start_timestamp": "0:05:33",
      "end_timestamp": "0:05:48"
    }
  },
  {
    "page_content": "một cái thành phần khác cũng rất là quan trọng trong cái ngôn ngữ lập trình Python và các cái ngôn ngữ lập trình khác đó chính là cấu trúc rẽ nhánh khi chúng ta thực hiện một cái câu lệnh tuần tự nào đó đúng không Thì đến một cái thời điểm nào đó chúng ta sẽ không đi theo một con đường nhất định và nó sẽ phụ thuộc vô cái điều kiện tại cái thời điểm kết thúc gần nhất và chúng ta có thể rẽ ra nhiều cái nhánh nhánh đi thì đây là cái cấu trúc rẽ nhánh và trong Python thì chúng ta sẽ có các từ khóa",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:45"
    }
  },
  {
    "page_content": "và trong Python thì chúng ta sẽ có các từ khóa để giúp cho chúng ta thực hiện được các công việc này đó chính là dùng cái từ khóa là If, Elif và Else nếu như chúng ta thỏa mãn một cái điều kiện nào đó Đây là cái điều kiện thì chúng ta sẽ thực hiện một cái thao tác biến đổi ngược lại ngược lại tức là không thỏa mãn cái điều kiện này thì chúng ta sẽ xét tiếp các điều kiện tiếp theo cứ như vậy không thỏa mãn thì chúng ta lại tiếp tục xem các điều kiện tiếp theo và cuối cùng đây chính là còn lại",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 1,
      "start_timestamp": "0:00:41",
      "end_timestamp": "0:01:33"
    }
  },
  {
    "page_content": "kiện tiếp theo và cuối cùng đây chính là còn lại còn lại thì chúng ta sẽ thực hiện cái câu lệnh này thì đó là cái ý nghĩa của If, Elif, Else và trong Python thì nó sẽ không có cái cấu trúc switch case nó sẽ không có switch case giống như là C++ và nó chỉ dùng 3 từ khóa là If, Elif và Else thì ở đây chúng ta sẽ xét một cái ví dụ đó là nếu như sinh viên làm bài tập đạt điểm là hơn 8 thì ở đây chúng ta hiểu là lớn hơn bằng 8 nha Thì học viên sẽ qua môn với cái kết luận đó là Excellent pass Tức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 2,
      "start_timestamp": "0:01:28",
      "end_timestamp": "0:02:06"
    }
  },
  {
    "page_content": "môn với cái kết luận đó là Excellent pass Tức là bài tập xuất sắc Còn nếu như sinh viên làm bài kiểm tra với cái điểm số là từ 6 cho đến 8 thì học viên này là qua môn và ngược lại tất cả những trường hợp còn lại thì sẽ được gọi là fail thì lưu ý ở đây chúng ta sẽ không dùng cái tư duy mặc định sẵn giống như là các quy ước về thang điểm của trường của mình đó thì ở đây Nếu như cái đầu bài nó yêu cầu như thế nào thì chúng ta sẽ tiến hành cài đặt đúng như theo yêu cầu ở trên và ở đây thì chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 3,
      "start_timestamp": "0:02:01",
      "end_timestamp": "0:02:57"
    }
  },
  {
    "page_content": "như theo yêu cầu ở trên và ở đây thì chúng ta sẽ tiến hành lập trình thử cái yêu cầu trên ha chúng ta sẽ có một cái nó gọi là 7.5 và chúng ta sẽ lớn hơn hoặc bằng 8 thì chúng ta sẽ in ra Khi kết luận đó là Excellent pass ngược lại tức là nếu như không lớn hơn hoặc bằng 8 thì lúc này chúng ta sẽ kiểm tra là nó có lớn hơn bằng 6 hay không vì nó không lớn hơn hoặc bằng 8 do đó chúng ta sẽ không cần thiết phải đưa vô cái điều kiện là lớn hơn 6 và bé hơn 8 nữa. Chúng ta chỉ cần là nó có lớn hơn bằng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 4,
      "start_timestamp": "0:02:51",
      "end_timestamp": "0:03:59"
    }
  },
  {
    "page_content": "hơn 8 nữa. Chúng ta chỉ cần là nó có lớn hơn bằng 6 hay không rồi chúng ta sẽ in ra đó là Well Pass trường hợp còn lại tức là chúng ta không lớn hơn 6 tức là bé hơn 6 thì chúng ta sẽ in ra là Fail thì chúng ta sẽ chạy thử ở đây thì nó sẽ đưa ra một cái thông báo à ở đây chúng ta sẽ viết sai đúng không là name 'result' Tức là cái biến 'result' chưa được định nghĩa ở đây là do ở đây chúng ta biết thiếu chữ t 7.5 thì nó sẽ là Well Pass Nếu như ở đây là 5.5 thì là fail và ở đây là 9.5 thì ở đây nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 5,
      "start_timestamp": "0:03:54",
      "end_timestamp": "0:04:48"
    }
  },
  {
    "page_content": "là 5.5 thì là fail và ở đây là 9.5 thì ở đây nó Kết quả nó sẽ là Excellent pass cấu trúc tiếp theo đó chính là cấu trúc lặp thì ở đây Chúng ta có một cái hình ảnh minh họa vui là thế nào là một cái cấu trúc lặp thì cái hình trên cái điện thoại ở đây chúng ta sẽ lặp đi lặp lại nhiều lần và cấu trúc lặp thì nó sẽ có hai dạng dạng đầu tiên đó là vòng For For tức là một tập hợp và một cái danh sách mà có cái tính lặp đi lặp lại 2 đó là For một cái Index nằm trong một cái giải giá trị nào đó thì ở",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 6,
      "start_timestamp": "0:04:42",
      "end_timestamp": "0:05:26"
    }
  },
  {
    "page_content": "Index nằm trong một cái giải giá trị nào đó thì ở đây là cái cách thức chúng ta sẽ sử dụng vòng For Ngoài ra thì trong Python nó cũng sẽ có cái cấu trúc gọi là While kiểm tra nếu thỏa mãn một cái điều kiện nào đó Tức là trong khi mà cái điều kiện này nó vẫn được thỏa mãn thì lúc đó chúng ta sẽ thực hiện cái câu lệnh này thì ở đây chúng ta sẽ xét một cái ví dụ là chúng ta sẽ khởi tạo một cái số Pi là 3,14 và tính diện tích hình tròn với danh sách các cái bán kính như nêu trên rồi thì ở đây chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 7,
      "start_timestamp": "0:05:18",
      "end_timestamp": "0:06:23"
    }
  },
  {
    "page_content": "các cái bán kính như nêu trên rồi thì ở đây chúng ta sẽ khởi tạo số pi rồi sau đó chúng ta sẽ có một cái list radius là bao gồm các giá trị là 2, 4 5 8 10 rồi và cái cách đơn giản nhất để chúng ta có thể tạo ra danh sách các cái diện tích tương ứng với các cái bán kính này đó chính là For r in radius nó cũng cho phép chúng ta hiểu Nó rất là gần với cái ngôn ngữ tự nhiên tức là với mỗi với mỗi chữ R nằm trong cái danh sách radius này thì mình sẽ thực hiện các lệnh gì đó chúng ta sẽ in ra là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 8,
      "start_timestamp": "0:06:19",
      "end_timestamp": "0:07:19"
    }
  },
  {
    "page_content": "thực hiện các lệnh gì đó chúng ta sẽ in ra là cái thông tin diện tích thì đây chính là cái danh sách các cái diện tích tương ứng với các cái bán kính trong cái biến trong cái list radius và trong Python thì nó sẽ có một cái gọi là Comprehension Comprehension lúc nó cho phép là đóng gói cái vòng For này và đưa vào bên trong các cái cấu trúc dữ liệu như là list và dictionary để chi để cho cái câu lệnh của mình nó gọn gàng hơn thì ở trong cái ví dụ ở đây chúng ta sẽ cùng làm một cái ví dụ về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 9,
      "start_timestamp": "0:07:15",
      "end_timestamp": "0:07:55"
    }
  },
  {
    "page_content": "ví dụ ở đây chúng ta sẽ cùng làm một cái ví dụ về Comprehension chúng ta in ra tất cả các giá trị diện tích đây thì chúng ta sẽ đóng gói tất cả các cái diện tích này vào bên trong một cái list những cái cú pháp lúc đó cũng cực kỳ đơn giản Đó là area ví dụ đây là tên biến ha sẽ là bằng một cái list và trong cái list này thì chúng ta sẽ for r in radius và chúng ta sẽ thực hiện cái gì với cái r này thì chúng ta sẽ thực hiện là bán kính nhân bán kính ở đây chúng ta có thể thử dùng là r bình phương",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 10,
      "start_timestamp": "0:07:49",
      "end_timestamp": "0:08:24"
    }
  },
  {
    "page_content": "ở đây chúng ta có thể thử dùng là r bình phương đi ha rồi sau đó thì chúng ta sẽ lấy số pi nhân với lại r bình phương lưu ý đó là cái câu lệnh mà chúng ta sẽ thực hiện với cái biến lặp này là chúng ta sẽ để đằng trước cái For thì lúc này thì toàn bộ các diện tích ở đây nó đã được đóng gói lại vào bên trong một cái kiểu là là list thì đây chính nó gọi là comprehension",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xaUMWpT1mUI",
      "filename": "xaUMWpT1mUI",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.3&1.4: Lập trình Python - Lệnh rẽ nhánh và vòng lặp",
      "chunk_id": 11,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong các bài tuần trước thì chúng ta được tìm hiểu về các cái mô hình học có giám sát trên dữ liệu dạng bảng. Thì trong thời gian gần đây chúng ta được nghe nói rất nhiều về những cái loại dữ liệu như là hình ảnh, văn bản và âm thanh. Và những cái loại dữ liệu này để có thể giải quyết và xử lý được, chúng ta sẽ phải cần những cái mô hình đặc biệt hơn, đó chính là các cái mô hình học sâu hay còn gọi là Deep Learning. Thì trong phạm vi của bài học ngày hôm nay, chúng ta sẽ cùng tìm hiểu về một",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:49"
    }
  },
  {
    "page_content": "ngày hôm nay, chúng ta sẽ cùng tìm hiểu về một trong những kiến trúc mạng rất là nổi tiếng đó chính là mạng CNN. Thì sau đây là những cái nội dung mà chúng ta sẽ cùng tìm hiểu. Đầu tiên đó là chúng ta sẽ tìm hiểu về bài toán phân loại ảnh với mạng Neural Network. Đây sẽ là cái tiền đề để dẫn dắt ờ cho cái mạng CNN về sau. Đầu tiên đó là chúng ta sẽ cùng hiểu khái niệm hình ảnh. thì nếu như dữ liệu dạng bảng của chúng ta biểu diễn dưới dạng là các cái cột và các cái dòng. Thì các cái cột này nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:44",
      "end_timestamp": "0:01:34"
    }
  },
  {
    "page_content": "cái cột và các cái dòng. Thì các cái cột này nó sẽ phải là số lượng cố định và kiểu dữ liệu cũng phải là thống nhất. Thì đối với dữ liệu dạng ảnh, chúng ta cũng sẽ biểu diễn dưới dạng là một ma trận. Tuy nhiên, cái bề ngang và bề cao của ảnh nó sẽ có kích thước thay đổi. Thì trong cái hình ảnh ở đây chúng ta minh họa nó là một cái ảnh xám, tức là ảnh không có màu sắc. Thì nó biểu diễn bởi một cái ma trận như bên tay phải. Và đối với trường hợp ảnh màu, chúng ta sẽ có ba kênh màu là màu Red,",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:29",
      "end_timestamp": "0:02:07"
    }
  },
  {
    "page_content": "ảnh màu, chúng ta sẽ có ba kênh màu là màu Red, Green và Blue, tương ứng là ba kênh màu: màu đỏ, màu xanh lá và màu xanh dương. Thì chúng ta sẽ có thêm một chiều nữa đó là chiều độ sâu (chiều depth). Và tương ứng, nó sẽ là ba cái ma trận chồng lên nhau. Thì bây giờ chúng ta sẽ giả sử chúng ta sử dụng một cái mạng đã được biết trước đó, đó chính là mạng Neural Network để giải quyết cái bài toán đó là phân loại hình ảnh. Bài toán phân loại hình ảnh này thì đầu vào của mình sẽ là một ảnh và đầu ra",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:02:03",
      "end_timestamp": "0:02:44"
    }
  },
  {
    "page_content": "này thì đầu vào của mình sẽ là một ảnh và đầu ra sẽ là phân vào các cái loại, ví dụ như ở đây là xe cộ, nhà cửa và con người. Thì đây là một cái bài toán phân loại đa lớp. Và chúng ta sẽ xét một cái mạng có cái kiến trúc rất là đơn giản với kiến trúc gọi là Fully Connected. Thì giả sử như cái ảnh đầu vào cũng rất là nhỏ. Ảnh thực sự mà nói là rất là nhỏ so với lại những cái ảnh, cái độ phân giải ảnh hiện nay có thể lên đến là hàng trăm, thậm chí là hàng ngàn pixel nhân với một hàng ngàn pixel.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:38",
      "end_timestamp": "0:03:15"
    }
  },
  {
    "page_content": "là hàng ngàn pixel nhân với một hàng ngàn pixel. Thì ở đây chúng ta lấy là cái ảnh có kích thước là 200x200. Và giả sử như cái mạng Neural Network này cũng rất là đơn giản, đó là chỉ có duy nhất một hidden layer, tức là một cái lớp ẩn mà thôi. Và số neuron của lớp ẩn này đúng bằng với lại cái số pixel. Thì ở đây tổng số lượng tham số của mình nó sẽ là 200 x 200 nhân cho 40.000, tức là 1,6 tỷ. Thì với cái kiến trúc mạng rất là đơn giản và với cái ảnh rất là nhỏ này, nó sẽ dẫn đến một cái vấn đề",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:03:10",
      "end_timestamp": "0:03:51"
    }
  },
  {
    "page_content": "ảnh rất là nhỏ này, nó sẽ dẫn đến một cái vấn đề đó là nó có quá nhiều tham số. Và việc quá nhiều tham số này sẽ dẫn đến cái hiện tượng đó là overfitting, tức là cái mô hình của mình nó quá phức tạp để có thể học được. overfitting. Và để giải quyết vấn đề này thì chúng ta sẽ sử dụng một cái mạng neuron với cái cơ chế chia sẻ trọng số và kết nối cục bộ. Thì kết nối đầu tiên đó là kết nối cục bộ, tức là các cái neuron này sẽ thay vì kết nối với tất cả toàn bộ các neuron ở trong ảnh đầu vào, thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:03:45",
      "end_timestamp": "0:04:24"
    }
  },
  {
    "page_content": "cả toàn bộ các neuron ở trong ảnh đầu vào, thì chúng ta sẽ chỉ kết nối với một cái vùng cục bộ đó. Thì giả sử như cái vùng cục bộ này có kích thước là 10x10. Và các cái neuron này nó đều chia sẻ trọng số với nhau, nó đều sử dụng chung một cái bộ trọng số. Như vậy thì bản chất của cái phép biến đổi này tức là chúng ta sử dụng một cái bộ trọng số chúng ta duyệt lên trên toàn bộ cái tấm hình đó. Thì đây chính là cái phép biến đổi Convolution của mình. Và cái số tham số của mình lúc này nó chỉ còn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:04:20",
      "end_timestamp": "0:05:08"
    }
  },
  {
    "page_content": "Và cái số tham số của mình lúc này nó chỉ còn là 10x10, tức là bằng 100 tham số. Nó ít hơn rất nhiều so với lại cái con số đó là khoảng hơn 1 tỷ tham số. Thì đây chính là cái mở đầu cho kiến trúc mạng CNN với cái phép biến đổi thay vì là Fully Connected thì chúng ta sẽ thay thế bằng cái phép biến đổi là Convolution. Và ý nghĩa của cái phép biến đổi Convolution này đó là chúng ta sẽ lọc ra được một cái đặc trưng. Đây là một cái đặc trưng sau khi thực hiện được với cái bộ lọc như đây. Và cái bộ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:05:01",
      "end_timestamp": "0:05:50"
    }
  },
  {
    "page_content": "thực hiện được với cái bộ lọc như đây. Và cái bộ lọc này thì được thiết kế, nó được thiết kế bởi một cái nhà khoa học. Thì trong cái kiến trúc mạng học sâu Deep Learning và cụ thể ở đây là mạng CNN, thì cái bộ trọng số cho cái filter này sau này nó sẽ không được thiết kế bởi nhà khoa học nữa mà nó sẽ được học từ dữ liệu. Thì đó chính là cái ý tưởng lớn nhất của mạng CNN.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=xD-o-30NeBA",
      "filename": "xD-o-30NeBA",
      "title": "[CS116 - Buổi 9] Part 1",
      "chunk_id": 9,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chủ đề, học sâu, machine learning, logistic regression, imageNet. Chủ đề, học sâu, machine learning, imageNet. Ví dụ như từ ensemble model này, một số tài liệu cũng có thể gọi là mô hình tổ hợp. Tuy nhiên, từ này như đã nói, tức là nó chưa thể hiện hết bản chất của cách thức huấn luyện của mô hình này. của cái mô hình này. Do đó thì ở đây chúng ta sẽ vẫn giữ nguyên cái tên gốc tiếng Anh của mình, đó chính là Ensemble Model. Và vị trí của cái bài học ngày hôm nay trong Machine Learning Pipeline",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:01:07"
    }
  },
  {
    "page_content": "học ngày hôm nay trong Machine Learning Pipeline đó chính là nó nằm ở đây. Ensemble Model đó là một cái mô hình để học và nó có cái sự kết hợp của nhiều cái mô hình con, nhiều cái mô hình thành phần để tạo thành một mô hình mới cho hiệu năng cao hơn, độ chính xác cao hơn và nó sẽ nằm trong bước xây dựng và huấn luyện mô hình. Thì nội dung của ngày hôm nay sẽ bao gồm 3 thành phần chính. Đầu tiên là chúng ta sẽ cùng tìm hiểu xem tại sao chúng ta cần phải có ensemble model này. Tiếp theo là các kỹ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:01:01",
      "end_timestamp": "0:01:54"
    }
  },
  {
    "page_content": "phải có ensemble model này. Tiếp theo là các kỹ thuật cơ bản bao gồm kỹ thuật voting, tức là lấy phiếu bầu, kỹ thuật averaging, tức là chúng ta cộng trung bình và weighted average, tức là chúng ta sẽ tính trung bình có trọng số, thì cái từ average này là viết tắt của chữ averaging. Và cuối cùng đó chính là kỹ thuật nâng cao trong Ensemble Learning, ví dụ như Stacking, Blending, Bagging và đặc biệt đó là Boosting. Đầu tiên đó là Ensemble là gì? Ensemble Learning là gì? Mục tiêu của các mô hình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:44",
      "end_timestamp": "0:02:34"
    }
  },
  {
    "page_content": "Ensemble Learning là gì? Mục tiêu của các mô hình máy học đó chính là chúng ta cần phải xây dựng một mô hình có tính chất tổng quát hóa cao. Đây chính là mục tiêu tối thượng Và tính tổng quát hóa cao này nó chỉ từ dữ liệu chỉ từ dữ liệu huấn luyện mà thôi Từ dữ liệu huấn luyện Tức là chúng ta chỉ với một tập con của dữ liệu trong tất cả những thứ dữ liệu có khả năng trên đời mà vẫn có khả năng là tổng quát hóa được Nếu như mô hình của mình mà học trên tất cả toàn bộ dữ liệu Cả toàn bộ dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:02:32",
      "end_timestamp": "0:03:12"
    }
  },
  {
    "page_content": "trên tất cả toàn bộ dữ liệu Cả toàn bộ dữ liệu thì không nói Còn ở đây là chúng ta làm sao Với những bộ dữ liệu ít hơn Nhưng mà nó vẫn phải đạt được tính tổng quát hóa cao Và có 2 cách chính Để cho mình có thể cải thiện được Tính tổng quát của mô hình của mình Đó chính là Cách đầu tiên đó là chúng ta sẽ cải thiện Hiệu suất của mô hình máy học Hay nói cách khác đó là chúng ta sẽ tập trung Để đi thiết kế Mô hình của mình sao cho nó đạt được tính tổng quát hóa cao. Thì ở đây chính là phương pháp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:03:10",
      "end_timestamp": "0:03:49"
    }
  },
  {
    "page_content": "tổng quát hóa cao. Thì ở đây chính là phương pháp kinh điển mà mình cần phải thực hiện. Phương pháp thứ 2 đó chính là chúng ta sẽ kết hợp nhiều mô hình. Từ nhiều mô hình này, nó chính là cái tổ hợp mà mình có đề cập bước mà giới thiệu. Chúng ta sẽ kết hợp nhiều mô hình lại với nhau và tổng hợp các kết quả của nhiều mô hình đó, tổng hợp các kết quả dự đoán của nhiều mô hình đó Lúc đó nó gọi là Ensemble Learning. Vì vậy, bài học ngày hôm nay chúng ta sẽ tập trung vào hướng tiếp cận số 2 trong",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:03:47",
      "end_timestamp": "0:04:33"
    }
  },
  {
    "page_content": "ta sẽ tập trung vào hướng tiếp cận số 2 trong việc cải thiện tính tổng quát hóa của mô hình máy học. Hình ở bên dưới đây minh họa cho ý tưởng của Ensemble Learning. Ở đây chúng ta sẽ thấy có 3 tập điểm là hình vuông, tam giác và hình tròn. Đường này là đường phân lớp cho tập hình vuông so với những phần tử còn lại. Vì vậy, để phân loại 3 tập điểm này, tại thời điểm này là khó. Chúng ta chỉ có thể tìm ra được một weak classifier, tức là một mô hình phân lớp yếu. Và tương tự như vậy, ở bên đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:04:23",
      "end_timestamp": "0:05:30"
    }
  },
  {
    "page_content": "hình phân lớp yếu. Và tương tự như vậy, ở bên đây chúng ta sẽ có một cái mô hình phân lớp yếu, một cái Weak Classifier, cái từ Weak Classifier thì nó sẽ như thế này. Nhưng nếu như chúng ta ensemble, chúng ta tổ hợp nó lại, thì nó sẽ tạo ra một cái Strong Classifier. Tại sao cái này lại có thể trở thành một cái Strong Classifier? Tại vì chúng ta thấy là với cái đường này nó chỉ có thể giúp cho chúng ta phân biệt được cái điểm hình vuông với lại những cái điểm còn lại. Đối với cái đường này thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:05:24",
      "end_timestamp": "0:05:55"
    }
  },
  {
    "page_content": "những cái điểm còn lại. Đối với cái đường này thì nó chỉ có thể giúp cho chúng ta phân biệt được cái hình tròn với những điểm còn lại. Nhưng nếu chúng ta kết hợp hai cái Classifier này lại với nhau để tạo thành một cái đường liên tục như thế này thì nó đã giúp chúng ta tách ra làm 3 phần và như vậy thì nó sẽ tạo ra 1 strong classifier Đương nhiên, hình này chỉ mang tính chất, làm minh họa và ý tưởng của thuật toán còn chi tiết, phía sau thì chúng ta sẽ còn rất nhiều những phương pháp ensemble",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:05:51",
      "end_timestamp": "0:06:38"
    }
  },
  {
    "page_content": "ta sẽ còn rất nhiều những phương pháp ensemble khác, hiệu quả hơn Thì tại sao chúng ta cần phải Ensemble Learning? Tại sao Ensemble Learning giúp chúng ta đạt được độ hiệu quả cao? Đó chính là câu hỏi lớn nhất mà chúng ta cần phải giải thích để tìm câu trả lời trong slide này. Đầu tiên, Ensemble Learning giúp chúng ta giải quyết vấn đề Variance, tức là sự biến động của mô hình của mình khi chúng ta thay đổi trên những tập dữ liệu khác nhau. Với cùng một mô hình, chúng ta thay đổi những tập dữ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:06:29",
      "end_timestamp": "0:07:19"
    }
  },
  {
    "page_content": "cùng một mô hình, chúng ta thay đổi những tập dữ liệu khác nhau, thì mô hình của mình vẫn phải giữ được sự ổn định, ít có sự biến động. Đó chính là vấn đề về giảm variance. Tại sao ensemble có thể giúp chúng ta giảm được variance? Vì chúng ta sử dụng nhiều mô hình để có thể lấy trung bình, chúng ta sẽ tính giá trị trung bình của giá trị dự đoán, thì nó sẽ gần với lại giá trị thực tế hơn. Sử dụng nhiều mô hình thì giúp cho chúng ta kéo giá trị tổng hợp gần với giá trị thực tế. Và giá trị thực tế",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 10,
      "start_timestamp": "0:07:10",
      "end_timestamp": "0:08:07"
    }
  },
  {
    "page_content": "hợp gần với giá trị thực tế. Và giá trị thực tế này chính là mô hình cuối cùng của mình cần phải đạt được. Cái việc này sẽ làm cho chúng ta giảm variance. Và cái việc giảm variance thì đồng nghĩa là chúng ta đang tránh được hiện tượng overfitting. Overfitting là gì? Nó chỉ đúng trên tập dữ liệu training. Nhưng nó lại rất là tệ trên tập dữ liệu test, tức là tập dữ liệu mà mình chưa thấy. Điều đó có nghĩa là nó đang có sự không ổn định của cái mô hình của mình. Vì sự dao động của mình quá lớn Và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 11,
      "start_timestamp": "0:08:04",
      "end_timestamp": "0:08:51"
    }
  },
  {
    "page_content": "hình của mình. Vì sự dao động của mình quá lớn Và việc giảm variance giảm sự dao động này Chính là giúp cho chúng ta giải quyết hiện tượng overfitting này Và để giảm được variance này Chúng ta sẽ sử dụng phương pháp cộng trung bình Cộng trung bình sẽ giúp cho kéo các sai số của mình về nhỏ nhất Và thuật toán Random Forest là một trong những thuật toán như vậy Thuật toán Random Forest đã kết hợp nhiều cây quyết định để làm giảm variance Trong phần mô hình phân lớp, chúng ta đã tìm hiểu về thuật",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 12,
      "start_timestamp": "0:08:43",
      "end_timestamp": "0:09:39"
    }
  },
  {
    "page_content": "mô hình phân lớp, chúng ta đã tìm hiểu về thuật toán Random Forest này rồi Đây là một trong những thuật toán tiêu biểu, giúp cho chúng ta giải quyết vấn đề variance và nó cũng thuộc trong nhóm Ensemble Learning Phía dưới đây là hình ảnh minh họa cho mô hình Ensemble Learning có thể giải quyết được hiệu quả cho vấn đề variance. Đầu vào chúng ta sẽ có những dữ liệu input và chúng ta sẽ đưa cho mô hình số 1, số 2, số 3 và mô hình thứ n. và chúng ta sẽ có được một chiến thuật để kết hợp, tổ hợp các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 13,
      "start_timestamp": "0:09:30",
      "end_timestamp": "0:10:28"
    }
  },
  {
    "page_content": "sẽ có được một chiến thuật để kết hợp, tổ hợp các kết quả của N mô hình này lại để tạo ra một giá trị output duy nhất. Ngoài ra, Ensemble Learning còn giúp chúng ta giải quyết được vấn đề Bias. Vấn đề BIAS có nghĩa là cái mô hình của mình rất khác xa so với mô hình thực tế Mô hình thực tế là khi chúng ta làm trên một dữ liệu tổng quát khách quan Còn mô hình của mình chỉ có thể tìm ra được những hàm dự đoán và mang tính chất gọi là cục bộ trên những mẫu dữ liệu cục bộ thôi Chứ không có tính tổng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 14,
      "start_timestamp": "0:10:17",
      "end_timestamp": "0:11:09"
    }
  },
  {
    "page_content": "mẫu dữ liệu cục bộ thôi Chứ không có tính tổng quát. Vì vậy thì mỗi một mô hình yếu, một weak classifier thì nó chỉ có thể đoán đúng cho một số tình huống dữ liệu. Như chúng ta biết, dữ liệu của mình sẽ rất là lớn. Và những mô hình yếu thì nó sẽ giúp chúng ta giải quyết được những tình huống cục bộ như thế này thôi. Chứ nó không giúp chúng ta giải quyết được những tình huống toàn diện. Nhưng nếu như chúng ta kết hợp nhiều mô hình yếu lại để tận dụng được điểm mạnh của mỗi mô hình, chúng ta kết",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 15,
      "start_timestamp": "0:11:00",
      "end_timestamp": "0:11:49"
    }
  },
  {
    "page_content": "dụng được điểm mạnh của mỗi mô hình, chúng ta kết hợp mô hình này với mô hình này, thì nó sẽ khắc phục được những trường hợp mà mô hình đã từng sai. Nghĩa là với mỗi mô hình yếu, nó sẽ có những tình huống đang sai. Và chúng ta sẽ dùng nhiều mô hình yếu khác để khắc phục cho những trường hợp mà mô hình yếu này đang sai. Tức là các mô hình có tính bổ trợ cho nhau. Các mô hình yếu sẽ phải có tính bổ trợ cho nhau để giúp cho mô hình này khắc phục được những điểm yếu của mô hình kia. Đó chính là ý",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 16,
      "start_timestamp": "0:11:41",
      "end_timestamp": "0:12:38"
    }
  },
  {
    "page_content": "những điểm yếu của mô hình kia. Đó chính là ý tưởng tại sao Ensemble Learning có thể giúp cho mình giải quyết vấn đề Bias. Cũng tương tự như vậy, vấn đề Bias này cũng dựa trên chiến thuật kết hợp giữa các mô hình kết hợp giữa các mô hình với nhau như thế nào để mô hình số 1 có thể bổ trợ cho mô hình số 2, khắc phục được cho mô hình số 2. Mô hình số 2 có thể khắc phục được cho mô hình số 3 thì nó sẽ phụ thuộc rất nhiều vào chiến thuật kết hợp này. Chiến thuật kết hợp này sẽ làm cho mô hình của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chiến thuật kết hợp này sẽ làm cho mô hình của mình giảm được tính bias. Với việc giảm được vấn đề về bias và giảm sự biến động của mô hình, Các bạn có thể thử nghiệm các loại dữ liệu khác nhau để giải quyết vấn đề về Overfitting. Đây là 2 lý do chính mà Ensemble Learning đã đem lại sự hiệu quả cho Ensemble Learning.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=yPGYgh-J3uY",
      "filename": "yPGYgh-J3uY",
      "title": "[CS116 - Buổi 13] Part 1",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phần tiếp theo thì chúng ta sẽ cài đặt một cái mạng cional Network và tập dữ liệu mà chúng ta sẽ sử dụng ở đây chính là tập dữ liệu mnis thì đây là một trong những tập dữ liệu rất là kinh điển khi làm trong lĩnh vực về thị giác máy tính ảnh đầu vào của cái tập dữ liệu này sẽ có cái thức là 28 nhân cho 28 đúng bằng cái kích thức ở đây và cái kiến trúc mạng CNN ở đây thì chúng ta sẽ sử dụng đó là kiến trúc mạng lenet được có từ những năm 1998 và kiến trúc mạng này Thực sự mà nó cũng không có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 0,
      "start_timestamp": "0:00:13",
      "end_timestamp": "0:00:46"
    }
  },
  {
    "page_content": "và kiến trúc mạng này Thực sự mà nó cũng không có sâu nó chỉ bao gồm hai cái nướ convolution và hai lớp convolution này thì có sử dụng các cái futter có kích thước là 3 x 3 và đối với cái lớp convolution đầu tiên thì chỉ có sáu cái phép conclusion sáu cái futter đối V lớp contion thứ hai thì sẽ có cái kích thước đó là 3 x 3 nhân cho 6 tại vì cái đầu vào của cái lớp conion này chính là cái feature map này mà feature map này có cái dep là bằng 6 do đó ở đây sẽ là là 6 Tuy nhiên thì trong quá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 1,
      "start_timestamp": "0:00:42",
      "end_timestamp": "0:01:22"
    }
  },
  {
    "page_content": "6 do đó ở đây sẽ là là 6 Tuy nhiên thì trong quá trình mà chúng ta cài đặt thì chúng ta cũng không cần phải chỉ ra tường minh là cái số input của mình là bao nhiêu tự cái chương trình nó sẽ tự cái deeping Framework nó sẽ tính cho mình cái con số này chúng ta chỉ cần cho biết cái kích thước bề ngang bề cao của cái filter và được và đồng thời chúng ta cũng cho cái deing Framework biết số filter đầu ra mong muốn là ở trong cái phép c r conversion thứ hai chính là 16 các cái phép biến đổi subs link",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 2,
      "start_timestamp": "0:01:17",
      "end_timestamp": "0:01:56"
    }
  },
  {
    "page_content": "hai chính là 16 các cái phép biến đổi subs link ở đây thực chất nó chính là cái phép biến đổi max pooling đây chính là cái phép biến đổi Max pooling rồi và ở phần cuối của mạng CN này đó chính là các cái lớp biến đổi Fully connected để tạo ra các cái vector có kích thước là 120 84 và 10 trong đó 10 thì tương ứng với lại cái số lớp đầu ra của mình đó chính là các cái con số từ 0 cho đến 9 vậy thì trong phần tiếp theo chúng ta sẽ tiến hành cài đặt cái mạng cion neuron Network này rồi thì bước đầu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 3,
      "start_timestamp": "0:01:48",
      "end_timestamp": "0:02:47"
    }
  },
  {
    "page_content": "cái mạng cion neuron Network này rồi thì bước đầu tiên thì chúng ta sẽ khởi tạo các cái tập dataset của mình thì trong cái keras nó đã có cái phương thức giúp cho mình Ờ load cái dataset rất là dễ dàng đó là keras dataset và chúng ta sẽ import cái tập dữ liệu là mnis à Sau đó chúng ta chỉ việc gọi là mnis load data thì tự động nó sẽ lấy từ trên mạng internet về giải nén và đưa vào các cái cặp biến là extrain eend và EX et đó thì ở đây chúng ta sẽ quan sát thử kích thước của các cái biến này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 4,
      "start_timestamp": "0:02:40",
      "end_timestamp": "0:03:26"
    }
  },
  {
    "page_content": "sẽ quan sát thử kích thước của các cái biến này xend chấm SH thì có kích thước là 60.000 nhân cho 28 x 28 thì 60.000 này tương ứng là tổng số mẫ còn 28 x 28 đó chính là cái kích thước bề ngang và bề cao của cái ảnh chữ số viết tay ets thì nó sẽ có kích thước là 60.000 thì ứng với từng cái xra nó sẽ có một cái giá trị label cái nhãn output của et đó thì ở đây chúng ta sẽ thử quan sát một số cái mẫu dữ liệu để quan sát thì chúng ta sẽ sử dụng thư viện đó là mli m. tyel as plp rồi plt ch chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 5,
      "start_timestamp": "0:03:20",
      "end_timestamp": "0:04:12"
    }
  },
  {
    "page_content": "viện đó là mli m. tyel as plp rồi plt ch chúng ta sẽ sử dụng cái hàm đó là Imo hàm Ino với cái biến là x và x này á thì nó có các cái phần thc cái chiều đó là 60.000 nh 28 x 28 thì ở chiều đầu tiên chúng ta sẽ lấy ra tại một cái vị trí nào đó đó là Index và trong trường hợp này thì chúng ta sẽ cho Index là bằng 123 cái con số bất kỳ trong khoảng từ 1 từ 0 cho đến 60.000 rồi à thành phần còn lại thì sẽ là hai chấm hai chấm tức là chúng ta sẽ lấy toàn bộ Cái nội dung của Tấm ảnh ra để chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 6,
      "start_timestamp": "0:04:07",
      "end_timestamp": "0:04:51"
    }
  },
  {
    "page_content": "toàn bộ Cái nội dung của Tấm ảnh ra để chúng ta hiển thị rồi sau đó chúng ta sẽ thực hiện thì thấy là cái ảnh này mình đoán đoán đó hình như là số 7 thì muốn biết chính xác nó là nhãn bao nhiêu thì chúng ta sẽ in ra là à nhãn của dữ liệu đó rồi Ở đây chúng ta sẽ lấy là y tr và chúng ta cũng sẽ truyền vào cái chỉ số là YX rồi Đúng như dự đoán thì cái nhãn này chính là nhãn của dữ liệu này chính là số 7 và chúng ta có thể thay đổi các cái chỉ số này ví dụ như là 10.000 rồi đó thì đây là tương ứng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 7,
      "start_timestamp": "0:04:45",
      "end_timestamp": "0:05:28"
    }
  },
  {
    "page_content": "ví dụ như là 10.000 rồi đó thì đây là tương ứng nhãn của nó sẽ là số 3 bước tiếp theo đó là chúng ta sẽ tền xử lý chúng ta sẽ chuẩn hóa cái dữ liệu extrain và ext của mình bằng cách đó là thay vì đưa cái miền giá trị từ 0 đến 255 thì chúng ta sẽ đưa về cái miền giá trị là từ 0 cho đến 1 để giúp cho cái quá trình huấn luyện nó được nhanh hơn và đồng thời là cái giá trị y của mình cũng sẽ được à chuyển đổi từ cái dạng Nhãn là các chỉ số từ 0 cho đến 9 chúng ta sẽ đưa nó về cái dạng One h encoding",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 8,
      "start_timestamp": "0:05:22",
      "end_timestamp": "0:06:04"
    }
  },
  {
    "page_content": "9 chúng ta sẽ đưa nó về cái dạng One h encoding cái dạng One h encoding thì One h encoding có nghĩa là gì à là ví dụ số 0 thì chúng ta sẽ đưa một cái vector trong đó có duy nhất một cái phần tử bật lên là là 1 và tất cả các cái phần tử còn lại sẽ để là số 0 r tương tự như vậy cho số 2 đi thì nó sẽ bật lên là 0 ở đây là 0 ở đây là 0 và nó sẽ bật lên Ở Đây Rồi tất cả các cái phần tử còn lại sẽ để ra số 0 đó thì đây là cái dạng on Hot and coding rồi Bước tiếp theo đó là chúng ta sẽ tiến hành cài",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 9,
      "start_timestamp": "0:05:59",
      "end_timestamp": "0:06:40"
    }
  },
  {
    "page_content": "Bước tiếp theo đó là chúng ta sẽ tiến hành cài đặt cái thực toán huấn luyện hay cụ thể đó là cài đặt cái mô hình thì cái mạng CNN ở đây chúng ta sẽ có các cái phương thức như là Build rồi train rồi constructor Vân Vân load getway vân vân thì ở đây có cái phương thức getway là chúng ta sẽ chưa cài đặt chúng ta sẽ cài đặt và để đưa lên trên xong hành cùng với lại cái hàm Trend kẹo Chúng ta quên à Xin lỗi chúng ta sẽ đưa lên trên ngang với lại phương thức là build không l chút nữa chúng ta sẽ quên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 10,
      "start_timestamp": "0:06:35",
      "end_timestamp": "0:07:15"
    }
  },
  {
    "page_content": "thức là build không l chút nữa chúng ta sẽ quên cái quá trình train của mạng CNN rất là lâu nếu mà chúng ta quên thực hiện một cái gì đấy và chúng ta thực hiện lại thì nó sẽ tốn thời gian rất là nhiều thì ở đây chúng ta sẽ phải cho cái model nó biết đó là input dimension rồi đồng thời là các cái cấu hình ví dụ như số lượng futter n là 6 n số lượng futter là 16 nè rồi số các cái output của các lớp poly connected là 120 84 thì chúng ta sẽ phải tham số hóa bốn cái bộ số này riêng cái con số cuối",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 11,
      "start_timestamp": "0:07:10",
      "end_timestamp": "0:08:06"
    }
  },
  {
    "page_content": "số hóa bốn cái bộ số này riêng cái con số cuối cùng đó là 10 đó chính là ờ số lượng cái nhãn mà mình cần nhận diện rồi thì nó sẽ cố định là 10 tại vì mình ý trước tập dữ liệu này là là có 10 mẫu 10 loại 10 10 nhãn 10 class và đồng thời thì chúng ta cũng sẽ tham số hóa cái hàm kích hoạt activation function rồi activation function rồi chúng ta sẽ có n convolution số 1 n số 2 rồi NFC 1 nf2 và mặt nhiên thì hàm activation chúng ta sẽ để là sigo chúng ta sẽ để là sigo rồi conion thì mặt nhiên chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 12,
      "start_timestamp": "0:07:59",
      "end_timestamp": "0:09:02"
    }
  },
  {
    "page_content": "ta sẽ để là sigo rồi conion thì mặt nhiên chúng ta sẽ để là 6 giống như trong cái thiết kế ở đây 2 thì mặt nhiên chúng ta sẽ để là 16 FC 1 thì chúng ta sẽ để là 120 và fc2 thì chúng ta sẽ để là 84 rồi sau đó thì chúng ta sẽ tiến hành cài đặt cái à các cái thành phần của cái mạng này bằng cách đó là chúng ta sẽ tiến hành lần lượt qua các cái lớp đối tượng qua cái lớp biến đổi lớp đầu tiên chính là cái lớp input input rồi input thì chúng ta sẽ cho biết cái Shap cái Shap của nó sẽ là bằng input",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 13,
      "start_timestamp": "0:08:54",
      "end_timestamp": "0:09:53"
    }
  },
  {
    "page_content": "biết cái Shap cái Shap của nó sẽ là bằng input dimension rồi và chúng ta sẽ trả ra một cái biến tên là input rồi tương tự như vậy thì chúng ta sẽ tiến hành chúng ta sẽ tiến hành thực hiện cái phép biến đổi conclusion thì ở đây là conion chúng ta sẽ sử dụng conion 2D và nó sẽ có các cái các cái tham số đầu tiên là số lượng futter thì chúng ta sẽ để là số lượng col số 1 cái tham số thứ hai là cal siz thì như hồi nãy chúng ta đề cập đó là kích thước của cái cal size này chính là kích thước của này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 14,
      "start_timestamp": "0:09:45",
      "end_timestamp": "0:10:46"
    }
  },
  {
    "page_content": "của cái cal size này chính là kích thước của này nó sẽ là 3 x 3 3 x 3 rồi Strike thì ở đây chúng ta sẽ để mặc định là một do đó chúng ta sẽ không Ờ để cái Strike Ở Đây Rồi ping thì chúng ta sẽ để là send Tại vì trong cái sơ đồ này chúng ta thấy trong sơ đồ này chúng ta thấy là ảnh đầu vào và ảnh đầu ra có kích thước giống nhau ảnh đầu vào 28 28 thì ảnh đầu ra là 28 28 ảnh đầu vào là 14 14 thì ảnh đầu ra cũng sẽ là 14 x 14 thì qua cái phép biến đổi conion thì chúng ta thấy là cái kích thước bề",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 15,
      "start_timestamp": "0:10:42",
      "end_timestamp": "0:11:48"
    }
  },
  {
    "page_content": "đổi conion thì chúng ta thấy là cái kích thước bề ngang và bề cao là không thay đổi khi thực hiện cái phép conion do đó chúng ta sẽ để ping là bằng xem rồi đây thì chắc là mình sẽ phải điền cái cái cái cái b nữa b là bằng tr rồi thì cơ bản đó là nó đã đầy đủ những cái à Nó còn thiếu một cái nữa đó là cái activation activation activation này sẽ để trước sẽ ra bằng function Rồi Rồi như vậy thì chúng ta đã cài đặt à cho cái đối tượng tên là conion 2D và chúng ta sẽ phải truyền vào cho nó là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 16,
      "start_timestamp": "0:11:42",
      "end_timestamp": "0:12:36"
    }
  },
  {
    "page_content": "2D và chúng ta sẽ phải truyền vào cho nó là cái input và trả ra nó sẽ ra là cái biến tên là C1 giống như trong cái sơ đồ ở đây rồi Tiếp theo thì chúng ta sẽ thử chạy ha Ok nó sẽ báo lỗi à 3 x 3 Ok nó không hiểu 3 x 3 là gì 3,3 rồi Hết Lỗi rồi bây giờ chúng ta sẽ thực hiện cái phép pulling pulling thì tương ứng đó chính là cái max pulling 2D ở đây ha và chúng ta sẽ có các cái tham số là full size thì mặt nhiên thì nó sẽ sử dụng đó là 2 x 2 do đó thì một cách tường minh ch chúng ta sẽ để ở đây là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 17,
      "start_timestamp": "0:12:30",
      "end_timestamp": "0:13:17"
    }
  },
  {
    "page_content": "một cách tường minh ch chúng ta sẽ để ở đây là 2 x 2 thì với cái cooling mà bằng 2 x 2 như thế này thì cái kích thước của mình nó sẽ được giảm xuống một nửa Strike ở đây thì chúng ta sẽ để Strike là bằng bằng 2 để sau khi thực hiện cái ping này thì cái kích thước của nó sẽ giảm xuống nữa rồi ngoài ra thì có ping thì chúng ta sẽ để là SH rồi và chúng ta sẽ truyền cái đầu vào cho nó chính là C1 và đầu ra sẽ là S2 giống như trong cái phên bản trong cái thiết kế ở đây rồi đối với cái phép biến đổi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 18,
      "start_timestamp": "0:13:12",
      "end_timestamp": "0:13:56"
    }
  },
  {
    "page_content": "cái thiết kế ở đây rồi đối với cái phép biến đổi conion tiếp theo chúng ta sẽ copy xuống nhưng mà khi copy thì cần phải lưu ý là sửa lại thay vì ở đây để là input thì nó sẽ để là s S2 sẽ để là S2 rồi và đầu ra sẽ là C C3 và số conclusion ở đây số filter ở đây nó sẽ là n con 2 kích thước không thay đổi lưu ý là hồi nãy kích thước là 3 x 3 và nó sẽ tự biết cái input S2 kích thước cái dep là bao nhiêu thì nó sẽ chọn cái filter cho phù hợp do đó chúng ta không cần phải tường minh để chỉ là kích",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 19,
      "start_timestamp": "0:13:50",
      "end_timestamp": "0:14:53"
    }
  },
  {
    "page_content": "chúng ta không cần phải tường minh để chỉ là kích thước 3 nh 3 nhân bao nhiêu rồi activation thì chúng ta cũng tái sử dụng lại tiếp theo nó sẽ chuyển sang cái phép là pulling rồi thì đầu vào chúng ta sẽ có là C3 và nó sẽ tạo ra là S4 và cái cấu hình thì cũng tương tự cấu hình cũng sẽ tương tự rồi bây giờ chúng ta sẽ tiếp tục cài đặt cho cái phép biến đổi Fully connected thì để thực hiện được cái Fully connected này chúng ta sẽ phải có một cái bước là flatten đó thì chúng ta sẽ gọi cái đối tượng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 20,
      "start_timestamp": "0:14:47",
      "end_timestamp": "0:15:41"
    }
  },
  {
    "page_content": "là flatten đó thì chúng ta sẽ gọi cái đối tượng flatten ở đây và truyền vào cái S4 để trả ra là F C ở đây thì nó sẽ đặt tên là fc4 đi ha rồi Tại vì thực sự mà nói phép plon nó không có biến đổi gì hết tiếp theo thì chúng ta sẽ thực hiện cái phép Fully connected nó chính là den rồi và tham số đầu tiên là số lượng unit Tức là số lượng output neuron sẽ trả ra thì chúng ta sẽ lấy cái tham số fc1 này đưa vào rồi activation thì chúng ta sẽ để là add function rồi us by là bằng true rồi và chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 21,
      "start_timestamp": "0:15:37",
      "end_timestamp": "0:16:18"
    }
  },
  {
    "page_content": "rồi us by là bằng true rồi và chúng ta sẽ truyền vào cái biến đó là fc4 thì trong cái sơ đồ ở đây nó để là C5 nhưng mà ờ để đúng với lại cái cái tên của nó đó là Fully connected thì chúng ta sẽ đặt tên lại đó là fc5 fc5 rồi tương tự như vậy cho cái biến đổi tiếp theo chúng ta sẽ để đầu vào là fc5 đầu ra sẽ là fc6 và số neuron độ ra sẽ là fc2 rồi cuối cùng đó chính là output đó thì fc6 sẽ được truyền vào đây và đầu ra sẽ là output và số neuron của mình sẽ là 10 tại vì mình biết trước cái đầ ra",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 22,
      "start_timestamp": "0:16:13",
      "end_timestamp": "0:17:06"
    }
  },
  {
    "page_content": "mình sẽ là 10 tại vì mình biết trước cái đầ ra của mình nó sẽ là 10 class riêng cái hạm activation function thì chúng ta sẽ phải để là sop max Tại vì đây là phân lớp dialog chứ không phải là phân lớp nhị phân Nếu mà phân lớp nhị phân thì chúng ta sẽ sử dụng sigo rồi cuối cùng thì chúng ta sẽ đóng gói toàn bộ cái input và output trong cái biến tên là model s. model sẽ là bằng Model rồi input và output rồi Như vậy thì chúng ta đã cài xong cho cái phần Build cái mô hình đối với cái hàm Trend thì",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 23,
      "start_timestamp": "0:16:57",
      "end_timestamp": "0:17:48"
    }
  },
  {
    "page_content": "phần Build cái mô hình đối với cái hàm Trend thì chúng ta sẽ sử dụng optimizer là Adam thì đây là một trong những cái optimizer rất là hiệu quả nó giúp cho chúng ta thoát ra được những cái điểm cực tiểu cục bộ hàm loss thì chúng ta sẽ sử dụng CR chúng ta sẽ sử dụng là cross entropy categorical cross entropy tức là ch ta thực hiện phân l lớp nhiều lớp rồi độ đo thì chúng ta sẽ sử dụng đo đo để đánh giá là acacy về quay thì chúng ta sẽ trả về c.m. layer và chúng ta sẽ truyền vào cái chỉ số của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 24,
      "start_timestamp": "0:17:43",
      "end_timestamp": "0:18:25"
    }
  },
  {
    "page_content": "layer và chúng ta sẽ truyền vào cái chỉ số của cái layer mà mình muốn trả về xong rồi gọi hàm getway rồi Như vậy thì chúng ta đã cài đặt xong cái mạng CNN và bước tiếp theo thì chúng ta sẽ khởi tạo tạo các cái mô hình rồi CNN ch view và ở đây thì chúng ta sẽ copy xuống các cái tham số để tránh bị sơ xóa đầu tiên input dimension thì cái ảnh này của mình á nếu Thông thường chúng ta sẽ để là 28 r phy 28 Tuy nhiên cái conclusion cái m đồ mô hình confusion nó chỉ có thể thực hiện được khi nó phải là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 25,
      "start_timestamp": "0:18:19",
      "end_timestamp": "0:18:50"
    }
  },
  {
    "page_content": "nó chỉ có thể thực hiện được khi nó phải là một cái tenser ba chiều do đó ở đây thì chúng ta sẽ để là 28 ph 28,1 và activation thì chúng ta sẽ để là sigo rồi conion số 1 Chúng ta sẽ để là 6 conversion số 2 thì chúng ta sẽ để là 16 và FC ở đây chúng ta sẽ để là một FC lớp số 1 Chúng ta sẽ để là 120 FC số 2 thì chúng ta sẽ để là 84 và hàm activation ở đây thì chúng ta sẽ để là hàm nữa rồi Bây giờ chúng ta sẽ chạy thử và chương trình thì chạy được rồi bây giờ chúng ta sẽ xem coi là cái mạng CNN",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "rồi bây giờ chúng ta sẽ xem coi là cái mạng CNN này CH Summary xem có thể thực hiện được hay không để xem cái kích thước cái cái kiến trúc của cái mạng CN này thì chúng ta có thể thấy là trong cái mạng CNN này nó thỏa mãn được đúng như cái kiến trúc mà chúng ta mong muốn là bao gồm thực hiện cái phép colion số 1 với s filter thực hiện conversion số 2 với 16 filter rồi và cái kích thước của các cái tenser thì cũng giảm dần đó là từ 28 xuống 14 xuống 7 giống như trong thiết kế ở đây và số neuron",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "7 giống như trong thiết kế ở đây và số neuron của mình sẽ là xin lỗi số tham số của mình nó sẽ là 100.000 tham số 100.000 tham số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=YyTbZa-WmHY",
      "filename": "YyTbZa-WmHY",
      "title": "[CS116 - Buổi 10] Part 3_0",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với phương pháp tinh chỉnh tham số đầu tiên đó chính là Grid Search hay còn có một cái tên gọi khác đó chính là tìm kiếm theo lưới hoặc một cái tên nó dân gian hơn đó chính là tìm kiếm vét cạn thì ý tưởng của cái phương pháp Grid Search đó là chúng ta sẽ vét cạn trên tất cả các cái tổ hợp tham số có khả năng xảy ra và sau đó thì chúng ta sẽ tiến hành thử nghiệm thử nghiệm trên từng cái tổ hợp tham số đó và sau khi chúng ta đã thử hết trên toàn bộ những cái tổ hợp tham số rồi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:38"
    }
  },
  {
    "page_content": "thử hết trên toàn bộ những cái tổ hợp tham số rồi thì chúng ta sẽ chọn ra cái tổ hợp cho cái kết quả tốt nhất lấy ví dụ như hình ở đây chúng ta sẽ có hai cái siêu tham số cho một cái mô hình và ứng với cái siêu tham số số 1 thì chúng ta sẽ thử trên cái giá trị nhỏ nhất cho đến cái giá trị là lớn nhất và chúng ta sẽ lấy mẫu đều tương tự như vậy cho cái siêu tham số số 2 chúng ta sẽ thử từ cái giá trị nhỏ nhất cho đến cái giá trị lớn nhất cho cái siêu tham số số hai này và chúng ta cũng sẽ lấy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:33",
      "end_timestamp": "0:01:13"
    }
  },
  {
    "page_content": "siêu tham số số hai này và chúng ta cũng sẽ lấy mẫu đều. Trường hợp nếu như cái không gian siêu tham số này là những cái giá trị rời rạc thì chúng ta có thể vét cạn được nhưng trong trường hợp nếu không gian siêu tham số này là những cái giá trị liên tục và cái giải giá trị của mình có thể là từ trừ vô cùng cho đến dương vô cùng thì chúng ta chỉ có thể thử trên những cái khoảng giá trị nhất định và chúng ta cũng chỉ có thể lấy mẫu đều chứ chúng ta không có khả năng thử được hết tất cả các cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:08",
      "end_timestamp": "0:01:44"
    }
  },
  {
    "page_content": "ta không có khả năng thử được hết tất cả các cái giá trị có khả năng xảy ra cho cái siêu tham số mà nhận giá trị liên tục và khi chúng ta đã chia khoảng giá trị mà mình có thể nhận được rồi thì chúng ta sẽ lần lượt duyệt từ trái sang phải từ trên xuống dưới để thử hết tất cả những cái tham số có khả năng xảy ra của cái mô hình và ứng với tại một cái cấu hình này thì chúng ta sẽ tiến hành là xây dựng cái mô hình. Chúng ta sẽ tiến hành xây dựng mô hình với cái siêu tham số này rồi sau đó chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:01:39",
      "end_timestamp": "0:02:20"
    }
  },
  {
    "page_content": "hình với cái siêu tham số này rồi sau đó chúng ta sẽ tiến hành huấn luyện và sau khi huấn luyện xong thì chúng ta sẽ tiến hành đánh giá rồi chúng ta sẽ đánh giá và đương nhiên để đánh giá cho hiệu quả thì chúng ta phải đánh giá trên một cái tập dữ liệu khách quan đó chính là tập validation đó, tập validation. Và sau khi chúng ta đánh giá trên tập validation rồi ra được cái độ chính xác hoặc là một cái độ đo định lượng thì chúng ta sẽ so sánh với tất cả những cái cấu hình này. Cái cấu hình nào",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:16",
      "end_timestamp": "0:02:59"
    }
  },
  {
    "page_content": "tất cả những cái cấu hình này. Cái cấu hình nào cho cái độ chính xác trên cái tập validation này là tốt nhất thì chúng ta sẽ lấy ở đó. Ví dụ như tại cái vị trí này là cái mô hình của mình nó cho cái độ chính xác cao nhất thì lúc đó chúng ta sẽ lấy cái bộ siêu tham số này để mà đi huấn luyện lại và chúng ta sẽ đi huấn luyện trên full toàn bộ cái tập dữ liệu training của mình để khi đó nó sẽ tận dụng được cái dữ liệu của mình nhiều hơn. Thì khi bình luận về cái phương pháp Grid Search này chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:02:54",
      "end_timestamp": "0:03:31"
    }
  },
  {
    "page_content": "luận về cái phương pháp Grid Search này chúng ta thấy nó sẽ có những cái ưu và khuyết điểm. Đầu tiên nếu xét về ưu điểm thì chúng ta thấy là đây là một cái thuật toán cực kỳ đơn giản và rất là dễ cài đặt đúng không? Chúng ta chỉ cần thực hiện hai cái vòng for trên chúng ta chỉ cần thực hiện các cái vòng for trên từng cái siêu tham số là xong rồi. Và còn lại là cái việc xây dựng mô hình cũng như huấn luyện mô hình thì nó cũng tương tự như là trong cái Machine Learning Pipeline. Và cái không gian",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:03:27",
      "end_timestamp": "0:03:58"
    }
  },
  {
    "page_content": "cái Machine Learning Pipeline. Và cái không gian tham số của mình chia ra như vậy á thì nó sẽ cho phép mình tìm kiếm nó toàn diện. Đương nhiên là như đã đề cập thì nếu như cái siêu tham số của mình mà nó là những cái con số thực thì cái việc mà vét hết tất cả các khả năng xảy ra là không khả thi. Nhưng nếu đó là những cái giá trị rời rạc thì chúng ta hoàn toàn có khả năng là duyệt trên hết được cái không gian tham số của các cái tham số mà có giá trị rời rạc. Còn nếu như à đối với những cái giá",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:03:54",
      "end_timestamp": "0:04:28"
    }
  },
  {
    "page_content": "trị rời rạc. Còn nếu như à đối với những cái giá trị mà dạng liên tục mặc dù chúng ta không thể vét hết được nhưng mà với cái phương pháp mà lấy mẫu đều trên các cái giá trị từ nhỏ nhất đến lớn nhất thì đâu đó nó cũng giúp cho chúng ta thực hiện được cái việc tìm kiếm nó tương đối là toàn diện trong cái không gian tham số của mình. Và cái điểm yếu của cái phương pháp này đó chính là nó đánh đồng cái vai trò của cái siêu tham số. Ví dụ như ở đây chúng ta thấy là siêu tham số số 1 và siêu tham số",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:04:24",
      "end_timestamp": "0:05:00"
    }
  },
  {
    "page_content": "ta thấy là siêu tham số số 1 và siêu tham số số 2 thì rõ ràng là nó sẽ có những cái siêu tham số có cái vai trò rất là quan trọng đến cái độ chính xác của mô hình nhưng chúng ta cũng lấy mẫu tương đương với lại những cái siêu tham số mà không có cái vai trò quan trọng. Ví dụ à khi cái cái siêu tham số số 1 này của chúng ta thay đổi các giá trị từ nhỏ nhất cho đến lớn nhất cũng không thay đổi đáng kể cái độ chính xác của mô hình. Ví dụ như nó chỉ giúp cho mình là tăng được từ 1 cho đến 2% thôi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:04:55",
      "end_timestamp": "0:05:34"
    }
  },
  {
    "page_content": "giúp cho mình là tăng được từ 1 cho đến 2% thôi mà chúng ta vẫn phải tốn chi phí để mà vét cạn hết trong cái không gian siêu tham số số 1 không quan trọng này. Trong khi đó cái siêu tham số quan trọng hơn, ảnh hưởng lớn đến cái hiệu năng của mô hình là siêu tham số số 2. Ví dụ như chúng ta chỉ cần thay đổi một cái bước nhảy ở siêu tham số số 2 này thôi nó có thể giúp cho chúng ta tăng được từ 5 cho đến 10% thì chúng ta lại thử với số mẫu đồng đều với lại cái số mẫu trên siêu tham số 1. Tức là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:05:28",
      "end_timestamp": "0:06:07"
    }
  },
  {
    "page_content": "với lại cái số mẫu trên siêu tham số 1. Tức là lẽ ra nếu phương pháp này tốt hơn thì nó phải xác định được siêu tham số nào cho cái sự thay đổi độ chính xác mô hình nhiều hơn thì chúng ta sẽ tập trung vét trên cái khu vực đó, lấy mẫu trên cái khu vực đó nhiều hơn. Còn những cái siêu tham số nào mà không có cái vai trò nhiều thì chúng ta sẽ giảm bớt cái tần suất của mẫu của mình đi. Và khuyết điểm tiếp theo của cái mô hình này đó chính là không gian tham số nó lớn. Ờ thì rõ ràng rồi, chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:06:02",
      "end_timestamp": "0:06:43"
    }
  },
  {
    "page_content": "gian tham số nó lớn. Ờ thì rõ ràng rồi, chúng ta nhìn trên cái sơ đồ này chúng ta thấy là số cái điểm mà chúng ta phải thử nghiệm là rất là dày. Do đó thì nếu mà chúng ta huấn luyện trên một cái mô hình mà có cái ờ số lượng tham số mô hình lớn cũng như là cái thời gian huấn luyện mà lâu có thể lên đến vài tiếng cho đến hàng tuần thì rõ ràng là cái việc thử nghiệm này không khả thi do cái không gian tìm kiếm quá lớn, không gian tham số quá lớn. Và chính vì cái điều đó nó cũng sẽ dẫn đến là cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:06:38",
      "end_timestamp": "0:07:17"
    }
  },
  {
    "page_content": "Và chính vì cái điều đó nó cũng sẽ dẫn đến là cái tính không hiệu quả. Cái tính không hiệu quả của cái mô hình Grid Search này. Cái tính không hiệu quả này nó thể hiện ở chỗ đó là trong những cái lần thử nghiệm chúng ta không kế thừa được những cái kết quả tìm kiếm trước đó. Nghĩa là gì? Ví dụ như tại cái thời điểm thứ ba này nè, chúng ta chỉ thử nghiệm độc lập so với lại các cái thử nghiệm trước và sau nó. Nó không hề có cái sự khai thác được những cái thông tin của à những cái lần thử nghiệm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 13,
      "start_timestamp": "0:07:11",
      "end_timestamp": "0:07:51"
    }
  },
  {
    "page_content": "cái thông tin của à những cái lần thử nghiệm trước. Lấy ví dụ nếu như chúng ta thử đến cái lần gần nhất và cho thấy là cái độ chính xác của nó nó không khác biệt nhiều so với lại cái à lần thứ một đúng không? Cái cái lần thử thứ hai nó không có cái sự thay đổi gì nhiều so với lần thứ một thì cái bước số ba này chúng ta có thể skip tức là chúng ta có thể bỏ qua để có thể nhảy xa hơn, tăng cái mức nhảy lên đó. Rồi ví dụ khi chúng ta thấy là từ đây sang đây đúng không? Từ đây sang đây mà cho cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 14,
      "start_timestamp": "0:07:43",
      "end_timestamp": "0:08:13"
    }
  },
  {
    "page_content": "sang đây đúng không? Từ đây sang đây mà cho cái độ à thay đổi của độ chính xác của mô hình tăng lên thì như vậy có vẻ cái xu hướng này, có vẻ cái xu hướng này nó đã giúp cho mình thay đổi đáng kể cái hiệu quả của mô hình thì chúng ta sẽ tiếp tục đi theo cái chiều như thế này thay vì chúng ta phải vét đi qua phải rồi xuống dưới lại đi qua trái rồi lại qua phải đó thì nó sẽ tốn rất nhiều thời gian để mà thử cho những cái cấu hình, cho những cái tham số mà không cần thiết. Và đó là những cái ưu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 15,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tham số mà không cần thiết. Và đó là những cái ưu điểm, khuyết điểm của cái mô hình Grid Search.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zk9bnirI-cs",
      "filename": "zk9bnirI-cs",
      "title": "[CS116 - Buổi 11] Part 2",
      "chunk_id": 16,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cuối cùng đó chính là cái quy trình đánh giá khách quan trong hai mục hai và 3 thì chúng ta nói về độ đo chúng ta nói về độ đo Ừ thế nào là một mô hình tốt thế nào là một mô hình không tốt rồi mô hình nào tốt hơn mô hình nào độ đo ra sao nhưng mà để cái kết quả mà cái con số mà chúng ta ra được ở đây á là cái con số khách quan và hợp lý thì chúng ta phải có cái quy trình thực hiện cái quy trình thực hiện nó là rất là quan trọng thế Thì ở đây chúng ta xét đến một cái quy trình đầu tiên mà mọi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:39"
    }
  },
  {
    "page_content": "ta xét đến một cái quy trình đầu tiên mà mọi người có thể thấy đó là tập dữ liệu train của mình nó sẽ là một phần của tập dữ liệu test Tức là ở đây chúng ta sẽ có toàn bộ cái dataset của mình là các cái điểm ở đây và tập train của mình mình sẽ lấy hết toàn bộ các cái tập trong dataset để làm cái tập train Và khi chúng ta muốn kiểm tra xem cái hiệu năng cái hiệu quả của cái mô hình này như thế nào thì chúng ta sẽ lấy luôn một phần chúng ta sẽ lấy luôn một phần dữ liệu của tập train ra để chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:00:34",
      "end_timestamp": "0:01:15"
    }
  },
  {
    "page_content": "luôn một phần dữ liệu của tập train ra để chúng ta đánh giá thì rõ ràng là cái cách đánh giá này nó không khách quan nó không khách quan nó không khách quan tại vì test trên chính cái dữ liệu train của mình nó sẽ rất dễ bị cái hiện tượng nó gọi là overfit nó không có tính tổng quát dữ liệu của mình sẽ rất là khớp với lại các cái mẫu dữ liệu này với toàn bộ mẫu dữ liệu này sau này khi chúng ta thử nghiệm trên những cái dữ liệu mới hoàn toàn chưa từng gặp trong cái bộ dataset thì có thể độ chính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:01:09",
      "end_timestamp": "0:01:51"
    }
  },
  {
    "page_content": "từng gặp trong cái bộ dataset thì có thể độ chính xác của mình nó sẽ rất là thấp do đó thì cái quy trình số một này nó vẫn có những cái giá trị nhất định nó sẽ phù hợp đối với những cái tình huống là dữ liệu của mình nó ít đó hoặc là cái thời gian huấn luyện của mình, thời gian để mà cái cái cái tốc độ để mà chạy cái mô hình của mình rất là chậm thì lúc đó mình sẽ sử dụng luôn chính cái tập train làm tập test tức là chúng ta khai thác những cái dữ liệu mà chúng ta đã được xử lý tính toán rồi và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:01:46",
      "end_timestamp": "0:02:24"
    }
  },
  {
    "page_content": "liệu mà chúng ta đã được xử lý tính toán rồi và à nó sẽ bị cái hiện tượng giống như chúng ta nói đó là không có cái tính khách quan và độ chính xác của mình nó sẽ thấp khi chúng ta thực hiện trên những cái tập nó gọi là out of sample dataset Tức là trên những cái tập ngoài mẫu trên tập ngoài mẫu thì cái độ chính xác của mình sẽ rất là kém và à đối với cái quy trình một thì nó sẽ độ chính xác cao cũng không thể phản ánh được đúng cái hiệu quả của mình tức là chúng ta không nên tự mãn hoặc tự à",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:02:19",
      "end_timestamp": "0:02:58"
    }
  },
  {
    "page_content": "mình tức là chúng ta không nên tự mãn hoặc tự à gọi là vui mừng khi mà chúng ta thấy với cái quy trình số một mà độ chính xác mà mình rất là tốt thì mình không nên lấy cái đó làm niềm vui chúng ta phải luôn đặt trong cái sự nghi ngờ đúng không và nó sẽ là một cái sự à nó gọi là kết quả của cái hiện tượng overfitting tức là mô hình đã được train quá đà trên tập dữ liệu dẫn đến là học cả những cái dữ liệu nhiễu và cái mô hình của mình nó sẽ không có cái tính tổng quát Tóm lại đó là khi chúng ta",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:02:53",
      "end_timestamp": "0:03:35"
    }
  },
  {
    "page_content": "có cái tính tổng quát Tóm lại đó là khi chúng ta làm với cái quy trình số 1 này thì điểm Lợi duy nhất đó chính là chúng ta tiết kiệm được thời gian nhưng mà điểm hại rất là nhiều nó sẽ khiến cho mô hình của mình chỉ tìm cách đó là tập trung trên những cái dữ liệu mà đang có của mình thôi và nó sẽ không có cố gắng để mà tổng quát hóa cái mô hình của mình lên và độ chính xác trên cái tập ngoài mẫu thì ờ độ chính xác trên cái tập ngoài mẫu thì nó phản ánh được cái hiệu quả khi áp dụng thực tế và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:03:30",
      "end_timestamp": "0:04:07"
    }
  },
  {
    "page_content": "phản ánh được cái hiệu quả khi áp dụng thực tế và làm sao để có thể cải thiện được cái độ chính xác trên cái tập ngoài mẫu này thì chúng ta sẽ phải sử dụng một cái quy trình khác chứ không thể nào mà sử dụng cái quy trình số một này và quy trình mà cải thiện cải thiện hơn so với lại cái phiên bản trước quy trình trước đó chính là quy trình số hai là tập train và tập test nó tách biệt hay còn gọi là train-test split thì nếu như đây là cái dataset toàn bộ dataset của mình thì chúng ta sẽ lấy",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:04:01",
      "end_timestamp": "0:04:48"
    }
  },
  {
    "page_content": "toàn bộ dataset của mình thì chúng ta sẽ lấy những cái tập train và những tập test là những cái tập mà có cái khác nhau về cái mẫu ví dụ đây chính là những cái mẫu dữ liệu mà chúng ta sẽ chọn ra để train nó sẽ có cái màu khác với cái màu này ha và khi test thì đây chính là những cái mẫu dữ liệu chúng ta sử dụng để test thì tập train và tập test nó tách biệt nhau ra hoàn toàn không có trùng lớp nhau thì đó là ý tưởng của cái quy trình số hai và với cái quy trình số hai thì nó sẽ không có đảm bảo",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:04:42",
      "end_timestamp": "0:05:21"
    }
  },
  {
    "page_content": "cái quy trình số hai thì nó sẽ không có đảm bảo được một số cái yếu tố khách quan ví dụ điều gì xảy ra nếu như những cái dữ liệu này chúng ta random ở đây đó là những cái tập dữ liệu dễ hoặc là đó là những cái tập dữ liệu Nó quá khó Nó quá khó dẫn đến khi chúng ta test thì chúng ta sẽ không biết được là ok mô hình của mình nó có thật sự quá xuất sắc hay không Nếu như chúng ta thử nghiệm trên dữ liệu dễ độ chính xác rất là cao nhưng mà đồng thời chúng ta cũng không biết là mô hình của mình có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:05:18",
      "end_timestamp": "0:06:01"
    }
  },
  {
    "page_content": "chúng ta cũng không biết là mô hình của mình có quá tệ hay không lỡ chúng ta gặp những cái dữ liệu quá khó gặp những dữ liệu quá khó thì dẫn đến đó là à độ chính xác của mình thấp và chúng ta cảm thấy bi quan về cái mô hình của mình đó do đó thì nó sẽ có một cái quy trình số ba đó là quy trình kiểm định chéo là K-fold cross validation thì với K-fold cross validation thì nó sẽ lần lượt chia cái tập dữ liệu của mình ra làm nhiều phần và ở trong trường hợp này K của mình chính là bằng 4 k của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:05:53",
      "end_timestamp": "0:06:40"
    }
  },
  {
    "page_content": "hợp này K của mình chính là bằng 4 k của mình bằng 4 và cái đối với cái fold số 1 đúng không thì chúng ta sẽ có cái tập như thế này đây chính là cái tập dữ liệu để train và đây chính là cái tập dữ liệu để test đối với cái fold số 2 thì chúng ta hoán đổi đây chính là cái tập dữ liệu để test và còn lại là để train đây sẽ là tập để test đây sẽ là tập để test rồi và chúng ta sẽ lần lượt sử dụng các cái tập dữ liệu của mình để train và test chúng ta sẽ lần lượt sử dụng các cái tập dữ liệu để train",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:06:34",
      "end_timestamp": "0:07:28"
    }
  },
  {
    "page_content": "sẽ lần lượt sử dụng các cái tập dữ liệu để train và test đầu tiên đó là với cái mẫu dữ liệu mà chúng ta test ở đây độ chính xác chúng ta ra được là 80% tức là khi chúng ta train trên cái 3/4 dữ liệu ở dưới rồi sau đó chúng ta test trên cái phần này thì nó ra được là 80% đối với cái fold số 2 chúng ta train trên cái phần này và chúng ta test trên cái dữ liệu ở đây thì độ chính xác của mình nó ra là 84% rồi tương tự như vậy cho cái fold số 3 độ chính xác là 82% fold số 4 độ chính xác là 86% như",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:07:22",
      "end_timestamp": "0:08:03"
    }
  },
  {
    "page_content": "xác là 82% fold số 4 độ chính xác là 86% như vậy thì chúng ta thấy với cái cách làm của cái quy trình số 3 là chúng ta đã test được đầy đủ trên toàn bộ mẫu dữ liệu rồi Mặc dù tại một thời điểm chúng ta chỉ test 20% số mẫu thôi chúng ta chỉ test 20% số mẫu nhưng mà qua 4 fold thì chúng ta đã duyệt qua hết tất cả những cái dữ liệu trong cái tập toàn bộ dataset của mình rồi và nó vẫn thỏa mãn được cái tính khách quan đó là tập dữ liệu train và test nó không có trùng nhau thì khi đó chúng ta sẽ có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 13,
      "start_timestamp": "0:07:58",
      "end_timestamp": "0:08:38"
    }
  },
  {
    "page_content": "nó không có trùng nhau thì khi đó chúng ta sẽ có một cái độ chính xác trung bình đó là bằng 80 cộng 84 cộng 82 cộng 86 tất cả chia 4 nó sẽ ra là 83% như vậy thì cái con số 83% sẽ là một cái con số mà mang tính chất khách quan tại vì nó đã được thử nghiệm trên tất cả những cái mẫu dữ liệu trong bộ dataset của mình theo cái quy trình chuẩn đó là tập train và test tách biệt nhau như vậy thì ở đây chúng ta sẽ Ờ có một cái góc nhìn tổng thể hơn để so sánh những cái Ưu khuyết điểm của ba cái Ờ ba cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 14,
      "start_timestamp": "0:08:33",
      "end_timestamp": "0:09:09"
    }
  },
  {
    "page_content": "sánh những cái Ưu khuyết điểm của ba cái Ờ ba cái phương pháp ở trên đối với cái Phương pháp mà tập test là một phần của tập train thì ưu điểm của nó rất là đơn giản đúng không quy trình của mình rất là đơn giản nhanh do chúng ta chỉ cần train một lần và chúng ta sẽ dùng một phần cái tập test xin lỗi dùng một phần cái dữ liệu train để đánh giá luôn như vậy là nó sẽ nhanh nhưng điểm yếu của nó đó là nó không khách quan và tính tổng quát của mô hình nó không được đảm bảo Tại vì mình train Sau đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 15,
      "start_timestamp": "0:09:02",
      "end_timestamp": "0:09:39"
    }
  },
  {
    "page_content": "nó không được đảm bảo Tại vì mình train Sau đó mình test trên chính dữ liệu đó thì nó không có tổng quát Còn đối với cái train-test split thì ý tưởng của nó thì cũng đơn giản dễ thực hiện Chúng ta chỉ tách nó ra làm hai phần 80 20 70 30 ví dụ vậy và cũng ít tốn kém về mặt chi phí so với lại cross validation Tại vì chúng ta train trên 80% Sau đó chúng ta chỉ test trên 20% còn lại và chúng ta chỉ thực hiện cái việc này đúng một lần thôi thì so với lại cái cross validation thì nó sẽ ít tốn kém hơn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 16,
      "start_timestamp": "0:09:36",
      "end_timestamp": "0:10:11"
    }
  },
  {
    "page_content": "lại cái cross validation thì nó sẽ ít tốn kém hơn nhưng cái train-test split này thì mặc dù là nó không khách quan so với lại cái cross validation đúng không khuyết điểm của nó là nó không khách quan nhưng mà không khách quan này là so với cross validation thôi nhưng mà so với lại cái test là một phần của train thì nó đã khách quan hơn rồi đó và điểm yếu thứ hai đó là nó sẽ tốn thêm một cái thời gian để để test Nhưng mà thực sự mà nói thì cái thời gian này cũng không đáng kể lắm đó thì cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 17,
      "start_timestamp": "0:10:06",
      "end_timestamp": "0:10:41"
    }
  },
  {
    "page_content": "thời gian này cũng không đáng kể lắm đó thì cái phương pháp train-test split này nó rất là phù hợp đối với cái tình huống đó là chúng ta không thể train đi train lại cái mô hình của mình nhiều lần chúng ta chỉ train một lần thôi thì nó phù hợp thì đó là khi cái tập dữ liệu của mình nó rất là lớn hoặc là cái mô hình của mình đó đó rất là nặng Ví dụ như các cái Deep learning Model nó train Nó sẽ tốn rất là nhiều thời gian và cuối cùng đó là K-fold cross validation thì ưu điểm của nó chính là nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 18,
      "start_timestamp": "0:10:36",
      "end_timestamp": "0:11:10"
    }
  },
  {
    "page_content": "cross validation thì ưu điểm của nó chính là nó đánh giá được toàn diện đánh giá được toàn diện cái tính tổng quát của mô hình tức là khi mà nó ra được cái con số là 83% thì cái con số đó là tương đối là khách quan tại vì nó đã được duyệt qua tất cả các cái tập dữ liệu trong dataset với quá trình train và test đó là tách biệt ra và Tuy nhiên thì cái K-fold validation này thì nó chỉ phù hợp với lại những cái tập dữ liệu ít hoặc là khi cái mô hình của mình nó huấn luyện nhanh tức là nếu như giả",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 19,
      "start_timestamp": "0:11:07",
      "end_timestamp": "0:11:49"
    }
  },
  {
    "page_content": "của mình nó huấn luyện nhanh tức là nếu như giả sử như chúng ta train Cái model đó nó tốn Khoảng vài tiếng thì ok chúng ta có thể dùng cross validation chúng ta thực hiện đó thì lặp đi lặp lại trên K lần nhưng nếu như cái mô hình này của mình nó train Nó tiến đến hàng tuần hoặc hàng tháng thì rõ ràng là phương pháp này không ổn nó không thể nào mà thực hiện đi thực hiện lại cái này được hàng tháng nhiều tháng trời được đúng không Và như khuyết điểm thì cũng đã đề cập á đó là cái chi phí của nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 20,
      "start_timestamp": "0:11:43",
      "end_timestamp": "0:12:29"
    }
  },
  {
    "page_content": "thì cũng đã đề cập á đó là cái chi phí của nó rất là cao do chúng ta phải huấn luyện nhiều lần cụ thể ở đây chính là huấn luyện K lần với k là số fold của mình số cái cái cái phần chia trong cái dataset của mình và như vậy thì trong bài hôm nay chúng ta đã cùng tìm hiểu về cách thức để chúng ta đánh giá cái mô hình của mình Tại sao chúng ta cần phải đánh giá cái mô hình các cái độ đo độ đo đánh giá của mình thì độ đo này nó sẽ là các cái hàm liên quan đến là hàm độ lỗi độ lỗi này sẽ phục vụ cho",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 21,
      "start_timestamp": "0:12:24",
      "end_timestamp": "0:13:06"
    }
  },
  {
    "page_content": "quan đến là hàm độ lỗi độ lỗi này sẽ phục vụ cho cái quá trình huấn luyện phục vụ cho cái quá trình huấn luyện và cái thứ hai đó là cái độ đo đánh giá độ đo đánh giá thì cái độ đo đánh giá này á là thực hiện thực hiện sau khi sau khi huấn luyện thì chính độ đo đánh giá này nó phải dễ hiểu và dễ cảm nhận bởi những cái người mà không có chuyên môn về máy học những cái khách hàng hoặc là người dùng cuối còn độ lỗi thì nhiệm vụ của nó đó là nó vẫn giúp cho cái mô hình của mình tiến đến cái giá trị",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 22,
      "start_timestamp": "0:13:01",
      "end_timestamp": "0:13:37"
    }
  },
  {
    "page_content": "cho cái mô hình của mình tiến đến cái giá trị Dự đoán và giá trị thực tế nó xấp xỉ nhau nhưng đồng thời nó phải tăng cái cái cái khả năng huấn luyện lên làm sao cho huấn luyện nó nhanh hơn do đó thì một cách tổng quát thì độ lỗi không nhất thiết phải là cái hàm độ đo đánh giá và cuối cùng đó là chúng ta nói về cái quy trình chúng ta nói về cái quy trình đánh giá tức là các cái độ đo này là các độ đo định lượng và đánh giá được cái kết quả của mình là tốt hay xấu Tuy nhiên nếu như không có cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 23,
      "start_timestamp": "0:13:32",
      "end_timestamp": "0:13:55"
    }
  },
  {
    "page_content": "là tốt hay xấu Tuy nhiên nếu như không có cái quy trình mà khách quan á Nếu mà không có cái quy trình khách quan thì các cái con số này đôi khi nó cũng không khách quan do cái đặc thù của mô hình của mình là có khả năng nó sẽ nhớ nó sẽ overfit quá khớp với lại cái tập dữ liệu huấn luyện thì nếu như chúng ta dùng Chính cái tập dữ liệu huấn luyện để mà test luôn thì nó sẽ không khách quan chúng ta phải chia nó ra làm hai phần tách biệt nhưng mà chia ra làm hai phần tách biệt thì cũng không chắc",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ra làm hai phần tách biệt thì cũng không chắc là khách quan tại vì có khả năng là cái phần dữ liệu test của mình rất là dễ hoặc là rất là khó do đó thì chúng ta sử dụng cái K-fold validation nó sẽ giúp cho chúng ta đánh giá khách quan hơn nhưng mà nói như vậy thì cũng không có nghĩa Đó là từng cái phương pháp như vậy thì nó không được sử dụng nó sẽ phải tùy vào những cái tình huống tùy xem mô hình của mình nó có nặng không huấn luyện có tốn thời gian hay không dữ liệu của mình nó có lớn hay",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "gian hay không dữ liệu của mình nó có lớn hay không để mà mình chọn lựa cái quy trình đánh giá khách quan cho phù hợp",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=ZO3SVFww3ZQ",
      "filename": "ZO3SVFww3ZQ",
      "title": "[CS116 - Buổi 5] Part 4",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "và cái cách triển khai tiếp theo đó chính là Model in service Model in service tức là gì Tức là cái mô hình của mình nó sẽ được đặt ngay trong cái server để triển khai cái dịch vụ của mình đặt ngay trong cái server để triển khai dịch vụ đó vì khí Ví dụ như ở đây client đúng không người dùng cuối họ gọi một cái api lên trên server và server của mình sẽ ngay trong cái con Server này chúng ta thực thi cái mô hình của mình để đưa ra cái kết quả dự đoán ngay trên chính cái server cung cấp cái api này",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 0,
      "start_timestamp": "0:00:01",
      "end_timestamp": "0:00:47"
    }
  },
  {
    "page_content": "ngay trên chính cái server cung cấp cái api này đó thì nó gọi là Model in service chúng ta sẽ đóng gói với cái cách thức triển khai này thì mô hình sẽ được đóng gói nè và sẽ cài đặt chung sẽ được đặt chung vào bên trong cái web server của mình thì đây chính là cái sự khác biệt lớn nhất Nếu như trong cái b prediction thì Model của mình sẽ được chạy trước chạy sẵn trước và đổ cái kết quả dự đoán vào bên trong database thì ở đây m của mình sẽ được gọi ngay khi có cái request của người dùng và cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 1,
      "start_timestamp": "0:00:41",
      "end_timestamp": "0:01:27"
    }
  },
  {
    "page_content": "gọi ngay khi có cái request của người dùng và cái mô hình của mình thì nó cũng sẽ được đặt chung với lại cái server cái web server cung cấp api cho người dùng và như vậy thì cái web server của mình nó sẽ tiến hành Tải hay C gọi là lad load cái mô hình này lên rồi gọi cái mô hình để thực hiện cái việc dự đoán khi có yêu cầu từ người dùng đó thì đây là cái cách thức triển khai model in service và cái với cái cách thức triển khai này thì chúng ta có thể thấy rằng là có ít ưu điểm nhưng mà rất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 2,
      "start_timestamp": "0:01:21",
      "end_timestamp": "0:02:05"
    }
  },
  {
    "page_content": "ta có thể thấy rằng là có ít ưu điểm nhưng mà rất nhiều khuyết điểm đúng không Ví dụ như là ưu điểm duy nhất của nó đó là nó sẽ tận dụng được cái hạ tầng của cái server hiện có Tức là cái Server này vốn nó được tạo ra để mà cung cấp cho cái api Ừ hoặc là cái web cho người dùng thì chúng ta sẽ dùng luôn Chính cái Server này để triển khai m lên trên đây luôn đó thì chúng ta sẽ tận dụng được cái hạ tầu không phải tốn không phải phát sinh thêm cái chi phí cho cái hạ tầng mới nhưng mà quyết điểm của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 3,
      "start_timestamp": "0:01:59",
      "end_timestamp": "0:02:44"
    }
  },
  {
    "page_content": "phí cho cái hạ tầng mới nhưng mà quyết điểm của nó thì chúng ta thấy rất là nhiều ở đây quyết điểm đầu tiên đó là cái server mình có thể được viết bằng cái ngôn ngữ khác à cái web server của mình có thể viết được ngôn ngữ khác Tại vì chúng ta biết rằng là các cái cái công nghệ mà về lập trình web nó rất là đa dạng à Nó có thể viết bằng PSP nè rồi nó có thể viết bằng Java nè đó rồi Thậm chí nó nó có thể viết bằng csap thì công nghệ rất là nhiều nhưng mà các cái công nghệ này á mà phục vụ cho lập",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 4,
      "start_timestamp": "0:02:40",
      "end_timestamp": "0:03:26"
    }
  },
  {
    "page_content": "mà các cái công nghệ này á mà phục vụ cho lập trình web á thì thường là không có phù hợp cho các cái mô hình máy học chúng ta biết rằng là mỗi một cái ngôn ngữ đạp trình sinh ra thì nó sẽ phục vụ tối ưu cho một số cái tác vụ nào đấy thôi đó thì khi chúng ta làm các ứng dụng dạng web thì nó sẽ dùng những cái ngôn ngữ phù hợp để làm web mà những cái ngôn ngữ này thì nó lại không có đáp ứng được cái mức độ của một cái mô hình máy học đó là phải tính toán cao có cái hiệu năng tính toán cao trên các",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 5,
      "start_timestamp": "0:03:19",
      "end_timestamp": "0:03:58"
    }
  },
  {
    "page_content": "toán cao có cái hiệu năng tính toán cao trên các cái phép toán trên số học hoặc là có khả năng xử lý được cái dữ nệu lớn vân vân thì đây là những cái điểm yếu của các cái ngôn ngữ lập trình khi làm cái web server như vậy thì web server nó sẽ không nó sẽ viết bằng nhiều ngôn ngữ khác nhau nhưng mà những cái ngôn ngữ đó nó lại không phù hợp cho cácem mình ha máy học của mình và mô hình của mình thì nó có thể cập nhật thường xuyên hơn cái code cái code web điều này có nghĩa là gì ở đây chúng ta sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 6,
      "start_timestamp": "0:03:55",
      "end_timestamp": "0:04:36"
    }
  },
  {
    "page_content": "web điều này có nghĩa là gì ở đây chúng ta sẽ có hai trong cái server này của chúng ta nó sẽ có chứa hai thứ một đó là cái code của cái model máy học và hai á đó chính là cái code của cái code web mình thì chúng ta biết rằng là cái code web của mình thông thường nó sẽ có cái tính ổn định rất là cao khi chúng ta triển khai một cái ứng dụng web đó rồi thì phải rất là lâu sau chúng ta mới cập nhật lại một cái phiên bản mới cho cái ứng dụng web của mình trong khi đó cái mô hình của mình thì nó sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 7,
      "start_timestamp": "0:04:31",
      "end_timestamp": "0:05:22"
    }
  },
  {
    "page_content": "mình trong khi đó cái mô hình của mình thì nó sẽ có cái tính chất cập nhật rất thường xuyên nó sẽ có thể cập nhật lại các cái trọng số của mô hình tại vì dữ liệu cái mô hình của mình Nó có thể là thậm chí là học theo thời gian mà nó sẽ học ờ học xin lỗi ở đây là học hoặc là huấn luyện học hoặc huấn luyện theo thời gian có những cái mô hình mà nó sẽ học Real Time luôn học theo Real Time theo thời gian thực tức là cứ vài vài giờ vài ngày vài tiếng là nó sẽ được học luôn đó thì cái tính cập nhật",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 8,
      "start_timestamp": "0:05:16",
      "end_timestamp": "0:05:56"
    }
  },
  {
    "page_content": "là nó sẽ được học luôn đó thì cái tính cập nhật của cái mô hình của mình nó sẽ rất là cao trong khi đó cái We này thì chậm dẫn đến là nó sẽ không có cái sự đồng bộ trong cái việc là chúng ta Cập nhật cái cái cái cái cái cái server của mình tiến hành quản lý và cập nhật Cái server của mình rồi cái mô hình của mình lớn á thì thậm chí là nó có thể tiêu tốn rất là nhiều cái tài nguyên của cái web server ví dụ những cái mô hình mà học sâu de learning nó sẽ sử dụng rất nhiều tài nguyên tính toán về",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 9,
      "start_timestamp": "0:05:51",
      "end_timestamp": "0:06:39"
    }
  },
  {
    "page_content": "nó sẽ sử dụng rất nhiều tài nguyên tính toán về ram về bộ nhớ về CPU Và thậm chí là gpo thì nó sẽ làm cho cái con server của mình nó chậm mà server của mình C chận thì nó sẽ không có thể thực hiện được những cái tác vụ chính của cái ứng dụng web đó nó sẽ làm ảnh hưởng đến cái hiệu quả của cái phần các cái ứng dục khác của nh web của mình và cái phần cứng của của cái web server thì có thể là nó không tối ưu cho mô hình của mình tức là khi chúng ta muốn triển khai một cái mô hình triển khai trên",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 10,
      "start_timestamp": "0:06:33",
      "end_timestamp": "0:07:30"
    }
  },
  {
    "page_content": "muốn triển khai một cái mô hình triển khai trên cái server mà đã có phục vụ cho cái một cái ứng dụng web nào đó thì thường người ta sẽ thiết kế cái phần cứng cho cái con Server này đáp ứng được những cái nhu cầu của cái web App ví dụ nó cần đáp ứng là bộ nhớ nhiều cái bộ HDD Tức là cái ổ cứng nhiều rồi CPU cũng nhiều ram nhiều nhưng mà khi chúng ta thực hiện trên các cái mô hình máy học đúng không Thì chúng ta không có cần cái ổ cứng nhiều đó cái mô hình của mình nhiều khi nó rất là ít nó chỉ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 11,
      "start_timestamp": "0:07:24",
      "end_timestamp": "0:08:04"
    }
  },
  {
    "page_content": "mô hình của mình nhiều khi nó rất là ít nó chỉ cần có vài ghb thôi là đủ rồi và CPU này nó cũng không cần nhiều mà nó lại cần có cái GPU à Nó cần phải có cái bộ tính toán vi xử lý song song thì lúc đó là nó sẽ có cái sự chênh lệch có cái sự mâu thuẫn giữa hai cái model cái code Model và code web trong cái việc là tiêu tốn cái tài nguyên phần cứng của mình cái tài nguyên để phục vụ cho cái phần code web này nè cho cái phần web App nà thì nó lại không có phục vụ tốt cho cái mô hình máy học và nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 12,
      "start_timestamp": "0:08:00",
      "end_timestamp": "0:08:50"
    }
  },
  {
    "page_content": "có phục vụ tốt cho cái mô hình máy học và nó sẽ có một cái vấn đề đó là cái mô hình vấn đề này cũng rất là nan giải Đó là mô hình máy học và cái web server của mình nó sẽ có thể scale khác nhau ý của cái câu này đó chính là gì Ví dụ khi chúng ta triển khai một cái code code web lên trên một cái con server thì nếu chỉ có cái ứng dụng web c thì một một máy tính có thể phục vụ được cho khoảng 100.000 người đó nhưng cũng với cái cấu hình phần cứn đó mà cho cái phần mà máy học thì một máy của mình á",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 13,
      "start_timestamp": "0:08:45",
      "end_timestamp": "0:09:22"
    }
  },
  {
    "page_content": "mà cho cái phần mà máy học thì một máy của mình á Đây là cho cái phần mà đây là cho cái phần mà web ha còn cho cái phần mà mô hình máy học thì một máy này của mình với cái một cái mô hình thì nó chỉ có thể phục vụ được cho khoảng 10.000 người thôi mình lấy ví dụ vậy và nó sẽ có cái sự chên lệch ở đây thì khi cái số lượng người dùng người ta tăng lên giả sử như Hiện giờ mình đang đang có 10.000 người thì mọi thứ vẫn ổn nhưng mà khi nó bước sang cái con số thứ 20.000 người thì một máy này không",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 14,
      "start_timestamp": "0:09:18",
      "end_timestamp": "0:09:55"
    }
  },
  {
    "page_content": "cái con số thứ 20.000 người thì một máy này không đủ để cho chúng ta triển khai cái mô hình nhưng nó vẫn đủ một máy nó vẫn đủ tại vì 10.000 người thì với cái dụ web nó vẫn còn nằm trong cái khả năng của nó nhưng mà đến cái phần này mô hình máy học nó đã không chịu được nữa tại vì cái khối lượng tính toán của nó quá lớn khi mà cái số lượng người dùng lên đến 20.000 người đó thì buộc chúng ta sẽ phải cái mua cái cái server nên chúng ta sẽ phải cấp phát thêm một cái con server mới đó nhưng mà khi",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 15,
      "start_timestamp": "0:09:49",
      "end_timestamp": "0:10:36"
    }
  },
  {
    "page_content": "phát thêm một cái con server mới đó nhưng mà khi chúng ta cấp phát một con server mới thì vô hình chung cái phần web server này cái phần web này nó lại thừa đó thì đó là cái sự không có đồng bộ trong cái việc mà chúng ta scale cái mô hình của mình lên khi à chúng ta sẽ sử dụng chung một con server cho hai cái tính năng và tiếp theo đó chính là cái model as service tức là chúng ta triển khai cái mô hình dưới dạng là các cái dịch vụ web đó thì ở trong đây chúng ta thấy rằng là thay vì chúng ta để",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 16,
      "start_timestamp": "0:10:30",
      "end_timestamp": "0:11:12"
    }
  },
  {
    "page_content": "đây chúng ta thấy rằng là thay vì chúng ta để model chung với cái con server của một cái web server ở đây thì chúng ta sẽ tách nó ra thành một cái máy riêng một cái server riê tách ra thành một cái con server ri và cái con cái cái cái server r này nó sẽ cung cấp cái api cho cái dịch vụ web của mình ở phía backend nhưng đồng thời nó cũng có thể kết nối trực tiếp với cái người dùng cuối à Nó có thể kết nối trực tiếp với cái người dùng cuối thông qua cái api luôn như vậy thì cái tính uyển chuyển",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 17,
      "start_timestamp": "0:11:06",
      "end_timestamp": "0:11:58"
    }
  },
  {
    "page_content": "qua cái api luôn như vậy thì cái tính uyển chuyển của nó rất là cao đúng không Tức là khi chúng ta triển khai một cái mua đồ riêng và một cái servering thì cái dịch vụ về dự đoán kết quả của máy học của mình có thể được cung cấp cho trực tiếp đến cái người dùng cuối nó cũng có thể cung cấp cho cái con server backend của phía mình Và thậm chí là nó có thể cung cấp cho các cái bên thứ ba có nhu cầu cho các cái đơn vị bên thứ ba có nhu cầu thì ở đây Model service tức là chúng ta sẽ thực thi cái mô",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 18,
      "start_timestamp": "0:11:54",
      "end_timestamp": "0:12:41"
    }
  },
  {
    "page_content": "Model service tức là chúng ta sẽ thực thi cái mô hình máy học của mình trên một cái con server r trên một cái con serv viên thay vì chúng ta sẽ không có dùng chung với cái server cái cái web server đó và web backend thì nó sẽ tương tác với cái mô hình của mình bằng cách gọi cái dịch vụ web hay còn gọi là api và nhận được cái phản ngồi ngược lại từ cái server đó có server mà có chứu mu hình đó của mình thì với cái cách làm này chúng ta sẽ thấy có những cái ưu điểm rất là nhiều nó sẽ có rất nhiều",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 19,
      "start_timestamp": "0:12:37",
      "end_timestamp": "0:13:20"
    }
  },
  {
    "page_content": "những cái ưu điểm rất là nhiều nó sẽ có rất nhiều ưu điểm ưu điểm đầu tiên về cái tính dependency tức là cái tính phụ thuộc á thì mô hình của mình mà có lỗi đúng không Nếu cái mu hình của mình có bất thì nó cũng sẽ không ảnh hưởng không ảnh hưởng không ảnh Hưng nhiều nha không ảnh hưởng đến cái ứng dụng web của mình tức là nếu như cái server của Đây là cái web server nè Còn đây là cái mod nè đ thì nếu như cái model này chết đúng không Thì cái web này nó vẫn còn hoạt động được ý của cái nó là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 20,
      "start_timestamp": "0:13:12",
      "end_timestamp": "0:13:55"
    }
  },
  {
    "page_content": "web này nó vẫn còn hoạt động được ý của cái nó là cái tính phụ thuộc của nó nó không có bị ảnh hưởng nhiều và cái tính mở rộng là khi chúng ta tách Cái m cái cái server của mình ra riêng á thì cái Server này về mặt phần cứng nó sẽ được chọn lựa những cái phần cứng phù hợp cho cái mô hình này hơn à tối ưu cho cái mô hình của chúng ta thay vì chúng ta phải bị phụ thuộc vào cái phần cứng cho cái phần web server thì ở đây chúng ta có thể tùy chọn những cái phần cứng tối ưu cho cái mô hình của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 21,
      "start_timestamp": "0:13:50",
      "end_timestamp": "0:14:29"
    }
  },
  {
    "page_content": "cái phần cứng tối ưu cho cái mô hình của mình và khi chúng ta mở rộng thì cái tính mở rộng của nó cũng sẽ được phù hợp hơn Ví dụ như hồi nãy chúng ta nói một cái web server có thể phục vụ được 100.000 người còn cái model server thì nó chỉ chỉ có thể phục vụ được khoảng 10 10.000 người thôi thì khi cái con số người dùng mà lên 20.000 người thì chúng ta chỉ cần tăng cái số server của cái phần model này lên gấp đôi còn cái web server vẫn giữ nguyên và dẫn đến là cái phần web server của chúng ta nó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 22,
      "start_timestamp": "0:14:25",
      "end_timestamp": "0:15:08"
    }
  },
  {
    "page_content": "và dẫn đến là cái phần web server của chúng ta nó sẽ không có bị thừa đúng không nó không có bị dư cái khả năng cung cấp dịch vụ cho người dùng của mình thì đó chính là cái tính mở rộng hay còn gọi là scalability và cuối cùng đó chính là cái tính linh động đó là cái dịch vụ của cái mô hình của mình á có thể được tái sử dụng cho các ứng dụng khác tức là ví dụ như chúng ta đang làm một cái dịch vụ là nhận diệt gương mặt đúng không Chúng ta đang muốn làm một cái dịch vụ là nhận diệt gương mặt và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 23,
      "start_timestamp": "0:15:02",
      "end_timestamp": "0:15:49"
    }
  },
  {
    "page_content": "làm một cái dịch vụ là nhận diệt gương mặt và có những cái bên thứ ba như là ngân hàng như là các cái công ty cung cấp các dịch vụ công ví dụ vậy như các cái đơn vị mà cung cấp dị vụ công họ cần cái tính xác thực bằng gương mặt thì chúng ta sẽ cung cấp cái api đó cho các cái bên đơn vị khác có thể cùng sử dụng chung thì một công đôi Việt và khuyết điểm của cái cách là Model ex service đó là nó có thể có cái độ trễ latency Tại sao Tại vì khi cái model của mình gọi lên trên cái web đúng không cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 24,
      "start_timestamp": "0:15:45",
      "end_timestamp": "0:16:29"
    }
  },
  {
    "page_content": "của mình gọi lên trên cái web đúng không cái web này giả sử như phía sau nó gọi backend là backend phía sau nó sẽ gọi cái model của mình thì ở đây nó sẽ có một cái độ trễ và từ đây trả về đây nó sẽ có độ trễ Tại vì Model của mình mà thông qua api thì lúc nào nó cũng sẽ có cái độ trẻ vì truyền qua cái môi trường à gọi là môi trường internet rồi nó sẽ phức tạp hơn về mặt hạ tầng thì đúng rồi Tại vì bình thường á cái cách là mod Ờ cái cách mà chúng ta đưa cái mod vào riêng một cái con server khác",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 25,
      "start_timestamp": "0:16:24",
      "end_timestamp": "0:17:05"
    }
  },
  {
    "page_content": "ta đưa cái mod vào riêng một cái con server khác thì chúng ta sẽ phải quản lý hai con server trong khi đó với cái cách Model inice thì chúng ta chỉ việc có quản lý có một server thôi nó sẽ đơn giản hơn đúng không Thì còn Model a service thì chúng ta sẽ phải quản lý cái khối lượng quản lý chúng ta sẽ nhiều hơn do chúng ta có đến hai cái loại server do đó phức tạp về mặt khả từ và để để triển khai cái mô hình ở dạng dịch vụ thì chúng ta sẽ có một số cái khái niệm mà chúng ta cần phải tìm hiểu đầu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 26,
      "start_timestamp": "0:16:58",
      "end_timestamp": "0:17:43"
    }
  },
  {
    "page_content": "cái khái niệm mà chúng ta cần phải tìm hiểu đầu tiên đó là rest api thì đây chính là một cái khái niệm về cái việc là cung cấp một cái dịch vụ web theo cái công thức là rest chúng ta sẽ có những cái quy tắc quy chuẩn về giữ Kiệt đầu vào và giữ kiện đầu ra cái input của cái api của mình nó sẽ có những cái chuẩn gì đúng không Nếu là số nguyên Nếu là số thực nếu là hình ảnh nếu là một cái file dữ liệu đó thì nó sẽ đóng gói với dạng là cấu trúc như thế nào là Jon hay là xml Vân Vân thì đó là những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 27,
      "start_timestamp": "0:17:38",
      "end_timestamp": "0:18:29"
    }
  },
  {
    "page_content": "thế nào là Jon hay là xml Vân Vân thì đó là những cái quy chuẩn của rest api rồi cái kết quả trả về của mình nó sẽ có cái format như thế nà thì đó là liên quan đến cái rest api rồi chúng ta sẽ phải có cái cái khái niệm liên quan đến cái quản lý cái tính phụ thuộc thì trong cái tính phụ thuộc ở đây chúng ch ta đã đề cập đó là mô hình của mình đúng không Thì nó sẽ có lỗi Ờ nếu mà cái mô hình của mình nó có lỗi thì nó sẽ ảnh hưởng đến cái ứng dụng web nó như thế nào thì ở đây chúng ta cũng sẽ",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 28,
      "start_timestamp": "0:18:25",
      "end_timestamp": "0:19:03"
    }
  },
  {
    "page_content": "web nó như thế nào thì ở đây chúng ta cũng sẽ tương tự như vậy khi cái mô hình của mình mà nó đang trục chặt nó có vấn đề thì cái ứng dụng web của mình nó sẽ phản ứng ra sao để tránh cái việc là phụ thuộc giữa cái ứng dụng web giữa cái ứng dụng web và cái m đồ để giúp cho mình là không có bị gây ra cái thiệt Hải cái yếu tố tiếp theo đó chính là cái tối ưu về mặt hiệu năng tối ưu về mặt hiệu năng khi chúng ta triển khai cái mô hình của mình Ờ đến cái người dùng cuối thì rõ ràng là cái việc chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 29,
      "start_timestamp": "0:18:59",
      "end_timestamp": "0:19:41"
    }
  },
  {
    "page_content": "cái người dùng cuối thì rõ ràng là cái việc chúng ta tối ưu về hiệu năng cũng rất là quan trọng Làm sao để cho cái mô hình của mình có thể chạy được nhẹ nè rồi làm sao công mình có mình có thể là nhanh nhẹ ở đây tức là í tốn tài nguyên tài nguyên này thì có thể bao gồm là về bộ nhớ đúng không và tài nguyên về tính toán rồi nhanh tức là làm sao để cho kể từ khi người ta cái người dùng người ta request cái mô hình của mình nó thực thi một cái gì đấy thì chúng ta sẽ phải thực thi với thời gian",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 30,
      "start_timestamp": "0:19:35",
      "end_timestamp": "0:19:45"
    }
  },
  {
    "page_content": "đấy thì chúng ta sẽ phải thực thi với thời gian thực đó là cái mà mong muốn lớn nhất Tuy nhiên nếu mà trong trường hợp có đội Trễ thì làm sao cái đội trẻ của mình là thấp nhất có thể thì ở đây chúng ta đang nói về yếu tố về tốc độ thì đây chính là yếu tố về hiệu năng rồi cái yếu tố về mở rộng theo chiều dọc hay còn gọi là horizontal scale tức là khi cái lượng người dùng của mình tăng lên đúng không vượt quá Cái khả năng của một cái mô hình của mình nó có thể đáp ứng một cái con server của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 31,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "nó có thể đáp ứng một cái con server của mình có thể đáp ứng thì chúng ta sẽ cấu hình và chúng ta có thể nâng cốc cái hạ tầng như thế nào để đáp ứng khi cái số lượng người dụng của mình thay đổi và cuối cùng đó là triển khai làm sao tích hợp hết mọi thứ có thể chạy một cách trơn tru trong một cái hệ thống tổng thể từ cái khâu là lấy cái dữ liệu thu thập dữ liệu rồi huấn luyện cập nhật huấn luyện mô hình theo thời gian rồi có thể gọi cái hàm dự đoán đến cái mô hình trên cái số lượng người dùng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 32,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "đoán đến cái mô hình trên cái số lượng người dùng Lớn rồi Làm sao có thể là đo lường các cái hiệu quả của cái việc dự đoán này như thế nào thì đó là cái vấn đề về triển khai",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zpcI-PT_MjE",
      "filename": "zpcI-PT_MjE",
      "title": "[CS116 - Buổi 14] Part 2_2",
      "chunk_id": 33,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Cuối cùng thì chúng ta sẽ cùng tìm hiểu một số cái mô hình à để giải quyết cho cái trường hợp là dữ liệu có mối quan hệ Phi tuyến thì mô hình đầu tiên đó chính là mô hình caris neighbor classifier thì cái ý tưởng của cái phương pháp này đó chính là chúng ta sẽ tìm k cái náng diện gần nhất trong trường hợp này K của mình là bằng 3 k của mình bằng 3 và cái nhãn của mình tương ứng với lại từng đặc trưng nó sẽ là các cái màu Ví dụ như đây là các điểm màu màu hồng đây là các điểm màu nâu và đây là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 0,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:00:38"
    }
  },
  {
    "page_content": "màu màu hồng đây là các điểm màu nâu và đây là các điểm màu đen thì với k = 3 và cái điểm ở đây chính là cái điểm đặc trưng đầu vào chúng ta sẽ tìm xem trong tất cả những cái điểm mẫ dữ liệu ở đây thì k cái láng diền gần nhất là k điểm nào và đây chính là k cái điểm gần nhất và chúng ta sẽ cùng thực hiện cái thao tác gọi là voting tức là chúng ta sẽ xem xem cái nhãn nào được xuất hiện nhiều lần thì trong ba cái điểm ở đây thì cái nhãn màu đen nó xuất hiện nhiều nhất do đó thì chúng ta sẽ kết",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 1,
      "start_timestamp": "0:00:32",
      "end_timestamp": "0:01:09"
    }
  },
  {
    "page_content": "nó xuất hiện nhiều nhất do đó thì chúng ta sẽ kết luận là cái điểm đặc trưng này sẽ nhận cái output của mình chính là cái nhãn màu đen chúng ta sẽ gán cái nhãn màu đen ở đây và đây cũng là một trong những cái thuật toán nó gọi là lazy learning lazy learning có nghĩa là mô hình này nó sẽ không có tham số gì hết và nó sẽ phải buộc để nhớ toàn bộ tất cả những cái dữ liệu đầu vào khi chúng ta tiến hành test chúng ta vẫn phải lưu các cái tập dữ liệu Trend đó thì điều này nó sẽ gây ra cái sự bất tiện",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 2,
      "start_timestamp": "0:01:04",
      "end_timestamp": "0:01:48"
    }
  },
  {
    "page_content": "đó thì điều này nó sẽ gây ra cái sự bất tiện đó là nó tốn bộ nhớ Nó sẽ tốn bộ nhớ điểm mạnh của đó của nó đó chính là nó có thể học được cho những cái tình huống là phi tuến tính nó chỉ cần tìm k cái láng diện gần nhất rồi sau đó nó sẽ dựa trên cái nhãn của C cái láng gìn gần nhất đó để mà nó đi gán cái nhãn tương ứng cho cái đặc trưng đầu bào dựa trên cái phương pháp là voting hoặc chúng ta sẽ có một cái cải tiến của phương pháp voting đó là VOT dựa trên cái trọng số những cái cái điểm nào mà",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 3,
      "start_timestamp": "0:01:43",
      "end_timestamp": "0:02:19"
    }
  },
  {
    "page_content": "dựa trên cái trọng số những cái cái điểm nào mà có cái khoảng cách gần hơn thì nó sẽ cho cái trọng số nó lớn hơn chúng ta tính toán cho nó cái trọng số lớn hơn và đây là một cái mô hình không có tham số thì chúng ta đã đề cập như ở trên mô hình này không có tham số cái k Ở đây nó không được gọi là tham số mà nó gọi là siê tham số siê tham số của mô hình còn cái tham số mà đưa ra cái quyết định xem có bao nhiêu nó đưa ra cái quyết định xem là với một cái đặc trưng đầu vào thì chúng ta sẽ tính",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 4,
      "start_timestamp": "0:02:14",
      "end_timestamp": "0:02:57"
    }
  },
  {
    "page_content": "một cái đặc trưng đầu vào thì chúng ta sẽ tính toán xử lý trên cái tham số đó đ từ đó đưa ra qu cái quyết định thì nó mới gọi là tham số của mô hình tham số mô hình đó thì m cái cái thuộc toán caris classifier này là nó không có tham số cho mô hình nhưng mà nó vẫ sẽ có một cái siêu tham số k và mô hình tiếp tiếp theo đó là mô hình multilayer percep hay còn gọi là neural Network thì đây là một trong những cái mô hình tổng quát nó giúp cho chúng ta giải quyết được trong cái tình huống là dữ liệu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 5,
      "start_timestamp": "0:02:53",
      "end_timestamp": "0:03:26"
    }
  },
  {
    "page_content": "giải quyết được trong cái tình huống là dữ liệu của mình có mối quan hệ phụ thuộc một cách phi tuyến tính với lại cái dữ liệu đầu vào bằng cách đó là học ra những cái đặc trưng trung gian giúp cho cái việc giải quyết à giúp cho cái việc mà đưa ra cái quyết định nó dễ dàng hơn thì ở đây chúng ta sẽ có một lớp ẩn nhưng mà trong trường hợp tổng quát thì cái số lượng h hidden layer này chúng ta có thể tăng lên là nhiều lớp ẩn có thể là 2 3 hoặc thậm chí là hàng trăm lớp ẩn đó đối với cái bài toán",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 6,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:03"
    }
  },
  {
    "page_content": "chí là hàng trăm lớp ẩn đó đối với cái bài toán phân lớp mà nhiều lớp thì output này nếu như K số phân lớp của mình cần phân loại đó là bằng Ờ Bằng bằng 3 đi thì chúng ta sẽ ra ba cái neuron nếu như K mà bằng 5 thì nó sẽ tạo ra là năm cái neuron như vậy thì cái mạng neuro Network này của mình nó có cái tính linh hoạt rất là cao nó vừa có thể giúp cho chúng ta giải quyết được các cái bài toán hồi quy và bài toán phân lớ đối với bài toán hồi quy chúng ta đã tìm hiểu trước đây thì cái output của",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 7,
      "start_timestamp": "0:03:58",
      "end_timestamp": "0:04:34"
    }
  },
  {
    "page_content": "chúng ta đã tìm hiểu trước đây thì cái output của mình là nó sẽ ra một neuron và cái neuron này thì chúng ta sẽ không có cái hàm kích hoạt mà chúng ta chỉ có duy nhất cái biến đổi tuyến tính từ cái lớp phía trước đến cái lớp cuối cùng là một nốt này thôi chúng ta sẽ không có hàm kích hoạt để chúng ta ép cái mì giá trị của mình về một cái khoảng nào đó thì cái tính linh động của cái mạng multilayer concept tron này rất là cao và một trong những cái thuật toán một trong những cái mô hình rất là",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 8,
      "start_timestamp": "0:04:28",
      "end_timestamp": "0:05:07"
    }
  },
  {
    "page_content": "cái thuật toán một trong những cái mô hình rất là hiệu quả và mạnh mẽ và là tiền đề cho các cái phương pháp ensemble về sau á đó chính là mô hình decision tre thì đây là một cái cấu trúc phân cấp và cũng không có tham số cái mô hình này là một cái mô hình không có tham số và mỗi một cái nút mỗi một cái nút Ví dụ như đây là một cái nút đây là một cái nút thì nó đại diện cho một cái thuộc tính hay là một cái đặc trưng nó đại diện cho một cái thuộc tính hay đặc trưng chúng ta sẽ tiến hành so sánh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 9,
      "start_timestamp": "0:05:03",
      "end_timestamp": "0:05:47"
    }
  },
  {
    "page_content": "tính hay đặc trưng chúng ta sẽ tiến hành so sánh kiểm tra xem cái thuộc tính và đặc trưng đó nó sẽ nhận cái giá trị Ờ từ bao nhiêu đến bao nhiêu cái khoảng giá trị của nó nó nằm trong cái đoạn nào để chúng ta sẽ phân nhánh nó ra và ở đây chúng ta sẽ có cái khái niệm là nhánh nhấn là từ cái nút đó tương ứng với lại một số trong số cái khả năng có xảy ra của thuộc tính ví dụ chúng ta xét đến cái yếu tố đó là trời có mưa hay không thì chúng ta sẽ có hai cái nhánh có khả năng xảy ra đó chính là có",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 10,
      "start_timestamp": "0:05:35",
      "end_timestamp": "0:06:28"
    }
  },
  {
    "page_content": "hai cái nhánh có khả năng xảy ra đó chính là có và không Trời có mây hay không chứ Thì có mây hay không thì có hoặc là không đối với những cái giá trị mà dạng liên tục Ví dụ như lớp cái lớp học của mình đó thì chó chúng ta có thể là đưa ra các cái nhánh ví dụ Ví dụ như nếu nhán là giá trị là 1 là lớp 1 nhán là 2 nhấn là 3 như vậy thì ở đây là chúng ta sẽ có thể là nhận được 12 nhánh thì chánh đó là nó thể hiện là số Cái khả năng mà có khả năng xảy ra của cái thuộc tính nào đó rồi mỗi một cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 11,
      "start_timestamp": "0:06:18",
      "end_timestamp": "0:06:57"
    }
  },
  {
    "page_content": "xảy ra của cái thuộc tính nào đó rồi mỗi một cái nút lá Tức là cái nút cuối cùng Đây là những cái nốt lá nè terminal nde Tức là những cái nốt lá Đây là cái nốt nó sẽ sẽ đưa ra cái quyết định phân loại cuối cùng dựa trên các cái thuộc tính đã duyệt trước đó ví dụ tại cái nút lá này thì để ra được cái thuộc tính của mình ở đây thì để ra được cái quyết định cuối cùng cái quyết định phân loại Cuối Cùng Ở đây thì chúng ta sẽ phải dựa vào các cái đặc trưng của các cái nốt ở trước đó đó là nốt này Nốt",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 12,
      "start_timestamp": "0:06:54",
      "end_timestamp": "0:07:40"
    }
  },
  {
    "page_content": "của các cái nốt ở trước đó đó là nốt này Nốt này và nốt này dựa trên ba cái nốt này thì chúng ta sẽ đưa ra được cái quyết định là cuối cùng của là tại đây là phân lớp nào thì đây chính là cái ý tưởng của decision tree Cây quyết định và ở đây chúng ta sẽ có một cái ví dụ đó là nếu hôm nay trời nắng độ ẩm cao và gió yếu thì hôm nay chúng ta có nên đi chơi cầu lông hay không đó thì đây là một cái cây quyết định trời nắng tức là Sunny ha độ ẩm cao đúng không độ ẩm cao thì chúng ta sẽ đến đây chúng",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 13,
      "start_timestamp": "0:07:35",
      "end_timestamp": "0:08:15"
    }
  },
  {
    "page_content": "không độ ẩm cao thì chúng ta sẽ đến đây chúng ta sẽ xem coi là độ ẩm của mình là cao tức là qua đây và khi chúng ta đã có trời nắng độ ấm cao thì ở đây chúng ta sẽ đưa ra quyết định luôn đó là chúng ta sẽ không có đi chơi chúng ta không đi và bất chấp là gió có yếu hay không yếu thì chúng ta cũng sẽ vẫn đưa ra cái quyết định là không có đi chơi thì đây chính là cái cái cái ý tưởng của tục toán decision trong cái việc đó là ứng với từng một cái nốt nè thì chúng ta sẽ có một cái đặc trưng ở đây",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 14,
      "start_timestamp": "0:08:10",
      "end_timestamp": "0:08:49"
    }
  },
  {
    "page_content": "nốt nè thì chúng ta sẽ có một cái đặc trưng ở đây là chúng ta đang nói về đặc trưng của thời tiết ở đây thì chúng ta đang nói về đặc trưng của độ ẩm và tương ứng với đặc trưng thời tiết Chúng ta có ba nhánh thì ba nhánh này tương ứng là ba cái khả năng xảy ra của cái đặc trưng thời tiết đó là trời nắng trời mây là trời mưa rồi và bây giờ làm sao chúng ta có thể xây dựng được một cái cây quyết định từ một cái bộ dữ liệu huấn luyện bộ dữ liệu huấn lị này thì chúng ta sẽ thấy là năm cái cột đầu",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 15,
      "start_timestamp": "0:08:45",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "lị này thì chúng ta sẽ thấy là năm cái cột đầu tiên á tương ứng nó sẽ là feature và cái cột cuối cùng của mình nó chính là cái giá trị output của mô hình cần dự đoán đó là có đi chơi hay không thì ở đây chúng ta sẽ dựa trên một cái loại độ đo đó gọi là độ đo information Gain information tức là thông tin Gain Tức là cái sự gia tăng thì nếu như chúng ta xây dựng cái cây chúng ta cố gắng là chọn ra những cái nhánh đi nào mà có cái information Gain cao nhất cái mức độ mà thông tin của nó nhiều nhất",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 16,
      "start_timestamp": "0:09:17",
      "end_timestamp": "0:10:07"
    }
  },
  {
    "page_content": "nhất cái mức độ mà thông tin của nó nhiều nhất đó thì chúng ta sẽ dựa trên độ đ information g để quyết định xem chọn Đặc trưng nào để phân loại cho cái nút tiếp theo thì ở đây muốn tính được cái information Gain chúng ta sẽ phải có thêm một cái khái niệm nữa đó là entropy là thể hiện cái mức độ đa dạng cái mức độ đa dạng của các cái loại trong cái đối của các cái loại đối tượng trong cái tập S của mình và khi đó thì chúng ta có cái công thức của entropy trong cái tập S là bằng trừ của p p log p",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 17,
      "start_timestamp": "0:10:01",
      "end_timestamp": "0:10:48"
    }
  },
  {
    "page_content": "entropy trong cái tập S là bằng trừ của p p log p với y chạy từ 1 cho đến C thì C này chính là cái số cái đối tượng số cái đối tượng ở trong cái tập S này của mình và information Gain nó sẽ được tính bằng entropy của nde cha Tức là cái nde ở phía trên trừ cho entropy của các cái nốt ở phía dưới expectation tức là trung bình của cái entropy của các cái n phía dưới và với s là tập hợp các cái đối tượng gồm có c nhãn rồi p với y chạy từ 1 cho đến C thì nó là tỷ lệ của cái nhãn thức y trong cái tập",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 18,
      "start_timestamp": "0:10:42",
      "end_timestamp": "0:11:41"
    }
  },
  {
    "page_content": "thì nó là tỷ lệ của cái nhãn thức y trong cái tập S của mình thì ở đây chúng ta sẽ lấy một cái ví dụ à giả sử như s của mình nó sẽ bao gồm hai chúng ta sẽ bao gồm được hai nhãn thôi là cộng và trừ thôi trong đây chúng ta thấy là cộng và trừ thôi rồi thì ở đây chúng ta sẽ có một cái tình huống đó là s sẽ bao gồm cộng trừ cộng trừ thì khi đó Ờ cái P của cộng nó sẽ là bằng 1/2 đúng không và P của trừ nó sẽ là bằng 1/2 Và khi đó thì cái độ đo entropy của mình entropy của s nó sẽ là bằng trừ của 1/2",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 19,
      "start_timestamp": "0:11:35",
      "end_timestamp": "0:12:22"
    }
  },
  {
    "page_content": "của mình entropy của s nó sẽ là bằng trừ của 1/2 log 1/2 vậy sau đó lại trừ cho 1/2 log của 1/2 đó thì ở đây chúng ta sẽ thấy là cái tính đa dạng của nó sẽ rất là cao khi chúng ta Trừ lấy hai cái giá trị này chúng ta cộng lại với nhau thì chúng ta sẽ ra cái entropy của mình trong trường hợp này nó chính là bằng 1 rồi trong trong tình huống tiếp theo đó là s của của mình mặc dù C của mình là bằng 2 tức là có hai Nhãn là cộng và trừ Nhưng nếu như à chúng ta chỉ có bao gồm Toàn cái dấu cộng và",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 20,
      "start_timestamp": "0:12:17",
      "end_timestamp": "0:12:57"
    }
  },
  {
    "page_content": "à chúng ta chỉ có bao gồm Toàn cái dấu cộng và không có cái dấu trừ nào thì khi đó P của cộng lúc này nó sẽ là bằng 1 100 ph và P của trừ của mình trong trường hợp này đó là bằng 0 thì lúc này cái entropy entropy của mình trong trường hợp này đ thì do cái tính đa dạng của mình nó rất là thấp nó chỉ có duy nhất một cái loại nào đó thôi thì khi đó Cái entropy của mình trong trường hợp này nó sẽ là bằng trừ của 1 log của 1 và trừ của 1 log 1 chính là bằng bằng 0 rồi sau đó chúng ta sẽ trừ cho 0",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 21,
      "start_timestamp": "0:12:51",
      "end_timestamp": "0:13:30"
    }
  },
  {
    "page_content": "là bằng bằng 0 rồi sau đó chúng ta sẽ trừ cho 0 nhân cho log của 0 thì vì ở đây chúng ta có cái số 0 ở đây nên xem như là chúng ta sẽ không tính toán như vậy entropy s nó thể hiện cái mức độ đa dạng trong trường hợp s của mình chỉ đơn thuần chứa một cái loại đối tượng thôi thì độ đa dạng của mình là bằng 0 trong trường hợp entropy của mình mà có cái sự xuất hiện của cộng trừ đồng đều nhau Tức là cái tính đa dạng giống nhau thì entropy của mình nó sẽ tiến về về 1 và khi đó thì à chúng ta luôn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 22,
      "start_timestamp": "0:13:25",
      "end_timestamp": "0:14:01"
    }
  },
  {
    "page_content": "nó sẽ tiến về về 1 và khi đó thì à chúng ta luôn mong muốn hướng đến là với một cái đặc trưng nó phân loại nó sẽ tách biệt hai cái tập cộng và trừ này ra làm hai phần như vậy là chúng ta đang muốn hướng đến cái tình huốn này đúng không Tức là khi chúng ta phân lại ra thì cái nhánh ở bên dưới nè nó chỉ bao gồm những cái tập hoặc là dấu cộng hoặc là dấu trừ thôi tức là cái entropy của mình nó là bằng 0 đó thì mình luôn mong muốn là cái entropy ở dưới là thấp đồng thời Ờ chúng ta không mong muốn",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 23,
      "start_timestamp": "0:13:55",
      "end_timestamp": "0:14:33"
    }
  },
  {
    "page_content": "dưới là thấp đồng thời Ờ chúng ta không mong muốn cái entropy của mình nó cao tại vì nếu như chúng ta phân loại xong mà các cái giá trị ở đây cộng và tr trừ ở đây nó vẫn xuất hiện song song với nhau tức là tỷ lệ giống nhau thì như vậy là cái đặc trưng ở đây nó sẽ không có cái tính phân biệt nó sẽ không có cái tính phân biệt cao đó thì để đại diện cho để đạt được cái mục tiêu đó là cái entropy ở cái nốt lá này thấp thì ở đây chúng ta sẽ phải có cái dấu trừ ở đằng trước thì khi cái dấu trừ này mà",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 24,
      "start_timestamp": "0:14:27",
      "end_timestamp": "0:15:03"
    }
  },
  {
    "page_content": "dấu trừ ở đằng trước thì khi cái dấu trừ này mà Ờ có cái dấu trừ này đằng trước mà giá trị ở đây mà thấp à giá trị ở đây thấp Tức là cái information Gain này là cao mà information Gain cao tức là th cái đặc trưng mà mình phân loại ở đây là chúng ta sẽ làm những cái đặc trưng quan trọng thì trên cái hình ở đây chúng ta sẽ thấy là có hai cái đặc trưng và với cái cách chọn đặc trưng ở bên tay trái chúng ta thấy là nó có cái information Gain cao là vì sao cái tỷ trọng của những dấu cộng và những",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 25,
      "start_timestamp": "0:14:57",
      "end_timestamp": "0:15:06"
    }
  },
  {
    "page_content": "vì sao cái tỷ trọng của những dấu cộng và những cái dấu trừ Nó bất đối xứng nhau dấu cộng nó lớn ác so với dấu trừ bên đây thì dấu trừ nó lớn át so với dấu cộng trong khi đó bên đây thì cái information Gain của mình nó là thấp À nó thấp là do các cái tỷ trọng của dấu cộng và dấu trừ nó xem xem nó đồng đều nhau như vậy thì mình không mong muốn à cái đặc trưng này chúng ta không mong muốn đi theo cái con đường này mà chúng ta luôn mong muốn chia ra theo cái con đường này để cho tạo ra những cái",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ra theo cái con đường này để cho tạo ra những cái đặc trưng có cái tính phân biệt đó phân phân biệt cao tức là chúng ta sẽ phân hóa dấu cộng sẽ Dồn hết về một bên và dấu trừ sẽ Dồn hết về một bên thì đó chính là cái ý tưởng của DC centry dựa trên cái độ đo information Gain để mà chúng ta có thể chọn ra các cái đặc trưng cho một cái nút trong cái cây của mình",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=zTEi9Q92mdg",
      "filename": "zTEi9Q92mdg",
      "title": "[CS116 - Buổi 8] Part 6",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trong phạm vi của môn này thì chúng ta sẽ ôn tập cái ngôn ngữ lập trình Python Tại vì như đã đề cập thì các bạn chắc là đã học Python trong một số cái môn học trước đây hoặc là sử dụng Python như là một trong những cái ngôn ngữ lập trình để làm đồ án của các cái môn học trước đây do đó thì trong môn học này thì chúng ta chỉ ôn tập đầu tiên thì chúng ta sẽ nói sơ qua một vài cái tính chất của Python đó là một cái ngôn ngữ bậc cao high level programming language. Nó là một cái trình thông dịch hay",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:17",
      "end_timestamp": "0:00:57"
    }
  },
  {
    "page_content": "language. Nó là một cái trình thông dịch hay còn gọi là một cái interpreter Và nó có cái tính đa năng thì như đã đề cập Python có thể lập trình ứng dụng hoàn toàn có thể lập trình máy học và Trí tuệ nhân tạo. Python có thể làm trong lĩnh vực về dữ liệu lớn thì nó rất là đa năng và một cái điều quan trọng nữa đó là Python hỗ trợ Lập trình hướng đối tượng. Đây là một trong những cái phong cách lập trình phổ biến được các lập trình viên trên thế giới sử dụng và cái tư tưởng Lập trình hướng đối",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:27"
    }
  },
  {
    "page_content": "giới sử dụng và cái tư tưởng Lập trình hướng đối tượng sẽ giúp cho lập trình viên có thể tiếp cận đến các ngôn ngữ này một cách dễ dàng. Đó là những cái lý do tại sao chúng ta nên học Python thì thứ nhất Đây là một ngôn ngữ rất là đơn giản thứ hai đó là rõ ràng, dễ đọc và cái thứ ba đó là một ngôn ngữ dễ học và cái thứ tư rất là quan trọng đó là Python có cộng đồng rất là lớn thì như chúng ta đã nói trong slide trước Python có từ không phải từ gần đây mà nó đã có từ hàng chục năm về trước Do đó",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:23",
      "end_timestamp": "0:02:02"
    }
  },
  {
    "page_content": "đây mà nó đã có từ hàng chục năm về trước Do đó thì Cộng đồng phát triển cái cộng đồng sử dụng ngôn ngữ Python cũng rất là nhiều do đó thì những cái mẹo những cái lỗi trong quá trình sử dụng Python sẽ được cộng đồng chia sẻ để cho chúng ta có thể kế thừa. Thì thư viện Python cũng chính vì cái lịch sử phát triển rất là lâu đời như vậy thì Python nó cũng có rất nhiều những cái thư viện đi kèm hỗ trợ. Ví dụ như SciPy, nó sẽ có scikit-learn scikit-learn sẽ là cái thư viện chính trong cái môn này.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 3,
      "start_timestamp": "0:01:59",
      "end_timestamp": "0:02:40"
    }
  },
  {
    "page_content": "sẽ là cái thư viện chính trong cái môn này. Ngoài ra thì nó cũng có thư viện như là xử lý tính toán số học NumPy rồi thư viện Matplotlib để Trực Quan Hóa thì đây là các cái thư viện rất là kinh điển trong Python. Và những gã khổng lồ nào đang sử dụng Python thì chúng ta thấy các cái ngôn ngữ và các gã khổng lồ có sử dụng Python có thể nhắc đến ví dụ như là Instagram rồi Google rồi Facebook thì đây là những cái gã khổng lồ có sử dụng ngôn ngữ Python trong các quá trình phát triển các sản phẩm",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:35",
      "end_timestamp": "0:03:28"
    }
  },
  {
    "page_content": "trong các quá trình phát triển các sản phẩm của họ. Và ở đây chúng ta đưa ra một cái ví dụ cực kỳ nhỏ, cực kỳ đơn giản để minh họa tại sao Python được ưa thích. Ở đây chúng ta thấy ngôn ngữ C C++ và Java đây là ba cái ngôn ngữ rất là phổ biến hiện nay thì để có thể thực hiện được một cái câu lệnh là Hello world thì các cái ngôn ngữ này sẽ phải làm rất là dài dòng trong khi đó Python chỉ cần thực hiện đúng một dòng code là chúng ta có thể thực hiện được rồi. Thì đây là một cái ví dụ nhỏ để minh",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:23",
      "end_timestamp": "0:04:07"
    }
  },
  {
    "page_content": "được rồi. Thì đây là một cái ví dụ nhỏ để minh họa cho cái việc Python rất là gọn gàng, dễ học. Về môi trường lập trình thì Python có rất nhiều những cái môi trường lập trình hỗ trợ thì nổi tiếng nhất chính là PyCharm. Bên cạnh đó thì Python cũng được hỗ trợ trong Visual Studio Code. thì trong phạm vi của môn học này thì tôi khuyến khích là các bạn có thể sử dụng Visual Studio Code. Tại vì đây là một cái IDE, một cái môi trường lập trình có tích hợp với rất nhiều những cái ngôn ngữ khác nhau.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:02",
      "end_timestamp": "0:04:48"
    }
  },
  {
    "page_content": "hợp với rất nhiều những cái ngôn ngữ khác nhau. Nếu như các bạn có học thêm với các cái ngôn ngữ khác như là C++, Java vân vân thì có thể sử dụng cái IDE này dùng chung luôn để chia sẻ đỡ nặng máy. Ngoài ra thì một cái tính chất Nữa của Visual Studio Code chính là rất là nhẹ. Bên cạnh đó thì chúng ta sẽ sử dụng một cái môi trường cũng rất là nổi tiếng gần đây đó là Jupyter. Đây là một cái web interface để cho phép chúng ta có thể lập trình Python và nhờ cái web interface thì chúng ta có thể",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 7,
      "start_timestamp": "0:04:44",
      "end_timestamp": "0:05:29"
    }
  },
  {
    "page_content": "và nhờ cái web interface thì chúng ta có thể tương tác nó thuận tiện hơn, trực quan hơn và cũng như chúng ta có thể chia sẻ cái file mã nguồn một cách dễ dàng để cho những cái người khác có thể theo dõi cái số liệu trong quá trình mà mình xử lý tính toán. rất là phổ biến hiện nay nữa đó chính là Colab. Colab là một cái môi trường lập trình được tài trợ bởi Google. Thì chỉ cần chúng ta có tài khoản Gmail thì đều có thể sử dụng và cái giao diện của nó thì cũng tương tự như là Jupyter Notebook tức",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:24",
      "end_timestamp": "0:06:06"
    }
  },
  {
    "page_content": "nó thì cũng tương tự như là Jupyter Notebook tức là các cái file mà chúng ta tương tác nó sẽ giống như là file notebook. Có điều là nó sẽ được lưu trữ online và hoàn toàn miễn phí ở Google. Các cái file notebook này sẽ được lưu trên Google Drive và dễ dàng chia sẻ với nhau. Vậy thì để có thể sử dụng được cái Colab thì chúng ta có thể truy cập vào địa chỉ là colab chấm research.google.com. Và đây sẽ là cái giao diện và đính kèm với cái bài giảng ngày hôm nay thì chúng ta sẽ có hai cái bài tập",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 9,
      "start_timestamp": "0:05:59",
      "end_timestamp": "0:06:44"
    }
  },
  {
    "page_content": "ngày hôm nay thì chúng ta sẽ có hai cái bài tập luyện tập. Ở đây thì chúng ta sẽ được thực hiện vào cuối buổi. Rồi về tài liệu tham khảo thì như đã đề cập ha, chúng ta sẽ có cái trang chủ của Colab và hai cái bài tập luyện tập sử dụng Colab. Ngoài ra thì chúng ta sẽ có các cái cuốn sách như đã liệt kê ở trong cái bìa sách ở đây: Python 101 và Python 201 tương ứng với lại hai cái mức độ, hai cái trình độ khác nhau. Đây là mức độ cơ bản và Đây là mức độ nâng cao hơn.",
    "metadata": {
      "video_url": "https://www.youtube.com/watch?v=_BGaEHA1U6s",
      "filename": "_BGaEHA1U6s",
      "title": "[CS116 -  Lập trình Python cho Máy học] Video 1.2.1: Lập trình Python - Biến và kiểu dữ liệu (P1)",
      "chunk_id": 10,
      "start_timestamp": "0:06:41",
      "end_timestamp": "0:06:44"
    }
  }
]