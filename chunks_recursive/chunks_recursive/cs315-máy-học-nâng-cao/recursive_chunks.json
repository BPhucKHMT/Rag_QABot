[
  {
    "page_content": "Như vậy thì trong phần số 2 này thì chúng ta đã cùng tìm hiểu về những chủ đề sau. Đầu tiên là chúng ta tìm hiểu về maximum likelihood cho cái log của PX. Chúng ta mong muốn có được một mô hình để tạo ra một cái ảnh x giống thật, giống với lại cái Pdata. Thế thì để đạt được cái việc này thì cái likelihood của log P này phải là lớn nhất. Và khi đưa cái log của PX này lên cực đại thì nó sẽ đưa đến một cái giải pháp, đó là chúng ta sẽ đẩy cái chặn dưới của log P. Thì đó chính là cái ELBO là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:06"
    }
  },
  {
    "page_content": "chặn dưới của log P. Thì đó chính là cái ELBO là evidence lower bound. Đẩy cái ELBO này lên, maximum ELBO này lên. Và khi chúng ta maximum ELBO này lên thì chúng ta sẽ có hai cái mô hình, đó là VAE và mô hình diffusion. Và đối với cái mô hình diffusion thì chúng ta sẽ có cái bước gọi là khuếch tán thuận. Và trong cái khuếch tán thuận này thì chúng ta sẽ thêm nhiễu vào cái ảnh của mình. Và ở đây là chúng ta không có tham số để học, không có tham số huấn luyện. Cái điều này nó giúp cho chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 1,
      "start_timestamp": "0:00:58",
      "end_timestamp": "0:01:47"
    }
  },
  {
    "page_content": "số huấn luyện. Cái điều này nó giúp cho chúng ta đơn giản hóa cái việc huấn luyện của cái mô hình diffusion mà chỉ dành cái dư địa để huấn luyện cho cái phần denoising, phần khử nhiễu. Chúng ta chỉ học khử nhiễu và học bằng cả ba cách. Cách đầu tiên đó là chúng ta sẽ tối ưu để sao cho cái x mũ theta xấp xỉ với lại x0. Cách thứ hai đó là chúng ta tối ưu cái epsilon theta sao cho xấp xỉ với lại cái epsilon. Và cách số ba đó là chúng ta sẽ tối ưu để cho cái x mũ theta xấp xỉ với lại cái gradient",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 2,
      "start_timestamp": "0:01:35",
      "end_timestamp": "0:02:38"
    }
  },
  {
    "page_content": "để cho cái x mũ theta xấp xỉ với lại cái gradient của log p theta. Thì đây giống như là cái hướng để khử nhiễu của mình. Thì đây là ba cái cách. Và sau đó thì chúng ta đã tìm hiểu về cách để điều hướng với hai kỹ thuật đó là classifier guidance. Với mỗi một cái condition mới, thì một cái condition chúng ta sẽ ra một cái classifier. Như vậy thì nó sẽ không có linh động trong cái việc là update hoặc là thay cái condition. Chúng ta sẽ có kỹ thuật khác cải tiến đó chính là classifier free guidance.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 3,
      "start_timestamp": "0:02:29",
      "end_timestamp": "0:03:22"
    }
  },
  {
    "page_content": "cải tiến đó chính là classifier free guidance. Tức là chúng ta sẽ bỏ luôn cái classifier này mà chúng ta chỉ đi fine-tune lại cái mô hình diffusion. Chỉ fine-tune lại diffusion, không có dùng thêm cái classifier nào để cho nó có thể là train được từ đầu, fine-tune từ đầu đến cuối. Sau đó chúng ta đã nói qua những cái vấn đề về độ phân giải khi chúng ta làm việc với latent, xin lỗi khi làm việc với diffusion. Và cái kỹ thuật mà cascade diffusion thì nó rất là cồng kềnh. Vì nó phải sử dụng đến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 4,
      "start_timestamp": "0:03:12",
      "end_timestamp": "0:03:54"
    }
  },
  {
    "page_content": "thì nó rất là cồng kềnh. Vì nó phải sử dụng đến hai ba cái mô hình nối tiếp nhau và độc lập nhau. Nó không có end to end, tức là kết nối từ đầu đến cuối. Do đó thì chúng ta có cái mô hình latent diffusion và mở ra một cái hướng nó gọi là end to end diffusion. Thì latent diffusion có thể nói là một trong những cái mô hình mà cho cái impact rất là lớn trong cộng đồng nghiên cứu. Là vì nó đã giúp cho chúng ta tính toán nhanh, rồi cái mô hình của mình đạt được cái độ phân giải rất là cao, chất",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 5,
      "start_timestamp": "0:03:47",
      "end_timestamp": "0:04:30"
    }
  },
  {
    "page_content": "mình đạt được cái độ phân giải rất là cao, chất lượng rất là tốt. Mặc dù là chúng ta chỉ tính trên cái không gian latent chứ không phải tính trên cái không gian ảnh gốc. Sau đó thì chúng ta quan tâm đến cái vấn đề về tốc độ tạo sinh. Thì thay vì chúng ta dùng một cái mô hình probabilistic là ddpm. Ddpm là cái mô hình mà chúng ta đã tìm hiểu trong phần lý thuyết. Thì chúng ta dùng một cái mô hình implicit model sampler để thay vì chúng ta từng bước là từ xt đến xt trừ 1. Hoặc từ xt trừ 1 về xt.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 6,
      "start_timestamp": "0:04:25",
      "end_timestamp": "0:05:16"
    }
  },
  {
    "page_content": "là từ xt đến xt trừ 1. Hoặc từ xt trừ 1 về xt. Hoặc là tính từ xt trừ 1 rồi mới đến xt. Thì chúng ta có thể trực tiếp đi từ x0, từ xt trừ 1 về xt. Hoặc ngược lại là từ x0 đến trực tiếp xt. Thì cái việc này tạo ra một cái công thức mà không phụ thuộc vô một cái yếu tố ngẫu nhiên nào. Dẫn đến là mô hình bỏ qua được các cái bước ở giữa. Progressive distillation, tức là chúng ta tạo ra những cái mô hình student. Hoặc là guided distillation, tức là tạo ra những cái mô hình mà nó đi tắt. Thay vì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 7,
      "start_timestamp": "0:05:10",
      "end_timestamp": "0:05:52"
    }
  },
  {
    "page_content": "là tạo ra những cái mô hình mà nó đi tắt. Thay vì chúng ta đi từng bước từng bước từng bước từng bước. Thì chúng ta sẽ đi tắt như thế này. Đi tắt đến đến mà không qua các cái bước trung gian. Và cái độ chính xác, cái chất lượng của hình ảnh vẫn rất là tốt, tương đương với những trạng thái ban đầu. Và tương tự như vậy cho cái mô hình consistency là có kết hợp với cả Latent Diffusion. Để mà cho cái chất lượng vừa tốt mà tốc độ vừa nhanh, thì trên đây đó là chúng ta đã tổng kết những cái gì đã học",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 8,
      "start_timestamp": "0:05:45",
      "end_timestamp": "0:06:08"
    }
  },
  {
    "page_content": "đó là chúng ta đã tổng kết những cái gì đã học trong phần các mô hình tạo sinh học sâu. Tạm biệt.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=--6FInuIyys",
      "filename": "--6FInuIyys",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết",
      "chunk_id": 9,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với kỹ thuật tái tham số. Đây là một trong những kỹ thuật quan trọng trong mô hình VAE. Một trong những rào cản chính là mô hình VAE không có đơn định mà có yếu tố ngẫu nhiên trong đó, dẫn đến khó khăn cho việc huấn luyện khi sử dụng giải thuật Gradient Descent. Chúng ta sẽ xem đồ thị tính toán của kiến trúc VAE như thế nào. Chúng ta sẽ nhắc lại VAE đó sẽ bao gồm thành phần encoder và decoder. Thì thành phần decoder này nó hoàn toàn tương tự như autoencoder. Và nó có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:18"
    }
  },
  {
    "page_content": "hoàn toàn tương tự như autoencoder. Và nó có thể tính đạo hàm được và thực hiện thuật toán backpropagation khi chúng ta đã tính được cái sai số này rồi. Cái hàm lỗi này rồi thì chúng ta có thể backpropagation được đến các cái bước, các cái trọng số theta của cái decoder này. Nhưng đối với cái quá trình encode thì cái điểm nghẽn của mình nó sẽ nằm ở chỗ này. Điểm nghẽn của mình nó sẽ nằm ở chỗ này. Đó là thao tác sampling và sampling thì đó là một cái thao tác mà trong giải tích nó không có và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:01:10",
      "end_timestamp": "0:01:51"
    }
  },
  {
    "page_content": "cái thao tác mà trong giải tích nó không có và không thể tính đạo hàm được. Nên nó sẽ khiến cho việc huấn luyện gặp khó khăn và ta không thể lan truyền ngược được. Cái gradient qua các cái lớp lấy mẫu chúng ta sẽ lan truyền hàm lỗi về đây, về đây, về đây. Nhưng mà đến đây thì chúng ta sẽ không lan truyền được. Vậy thì bây giờ chúng ta sẽ có những cái giải pháp gì? Đó là chúng ta sẽ tái tham số lớp lấy mẫu. Thì cái lớp lấy mẫu của chúng ta chỉ là cái lớp này. Đây là cái lớp lấy mẫu. Hay là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:01:43",
      "end_timestamp": "0:02:40"
    }
  },
  {
    "page_content": "là cái lớp này. Đây là cái lớp lấy mẫu. Hay là sampling layer. Rồi, nếu như chúng ta giữ nguyên cái công thức đó là z là xấp xỉ, z là sampling theo cái phân bố mi và sigma bình phương. Rồi, thì rõ ràng chúng ta sẽ không có thể tính toán được. Rồi, chúng ta sẽ bỏ đi cái bước lấy mẫu này mà chúng ta sẽ đưa nó về một cái dạng thức khác. Đó là cái dạng thức tái tham số. Thì xét một cái mẫu ẩn vector z, thì trong đó mi và sigma là hai cái vector cố định được chia theo tỷ lệ là hằng số ngẫu nhiên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:02:29",
      "end_timestamp": "0:03:42"
    }
  },
  {
    "page_content": "định được chia theo tỷ lệ là hằng số ngẫu nhiên được rút ra từ phân bố cho trước. Thế thì khi đó, cái việc mà chúng ta lấy mẫu một cái vector z, nếu chúng ta lấy mẫu một cái vector z, xoay xung quanh cái phân bố normal distribution mi và sigma bình, thì nó sẽ tương đương với cái việc chúng ta sẽ lấy mẫu một cái điểm trong cái phân bố là từ mi. Rồi, không một, chúng ta sẽ lấy một cái epsilon. Thì z, ở trong, lấy mẫu z theo cái phân bố Gaussian với tham số là cố định là mi và sigma bình phương,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:03:21",
      "end_timestamp": "0:04:24"
    }
  },
  {
    "page_content": "tham số là cố định là mi và sigma bình phương, thì nó sẽ tương đương với cái việc chúng ta lấy mẫu epsilon theo phân bố chuẩn là 0,1. Và chúng ta sẽ nội suy từ epsilon này ra cái vector z bằng cái công thức như ở đây. z sẽ là bằng mi cộng cho sigma nhân cho epsilon. Trong đó epsilon là một cái biến nhiễu được lấy mẫu xoay xung quanh cái phân bố chuẩn 0,1 này. Thì ở đây chúng ta dùng cái phép nó gọi là element y. Rồi đó, tức là chúng ta sẽ tích từng phần tử. Thì tại sao chúng ta lại dùng element",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:04:16",
      "end_timestamp": "0:05:08"
    }
  },
  {
    "page_content": "phần tử. Thì tại sao chúng ta lại dùng element y? Tại vì mi và sigma đó là những cái vector, ví dụ như là vector d chiều. Sigma cũng là một cái vector d chiều. Thì epsilon của mình nó cũng sẽ thuộc một cái vector d chiều. Đó là một cái vector nhiễu d chiều. Trong đó từng cái chiều của sigma, xe gọi từng cái chiều của epsilon, thì sẽ là một cái vector, là một cái giá trị được sampling theo phân bố chuẩn 0,1. Thì khi chúng ta dùng cái công thức này là z bằng mi cộng cho sigma nhân tích từng phần",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:05:03",
      "end_timestamp": "0:06:05"
    }
  },
  {
    "page_content": "là z bằng mi cộng cho sigma nhân tích từng phần tử với epsilon, thì khi đó expectation của z của chúng ta nó đúng là bằng mi luôn. Và variance của z cũng đúng là bằng sigma. Thì đây chính là cái tính chất mà tái tham số hóa, tức là thay vì chúng ta sử dụng một cái lớp sampling layer là lấy mẫu z theo cái biến, theo cái phân bố Gaussian mi sigma bình, thì chúng ta đi lấy mẫu, đi sampling cái này. Chúng ta sẽ đi sampling epsilon. Còn các giá trị mi và sigma này là cố định, là tất định, được tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:06:01",
      "end_timestamp": "0:06:58"
    }
  },
  {
    "page_content": "và sigma này là cố định, là tất định, được tính toán từ encoder. Thì khi đó là chúng ta sẽ không có bị cái hiện tượng gọi là lan truyền ngược, nó không có đi được. Thì tại sao? Ở đây chúng ta sẽ có một cái hình ví dụ minh họa, đó là từ cái phi và x, thì chúng ta sẽ tính ra được hai cái giá trị mi và sigma. Chúng ta sẽ tính ra được mi và sigma. Với mi và sigma này, chúng ta sẽ sampling cái vector z. Để từ vector z này chúng ta sẽ đi tiếp cái hàm decode. Đây là cái hàm decode để tạo, để tái tạo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:06:54",
      "end_timestamp": "0:07:50"
    }
  },
  {
    "page_content": "decode. Đây là cái hàm decode để tạo, để tái tạo x1. Vậy cái vector z này được thực hiện với phép sampling. Đây là một phép không tính đạo hàm được. Do đó khi chúng ta thực hiện thuật toán lan truyền ngược từ phía trên xuống, đến cái bước này nó sẽ gặp một stochastic node, tức là một node ngẫu nhiên, có yếu tố ngẫu nhiên. Thì nó sẽ không lan truyền về đây để cập nhật cái phi được. Nó không huấn luyện được. Trong khi đó, nếu như chúng ta tái tham số lại cái lớp lấy mẫu, thì ở đây chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:07:41",
      "end_timestamp": "0:08:21"
    }
  },
  {
    "page_content": "số lại cái lớp lấy mẫu, thì ở đây chúng ta sẽ sampling cái z epsilon tuân theo phân bố 0,1. Thì cái node epsilon này là một stochastic node. Nhưng nó là một cái giá trị và nó không phải đi cập nhật, nó sẽ không có đi cái bước lùi về sau nữa. Đây là cái node cuối cùng rồi. Nên nó sẽ không ảnh hưởng gì đến cái quá trình huấn luyện của mình. Cái quá trình huấn luyện của mình đó là khi chúng ta tính được cái loss ở phía trên, chúng ta lan truyền xuống, và đến đây thì chúng ta gặp cái z. Và z này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:08:18",
      "end_timestamp": "0:08:57"
    }
  },
  {
    "page_content": "và đến đây thì chúng ta gặp cái z. Và z này thì hoàn toàn là một cái node deterministic, tức là một cái node tất định, tức là không có yếu tố ngẫu nhiên. Nó sẽ được tính từ mi và sigma, được tính toán từ phi và x. Qua cái bước encode, chúng ta sẽ có được một cái cặp mi và sigma cố định. Còn epsilon ở đây là một cái giá trị chúng ta truyền vào z. Thì có cái giá trị này, chúng ta nhân với mi, chúng ta nhân với sigma, và sau đó cộng với mi thì nó sẽ ra một node tương đương. Với cái việc là z của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:08:53",
      "end_timestamp": "0:09:39"
    }
  },
  {
    "page_content": "sẽ ra một node tương đương. Với cái việc là z của mình tuân theo một cái phân bố là Gaussian. Tuân theo cái phân bố Gaussian. Thì vì cái node này là tất định, là deterministic, nên khi chúng ta lan truyền ngược về, rồi chúng ta lại lan truyền ngược về đây, để đi tính cái đạo hàm theo cái tham số phi, thì khi đó chúng ta sẽ huấn luyện được. Học là cập nhật lại được cái tham số của mô hình. Còn cái bước này là chúng ta sẽ không có đi qua đây được, là vì nó bị chặn bởi cái node stochastic này. Như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:09:36",
      "end_timestamp": "0:10:18"
    }
  },
  {
    "page_content": "là vì nó bị chặn bởi cái node stochastic này. Như vậy thì chúng ta tóm tắt cái kiến trúc VAE, là Variational Autoencoder. VAE một cái nhiệm vụ của nó đó là biểu diễn dữ liệu thật. Đây là dữ liệu thật. Vào một cái không gian ẩn để huấn luyện, tức là x sẽ được biểu diễn bởi một cái vector z. Cái thứ 2, đó là chúng ta sẽ tái tạo lại cái dữ liệu này thông qua học không giám sát, tức là chúng ta không cần có cái nhãn, thì là nhờ học không giám sát. Thì tại sao chúng ta có thể tái tạo lại được? Thì z",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 13,
      "start_timestamp": "0:10:15",
      "end_timestamp": "0:11:09"
    }
  },
  {
    "page_content": "tại sao chúng ta có thể tái tạo lại được? Thì z qua cái decoder nó sẽ tạo ra cái x mũ, và chúng ta sẽ lấy cái x mũ này, chúng ta đi so sánh với lại x, rồi sau đó chúng ta tính cái sai số, và chúng ta sẽ tìm cách đi minimize cái này, đi tìm min cái sai số này, đó là tái tạo lại thông qua học không giám sát. Cái thứ 3 đó là thủ thuật tham số hóa, thủ thuật tái tham số hoặc là tham số hóa, để huấn luyện cái mô hình dựa trên gradient. Thì cái bước sampling ở đây, cái sampling ở đây là một cái thao",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 14,
      "start_timestamp": "0:11:06",
      "end_timestamp": "0:11:48"
    }
  },
  {
    "page_content": "ở đây, cái sampling ở đây là một cái thao tác mà không có đạo hàm, không tính đạo hàm được. Nên chúng ta sẽ lấy mẫu một cái biến epsilon theo phân bố là 0,1, sau đó chúng ta sẽ tạo ra vector z bằng cách lấy epsilon, đi nhân với lại sigma, rồi sau đó cộng với mi để ra được cái vector z, thì khi chúng ta huấn luyện, chúng ta lan truyền cái sai số đến z này, thì chúng ta lại tiếp tục lan truyền ngược vào đây, trước chúng ta không có đi qua con đường này. Tại vì epsilon là một cái giá trị mà mình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 15,
      "start_timestamp": "0:11:44",
      "end_timestamp": "0:12:22"
    }
  },
  {
    "page_content": "này. Tại vì epsilon là một cái giá trị mà mình lấy mẫu ngẫu nhiên và nó không có cái tham số gì để học ở đây, nên chúng ta không có đi qua con đường này, mà chúng ta sẽ đi qua cái đường encode. Cái thứ tư, đó là nó giải thích các cái biến tiềm ẩn bằng cách là sử dụng nhiễu, tức là trong cái không gian tiềm ẩn của mình. Một cái hình ảnh khi chúng ta ánh xạ vào cái không gian latent, thì nó sẽ ra một cái phân bố, và cái phân bố này chúng ta hoàn toàn là ngẫu nhiên, thì chúng ta sẽ random một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 16,
      "start_timestamp": "0:12:19",
      "end_timestamp": "0:13:00"
    }
  },
  {
    "page_content": "là ngẫu nhiên, thì chúng ta sẽ random một cái vector z, theo cái phân bố này, từ cái vector z này chúng ta khôi phục ngược trở lại, thì nó sẽ tạo ra cái mối quan hệ của chúng ta, và chúng ta sẽ dùng nó để làm cái phân bố này, để khôi phục ngược trở lại, thì nó sẽ tạo ra cái mối quan hệ giữa không gian tiềm ẩn và cái không gian ảnh thật, nhưng đồng thời nó vẫn đảm bảo được cái yếu tố đó là khi chúng ta có một cái vector z phải ở đây, thì chúng ta gần với lại vector z thì decode ra nó cũng ra con",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 17,
      "start_timestamp": "0:12:57",
      "end_timestamp": "0:13:36"
    }
  },
  {
    "page_content": "gần với lại vector z thì decode ra nó cũng ra con số gần giống con số 3, và nó sẽ là một cái công cụ để giúp cho chúng ta có thể tạo được cái mẫu dữ liệu mới, nghĩa là sao? khi chúng ta đã huấn luyện xong cái mô hình, thì chúng ta sẽ không cần có cái bước encode nữa, mà chúng ta sẽ sampling ngẫu nhiên một cái vector z, và từ đó chúng ta gọi cái hàm decode, để chúng ta tạo ra một cái tấm ảnh, và cái ảnh này qua cái variational autoencoder, thì nó sẽ tạo ra được một cái tấm hình mà nó có cái ý",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 18,
      "start_timestamp": "0:13:32",
      "end_timestamp": "0:13:49"
    }
  },
  {
    "page_content": "nó sẽ tạo ra được một cái tấm hình mà nó có cái ý nghĩa, nó sẽ không bị cái điểm yếu của autoencoder, nó sẽ có những cái khoảng trống mà nó không tạo ra được một cái dữ liệu để có ý nghĩa, thì cái phần này chúng ta sẽ làm trong cái phần bài thực hành, để hiểu hơn là một cái vector z ngẫu nhiên trong không gian latent, khi chúng ta decode, nó ra một cái giá trị có nghĩa và một cái giá trị không có nghĩa như thế nào? Hãy subscribe cho kênh Ghiền Mì Gõ để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-2bJ_8EO9ZE",
      "filename": "-2bJ_8EO9ZE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 4",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng tìm hiểu về sự tiến hóa của các mô hình dạng chuỗi, tức là cụ thể cho các mô hình kiểu như văn bản, có yếu tố thứ tự. Trong hồi trước, chúng ta tìm hiểu về mô hình của mạng CNN liên quan đến loại dữ liệu đó là có yếu tố không gian, là không gian của ảnh bao gồm là chiều cao và chiều ngang. Đối với mô hình dạng chuỗi, nó sẽ có một số đặc thù, đó là dữ liệu phụ thuộc theo 1 chiều, đối với dữ liệu về hình ảnh thì nó phụ thuộc 2 chiều. Vậy thì chúng ta sẽ bắt đầu với mạng Neural",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:12"
    }
  },
  {
    "page_content": "Vậy thì chúng ta sẽ bắt đầu với mạng Neural Network. Vấn đề đối với mạng Neural Network khi chúng ta áp dụng vào dữ liệu văn bản đó là vì dữ liệu văn bản là một loại dữ liệu đặc biệt mà nó có độ dài là không cố định. Trong khi đó chúng ta biết là trong một cái mạng Neural Network thì cái đầu vào của chúng ta là có số lượng Neural là cố định. Cái số lượng Neural này là cố định. Ví dụ chúng ta có một cái 2 cái tình huống đó là tuyệt quá là chúng ta chỉ có 2 giá trị, 2 từ trong khi cái đầu vào của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:54",
      "end_timestamp": "0:01:55"
    }
  },
  {
    "page_content": "chỉ có 2 giá trị, 2 từ trong khi cái đầu vào của chúng ta có đến 4 Neural. Rồi bầu trời xanh và nắng vàng óng ánh, ví dụ vậy thì nó sẽ có nhiều hơn 4 từ. Thì cái việc này nó khiến cho cái việc chúng ta sử dụng cái mạng Neural Network để phục vụ cho các bài toán bên xử lý ngôn ngữ tự nhiên là trở nên không khả thi. Thế thì đâu đó cũng sẽ có một số giải pháp để giải quyết cái tình huống này, đó là chúng ta có thể sử dụng cái vector là Bag-of-Words. Tức là Bag-of-Words nó sẽ biến mọi câu, mọi văn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:37",
      "end_timestamp": "0:02:31"
    }
  },
  {
    "page_content": "Tức là Bag-of-Words nó sẽ biến mọi câu, mọi văn bản thành một cái vector cố định về số chiều. Tức là cái số chiều của mình là cố định. Thì khi đó chúng ta map cái số chiều này vào cái input này thì nó sẽ giúp cho chúng ta không có bị vấn đề là sự chênh lệch về kích thước của dữ liệu đầu vào. Tuy nhiên nếu chúng ta dùng cái phương pháp Bag-of-Words thì nó lại không quan tâm đến cái yếu tố thứ tự của từ. Tức là từ Do you, cái câu là Do you understand? Với lại you do understand? Thì nếu biểu diễn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:17",
      "end_timestamp": "0:03:12"
    }
  },
  {
    "page_content": "Với lại you do understand? Thì nếu biểu diễn bằng cái phương pháp Bag-of-Words thì hai cái câu này có cái vector giống nhau. Cái từ Do nó bật lên, từ you bật lên, đây là từ Do, đây là từ understanding. Tại vì cái thứ tự của từ điển của mình mình sẽ không biết trước ha. Có thể là sắp theo thứ tự alpha, rồi từ you. Thế thì cả hai cái câu Do you understand và you do understand thì đều có chung một cái vector biểu diễn, đó là những cái vị trí của từ Do từ you và từ understand sẽ bật lên là 1, còn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:53",
      "end_timestamp": "0:03:51"
    }
  },
  {
    "page_content": "Do từ you và từ understand sẽ bật lên là 1, còn những vị trí còn lại sẽ để là 0. Nhưng mà cách làm này rõ ràng là không phù hợp vì cái câu Do you understand? Đây là bản chất là một cái câu hỏi. Còn you do understand? Đó là bản chất là một câu trả lời. Hoặc là cái câu khẳng định. Đây là cái câu khẳng định. Thì dẫn đến đó là khác nhau hoàn toàn về mặt ngữ nghĩa. Thì ở đây chúng ta sẽ thấy là nếu từ Do đặt trước từ you thì đó sẽ là câu hỏi. Nhưng mà từ Do đặt sau từ you thì nó lại là câu khẳng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:38",
      "end_timestamp": "0:04:42"
    }
  },
  {
    "page_content": "mà từ Do đặt sau từ you thì nó lại là câu khẳng định. Vậy thì mạng Recurrent Neural Network nếu chúng ta dùng một cách cơ bản như thế này thì hoàn toàn không thể giúp chúng ta mã hóa được và biểu diễn được đầy đủ cái ngôn ngữ của mình. Do đó thì chúng ta sẽ có kiến trúc ANN. ANN thì nó sẽ encode cái thứ tự của các từ thông qua cái dấu mũi tên từ trái sang phải như thế này. Ý nghĩa của cái việc ANN mã hóa thứ tự này đó là gì? Tại cái thời điểm t, chúng ta đưa vào một cái từ thứ t thì đến cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:29",
      "end_timestamp": "0:05:16"
    }
  },
  {
    "page_content": "t, chúng ta đưa vào một cái từ thứ t thì đến cái node hidden ở giữa đây, nó sẽ nhận thông tin của quá khứ. ST chính là cái thông tin của quá khứ. Nó chứa cái thông tin của cái từ ST trừ 1 trước đó. Như vậy thì với cái dấu mũi tên này nó sẽ xử lý, nó sẽ nhận đầu vào là có cả thông tin của quá khứ lẫn thông tin của hiện tại. Nhưng cái thông tin của cái từ hiện tại sẽ được có cái tín hiệu nó nhiều hơn, nó sẽ thể hiện được là nó đến sau. Còn cái ST trừ 1 nó sẽ chứa cái thông tin của từ ST trừ 1.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:04:55",
      "end_timestamp": "0:06:06"
    }
  },
  {
    "page_content": "trừ 1 nó sẽ chứa cái thông tin của từ ST trừ 1. Nhưng mà vì nó đến sau nên cái số thao tác biến đổi trên ST trừ 1 của mình nó rất là nhiều. Thì cái lượng thông tin của nó sẽ bị mất mát. Vậy thì đây chính là cái cách mà ANN đã encode cái thứ tự thông qua cái trình tự thực hiện các phép biến đổi. Thế thì chi tiết cái nội dung tính toán của mình đó là gì? Thì tại cái thời điểm thứ t thì chúng ta sẽ tính bước số 1. Đó là chúng ta sẽ lấy thông tin của quá khứ. Đây là thông tin của quá khứ. Kết hợp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:53",
      "end_timestamp": "0:06:52"
    }
  },
  {
    "page_content": "quá khứ. Đây là thông tin của quá khứ. Kết hợp với lại cái thông tin của hiện tại để chúng ta có một cái thông tin đầy đủ vừa có quá khứ vừa có hiện tại. Tức là chúng ta đang tính cái ST ở đây. Và hai ma trận U và W, mục đích của nó đó là đưa cái vector ST và ST trừ 1 là ở hai cái không gian khác nhau về cùng một không gian. Vậy W và U sẽ giúp ST và cái thông tin quá khứ ST trừ 1 về cùng một không gian để mà chúng ta tính toán. Và khi ST đã được trộn cái thông tin của cả quá khứ và hiện tại thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:38",
      "end_timestamp": "0:08:09"
    }
  },
  {
    "page_content": "trộn cái thông tin của cả quá khứ và hiện tại thì chúng ta sẽ tiến đến cái bước số 2. Đó là chúng ta sẽ bắt đầu decode. Chúng ta sẽ đi tính cái giá trị dự đoán. Đó là y ngã t. Y ngã t được tính trực tiếp từ ST. Thì công thức của mình cũng rất đơn giản. Đó là softmax của V nhân ST. Bản chất của V này đó là ánh xạ hoặc là chuyển từ cái không gian của cái lớp hidden này về cái không gian của cái output. Thì ở đây chúng ta sẽ có 3 cái tham số đó là U, W và V. Thì 3 cái tham số này chúng ta để ý là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:07:53",
      "end_timestamp": "0:08:51"
    }
  },
  {
    "page_content": "U, W và V. Thì 3 cái tham số này chúng ta để ý là nó xuất hiện trên tất cả các cái giá trị thời gian. Tức là 3 cái giá trị U, V, W này là chia sẻ trọng số. V, W là share parameter. Vậy là cho dù cái văn bản của chúng ta có dài như thế nào đi chăng nữa thì nó vẫn dùng cùng một cái bộ tham số U, V, W. Thì cái ANN đó là một cái mô hình mà nó có đa tác vụ cho lĩnh vực về NLP. Tại sao gọi là đa tác vụ? Tại vì với một cái kiến trúc của ANN chúng ta có thể giải quyết rất nhiều những cái bài toán khác",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:08:33",
      "end_timestamp": "0:09:46"
    }
  },
  {
    "page_content": "thể giải quyết rất nhiều những cái bài toán khác nhau trong lĩnh vực xử lý ngôn ngữ tự nhiên. Ví dụ, 1 to 1, tức là từ một cái từ đầu vào chúng ta sẽ tạo ra một cái từ đầu ra. Và đây có thể dùng trong cái lĩnh vực ví dụ như là dịch từ, rồi 1 to many. Ví dụ như chúng ta có cho trước một cái từ này là cái chủ đề. Cái chủ đề của một cái bài thơ chẳng hạn và output của chúng ta sẽ là bài thơ. Many to 1 thì một cái ứng dụng khá là phổ biến và kinh điển. Đó chính là sentiment analysis, tức là phân",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:09:10",
      "end_timestamp": "0:10:14"
    }
  },
  {
    "page_content": "điển. Đó chính là sentiment analysis, tức là phân loại cảm xúc văn bản. Đầu vào của chúng ta sẽ là một cái văn bản. Và đầu ra sẽ cho biết là cái sentiment của nó là gì? Là positive hay là negative hay là neutral? Và cái tình huống phía sau đó là many to many thì nó sẽ có hai dạng dạng 1 và dạng 2. Cả hai dạng này thì ứng dụng trong thực tế cũng rất là nhiều. Ví dụ như chúng ta nhận cái dữ liệu đầu vào sau đó chúng ta sẽ trả lời. Thì đây là cái ứng dụng trong lĩnh vực về chatbot. Hoặc là lĩnh",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:09:58",
      "end_timestamp": "0:10:51"
    }
  },
  {
    "page_content": "ứng dụng trong lĩnh vực về chatbot. Hoặc là lĩnh vực về dịch máy. Hoặc là về lĩnh vực, ví dụ như tóm tắt văn bản. Thì cái many to many dạng 1 có rất nhiều những cái ứng dụng hiện đại. Many to many dạng 2 tức là nó khác biệt so với dạng 1 đó là đối với dạng 1 chúng ta phải xem hết toàn bộ input xong đó chúng ta mới đi trả lời. Còn many to many dạng 2 thì chúng ta chỉ... chúng ta nhận được đến đâu thì chúng ta sẽ ra cái output trên đó. Nhận đến đâu và ra output trên đó thì có thể dùng trong cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:10:39",
      "end_timestamp": "0:11:39"
    }
  },
  {
    "page_content": "và ra output trên đó thì có thể dùng trong cái bài toán là part-of-speech hoặc là gán nhãn từ loại. Vì cái slide này chúng ta có thể thấy đó là ANN nó có tính đa tác vụ rất là cao. Nó có thể áp dụng cho rất nhiều những cái thể loại bài toán khác nhau của lĩnh vực ANN. Bây giờ chúng ta sẽ đến cái kiến trúc của các biến thể của mạng ANN thì ở bên trái đó là một cái dạng biểu diễn dạng node như thế này là một cái ô tròn. Nhưng mà để hình dung nó ở góc độ là vector thì chúng ta sẽ dùng cái dạng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:11:22",
      "end_timestamp": "0:12:17"
    }
  },
  {
    "page_content": "ở góc độ là vector thì chúng ta sẽ dùng cái dạng biểu diễn bên tay phải. Ví dụ cái từ đ thì nó sẽ có cái vector embedding tương ứng của nó và chúng ta sẽ encode nó thành một cái từ s, s1. Thì cái s1 của mình nó sẽ là một cái vector biểu diễn tương tự như vậy. Movie, thông qua cái vector embedding của từ Movie chúng ta sẽ tính toán để tạo ra cái vector s2, cứ như vậy cho đến s5. Cái cách biểu diễn này nó sẽ hình dung được, giúp chúng ta hình dung được cái dạng vector biểu diễn của các trạng thái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:12:06",
      "end_timestamp": "0:12:54"
    }
  },
  {
    "page_content": "được cái dạng vector biểu diễn của các trạng thái ẩn trong mạng ANN. Còn cách bên phải ở đây thì nó sẽ cho chúng ta thấy được cái quy trình đi từ đâu đến đâu. Nhưng mà nó sẽ khiến chúng ta nhầm lẫn rằng là đây là một cái giá trị scalar. Thực tế không phải, nó sẽ phải là một cái vector. Thế thì chúng ta sẽ cùng đến với cái biến thể đầu tiên, đó là Bi-directional ANN. Thì cái vấn đề của các cái mạng ANN trước đây đó là gì? Đó là ANN chỉ đọc dữ liệu một chiều. Ví dụ chúng ta có The Movie World",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": "0:12:43",
      "end_timestamp": "0:13:27"
    }
  },
  {
    "page_content": "liệu một chiều. Ví dụ chúng ta có The Movie World terribly, thì nếu như chúng ta đọc đến cái chữ terribly, thì cái từ này nó sẽ mang cái ý nghĩa đó là negative. Nó sẽ mang cái ý nghĩa là negative. Và nó mang cái nghĩa negative này thì nó sẽ truyền ra cái output, thì ở đây nó sẽ mang cái giá trị là negative. Nhưng để mà biết được cái ý nghĩa thực sự của nó là positive hay negative thì chúng ta phải nhìn thấy được cái từ phía sau. Đó là terribly exciting, tức là cái bộ phim này thì rất là hào",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": "0:13:13",
      "end_timestamp": "0:14:12"
    }
  },
  {
    "page_content": "exciting, tức là cái bộ phim này thì rất là hào hứng một cách khủng khiếp. Hoặc là chúng ta hay nói là cái bộ phim này là hay khủng khiếp. Thì cái từ khủng khiếp nếu bắt đầu chúng ta nghe thì nó sẽ là tiêu cực nhưng mà có thêm cái từ hay thì nó sẽ là tích cực. Ở đây cũng hoàn toàn tương tự. Cái từ exciting này là một cái nghĩa tích cực. Nhưng nó lại xuất hiện sau cái từ terribly dẫn đến là chúng ta không thấy được cái từ này để đưa ra cái nhận định là terribly này là tích cực hay tiêu cực. Do",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 19,
      "start_timestamp": "0:13:58",
      "end_timestamp": "0:14:45"
    }
  },
  {
    "page_content": "định là terribly này là tích cực hay tiêu cực. Do đó thì khi chúng ta đi từ trái sang phải thì cái từ terribly này tự thân nó được hiểu là nghĩa tiêu cực. Do đó thì cái việc nhìn một chiều này sẽ khiến chúng ta đưa ra cái output nó không có toàn diện. Do đó thì cần có cái ngữ cảnh để đọc từ bên phải. Tức là chúng ta cần phải có cái thông tin ngữ cảnh của các từ bên phải để bổ trợ thêm cho cái từ ở bên trái. Do đó thì chúng ta sẽ có một cái bước nữa, nó sẽ có một cái module nữa để duyệt theo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 20,
      "start_timestamp": "0:14:32",
      "end_timestamp": "0:15:20"
    }
  },
  {
    "page_content": "nữa, nó sẽ có một cái module nữa để duyệt theo chiều ngược lại. Vậy thì cái biến thể Bi-directional ANN thì cái phần màu xanh là đi theo chiều thuận. Còn cái B St là từ trái sang phải. Còn cái phần màu cam thì ở đây có thể là do chúng ta dùng màu sắc nó bị đảo ngược. Màu xanh sẽ là từ trái sang phải, màu cam sẽ là từ phải sang trái. Vậy thì hai cái màu này đang đảo ngược. Chúng ta chỉ cần để ý vào cái sơ đồ ở đây. Khi chúng ta có được cái thông tin tại một cái từ nhưng mà đọc từ trái sang phải",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 21,
      "start_timestamp": "0:15:02",
      "end_timestamp": "0:15:55"
    }
  },
  {
    "page_content": "tin tại một cái từ nhưng mà đọc từ trái sang phải và từ phải sang trái. Ví dụ cái từ worst này đi, cái từ terribly này đi. Thì nó đã có được đầy đủ thông tin. Nó sẽ có cái thông tin khi chúng ta đọc từ trái sang và đồng thời và cái vector màu cam này nó sẽ có được thông tin khi chúng ta đọc từ phải sang. Thì cái từ terribly này sẽ thấy được cái từ exciting ở phía trước. Và khi chúng ta concatenate hai cái vector này lại với nhau thì cái vector này nó sẽ có cái tính đầy đủ toàn diện hơn. Và khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 22,
      "start_timestamp": "0:15:41",
      "end_timestamp": "0:16:27"
    }
  },
  {
    "page_content": "nó sẽ có cái tính đầy đủ toàn diện hơn. Và khi đó thì nó sẽ tạo ra cái output của mình nó sẽ chuẩn xác hơn. Thì đây chính là cái biến thể Bi-directional ANN. Chúng ta sẽ cùng đến với cái biến thể tiếp theo đó là DeepStack ANN. Vấn đề ở đây đó là gì? Để mà có cái DeepStack ANN. Vấn đề đó là ANN. Cho đến bây giờ thì bản chất nó chỉ là một, nó chưa phải là một cái mô hình thật sự là sâu. Cái sâu ở đây là nó mới chỉ sâu theo cái trục thời gian là đi theo cái trục này. Khi cái văn bản của mình ngắn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 23,
      "start_timestamp": "0:16:18",
      "end_timestamp": "0:17:13"
    }
  },
  {
    "page_content": "theo cái trục này. Khi cái văn bản của mình ngắn thì nó không sâu nhưng mà khi văn bản của mình nó dài, những cái đoạn văn bản dài thì đó là một cái mô hình sâu theo trục thời gian. Nhưng nếu xét về yếu tố đặc trưng thì cái đặc trưng này vẫn là một cái đặc trưng thấp, đặc trưng thấp thấp. Hay nó cách khác đó là đặc trưng đơn giản. Nó không thể giúp chúng ta giải quyết được các bài toán phức tạp. Do đó chúng ta cần có một cái nhu cầu, đó là tăng cái độ sâu theo cái trục đứng như thế này. Thì để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 24,
      "start_timestamp": "0:17:01",
      "end_timestamp": "0:18:06"
    }
  },
  {
    "page_content": "cái độ sâu theo cái trục đứng như thế này. Thì để làm chuyện đó chúng ta sẽ dùng cái kiến trúc đó là DeepStack chúng ta sẽ trồng nhiều lớp lên với nhau. Ở đây là layer 1, layer 2 và layer 3, nó được trồng lên nhau. Và với mỗi cái layer thì chúng ta sẽ tổng hợp được cái thông tin đặc trưng ở một cái cấp độ. Ví dụ như ở đây sẽ là low level feature, đây là mid level feature, đây là low và đây sẽ là high level feature. Thì khi đến cái đặc trưng ở trên tầng số 3 thì nó cũng giống như cái mạng CNN",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 25,
      "start_timestamp": "0:17:57",
      "end_timestamp": "0:19:09"
    }
  },
  {
    "page_content": "trên tầng số 3 thì nó cũng giống như cái mạng CNN của một xử lý ảnh. Đó là đặc trưng của mình đã có cái tính chất gọi là đặc trưng phức tạp hơn, phi tuyến tính hơn. Thì hy vọng là nó giúp chúng ta giải quyết được cái bài toán khó. Thì như vậy khi chúng ta trồng các layer lên thì chúng ta sẽ có cái trạng thái ẩn từ lớp thứ y. Thì SI sẽ là đầu vào cho cái layer thứ y cộng 1, như vậy cái trạng thái ẩn của layer thứ y chính là cái SI. Nó sẽ là cái input để đi tính cái SI cộng 1. Thì layer số 1 nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 26,
      "start_timestamp": "0:18:48",
      "end_timestamp": "0:19:43"
    }
  },
  {
    "page_content": "input để đi tính cái SI cộng 1. Thì layer số 1 nó sẽ truyền lên layer số 2, rồi lên layer số 3. Thì đó là cái ý nghĩa. Và chúng ta sẽ có cái công thức ở layer số 1 là S1 là ở đây. Và ở đây, ví dụ như là S1 tại vị trí T, thì nó sẽ được tính toán giống như một cái ANN bình thường. Nó cũng sẽ nhận vào cái thông tin của quá khứ tại cái tầng thứ 1. Nó nhận thông tin từ đây sang. Rồi kết hợp với thông tin tại cái thời điểm XT hiện tại để tổng hợp ra cái S1T. Sau đó chúng ta sẽ đi tính S2T. Nó sẽ tổng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 27,
      "start_timestamp": "0:19:37",
      "end_timestamp": "0:20:16"
    }
  },
  {
    "page_content": "S1T. Sau đó chúng ta sẽ đi tính S2T. Nó sẽ tổng hợp thông tin từ 2 phía. Thứ nhất là từ quá khứ. Nhưng mà quá khứ tại cái tầng thứ 2, tức là ST-1-2. Sau đó nó sẽ tổng hợp, nó sẽ nhận cái thông tin từ ST1, S1T từ dưới lên. Tức là layer số 2 sẽ được tính toán từ layer thứ 1. Đây chính là chúng ta đang tạo ra một đặc trưng mới. Một đặc trưng tổng hợp mới từ cái lớp phía trước đó. Tương tự như vậy, từ S2T, chúng ta sẽ đi tính S3T. Và đồng thời nó sẽ còn có kết hợp thông tin của S3T-1 ở phía trước",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 28,
      "start_timestamp": "0:20:05",
      "end_timestamp": "0:20:56"
    }
  },
  {
    "page_content": "còn có kết hợp thông tin của S3T-1 ở phía trước là thông tin của quá khứ, ở tầng thứ 3. Như vậy thì đây chính là công thức và kiến trúc của DeepStack ANN. Trong một số tài liệu người ta luôn khuyến nghị, đó là chúng ta nên sử dụng DeepStack nhưng mà không nên dùng quá nhiều. Ví dụ như là chúng ta dùng từ 2 cho đến khoảng 4 lớp là vừa đủ. Còn chưa có nhiều tài liệu nói là khi chúng ta dùng thêm nhiều hơn nữa, ví dụ như là hàng chục hoặc hàng trăm lớp. Thường là từ 2 cho đến 4 lớp. Riêng trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "lớp. Thường là từ 2 cho đến 4 lớp. Riêng trong Transformer thì có thể là với dữ liệu phức tạp hơn, bài toán thách thức hơn, thì có thể là số lớp của mình sẽ cao hơn. Thế thì chúng ta đã học về Bi-directional và DeepStack, do đó chúng ta cũng sẽ có một hỗn hợp của hai biến thể này. Đó là vừa Bi-directional, tức là đi theo chiều từ trái sang phải, nhưng đồng thời cũng sẽ có chiều đi từ phải sang trái, thông qua dấu mũi tên nét đứt này. Và nó sẽ stack lên nhiều tầng, thì đây sẽ là layer 1, đây là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "lên nhiều tầng, thì đây sẽ là layer 1, đây là layer 2 và đây là layer 3. Nó sẽ kết hợp vừa 2 chiều và vừa DeepStack để tận dụng được thế mạnh của từng cái biến thể của mình. Đó là thứ nhất, đọc được nhiều chiều, cái thứ 2, đặc trưng của mình sẽ phân cấp tốt hơn, có nhiều thông tin hơn. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=-7JWQptLoMQ",
      "filename": "-7JWQptLoMQ",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)",
      "chunk_id": 31,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Mô hình ngôn ngữ thì giá tiếp theo mà chúng ta sẽ cùng tìm hiểu đó chính là SIM Do Microsoft phát triển, nhưng SAM là mô hình của Meta SIM có một cách đi khác, đó là họ dựa trên cách thức để tương tác với ảnh cho tiện hơn Cách thức để tương tác có rất nhiều cách 1 là dùng dạng điểm là Point 2 là Bounding Box 3 là Mask 4 là Scribble và thậm chí là đương nhiên nó vẫn sẽ Support cho việc dùng Text Prompt Thế thì chúng ta sẽ đến phần phát triển bài toán Nếu như mô hình trước đây là Grounding DINO x",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:08"
    }
  },
  {
    "page_content": "Nếu như mô hình trước đây là Grounding DINO x SAM thì nó đạt được độ chính xác tốt Đặc biệt là nhờ SAM được huấn luyện dựa trên các tập dữ liệu lên đến là hàng tỷ ảnh Thì sự đa dạng của hình ảnh sẽ giúp SAM phân đoạn được rất chính xác Nhưng việc này khá là cồng kềnh do nó phải kết hợp 2 mô hình lại với nhau đó là Grounding DINO và SAM mà nó không phải huấn luyện 1 mô hình từ đầu đến cuối Có mô hình nào chúng ta có thể segment từ Text tốt hơn mà không cần phải chạy SAM hay không Đại như đã nói,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:01:02",
      "end_timestamp": "0:01:51"
    }
  },
  {
    "page_content": "không cần phải chạy SAM hay không Đại như đã nói, việc kết hợp 2 mô hình Grounding DINO với SAM sẽ tạo ra sự cồng kềnh không đáng có Thế thì chúng ta sẽ có mô hình SIM đó là Segment Everything Everywhere At Once Và trên đây đó là một vài ví dụ về kết quả được thực hiện bởi SIM Đầu vào chúng ta có thể là không có Prompt hoặc Visual Prompt Ví dụ như là một điểm Bounding Box hoặc là một Scribble Và nó có thể là một câu Text Prompt Ví dụ như là PersonInBlue hoặc là một dạng Referred Prompt Ví dụ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:43",
      "end_timestamp": "0:02:42"
    }
  },
  {
    "page_content": "hoặc là một dạng Referred Prompt Ví dụ như là kết hợp giữa Scribble với tấm ảnh Ví dụ, ở đây chúng ta đưa vào một ảnh mẫu của một đối tượng là con mèo Sau đó chúng ta sẽ để Scribble này hàm ý đó là chúng ta sẽ segment những đối tượng nào mà có dạng thức giống như đối tượng này Thế thì khi chúng ta Inferring thì chúng ta phải khoanh vùng cả Doraemon Đó là cũng là một con mèo máy và con mèo ở đây Thế thì kiểu Referred Prompt là một kiểu khá là thú vị Tại vì nhiều khi chúng ta không biết đối tượng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:02:35",
      "end_timestamp": "0:03:42"
    }
  },
  {
    "page_content": "vị Tại vì nhiều khi chúng ta không biết đối tượng đó là gì thì làm sao chúng ta có thể viết được Prompt Cái này dùng khi chúng ta không biết đối tượng của mình là gì Tên là gì Đó chính là dụng ý của tại sao chúng ta lại phải sử dụng Scribble kết hợp với ảnh mẫu, ảnh hàm chiếu Cuối cùng đó chính là Composition, tức là nó có thể phối hợp giữa hai đối tượng, ba đối tượng với nhau Nó là một cái đường như thế này Và nó sẽ có thêm kèm một cái văn bản nữa, đó là cái Largest Bear, tức là con gấu lớn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:03:30",
      "end_timestamp": "0:04:18"
    }
  },
  {
    "page_content": "nữa, đó là cái Largest Bear, tức là con gấu lớn nhất trong con gấu ở đây Thì đây là một cái kiểu mà rất là phức tạp, cái dạng Prompt rất là phức tạp Và điểm đến của SIM có lẽ là tạo ra các thể thức tương tác tương tự như là GPT-4V Đó chính là sức phát triển động cơ về cách thức tương tác của SIM Trong sơ đồ này chúng ta sẽ thấy, đó là cái mô hình này, thứ nhất là nó được trained end-to-end Tức là nó sẽ không có cái bước kết hợp với lại mô hình SAM Cái thứ hai là nó có rất nhiều những cái thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:04:07",
      "end_timestamp": "0:05:22"
    }
  },
  {
    "page_content": "SAM Cái thứ hai là nó có rất nhiều những cái thể thức khác nhau Trong đó có cái thể thức là dạng Visual, dạng Visual Prompt, ví dụ như là một cái đường do người dùng vẽ tự do Rồi Scribble là một cái đường ngoằn ngoèo, có chứa cái đối tượng cần quan tâm Bounding Box Point Và đầu vào thì chúng ta sẽ còn có text encoder và image encoder tương ứng cho cái Text Prompt dạng văn bản Và ảnh sẽ là trạng tham chiếu Thế thì đối với Visual Prompt thì chúng ta sẽ qua một cái module, đó là Visual Sampler Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:05:11",
      "end_timestamp": "0:06:09"
    }
  },
  {
    "page_content": "sẽ qua một cái module, đó là Visual Sampler Thì mục tiêu của Visual Sampler đó là mọi Visual Prompt sẽ được đưa về cùng một định dạng thống nhất Đó là chúng ta sẽ đưa về các cái Token, Feature Embedding của các cái Token Và ý tưởng đó là từ một Visual Prompt, ví dụ như là Scribble, chúng ta kết hợp với lại image feature Tại vì chúng ta sẽ cần có sự tương tác với không gian ảnh để chúng ta lấy ra đối tượng mà chúng ta cần quan tâm Thì cái image feature là từ cái module màu tím này kết hợp với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:06:01",
      "end_timestamp": "0:06:39"
    }
  },
  {
    "page_content": "feature là từ cái module màu tím này kết hợp với lại Visual Prompt Qua cái module Mask Pooling để chúng ta nội suy ra cái Token của mình Thì cái module Visual Prompt sẽ thực hiện tại cái vị trí mà người dùng vẽ hoặc là click hoặc là cái vùng bên trong cái Bounding Box của mình Thì đây chính là những cái phương thức tương tác khác hoàn toàn so với lại những cái phương pháp thông thường Thông thường thì người ta chỉ tương tác là Bounding Box hoặc là Point thôi Còn bây giờ lại có thể là ở dạng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:06:32",
      "end_timestamp": "0:07:26"
    }
  },
  {
    "page_content": "là Point thôi Còn bây giờ lại có thể là ở dạng Scribble, dạng Composite, tức là dạng phức hợp hoặc là Referring Image Rồi thì dựa vào cái Mask và các cái đặc trưng tương ứng với ảnh thì chúng ta sẽ trích xuất ra các cái đặc trưng và chúng ta sẽ nội suy ra thành 512 Token Thì đây là 512 Token Được trích ra từ đặc trưng ảnh và cái Scribble ở đây Ở cái bước tiếp theo đó là chúng ta sẽ tương tác giữa các cái loại Query với nhau Thì tương tự như các cái mô hình hiện đại như là SAM hoặc là DETR thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:07:17",
      "end_timestamp": "0:08:15"
    }
  },
  {
    "page_content": "cái mô hình hiện đại như là SAM hoặc là DETR thì chúng ta sẽ có một cái Learnable Query Bản chất ở đây sẽ là một cái Tensor có thể huấn luyện được Thì cái Learnable Query này nó sẽ tạo ra các cái Query mà có thể đến từ những cái đối tượng có trong tấm ảnh Và sau đó thì nó sẽ duplicate, tức là nó sẽ nhân bản cái Learnable Query này để cho cái Object Query, Text Query và Visual Query Thì cái Visual Query này nó sẽ đến từ các cái phần liên quan đến cái Visual Prompt Còn Text Query thì nó đến từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:08:08",
      "end_timestamp": "0:09:01"
    }
  },
  {
    "page_content": "cái Visual Prompt Còn Text Query thì nó đến từ Text Prompt Còn Object Query thì nó có thể đến từ các cái Memory Prompt, có thể đến từ các cái đối tượng mà được mô tả bên trong tấm ảnh của mình Rồi, thì Object Query nó sẽ tương tác cái Attention, nó sẽ tương tác thông qua cái phép biến đổi Attention Với chính nó, tức là nó sẽ tương tác trong nội bộ của nó và với các cái đặc trưng ảnh trong tấm ảnh của mình Rồi Text Query thì nó sẽ bổ sung thêm cái Text Prompt trong lúc huấn luyện Thì Text Prompt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:08:56",
      "end_timestamp": "0:09:53"
    }
  },
  {
    "page_content": "Text Prompt trong lúc huấn luyện Thì Text Prompt ở đây, nó sẽ bổ sung thêm vào trong Text Query khi huấn luyện Và cái Text Prompt này thì nó tương ứng là những cái Query dạng văn bản, dạng câu mô tả của người dùng Rồi, đối với cái Visual Query thì nó sẽ có cái sự kết hợp cả Visual Prompt, tức là những cái Prompt mà ở dạng Point, dạng Bounding Box hoặc là dạng Scribble v.v. Rồi nó kết hợp với Memory Prompt thì Memory Prompt là những cái quá khứ chat hoặc là tương tác với lại cái hệ thống này của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:09:45",
      "end_timestamp": "0:10:24"
    }
  },
  {
    "page_content": "hoặc là tương tác với lại cái hệ thống này của mình Thì một vài cái tương tác có thể xảy ra mà không cần huấn luyện, đó là tạo nên sự đa dạng về tác vụ có thể chạy Ví dụ như từ Text Prompt, chúng ta có thể tạo ra các cái Visual Query Và từ Visual Prompt thì chúng ta có thể tạo ra các Text Query, thì đó chính là sự đa dạng về tác vụ có thể chạy được của cái mô hình này Và dựa trên đây thì đó là một vài cái hình ảnh kết quả khi chúng ta chạy với SIM Thì chúng ta thấy khi chúng ta chấm cái điểm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 13,
      "start_timestamp": "0:10:20",
      "end_timestamp": "0:11:06"
    }
  },
  {
    "page_content": "SIM Thì chúng ta thấy khi chúng ta chấm cái điểm này thì SIM đã khoanh vùng chính xác cái con báo ở đây Vì chúng ta thấy khi chúng ta chấm cái điểm này thì nó đã khoanh vùng chính xác cái thuyền Tương tự như vậy cho Scribble thì nó sẽ khoanh vùng được cái vùng Building Vậy thì điều gì ở SIM nó đã vượt trội hơn so với SIM? Thì đó chính là SIM nó có thể hoạt động tốt ở nhiều cái loại ảnh khác nhau Đó một phần đến từ cái việc dữ liệu của nó là rất là đa dạng Ví dụ hình ở đây là ảnh Painting, tức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 14,
      "start_timestamp": "0:10:58",
      "end_timestamp": "0:11:49"
    }
  },
  {
    "page_content": "là đa dạng Ví dụ hình ở đây là ảnh Painting, tức là ảnh tranh vẽ Rồi ảnh ở đây là ảnh ở thế giới thực, ảnh ở đây là ảnh đã được xử lý bằng các công cụ xử lý ảnh Rồi ảnh bên đây là ảnh ở trong cái màn hình của game mô phỏng Thì cái sự đa dạng này tạo ra sự khác biệt giữa SIM đối với lại SIM Ngoài ra một cái điểm đặc biệt nữa của SIM so với SIM đó chính là cái Referring Segmentation Thì như chúng ta biết có những cái nội dung mà chúng ta không thể dùng lời để mô tả được thì chúng ta có thể dùng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 15,
      "start_timestamp": "0:11:44",
      "end_timestamp": "0:12:25"
    }
  },
  {
    "page_content": "dùng lời để mô tả được thì chúng ta có thể dùng cái ảnh ví dụ Thì cái Referring Image chúng ta sẽ kết hợp thêm cái Point này là cái điểm Thì hàm ý đó là chúng ta đang muốn truy vấn cái đối tượng là cái con voi Thì khi chúng ta đưa cái Referring Image kết hợp với lại cái Prompt này thì nó sẽ segment được các cái đối tượng có cái nhãn, có cái class tương tự Thì đây chính là cái kết quả của mình khi sử dụng cái Referring Image Ở bên dưới thì đó là Referring Image nhưng mà nó sử dụng cái Scribble",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 16,
      "start_timestamp": "0:12:23",
      "end_timestamp": "0:12:59"
    }
  },
  {
    "page_content": "Referring Image nhưng mà nó sử dụng cái Scribble tức là hàm ý là lấy cái con sông và Output của mình thì nó cũng đã khoanh vùng và chính xác được cái con sông ở trong cái tấm ảnh của mình Thì đây rõ ràng là một cái ưu điểm khác, một cái thể thức tương tác khác biệt giữa SIM với lại Segmentation à với lại SIM Và đặc biệt đó là SIM có thể làm việc tốt được trên cái dữ liệu hình ảnh hạ lẫn video Thì trong cái ví dụ này chúng ta thấy là cái con chó đã được khoanh vùng trên cái dữ liệu video khá là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "đã được khoanh vùng trên cái dữ liệu video khá là mượt mà Tương tự như vậy cái vũ công ballet cũng hoạt động rất là tốt Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=088gBBCryJI",
      "filename": "088gBBCryJI",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 2",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Lan truyền ngược Lan truyền ngược là một trong những thuật toán rất phổ biến trong các mô hình học dựa trên Gradient Và trong đó có rất nhiều mô hình hiện đại như Deep Learning, học sâu Chi tiết thuật toán Backpropagation vận hành như thế nào, chúng ta sẽ cùng tìm hiểu trong những chương sau Đầu tiên chúng ta sẽ nhắc lại về mô hình dựa trên Gradient Trong mô hình dựa trên Gradient, chúng ta phải tính toán giá trị dự đoán là y ngã Y ngã trong trường hợp này chính là bằng fθx Và mình mong muốn là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:58"
    }
  },
  {
    "page_content": "hợp này chính là bằng fθx Và mình mong muốn là cho giá trị dự đoán xấp xỉ với giá trị thực tế Thế thì có 3 công việc cần phải làm, chúng ta đang tập trung vào công việc cuối cùng Đối với công việc tìm tham số tối ưu của mô hình, tức là tìm theta sao sao cho hàm lỗi này là nhỏ nhất Trong hồi trước chúng ta đã nói có một số thuật toán để tìm cái điện tối ưu Cụ thể đó là Stochastic Gradient Descent, Momentum, Root Mean Square Propagation và Adam Thế thì chúng ta sẽ cùng ôn lại các thuật toán này,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:01:40"
    }
  },
  {
    "page_content": "thì chúng ta sẽ cùng ôn lại các thuật toán này, thì nó sẽ có những điểm đặc điểm gì chung Chúng ta thấy là cả 3 thuật toán giữa Momentum, Root Mean Square Propagation và Adam Điểm chung đó là các thao tác phức tạp nhất được tính trên Gradient Nghĩa là ở đây chúng ta thấy có rất nhiều các bước thực hiện, nhưng các bước này đều rất là đơn giản Đó chỉ đơn giản là gán giá trị và cộng trừ nhân chia Nhưng mà riêng cái thao tác phức tạp nhất của cả 3 thuật toán ở trên đó chính là tính đạo hàm Đây là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 2,
      "start_timestamp": "0:01:34",
      "end_timestamp": "0:02:16"
    }
  },
  {
    "page_content": "thuật toán ở trên đó chính là tính đạo hàm Đây là tính đạo hàm, và đây là tính đạo hàm Thế thì tại sao cái việc tính Gradient là khó, thì chúng ta sẽ có một số lý do sau Đầu tiên đó là các hàm lỗi của mình, cái hàm Tri Theta của mình Thường là những hàm rất phức tạp, vì nó có chứa cả hàm mô hình Fthx lẫn hàm để tính sai số giữa dự đoán và giá trị thực tế Hay rất khác, đó là cái hàm Tri Theta của mình, nó sẽ là một cái hàm hợp Hàm hợp tức là một cái hàm của rất nhiều những hàm thành phần bên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 3,
      "start_timestamp": "0:02:09",
      "end_timestamp": "0:03:04"
    }
  },
  {
    "page_content": "cái hàm của rất nhiều những hàm thành phần bên trong Trong đó là bao gồm Fthx và cái sai số, và cái hàm để tính sai số Rồi lý do thứ 2 đó là cái mô hình của mình, thì nó không phải là một cái mô hình, là một cái hàm đơn biến mà nó có thể chứa rất nhiều tham số Ví dụ Theta của mình, nó không phải là một giá trị Scalar, nó không phải là một cái biến đơn mà nó có thể chứa rất nhiều cái biến bên trong Bao gồm là Theta1, Theta2, ThetaN Thì đây là một cái hàm lỗi của mình, nó sẽ là một cái hàm đa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 4,
      "start_timestamp": "0:02:53",
      "end_timestamp": "0:03:41"
    }
  },
  {
    "page_content": "một cái hàm lỗi của mình, nó sẽ là một cái hàm đa biến theo Theta Thì dưới đây sẽ là một số cái ví dụ Ctheta của mình, nó có thể là bằng một phần một cộng cho E mũ trừ ThetaX Chúng ta lưu ý rằng là đây là cái thao tác thực hiện là nhân ma trận, nhân giữa vector và ma trận Vector hoặc là ma trận Hoặc nó cũng có thể là một cái hàm lồng trong hàm phức tạp như thế này Một chia cho một cộng E mũ rồi lại trừ cho Theta chia cho một cộng E mũ, một cộng ThetaX Thì đây là một vài cái ví dụ Vậy thì công",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 5,
      "start_timestamp": "0:03:34",
      "end_timestamp": "0:04:28"
    }
  },
  {
    "page_content": "ThetaX Thì đây là một vài cái ví dụ Vậy thì công việc của chúng ta đó là làm sao chúng ta tính được đạo hàm của cái hàm này Và lưu ý là đây mới chỉ là những hàm tương đối cơ bản đơn giản, chưa thực sự phức tạp Trong các mô hình học sâu, ví dụ như chúng ta có những cái hàm Fx mà nó có thể là chứa F1 của F2, của F thứ 100X Tức là nó có chứa 100 cái hàm thành phần Các mô hình học sâu là cực kỳ phức tạp, do đó thì những hàm ở đây cũng chưa thực sự là quá phức tạp Mà nó cũng đã khiến chúng ta đổ mồ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 6,
      "start_timestamp": "0:04:14",
      "end_timestamp": "0:05:07"
    }
  },
  {
    "page_content": "quá phức tạp Mà nó cũng đã khiến chúng ta đổ mồ hôi hột để làm sao có thể tính toán được cái gradient, tức là đạo hàm cho cái vector Vậy thì chúng ta sẽ nhắc lại cái kiến thức cũ của phổ thông và phòng giải tích 1 trong học kỳ 1 của lớp của đại học Đó là chúng ta sẽ sử dụng cái đạo hàm của hàm hợp, công thức đạo hàm của hàm hợp Với cái công cụ đó là quy tắc chuỗi hay còn gọi là chain rule Thì ở đây chúng ta sẽ dùng cái chain rule để cho nó đồng bộ với các tài liệu viết bằng tiếng Anh Và trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 7,
      "start_timestamp": "0:05:02",
      "end_timestamp": "0:05:48"
    }
  },
  {
    "page_content": "bộ với các tài liệu viết bằng tiếng Anh Và trong rất nhiều tài liệu thì họ vẫn dùng cái từ là chain rule Vì việc sử dụng cái quy tắc chuỗi để tính đạo hàm của hàm hợp, đó là 1 trong những cái quy tắc cơ bản Thì chúng ta nhắc lại, đó là ký hiệu hàm hợp fx là bằng fn, fn-1, v.v.v cho đến f1, tức là cái hàm này gồm có n hàm thành phần Và với n hàm thành phần này thì chúng ta dùng cái hệ thống ký hiệu của phổ thông, tức là fx Nhưng mà trong cái chương trình của cái môn máy học nâng cao thì chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 8,
      "start_timestamp": "0:05:41",
      "end_timestamp": "0:06:22"
    }
  },
  {
    "page_content": "trình của cái môn máy học nâng cao thì chúng ta sử dụng cái hệ thống ký hiệu đó là g và theta Thì nó cũng hoàn toàn tương tự như là fx Bình thường chúng ta sẽ ghi là g của theta Còn chúng ta dùng cái ký hiệu của fx để cho nó gần gũi với lại toán phổ thông để cho các bạn dễ theo dõi trước Sau đó chúng ta sẽ áp dụng vào cái ký hiệu của các mô hình máy học sau, đó là g theta Chúng ta sẽ dùng cái hệ thống này sau Thì quy tắc của tính chain rule đó là gì? Đó là đạo hàm của f theo x Thì sẽ được tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 9,
      "start_timestamp": "0:06:19",
      "end_timestamp": "0:07:11"
    }
  },
  {
    "page_content": "gì? Đó là đạo hàm của f theo x Thì sẽ được tính bằng đạo hàm của f thứ n theo f thứ n-1 Tức là chúng ta xem fn-1 giống như là một biến, nó không phải là một hàm mà nó là một biến Thì chúng ta sẽ tính đạo hàm của fn theo fn-1 Rồi nhân đạo hàm của fn-1 theo fn-2 Rồi cho đến đạo hàm fn-2 Đạo hàm 2 theo đạo hàm f1 và đạo hàm f1 theo x Thì chúng ta thấy là cái công thức này nhìn rất là phức tạp Lý do đó là vì có rất nhiều hệ thống ký hiệu và với rất nhiều hàm thành phần Vậy thì chúng ta sẽ có một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 10,
      "start_timestamp": "0:07:05",
      "end_timestamp": "0:08:09"
    }
  },
  {
    "page_content": "nhiều hàm thành phần Vậy thì chúng ta sẽ có một cái mẹo để nhớ cái quy tắc này Đó là nếu như chúng ta dùng cái dấu gạch này Thì là fd của fn-1 thì ở phía sau đó trên tử sẽ là dfn-1 và chúng ta thấy là nó sẽ khử nhau Tử là có dfn-1, mẫu là có dfn-1, nó sẽ khử nhau Rồi mẫu có dfn-2 thì ở phía sau đó sẽ là dfn-2 Tiếp tục cứ như vậy, ở đây là tử có dfn-1 và mẫu có dfn-1, nó sẽ khử Vậy còn lại là gì? Chúng ta sẽ còn lại là dfn-dx, tức là đạo hàm của f theo x Thì đây là một cái quy tắc để nhớ thôi Đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 11,
      "start_timestamp": "0:07:58",
      "end_timestamp": "0:08:51"
    }
  },
  {
    "page_content": "theo x Thì đây là một cái quy tắc để nhớ thôi Đó là dfn-1, sau đó là n-1, n-2, n-2, n-3, rồi v.v.v cho đến f2 theo f1 và f1 theo x Thì x sẽ là cái biến số của mình, nó sẽ nằm ở cuối cùng ở đây Thì chúng ta sẽ xét một cái ví dụ cho đơn giản và trực quan Ví dụ như fx, iz là bằng x cộng i, tất cả nhân với z Thì ở đây giả sử như chúng ta xem xét là, chúng ta tại một thời điểm thì chúng ta chỉ xét với một biến x Tức là tất cả những cái hàm ở trên đây sẽ được đưa về cái hàm chỉ có một biến thôi Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 12,
      "start_timestamp": "0:08:45",
      "end_timestamp": "0:09:43"
    }
  },
  {
    "page_content": "sẽ được đưa về cái hàm chỉ có một biến thôi Thì đặt cái công việc đầu tiên chúng ta phải tính toán, đó là cái việc tính x cộng i Đây là cái thao tác đầu tiên chúng ta tính, thì đây sẽ là biểu diễn bởi hàm f1 Sau khi chúng ta tính cái f1 là x cộng i xong, thì chúng ta sẽ lại nhân với z, thì đây sẽ là hàm f2 Nhưng ở đây chúng ta sẽ xét trên một biến x trước, thì f1x sẽ là bằng x cộng i Sau đó chúng ta lại lấy f1 nhân với z để ra f2 Như vậy công thức của f2 mà theo cái biến x thì nó sẽ là bằng f1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 13,
      "start_timestamp": "00:09:34",
      "end_timestamp": "0:10:32"
    }
  },
  {
    "page_content": "của f2 mà theo cái biến x thì nó sẽ là bằng f1 nhân với z Nhưng mà trong trường hợp này, f1 của chúng ta chính là cái biến số của mình Thì khi đó, fx của mình, cái công thức fx ban đầu của mình sẽ là bằng f2 của f1x Khi chúng ta thế vào, thì f2 chính là z nhân x Do đó, f2 của f1x sẽ là bằng z nhân cho xx, trong trường hợp này chính là f1 F1 chúng ta sẽ thế vào bằng công thức này, đó là x cộng i Rồi, khi đó thì đạo hàm của f1 theo x, lưu ý là ở đây chúng ta chỉ đang xét với một biến x thôi Chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 14,
      "start_timestamp": "0:10:25",
      "end_timestamp": "0:11:22"
    }
  },
  {
    "page_content": "chúng ta chỉ đang xét với một biến x thôi Chúng ta sẽ làm cái việc tương tự, cái việc này tương tự cho biến i, chúng ta sẽ làm sao Đạo hàm của f1 theo x, thì đạo hàm của f1 theo x chính là trong công mắc của x, thì i chính là hằng số Do đó đạo hàm của f1 theo x chính là 1 Rồi, đạo hàm của f2 theo f1 là bao nhiêu? Đạo hàm của f2 theo f1, tức là chúng ta sẽ tính đạo hàm của cái này theo x Chúng ta sẽ tính đạo hàm của cái này theo x, thì trong biến x, thì z chính là hằng số do đó đạo hàm của cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 15,
      "start_timestamp": "0:11:15",
      "end_timestamp": "0:12:09"
    }
  },
  {
    "page_content": "x, thì z chính là hằng số do đó đạo hàm của cái này sẽ là bằng z Đạo hàm của f2 theo f1 chính là z Rồi, như vậy thì chúng ta sẽ sử dụng, áp dụng cái công thức chain rule là d của f theo x sẽ là bằng df2 theo f1 Sau đó df1 theo x, thì df2 theo f1 chính là z, nguyên cái cọp này sẽ là z Và df1 theo x chính là 1 Như vậy z nhân 1 chính là bằng z, như vậy đạo hàm của f theo x sẽ là bằng z Hoàn toàn tương tự cho i và z, chúng ta sẽ làm cái công việc này cho đạo hàm của f theo i và đạo hàm của f theo z",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 16,
      "start_timestamp": "0:12:02",
      "end_timestamp": "0:13:20"
    }
  },
  {
    "page_content": "cho đạo hàm của f theo i và đạo hàm của f theo z Thì đối với biến i Vì chúng ta có nhiều biến nên tại một thời điểm chúng ta chỉ xem xét một biến thôi Thì công việc đầu tiên chúng ta sẽ tính toán, đó là phép cộng ở đây Thì f1 của ta, bây giờ nó không phải là biến x nữa mà sẽ là biến theo i, thì nó vẫn sẽ là bằng x cộng i Và f2 của mình theo biến i thì nó cũng sẽ là bằng giá trị f1 nhân với z Và f1 theo nhân với z như vậy sẽ là z nhân với i Tại vì trong trường hợp này f1 của mình sẽ là biến số,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 17,
      "start_timestamp": "0:13:09",
      "end_timestamp": "0:14:19"
    }
  },
  {
    "page_content": "trong trường hợp này f1 của mình sẽ là biến số, f1 của mình sẽ là biến số Như vậy thì f2 i là bằng z i Và khi đó thì công thức f của i sẽ là bằng f2 của f1 của i Thì x cộng i là x cộng i Rồi, f2 của f1 là z nhân với i Thay là z nhân với lại cái f1 này Mà f1 của mình là x cộng i Tức là khi chúng ta triển khai ở đây thì f1 i chính là chúng ta xem nó như là một cái biến Rồi chúng ta triển khai vô thì nó sẽ là z nhân với lại cái biến Tức là z nhân với f1, mà f1 thì nó lại là bằng x cộng i Rồi, khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 18,
      "start_timestamp": "0:14:16",
      "end_timestamp": "0:15:12"
    }
  },
  {
    "page_content": "f1, mà f1 thì nó lại là bằng x cộng i Rồi, khi đó chúng ta sẽ tính đạo hàm Đạo hàm là d của f1 theo i D của f1 theo i thì nó sẽ là bằng 1 Tại trong có mắt của i thì x là bằng hằng số D của f2 theo f1 Tức là đạo hàm của công thức này Và đạo hàm của công thức này là bằng z Rồi, như vậy thì chúng ta sẽ có đạo hàm của f theo biến i Chính là bằng đạo hàm của f2 theo f1 Nhân cho đạo hàm của f1 theo i Vì f2 theo f1 chính là bằng z Và df1 theo i chính là bằng 1, không bằng z Tương tự như vậy chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 19,
      "start_timestamp": "0:14:58",
      "end_timestamp": "0:15:43"
    }
  },
  {
    "page_content": "là bằng 1, không bằng z Tương tự như vậy chúng ta sẽ tính cho đạo hàm của f theo z Thì chúng ta thấy là cái cách làm này, Chain Rule này thì nó sẽ rất là bài bảng và có thể tổng quát hóa được Và bây giờ chúng ta sẽ tìm cách biểu diễn cái công thức của cái fx, iz này dưới dạng là biểu đồ, đồ thị tính toán Như sau, đầu vào chúng ta sẽ có x, y và z Bước đầu tiên chúng ta sẽ thực hiện là lấy x, y, đây là toán tử cộng Và đầu ra của mình sẽ là hàm f1 Sau đó chúng ta lấy cái z này đem nhân với cái f1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 20,
      "start_timestamp": "0:15:37",
      "end_timestamp": "0:16:27"
    }
  },
  {
    "page_content": "Sau đó chúng ta lấy cái z này đem nhân với cái f1 để ra cái f2, thì đây chính là cái hàm f của mình Rồi, thì đây là cái cách biểu diễn dưới dạng đồ thị tính toán Trong đó mỗi một cái node tính toán sẽ là một toán tử và đầu vào nó sẽ nhận các cái biến số Thế thì chúng ta sẽ đến với một trong những thuật toán đầu tiên, đó chính là thuật toán Feed Forward Tức là trước khi thực hiện Backpropagation, Backpropagation là lan truyền nghịch Thì chúng ta sẽ phải làm cái thuật toán lan truyền thuận, tức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 21,
      "start_timestamp": "0:16:20",
      "end_timestamp": "0:17:02"
    }
  },
  {
    "page_content": "sẽ phải làm cái thuật toán lan truyền thuận, tức là chúng ta sẽ đi tính cái giá trị của hàm f trước Dựa trên cái đồ thị tính toán, thì giả sử ở đây chúng ta vẫn sử dụng các cái hàm như đã nêu ở trên Thì x, x nó sẽ là bằng f2 của f1, x thì đầu tiên ta sẽ xây dựng cái đồ thị tính toán Rồi sau đó chúng ta sẽ tính giá trị tại các cái node, biết rằng là chúng ta sẽ chọn ra một cái bộ giá trị x, y, z khởi tạo ban đầu Đây chính là cái giá trị khởi tạo Và chúng ta sẽ đi tính đạo hàm tại cái giá trị x",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 22,
      "start_timestamp": "0:16:56",
      "end_timestamp": "0:17:35"
    }
  },
  {
    "page_content": "Và chúng ta sẽ đi tính đạo hàm tại cái giá trị x bằng 3, y bằng trừ 4 và z bằng 5 Đầu tiên đó là chúng ta sẽ xây dựng cái đồ thị tính toán, giống như ở trong slide trước, thì đây chính là đồ thị tính toán Và chúng ta sẽ có các cái node là node cộng, rồi node nhân Sau đó chúng ta sẽ lần lượt thay các cái giá trị này vào các cái node, thì x là bằng 3, y là bằng trừ 4 và z là bằng 5 Sau đó chúng ta cứ lần lượt lan truyền thuận lên, lan truyền thuận về phía trước Đầu tiên đó là thực hiện phép cộng,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 23,
      "start_timestamp": "0:17:25",
      "end_timestamp": "0:17:35"
    }
  },
  {
    "page_content": "về phía trước Đầu tiên đó là thực hiện phép cộng, thì f1 bước này nó sẽ là bằng 3 cộng cho trừ 4, thì nó sẽ là bằng trừ 1 Sau khi chúng ta đã tính f1 xong, thì chúng ta sẽ thực hiện cái node phép nhân Thì f2 nó sẽ là bằng f1 nhân với trừ 5, tức là f1 nhân với 5, tức là bằng trừ 1 nhân với 5 là bằng trừ 5 Như vậy thì cái thuật toán lan truyền thuận đó là một cái thuật toán quan trọng để giúp chúng ta xây dựng cái đồ thị tính toán Cái bước quan trọng đầu tiên đó là xây dựng được cái đồ thị tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "đầu tiên đó là xây dựng được cái đồ thị tính toán Là một cái bước tiền đề quan trọng trước khi chúng ta có thể tính được cái đạo hàm của hàm f theo các cái biến x này, các cái biến x, x, y, z này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=0PqzYo2Z-20",
      "filename": "0PqzYo2Z-20",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với phần cài đặt minh họa cho học tương phản Contrasted Mini Đây là một kỹ thuật được sử dụng trong huấn luyện với Moon Clip Với dụng minh họa này, hình này là lấy từ paper gốc của Moon Clip Và trong sơ đồ này, chúng ta thấy là một văn bản của mình Thì qua text encoder, chúng ta có thể sử dụng class retrain model Nhưng mà để cho đơn giản, với cài đặt, chúng ta tập trung nhiều vào phần học tương phản Nên ở đây chúng ta sẽ sử dụng dữ liệu mô phỏng, đó là một random vector Và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:03"
    }
  },
  {
    "page_content": "dụng dữ liệu mô phỏng, đó là một random vector Và tương tự như vậy cho dữ liệu ảnh, chúng ta cũng sẽ sử dụng random vector Thể hiện ở trong hai cái hàm pos.random Và như vậy chúng ta sẽ tiến hành các bước thực hiện với contrasted learning này Đó là chúng ta sẽ có một bước từ vector mô phỏng chúng ta sẽ chuẩn hóa để tạo ra các vector T1, T2, T3 cho đến Tn này Với mỗi t, nó sẽ là một embedding cho một văn bản Còn với một ảnh y1, y2 v.v., nó sẽ là một vector biểu diễn cho một ảnh Trong cái ví dụ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 1,
      "start_timestamp": "0:00:58",
      "end_timestamp": "0:02:00"
    }
  },
  {
    "page_content": "một vector biểu diễn cho một ảnh Trong cái ví dụ này chúng ta thấy nó có tất cả là n ảnh Thì ở đây chúng ta sẽ có n chính là số lượng cặp hình ảnh văn bản Trong một batch dữ liệu mà chúng ta ném đi để huấn luyện Và mỗi một vector này y1, t1, in, tn Biểu diễn bằng một vector có kích thước là d D là bằng 8, để tạo ra ma trận y Vì tức là embedding của ảnh y1 cho đến in Thì chúng ta sẽ tạo torch.random n như d Trong đó n là số ảnh và d chính là số chiều của mỗi vector biểu diễn Thì nếu đúng ra thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 2,
      "start_timestamp": "0:01:53",
      "end_timestamp": "0:02:57"
    }
  },
  {
    "page_content": "của mỗi vector biểu diễn Thì nếu đúng ra thì nó sẽ lấy từ một pretrained model Và chúng ta feed qua n ảnh Nhưng ở đây để cho đơn giản thì chúng ta tạo ra vector ngẫu nhiên Sau đó thì tương tự như vậy thì te Nếu đúng là te nó sẽ phải tương đồng với ire Tức là embedding của ảnh nó sẽ tương đồng với ire Tuy nhiên ở đây chúng ta mong muốn là không phải sử dụng các dữ liệu thật Nếu chúng ta sử dụng chính te này là i luôn Thì ma trận này sẽ tiến về một ma trận đơn vị Nhưng mà vì chúng ta muốn nó có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 3,
      "start_timestamp": "0:02:52",
      "end_timestamp": "0:03:56"
    }
  },
  {
    "page_content": "ma trận đơn vị Nhưng mà vì chúng ta muốn nó có cái tương chất gọi là ngẫu nhiên Và không có sự tương đồng một cách tuyệt đối Nên ở đây chúng ta sẽ cộng thêm một cái đại lượng nhiễu để cho tạo ra sự sai khác giữa ảnh và văn bản đủ nhỏ Sau đó thì chúng ta sẽ tiến hành chuẩn hóa hai vector này Thì để chuẩn hóa thì chúng ta phải viết thêm một cái hàm Đó là hàm norm L2 Thế thì ở đây chúng ta sẽ cài đặt to-do này Đó là L2Norm Rồi, thì ở đây chúng ta sẽ def và chúng ta sẽ truyền vào một cái vector V",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 4,
      "start_timestamp": "0:03:38",
      "end_timestamp": "0:05:09"
    }
  },
  {
    "page_content": "sẽ def và chúng ta sẽ truyền vào một cái vector V Về đây chúng ta để lại vector đây Sau đó Vector sẽ là bằng Vector chia cho norm của norm L2 Rồi, thì ở đây nếu chúng ta chuẩn hóa trên full toàn bộ với mỗi một vector như thế này thì mọi chuyện là đơn giản rồi Nhưng mà ở đây vì chúng ta đưa vector vào nó không phải là một vector mà nó là một cái ma trận Te và E Mà chúng ta đang muốn lấy theo một cái trục là theo trục của N Tức là với mỗi một cái dữ liệu thì chúng ta sẽ đi chuẩn hóa trên cái trục",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 5,
      "start_timestamp": "0:04:53",
      "end_timestamp": "0:05:59"
    }
  },
  {
    "page_content": "liệu thì chúng ta sẽ đi chuẩn hóa trên cái trục của đặc trưng thôi Tức là cái trục D này thôi Do đó thì ở đây chúng ta sẽ để lại cái dimension là bằng trừ 1 Rồi, thì nó sẽ đi chuẩn hóa theo cái trục D này Rồi, ngoài ra thì chúng ta sẽ không có thay đổi số chiều do đó ở đây chúng ta sẽ để keepDim là bằng True Thì đây chính là cái hàm chuẩn hóa L2 và chúng ta sẽ đặt hàm này cho cái biến là Te và sẽ gán ngược trở lại là Te Rồi tương tự như vậy là Ea cũng sẽ là gán ngược trở lại cho Ea tức là Image",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 6,
      "start_timestamp": "0:05:47",
      "end_timestamp": "0:06:48"
    }
  },
  {
    "page_content": "cũng sẽ là gán ngược trở lại cho Ea tức là Image Embedding Tiếp theo thì chúng ta sẽ đi tính cái Logit bằng cách đó là tích vô hướng Tạm thời là chúng ta sẽ không có dùng cái Temperature Chúng ta sẽ để Te. Thì ở đây chúng ta có thể dùng hàm dot vào dot hoặc là chúng ta sử dụng hàm của torch đó là .matmul Rồi, và chúng ta sẽ truyền là Ea và Te Rồi, thì sau khi chúng ta xử lý xong thì chúng ta sẽ ra được một cái Logit Tức là cái kết quả của cái phép nhân tích vô hướng giữa hai cái ma trận Thực ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 7,
      "start_timestamp": "0:06:42",
      "end_timestamp": "0:07:43"
    }
  },
  {
    "page_content": "nhân tích vô hướng giữa hai cái ma trận Thực ra là ma trận là chúng ta đang xử lý hàng loạt Còn đúng ra thì nó sẽ là xử lý cho từng cái cặp vector 1 với nhau Và ở đây chúng ta chú ý là khi chúng ta để đảm bảo được cái việc nhân tích vô hướng thì cái Te này nó sẽ phải chuyển vị Tại vì ban đầu cái Te và Ea đều cùng có kích thước là Nd Muốn nhân được với nhau thì cái Te là Nd, thì phải nhân, cái Ea là Nd Thì nhân với lại cái Te nó sẽ là Dn, tức là cái ma trận kích thước là Nd Sẽ nhân với cái ma",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 8,
      "start_timestamp": "0:07:37",
      "end_timestamp": "0:08:33"
    }
  },
  {
    "page_content": "cái ma trận kích thước là Nd Sẽ nhân với cái ma trận là Dn Đó là lý do tại sao chúng ta phải chuyển vị Và đầu ra của mình nó sẽ trả về là một cái ma trận kích thước là Nd Thì đúng như trong cái sơ đồ này là kích thước của mình sẽ là N, nhân cho N Rồi, và chút nữa chúng ta cũng sẽ thử nghiệm xem khi chúng ta thêm tô vô thì nó sẽ như thế nào Rồi bây giờ chúng ta sẽ kết nối với lại cái máy Thì thật ra ở đây chúng ta cũng không cần phải có overview do là chúng ta tính toán dữ liệu cũng không có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 9,
      "start_timestamp": "0:08:27",
      "end_timestamp": "0:09:25"
    }
  },
  {
    "page_content": "do là chúng ta tính toán dữ liệu cũng không có nặng Rồi, torch initialize thì ở đây chắc là chúng ta chưa chạy cái lệnh này March, ở đây chắc là dư một cái dấu Rồi, bây giờ chúng ta sẽ chạy lại cái code này Và sau khi chúng ta trực quan hóa cái logic thì chúng ta thấy là vì nó có cái yếu tố nhiễu nên cái ma trận của mình Nó có thể là phát sáng cái đường ở giữa nhưng mà nó sẽ có cái đại lượng nhiễu nên chúng ta sẽ thấy là nó sẽ lè ra và phát sáng ở một số khu vực như thế này Rồi, và đương nhiên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 10,
      "start_timestamp": "0:09:13",
      "end_timestamp": "0:10:10"
    }
  },
  {
    "page_content": "ở một số khu vực như thế này Rồi, và đương nhiên khi contrasting learning thì chúng ta sẽ cố gắng là để cho cái ma trận này càng tiến về cái ma trận đơn vị Rồi, sau đó chúng ta sẽ tạo cái ma trận đơn vị đó trong những cái phần sau Rồi, trước hết thì chúng ta sẽ visualize cái dòng số 3 ở đây Nhìn nó như thế nào Thì để visualize dòng số 3 chúng ta sẽ lấy logic 3, 2 chấm, tức là lấy nguyên một cái dòng Và ở đây chúng ta sẽ truyền là none 3 chấm, tức là chúng ta sẽ lấy hết tất cả cái ô này để vẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 11,
      "start_timestamp": "0:10:03",
      "end_timestamp": "0:11:00"
    }
  },
  {
    "page_content": "tức là chúng ta sẽ lấy hết tất cả cái ô này để vẽ lên Rồi, chúng ta thấy bản chất nó chính là cái ô này đem xuống thôi Thì ở đây chúng ta đang trực quan hóa cái dòng số 3 lên Và đây là cái logic Sau đó thì chúng ta sẽ viết cái hàm để mà tạo cái label Thì ở đây chúng ta sẽ tạo một cái biến đó là label One Hot Thì nó sẽ là bằng F.One Hot Rồi, truyền cái label vào Và số class của mình nó sẽ là bằng n Và để cho cái mô hình này có thể huấn luyện hiệu quả được Thì chúng ta sẽ có thể là đưa vào GPU",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 12,
      "start_timestamp": "0:10:55",
      "end_timestamp": "0:11:30"
    }
  },
  {
    "page_content": "quả được Thì chúng ta sẽ có thể là đưa vào GPU Tuy nhiên thì ở đây chúng ta thấy là cái kích thước ma trận quá nhỏ Chúng ta không cần phải truyền vào GPU mà chúng ta có thể dùng trực tiếp CPU để có thể tính toán được Nên ở đây thì chúng ta chỉ cần gọi cái hàm như thế này là được Rồi sau đó thì chúng ta sẽ trực quan hóa cái ma trận này Thì chúng ta thấy là nếu đúng thì cái ma trận ở trên là sẽ phải đưa về đúng với lại cái ma trận đơn vị như thế này Rồi, bây giờ chúng ta sẽ trực quan cái hàng số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 13,
      "start_timestamp": "0:11:27",
      "end_timestamp": "0:12:44"
    }
  },
  {
    "page_content": "Rồi, bây giờ chúng ta sẽ trực quan cái hàng số 3 của cái ma trận đơn vị này lên Bằng cách đó là chúng ta sẽ gọi cái hàm imshow Chúng ta copy cái code phía trên xuống plt.imshow Chúng ta sẽ imshow cái label one-hot Rồi, và cũng lấy cái dòng số 3 Chúng ta sẽ lấy dòng số 3 đúng không? Rồi, lấy dòng số 3, 2 chấm Rồi, nâng Rồi, thì ở đây chúng ta thấy là lẽ ra chúng ta phải show cái logit và cái one hot Do đó thì chúng ta sẽ show cái logit trước Cái ví dụ hồi nãy thì chúng ta nhập sai lỗi chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 14,
      "start_timestamp": "0:12:38",
      "end_timestamp": "0:13:36"
    }
  },
  {
    "page_content": "ví dụ hồi nãy thì chúng ta nhập sai lỗi chúng ta Rồi, thì nó đã lấy cái dòng thứ 3 đem xuống đây Sau đó chúng ta sẽ show cái one hot để cho chắc chúng ta sẽ copy xuống Rồi, ở đây chúng ta sẽ phải tạo một cái figure mới Rồi, thì đây chính là cái dữ liệu của cái logit, tức là cái mà chúng ta nhân tích vô hướng giữa hai cái embedding Còn cái bên hàng dưới cùng sẽ là cái ground truth mà lẽ ra chúng ta hướng về Vì là cái ti, tức là cái embedding của ảnh và embedding của văn bản bắt đầu được lấy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 15,
      "start_timestamp": "0:13:28",
      "end_timestamp": "0:14:11"
    }
  },
  {
    "page_content": "của ảnh và embedding của văn bản bắt đầu được lấy giống nhau, chỉ là cộng thêm nhiễu Nên chúng ta thấy là tại vị trí này nó đã bật lên là 1 rồi Nếu đúng thì giá trị bắt đầu với môn khởi tạo của mình sẽ lộn xộn chứ không phải là phát sáng như thế này Vì đây chúng ta đang mô phỏng, cái việc mà contrastive learning nên chúng ta sẽ dùng cái dữ liệu dạng random như vậy Rồi, thì cái hàm mất mát ở đây chúng ta tiếp theo sẽ sử dụng chính là Sử dụng cái hàm cross entropy giữa hai cái vector này Và khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 16,
      "start_timestamp": "0:14:07",
      "end_timestamp": "0:14:50"
    }
  },
  {
    "page_content": "hàm cross entropy giữa hai cái vector này Và khi đó thì chúng ta sẽ tính cái T3, tức là cái text embedding với lại y0, T3 với lại y1, T3 với y2 v.v. Thì chúng ta sẽ tính theo hàng rồi sau đó chúng ta sẽ tính theo cột Thì đầu tiên là chúng ta sẽ lấy cột trước thay vì hàng Tóm lại đó là chúng ta sẽ tính theo từng hàng và từng cột Trong cái sơ đồ này, với cái dòng số 3 là chúng ta sẽ tính theo hàng Tức là với ảnh số 3 chúng ta sẽ đi so với tất cả các cái văn bản để xem coi là cái sai số của mình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 17,
      "start_timestamp": "0:14:43",
      "end_timestamp": "0:15:40"
    }
  },
  {
    "page_content": "các cái văn bản để xem coi là cái sai số của mình là bao nhiêu Và đối xứng lại thì chúng ta cũng sẽ có cái khía cạnh là cột số 3 là cái văn bản đúng ra phải trả về Thì nó sẽ đi so với lại những cái ảnh khác Thì chúng ta sẽ tính cái loss theo tổng hàng và cột Thế thì nếu mà chúng ta tính theo từng hàng và cột như vậy thì chúng ta sẽ phải viết một cái vòng for Nhưng mà để có thể thực hiện trọn vẹn thì chúng ta cũng tính rất là dễ Đó là chúng ta chỉ việc lấy lossA nè là bằng chính cái logic. Chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 18,
      "start_timestamp": "0:15:30",
      "end_timestamp": "0:16:34"
    }
  },
  {
    "page_content": "việc lấy lossA nè là bằng chính cái logic. Chúng ta sẽ nhân với lại cái... Chúng ta sẽ lấy để... Xin lỗi ở đây chúng ta không phải là nhân vô hướng và chúng ta sẽ dùng cái hàm cross entropy Chúng ta sẽ dùng cái hàm cross entropy để mà tính như vậy thì f.cross entropy Rồi chúng ta sẽ truyền vào cái logic và cái one-hot vector tức là cái label của mình Thì ở trong trường hợp này cái label của mình chính là cái nhãn mà chúng ta đã setup ở phía trên Đây, cái label này Thì được gán từ một, tức là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 19,
      "start_timestamp": "0:16:28",
      "end_timestamp": "0:17:20"
    }
  },
  {
    "page_content": "Đây, cái label này Thì được gán từ một, tức là ảnh thứ nhất, nhãn là một, ảnh thứ hai, nhãn là hai, và cái cặp ảnh thứ n, nhãn là n Rồi, chúng ta sẽ show... Chúng ta sẽ đi tính cái loss này bằng cách lấy logic nhân với lại cái label Rồi, bây giờ chúng ta sẽ tính cái hàm loss này là logic và label Rồi, sau đó chúng ta sẽ đi print nó ra Rồi, chúng ta sẽ tính tương tự như vậy cho cái loss của t, tức là theo text Với text tức là gì? Chúng ta sẽ đi cố định cái text, ví dụ text là t3 và chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 20,
      "start_timestamp": "0:17:17",
      "end_timestamp": "0:17:50"
    }
  },
  {
    "page_content": "cố định cái text, ví dụ text là t3 và chúng ta sẽ cho y chạy từ trên xuống Thế thì bản chất cái cách tính của t3 với trên theo hàng y3 và t3 thì chúng ta chỉ cần lật cái ma trận lại là xong Rồi, sau đó ở đây chúng ta sẽ sửa lại cái code Đó là chấm, chúng ta thêm một cái thành phần chuyển vị vào đây ha Thì chúng ta sẽ lấy logic này, chuyển vị, cross entropy Và loss tổng hợp thì sẽ là bằng trung bình cộng của hai loss này Đó là bằng loss của y cộng cho loss của t Rồi, thì bây giờ chúng ta sẽ lần",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cho loss của t Rồi, thì bây giờ chúng ta sẽ lần lượt chạy cái code Đây là theo cột ha, đây là trực quan hóa theo cột Chúng ta lấy ra, thì nếu đúng cái cột này, nó sẽ phải hướng về cái vector này Và nó sẽ bật sáng lên tại cái hàng thứ 3 Rồi, bây giờ chúng ta sẽ tính thử Thì cái loss của mình đó là loss theo trực y, nó ra là 2,410 Và theo cái trực t, rất là văn bản, thì là 2,2406 Và trung bình cộng là 248",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=1bO6WwfVibE",
      "filename": "1bO6WwfVibE",
      "title": "[CS315 - Chương 4] Tutorial - Contrastive Learning",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng nghiên cứu về một mô hình ngôn ngữ thị giác có sử dụng đến LLM, Large Language Model để cho bài toán hiểu nội dung của ảnh. Đầu tiên, chúng ta sẽ đặt câu hỏi đó là LLM là gì? LLM là viết tắt của chữ Large Language Model là một kỹ thuật của Deep Learning và trong đó nó có thể giải quyết được các bài toán khác nhau trong xử lý ngôn ngữ tự nhiên bao gồm tổng hợp thông tin, dự đoán, tạo ra các nội dung chat, v.v. Điểm đặc biệt của LLM là nó có chữ LAS, trước đây có mô hình Large",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:00"
    }
  },
  {
    "page_content": "LLM là nó có chữ LAS, trước đây có mô hình Large Language Model nhưng bây giờ nó có chữ LAS này, lý do là LAS này có thể hiểu là số lượng tham số của mô hình có thể lên đến hàng tỷ để chứa được những thông tin từ những nguồn dữ liệu khổng lồ trên internet Nhìn chung thì nó giống như là một công cụ nén mọi thứ để có mặt trên internet tuy nhiên nó không chỉ đơn giản là nén mà một số mô hình LLM gần đây nó còn có khả năng là suy luận và có khả năng khai thác được những thông tin đa chiều Ví dụ như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:50",
      "end_timestamp": "0:01:45"
    }
  },
  {
    "page_content": "khai thác được những thông tin đa chiều Ví dụ như có thể dùng LAS để cho các tác vụ của những lĩnh vực không phải bên lĩnh vực về xử lý ngôn ngữ tự nhiên Ví dụ như là hình ảnh hoặc là âm thanh, LLM không chỉ hiệu quả cho các tác vụ về văn bản mà nó có nhiều nghiên cứu để chứng minh và khai thác được LLM cho khả năng suy diễn trên các thao tác LLM sẽ có tính tổng quát hóa rất là cao để khi chúng ta cho nó thực hiện trên một tác vụ mới, nó chưa từng thấy bao giờ thì nó vẫn có thể hoạt động tốt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:35",
      "end_timestamp": "0:02:25"
    }
  },
  {
    "page_content": "từng thấy bao giờ thì nó vẫn có thể hoạt động tốt được Ví dụ như nó có thể dự báo thời tiết, chơi cờ vua, sử dụng chuỗi gen, xử lý hình ảnh, tổng quát hóa và nó có thể hoạt động ghi nhớ và suy luận như là bộ não của con người Với tác vụ về thị giác máy tính, ngoài các đặc trưng từ giác quan như mắt, con người có những kỹ năng khác mà nó có thể sử dụng Ví dụ như nó có thể sử dụng bộ não của con người, nó có thể sử dụng bộ não của con người, nó có thể sử dụng bộ não của con người Với tổng quát",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:02:17",
      "end_timestamp": "0:03:07"
    }
  },
  {
    "page_content": "có thể sử dụng bộ não của con người Với tổng quát hóa, con người có những kỹ năng khác mà đôi khi chúng ta cũng không tự nhận ra được Ví dụ như chúng ta có khả năng kết hợp đặc trưng, thị giác mà chúng ta nhìn thấy qua mắt, với những khả năng suy luận của chúng ta Giác quan regarding to stats, to t Tribunal..., Pewillos..., gay, sex & tur çalışaram làm kiến thức đểiving Ol M \") Đisiónеч algorithms pela M bisog không thể sử dụng đяет 책 ز gelecek thì đ Million Broadcasting, đó jogxe đ guarantees",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:59",
      "end_timestamp": "0:03:45"
    }
  },
  {
    "page_content": "thì đ Million Broadcasting, đó jogxe đ guarantees irgenda imaginer mriverant plutos và Dal seal rap minced vào trong các tác vụ của thị giác máy tính là LLM có thể giúp được để giải quyết các tác vụ của thị giác máy tính Vậy thì chúng ta sẽ đến với mô hình đầu tiên có khai thác LLM, đó chính là mô hình LLaVA chúng ta sẽ so sánh kết hợp LLM với các mô hình trước đây trước đây chúng ta có mô hình GPT-4, mô hình CLIP chúng ta sẽ có một hình ảnh khá là thú vị ở đây đó là người đàn ông đang ủi đồ ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:03:41",
      "end_timestamp": "0:04:36"
    }
  },
  {
    "page_content": "là thú vị ở đây đó là người đàn ông đang ủi đồ ở ngoài đường trên chiếc xe taxi chúng ta hỏi user đặt câu hỏi có gì bất thường trong tấm hình này hay không mô hình LLaVA của chúng ta đã trả lời được chính xác đó là hành động là ủi đồ và đồng thời có thể lý giải được tại sao hành động này là bất thường do nó khai thác được thông tin, tri thức trước đó để nó có thể đưa ra kết luận đó là hành động ủi đồ, hành động bất bình thường ở đây nó nói là đây không phải là một nơi điển hình để làm công việc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:04:30",
      "end_timestamp": "0:05:35"
    }
  },
  {
    "page_content": "không phải là một nơi điển hình để làm công việc này ví dụ việc ủi đồ thường được ở nơi an toàn hơn, ổn định hơn như là nhà hoặc là nó đã giải thích được hành vi ủi đồ chỉ nên áp dụng ở nơi an toàn và ổn định còn đây là ngoài đường, nó không có an toàn và không có ổn định thì đó chính là hai thông tin của tri thức trước đó đã giúp cho mô hình của mình trả lời được câu hỏi tương tự như vậy thì cho mô hình như này ở đây thì nó có thể giải thích cái meme này chi tiết được hay không thì rõ ràng là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:05:31",
      "end_timestamp": "0:06:22"
    }
  },
  {
    "page_content": "meme này chi tiết được hay không thì rõ ràng là chúng ta rất là bất ngờ là LLaVA có thể nhìn nó và hiểu nó như là một cái bản đồ thế giới như là một cái bản đồ thế giới mặc dù về mặt vật liệu thì chúng ta thấy đây là những cái tấm ảnh mà đây là những cái vật liệu mà không có được dùng để vẽ bản đồ nhưng mà người dùng, người chụp ảnh họ đã sắp xếp những cái món ăn, đồ ăn lại để sao cho nó nhìn giống như 5 châu của chúng ta và nhờ chúng ta chỉ dẫn cho nó biết đây là một cái meme nên nó có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:06:14",
      "end_timestamp": "0:07:02"
    }
  },
  {
    "page_content": "dẫn cho nó biết đây là một cái meme nên nó có thể khai thác được cái thông tin trước đó ví dụ như là thông tin về trái đất là nó sẽ gồm các cái châu lục nào vâng vâng thì world map là liên tưởng đến world map rồi các cái lục địa, hải đảo thì đây chính là cái minh họa cho cái việc khai thác cái thông tin tri thức trước đó của LLM để mà giải quyết các cái bài toán của thị giác máy tính trong khi các cái mô hình như là GPT-4 hoặc là CLIP thì chưa có thể giúp cho chúng ta giải quyết được tốt các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:06:56",
      "end_timestamp": "0:07:39"
    }
  },
  {
    "page_content": "có thể giúp cho chúng ta giải quyết được tốt các cái công việc này đặc biệt là CLIP mặc dù là mang tiếng là đã được train là một cái mô hình ngôn ngữ mô hình ngôn ngữ thị giác được train với rất nhiều những cái dữ liệu và sử dụng rất nhiều những cái image encoder và text encoder tốt nhất nhưng mà nó vẫn không có giải thích được chính xác và chi tiết cho hai cái ví dụ ở trên như vậy thì cái kiến trúc LLaVA ở đây nó có cái điểm gì đặc biệt thì thực sự mà nói kiến trúc này nó rất là đơn giản chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 10,
      "start_timestamp": "00:07:35",
      "end_timestamp": "0:08:27"
    }
  },
  {
    "page_content": "sự mà nói kiến trúc này nó rất là đơn giản chúng ta nhìn trong cái sơ đồ này chúng ta có thể thấy ở đây có hai cái pre-train model đó chính là cái vision encoder và cái language model thì đây sẽ là một cái LLM là một cái mô hình ngôn ngữ lớn ví dụ như là mô hình LLaMA là LLaMA chẳng hạn rồi LLaMA-2 và vision encoder thì chúng ta có thể sử dụng là ViT hoặc là các cái mô hình của CNN rồi và đây là hai cái large pre-train model và chúng ta sẽ sử dụng ViT để trích xuất đặc trưng ảnh thì với cái ảnh",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 11,
      "start_timestamp": "00:08:21",
      "end_timestamp": "0:09:17"
    }
  },
  {
    "page_content": "ViT để trích xuất đặc trưng ảnh thì với cái ảnh XV đưa vào thì chúng ta sẽ có được cái đặc trưng và đặc trưng biểu diễn này thì sẽ được đặc trưng này sẽ được biểu diễn dưới dạng là token và qua cái lớp MLP thì nó sẽ đưa về cái đầu vào giống như là một cái mô hình ngôn ngữ lớn thì nhờ có cái module ZV này nó sẽ giúp cho chúng ta ánh xạ tức là qua cái module projection W này nó sẽ giúp cho chúng ta ánh xạ sang cái không gian HV thì đây là cái dạng biểu diễn token mà tương tự như trong cái LLM hay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 12,
      "start_timestamp": "00:09:13",
      "end_timestamp": "0:09:59"
    }
  },
  {
    "page_content": "biểu diễn token mà tương tự như trong cái LLM hay nói cách khác đó là nó đang map cái đặc trưng của không gian ảnh sang cái đặc trưng của mô hình ngôn ngữ lớn thế thì chúng ta sẽ đi chi tiết hơn đó là làm sao để huấn luyện được cái mô hình LLaVA thì LLaVA có hai bước huấn luyện chính bước đầu tiên đó là tiền huấn luyện để căn chỉnh cái đặc trưng ảnh và ngôn ngữ thì đây chính là cái ý mà chúng ta vừa mà nói khi nãy và cái bước thứ hai đó là tinh chỉnh để fine-tune lại toàn bộ mô hình để có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 13,
      "start_timestamp": "00:09:54",
      "end_timestamp": "0:10:39"
    }
  },
  {
    "page_content": "chỉnh để fine-tune lại toàn bộ mô hình để có thể nó gọi là instruction fine-tuning để mà mình có thể giải quyết các cái tác vụ trên ảnh còn cái bước tiền huấn luyện thì nhiệm vụ của nó chỉ đơn giản đó là align cái đặc trưng thị giác về với lại đặc trưng của được huấn luyện bởi mô hình ngôn ngữ lớn thế thì đối với cái bước căn chỉnh đặc trưng ảnh và ngôn ngữ thì đây là một cái bước mà đưa cái đặc trưng ảnh với các visual token về cái không gian text token embedding của mô hình ngôn ngữ lớn như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 14,
      "start_timestamp": "00:10:35",
      "end_timestamp": "0:11:22"
    }
  },
  {
    "page_content": "text token embedding của mô hình ngôn ngữ lớn như chúng ta đã nói và cả visual encoder và LLM đều được đóng băng tức là chúng ta sẽ frozen đóng băng cái này và đóng băng cái này và không tiến hành huấn luyện chúng ta chỉ huấn luyện trên cái module chiếu tức là cái module projection này thì chúng ta sẽ train trên đây để tìm ra cái ma trận W nhằm ánh xạ cái vector zv cái vector zv tức là cái kết quả sau khi đưa cái tấm ảnh xv qua cái visual encoder thì cái zv sẽ được đưa về cái HV tức là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 15,
      "start_timestamp": "0:11:20",
      "end_timestamp": "0:12:08"
    }
  },
  {
    "page_content": "thì cái zv sẽ được đưa về cái HV tức là cái không gian đặc trưng của mô hình ngôn ngữ lớn và để mà tiền huấn luyện này thì chúng ta cần phải có một cái bộ dữ liệu và bộ dữ liệu này chúng ta sẽ lấy từ các bộ dữ liệu image captioning dataset ví dụ như là COCO chẳng hạn chúng ta sẽ lập và xử lý để đưa về cái dạng format như sau và cái prompt của mình sẽ có cái dạng human 2.xq xv stock và assistant xc stock trong đó xv của chúng ta chính là cái ảnh của mình còn xc chính là cái caption được lấy từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 16,
      "start_timestamp": "0:12:04",
      "end_timestamp": "0:12:47"
    }
  },
  {
    "page_content": "của mình còn xc chính là cái caption được lấy từ các tập dataset ví dụ như là tập COCO rồi xq thì sẽ là một câu instruction ví dụ như là describe image concisely tức là mô tả tấm hình một cách chi tiết hoặc là summarize visual content of the image đây là những cái cách nói khác nhau những cái dạng câu hỏi khác nhau được viết lại bằng cái công cụ GPT tức là chúng ta sẽ nhờ ChatGPT để viết những cái biến thể khác nhau cho cái ý đó là tóm tắt cái nội dung hình ảnh tóm tắt cái nội dung của một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 17,
      "start_timestamp": "00:12:43",
      "end_timestamp": "0:13:35"
    }
  },
  {
    "page_content": "dung hình ảnh tóm tắt cái nội dung của một cái tấm ảnh cho trước bằng cái dạng ngôn ngữ văn bản thì đây là cái ý việc chuẩn bị dữ liệu và khi chúng ta đưa dữ liệu, chúng ta huấn luyện chúng ta tạo xong dữ liệu này thì chúng ta sẽ đưa vào để mà tinh chỉnh toàn bộ mô hình thì đây là cái bước tinh chỉnh với những dữ liệu đa dạng hơn và sinh ra từ GPT-4 tức là bên cạnh dữ liệu mà chúng ta lấy từ COCO như hồi nãy thì chúng ta còn có thể lấy ra những dữ liệu mà tạo ra bởi ChatGPT và lúc này thì cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 18,
      "start_timestamp": "0:13:32",
      "end_timestamp": "0:14:19"
    }
  },
  {
    "page_content": "dữ liệu mà tạo ra bởi ChatGPT và lúc này thì cái tham số cái tham số của mô hình vision encoder thì vẫn được giữ nguyên và chúng ta sẽ tiếp tục tinh chỉnh cho hai cái module này để nhờ có cái language model chúng ta sẽ tinh chỉnh cái mô hình F_phi để cho nó có thể giải quyết được cái tác vụ mà chúng ta đang hỏi ở đây rồi và dữ liệu cho việc tinh chỉnh thì chúng ta có thể sử dụng COCO image captioning dataset rồi kết hợp với lại few-shot example từ người dùng thì cái kỹ thuật này gọi là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 19,
      "start_timestamp": "00:14:16",
      "end_timestamp": "0:15:03"
    }
  },
  {
    "page_content": "example từ người dùng thì cái kỹ thuật này gọi là in-context learning với few-shot prompting tức là chúng ta sẽ cho mô hình một vài ví dụ và nó sẽ tạo sinh ra thêm cho chúng ta khi chúng ta đưa những mẫu dữ liệu mới ví dụ như là context style 1 là loại dữ liệu của chúng ta đầu vào của chúng ta đó là caption là group people standing outside of a black vehicle thì đây là cái câu mô tả rồi cái dạng đầu vào tiếp theo đó là cái dạng bounding box có thể có tọa độ của đối tượng như là người của những",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 20,
      "start_timestamp": "00:15:00",
      "end_timestamp": "0:15:55"
    }
  },
  {
    "page_content": "có tọa độ của đối tượng như là người của những người trong tấm hình backpack v.v. thì nó sẽ là có tọa độ làm dữ liệu đầu vào và có 3 dạng câu hỏi được yêu cầu cái dạng câu hỏi đầu tiên đó là dạng câu hỏi hội thoại dạng hội thoại ví dụ như đây là một dạng hội thoại hội thoại, ví dụ như là what type of vehicle is featured in the image thì câu trả lời đó là the image features black sport utility vehicle SUV thế thì đây là cái dạng câu hỏi dạng conversation và conversation thì chúng ta biết rằng là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 21,
      "start_timestamp": "00:15:52",
      "end_timestamp": "0:16:34"
    }
  },
  {
    "page_content": "và conversation thì chúng ta biết rằng là nó không phải chỉ có một cặp câu hỏi đáp mà nó sẽ có một cái chuỗi như thế này mà có rất nhiều dạng hỏi rồi đáp và cái dạng thứ 2 câu trả lời thứ 2 đó là detail description tức là dạng mô tả chi tiết thế thì đây là cái dạng ví dụ cho cái dạng phản hồi image is an underground, parking area gì đấy thì đây là một cái câu mô tả rất là dài và chi tiết và cái dạng câu trả lời thứ 3 đó là reasoning, đây là những câu hỏi khó và phải lý giải được nội dung liên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 22,
      "start_timestamp": "0:16:31",
      "end_timestamp": "0:17:13"
    }
  },
  {
    "page_content": "câu hỏi khó và phải lý giải được nội dung liên quan ví dụ như chúng ta đưa vào một câu hỏi là what challenge do these people face thì ở đây cái câu trả lời của mình sẽ phải có tính lập luận từng bước và logic thì đây là những dữ liệu phục vụ cho việc tinh chỉnh mà chúng ta sẽ khai thác công cụ ChatGPT để tạo ra thế thì cái việc cải thiện của LLaVA đó là chúng ta có thể cải thiện cái chất lượng của LLaVA thông qua việc tăng cường chất lượng của dữ liệu do đó là chúng ta phải để tâm tại vì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 23,
      "start_timestamp": "00:17:10",
      "end_timestamp": "0:17:56"
    }
  },
  {
    "page_content": "của dữ liệu do đó là chúng ta phải để tâm tại vì garbage in, garbage out tức là nếu mà rác vào rác ra nếu mà dữ liệu huấn luyện là dữ liệu không có sạch và có chứa nhiều thông tin không liên quan đến tấm ảnh thì nó có thể gây ra mô hình LLaVA học bị sai do đó chúng ta sẽ thêm các dữ liệu mới đồng thời phải xử lý lại dữ liệu lọc lại dữ liệu của mình cho chất lượng của dữ liệu nó ngày càng tốt, rồi thay đổi kiến trúc ví dụ như chúng ta có thể thay đổi kiến trúc dữ liệu của dữ liệu của dữ liệu của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 24,
      "start_timestamp": "00:17:53",
      "end_timestamp": "0:18:50"
    }
  },
  {
    "page_content": "đổi kiến trúc dữ liệu của dữ liệu của dữ liệu của dữ liệu có thể thay đổi kiến trúc dữ liệu của dữ liệu và tăng kích thước của LLM lên hay là sử dụng mô hình LLM hiện đại hơn và có performance, có độ chính xác cao hơn và một ý cuối để cải thiện chất lượng của mô hình LLaVA đó chính là tăng kích thước ảnh tại vì khi chúng ta giải quyết các bài toán hay là GQA Grounded Question Answering thì nó sẽ đòi hỏi chúng ta quan sát rất là chi tiết bên trong tấm ảnh chứ không phải là thông tin toàn cục mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 25,
      "start_timestamp": "0:18:47",
      "end_timestamp": "0:19:32"
    }
  },
  {
    "page_content": "tấm ảnh chứ không phải là thông tin toàn cục mà thông tin chi tiết muốn nổi bật thì kích thước ảnh của mình nó phải đủ lớn, thì cái sơ đồ bên đây cho thấy đó là khi chúng ta scale up LLM, tức là chúng ta từ 7B 7 tỷ lên mô hình là 13 tỷ thì độ chính xác của mình tăng lên khoảng 1,3% đối với độ đo là GQA hoặc là MMI thì nó tăng từ 1510 lên 1531 rồi khi chúng ta tăng độ phân giải lên tương ứng là giải pháp số 3 thì chúng ta thấy là nó đã tăng từ mô hình LLaVA lên tương ứng là giải pháp số 3 thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 26,
      "start_timestamp": "00:19:29",
      "end_timestamp": "0:20:14"
    }
  },
  {
    "page_content": "mô hình LLaVA lên tương ứng là giải pháp số 3 thì chúng ta thấy là nó đã tăng từ 50% lên 51% 50% lên 51% rồi cải thiện cái chất lượng của dữ liệu thì thế thì đây là những cái cải tiến quan trọng mà LLaVA đã cho cái kết quả thậm chí là còn cao hơn cả GPT Ultra và GPT-4V thì như đã nói ban đầu cái mô hình LLaVA NEXT là cái phiên bản tốt nhất hiện nay là cái phiên bản tốt nhất tại thời điểm hiện tại thì khi so sánh với lại GPT-4V thì đây là cho cái kết quả tốt hơn cả GPT-4V và lưu ý là GPT-4V đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "kết quả tốt hơn cả GPT-4V và lưu ý là GPT-4V đó là một mô hình close source trong khi đó LLaVA NEXT đó là một cái mô hình mã nguồn mở là open source thì điều này cho thấy là cái cộng đồng nghiên cứu open source họ rất là năng động và tạo ra được những cái mô hình rất là chất lượng để chia sẻ cho cộng đồng thì trong cái bản biểu ở bên đây chúng ta thấy đó là cái hiệu quả của GPT Pro GPT Ultra thì chúng ta thấy là LLaVA NEXT cho cái kết quả nó có thể bị cao hơn so với lại GPT Pro và thậm chí là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "thể bị cao hơn so với lại GPT Pro và thậm chí là cao trong một số task thì nó cao hơn cả GPT-4V Rồi, thế thì đây chính là cái thành tựu của cái mô hình mà có sự kết hợp của image encoder kết hợp với LLM tức là một cái mô hình ngôn ngữ thị giác trong những phần tiếp theo thì chúng ta sẽ cùng tìm hiểu qua một số cái biến thể khác của cái mô hình thị giác này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2cyeOg51SlE",
      "filename": "2cyeOg51SlE",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 3",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cài đặt một cái mạng Convolutional Network và tập dữ liệu mà chúng ta sẽ sử dụng ở đây chính là tập dữ liệu MNIST. Đây là một trong những tập dữ liệu rất là kinh điển khi làm trong lĩnh vực về thị giác máy tính. Ảnh đầu vào của tập dữ liệu này sẽ có kích thước 28 x 28, đúng bằng cái kích thước ở đây. Và kiến trúc mạng CNN ở đây chúng ta sẽ sử dụng đó là kiến trúc mạng LeNet được có từ những năm 1998. Và kiến trúc mạng này thực sự mà nó cũng không có sâu, nó chỉ bao gồm 2 lớp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:46"
    }
  },
  {
    "page_content": "sự mà nó cũng không có sâu, nó chỉ bao gồm 2 lớp convolution. Và 2 lớp convolution này thì sử dụng các filter có kích thước là 3 x 3. Và đối với lớp convolution đầu tiên thì chỉ có 6 filter. Đối với lớp convolution thứ 2 thì sẽ có kích thước 3 x 3, nhân cho 6. Tại vì đầu vào của lớp convolution này chính là feature map này, mà feature map này có depth là bằng 6. Vì đó ở đây sẽ là 6. Tuy nhiên thì trong quá trình mà chúng ta cài đặt thì chúng ta cũng không cần phải chỉ ra tường minh là số input",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:41",
      "end_timestamp": "0:01:27"
    }
  },
  {
    "page_content": "cũng không cần phải chỉ ra tường minh là số input của mình là bao nhiêu. Tự cái deep learning framework sẽ tính cho mình cái con số này. Chúng ta chỉ cần cho biết cái kích thước bề ngang, bề cao của filter là được. Và đồng thời chúng ta cũng cho deep learning framework biết số filter đầu ra mong muốn là trong phép convolution thứ 2 chính là 16. Các phép biến đổi subsampling ở đây thực chất chính là phép biến đổi max pooling. Và phần cuối của mạng CNN này chính là các lớp biến đổi fully",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:22",
      "end_timestamp": "0:02:10"
    }
  },
  {
    "page_content": "của mạng CNN này chính là các lớp biến đổi fully connected để tạo ra các filter có kích thước là 120, 84 và 10. Trong đó 10 thì tương ứng với lại số lớp đầu ra của mình là các con số từ 0 cho đến 9. Vậy thì trong phần tiếp theo chúng ta sẽ tiến hành cài đặt mạng convolution neural network này. Bước đầu tiên chúng ta sẽ khởi tạo các tập dataset của mình. Trong Keras nó đã có phương thức giúp cho mình load dataset rất dễ dàng. Đó là Keras.datasets và chúng ta sẽ import tập dữ liệu là MNIST. Sau",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:03",
      "end_timestamp": "0:03:01"
    }
  },
  {
    "page_content": "và chúng ta sẽ import tập dữ liệu là MNIST. Sau đó chúng ta chỉ việc gọi là MNIST.load_data thì tự động nó sẽ lấy từ trên mạng internet về giải nén và đưa vào các cặp biến là X_train, y_train và X_test, y_test. Chúng ta sẽ quan sát thử kích thước của các ký biến này. X_train có kích thước là 60.000 x 28 x 28. 60.000 này tương ứng là tổng số mẫu. 28 x 28 là kích thước bề ngang và bề cao của ảnh chữ số viết tay. y_train có kích thước là 60.000. Vì ứng với từng cái X_train nó sẽ có một cái giá trị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:50",
      "end_timestamp": "0:03:49"
    }
  },
  {
    "page_content": "ứng với từng cái X_train nó sẽ có một cái giá trị label, một cái nhãn output của y_train. Thì ở đây chúng ta sẽ thử quan sát một số mẫu dữ liệu. Để quan sát thì chúng ta sẽ sử dụng thư viện đó là matplotlib.pyplot as plt. Vì ứng với tổng số mẫu. Chúng ta sẽ sử dụng cái hàm imshow với cái biến là X_train. X_train này nó có các cái chiều 60.000 x 28 x 28. Ở chiều đầu tiên chúng ta sẽ lấy ra tại một cái vị trí nào đó, đó là index. Và trong trường hợp này thì chúng ta sẽ cho index là bằng 123, cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:46",
      "end_timestamp": "0:04:29"
    }
  },
  {
    "page_content": "này thì chúng ta sẽ cho index là bằng 123, cái con số bất kỳ trong khoảng từ 0 cho đến 60.000. Rồi thành phần vào lại thì sẽ là [:, :]. Tức là chúng ta sẽ lấy toàn bộ cái nội dung của tấm ảnh ra để chúng ta hiển thị. Rồi sau đó chúng ta sẽ thực hiện thì thấy là cái ảnh này mình đoán đoán nó hình như là số 7. Thì muốn biết chính xác đó là nhãn bao nhiêu thì chúng ta sẽ in ra là nhãn của dữ liệu. Rồi ở đây chúng ta sẽ lấy là y_train và chúng ta cũng sẽ truyền vào cái trị số là index. Rồi đúng như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:23",
      "end_timestamp": "0:05:10"
    }
  },
  {
    "page_content": "sẽ truyền vào cái trị số là index. Rồi đúng như dự đoán thì cái nhãn này chính là, nhãn của dữ liệu này chính là số 7. Và chúng ta có thể thay đổi các cái trị số này, ví dụ như là 10.000. Rồi, thì đây là tương ứng nhãn của nó sẽ là số 3. Tiếp theo, đó là chúng ta sẽ tiền xử lý chúng ta sẽ chuẩn hóa cái dữ liệu X_train và X_test của mình. Bằng cách đó là thay vì đưa cái miền giá trị từ 0 đến 255, thì chúng ta sẽ đưa về cái miền giá trị là từ 0 cho đến 1. Để giúp cho cái quá trình huấn luyện nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:05:02",
      "end_timestamp": "0:05:44"
    }
  },
  {
    "page_content": "đến 1. Để giúp cho cái quá trình huấn luyện nó được nhanh hơn. Và đồng thời là cái giá trị y của mình cũng sẽ được chuyển đổi từ cái dạng nhãn là cái chỉ số từ 0 cho đến 9. Chúng ta sẽ đưa nó về cái dạng One Hot Encoding. Vì dạng One Hot Encoding, thì One Hot Encoding nó như là gì? Ví dụ số 0, thì chúng ta sẽ đưa một cái vector trong đó có duy nhất một cái phần tử bật lên là 1. Và tất cả các phần tử còn lại sẽ để là số 0. Và tương tự như vậy cho số 2 đi, thì nó sẽ bật lên là 0, ở đây là 0, ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:36",
      "end_timestamp": "0:06:31"
    }
  },
  {
    "page_content": "số 2 đi, thì nó sẽ bật lên là 0, ở đây là 0, ở đây là 0 và nó sẽ bật lên ở đây. Và tất cả các phần tử còn lại sẽ để là số 0. Thì đây là cái dạng One Hot Encoding. Rồi bước tiếp theo, đó là chúng ta sẽ tiến hành cài đặt cái thuật toán huấn luyện hay cụ thể đó là cài đặt cái mô hình. Thì cái mạng CNN, ở đây chúng ta sẽ có các phương thức như là Build, Train, Constructor, Load, Get Weights. Ở đây có các phương thức Get Weights là chúng ta sẽ chưa cài đặt, chúng ta sẽ cài đặt để đưa lên Train song",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:21",
      "end_timestamp": "0:07:06"
    }
  },
  {
    "page_content": "đặt, chúng ta sẽ cài đặt để đưa lên Train song hành cùng với lại hàm Train để kẻo chúng ta quên. Xin lỗi, chúng ta sẽ đưa lên Train ngang với lại phương thức là Build để không một chút nữa chúng ta sẽ quên. Cái quá trình Train của mạng CNN rất là lâu, nếu mà chúng ta quên thực hiện cái gì đấy và chúng ta thực hiện lại thì nó sẽ tốn thời gian rất là nhiều. Thì ở đây chúng ta sẽ phải cho cái model nó biết đó là Input Dimension. Rồi, đồng thời là các cấu hình, ví dụ như số lượng filter là 6, số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:06:51",
      "end_timestamp": "0:07:44"
    }
  },
  {
    "page_content": "các cấu hình, ví dụ như số lượng filter là 6, số lượng filter là 16, rồi số các output của các lớp Fully Connected là 120, 84. Thì chúng ta sẽ phải tham số hóa 4 cái bộ số này. Riêng cái con số cuối cùng đó là 10, đó chính là số lượng cái nhãn mà mình cần nhận diện rồi thì nó sẽ cố định là 10. Rồi, mình biết trước tập dữ liệu này là có 10 mẫu, 10 loại, 10 nhãn, 10 class. Và đồng thời thì chúng ta cũng sẽ tham số hóa cái hàm kích hoạt Activation Function. Rồi, Activation Function. Rồi, chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:07:33",
      "end_timestamp": "0:08:31"
    }
  },
  {
    "page_content": "Function. Rồi, Activation Function. Rồi, chúng ta sẽ có n Convolution số 1, n Convolution số 2, n FC1, n FC2. Và mặc định thì hàm Activation chúng ta sẽ để là Sigmoid. Rồi, Convolution thì mặc định chúng ta sẽ để là 6, giống như trong cái thiết kế ở đây. Convolution số 2 thì mặc định chúng ta sẽ để là 16. FC1 thì chúng ta sẽ để là 120. Và FC2 thì chúng ta sẽ để là 84. Rồi, sau đó thì chúng ta sẽ tiến hành cài đặt các thành phần của cái mạng này. Bằng cách đó là chúng ta sẽ tiến hành lần lượt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:08:28",
      "end_timestamp": "0:09:28"
    }
  },
  {
    "page_content": "Bằng cách đó là chúng ta sẽ tiến hành lần lượt qua các lớp đối tượng, qua lớp biến đổi. Lớp đầu tiên chính là lớp Input. Rồi, Input thì chúng ta sẽ cho biết cái shape của nó sẽ là bằng Input Dimension. Rồi, và chúng ta sẽ trả ra một cái biến tên là Input. Rồi, tương tự như vậy thì chúng ta sẽ tiến hành thực hiện phép biến đổi Convolution. Thì ở đây là Convolution chúng ta sẽ sử dụng Convolution 2D. Và nó sẽ có các tham số. Đầu tiên là số lượng filter thì chúng ta sẽ để là số lượng Convolution",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:09:16",
      "end_timestamp": "0:10:17"
    }
  },
  {
    "page_content": "filter thì chúng ta sẽ để là số lượng Convolution số 1. Cái tham số thứ 2 là Convolution thì như hồi nãy chúng ta đã gặp, đó là kích thước của cái Convolution này chính là kích thước của nó sẽ là 3 x 3. Rồi, Stride thì ở đây chúng ta sẽ để mặc định là 1, vậy là chúng ta sẽ không để cái Stride ở đây. Rồi, Padding thì chúng ta sẽ để là same. Tại vì trong cái sơ đồ này chúng ta thấy, trong sơ đồ này chúng ta thấy là ảnh đầu vào và ảnh đầu ra có kích thước giống nhau. Ảnh đầu vào là 28, 28 thì ảnh",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:10:07",
      "end_timestamp": "0:11:22"
    }
  },
  {
    "page_content": "thước giống nhau. Ảnh đầu vào là 28, 28 thì ảnh đầu ra là 28, 28. Ảnh đầu vào là 14, 14 thì ảnh đầu ra cũng sẽ là 14 x 14. Thì qua cái phép biến đổi Convolution thì chúng ta thấy là cái kích thước bề ngang và bề cao là không thay đổi khi thực hiện cái phép Convolution. Do đó chúng ta sẽ để Padding là bằng same. Rồi, thì chắc là mình sẽ phải điền cái use_bias là bằng true. Rồi, thì cơ bản đó là nó đã đầy đủ những cái... à nó còn thiếu một cái nữa đó là cái activation. Activation này sẽ để trước",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:11:17",
      "end_timestamp": "0:12:19"
    }
  },
  {
    "page_content": "đó là cái activation. Activation này sẽ để trước bias. Bias sẽ là bằng activation. Rồi, như vậy thì chúng ta đã cài đặt cho cái đối tượng tên là Convolution2D và chúng ta sẽ phải truyền vào cho nó là cái input. Và trả ra nó sẽ ra là cái biến tên là C1, giống như trong cái sơ đồ ở đây. Rồi, tiếp theo thì chúng ta sẽ thử chạy. Ok, nó sẽ báo lỗi. À, 3x3, ok, nó không hiểu 3x3 là gì. 3,3. Rồi, hết lỗi rồi. Bây giờ chúng ta sẽ thực hiện cái phép Pooling. Pooling thì tương ứng nó chính là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:12:07",
      "end_timestamp": "0:13:06"
    }
  },
  {
    "page_content": "Pooling. Pooling thì tương ứng nó chính là cái MaxPooling2D ở đây. Và chúng ta sẽ có cái tham số là pool_size thì mặc định nó sẽ sử dụng đó là 2x2. Do đó thì một cái tường minh chúng ta sẽ để ở đây là 2x2. Với cái Pooling mà bằng 2x2 như thế này thì cái kích thước mình sẽ được giảm xuống một nửa. Ở đây thì chúng ta sẽ để Stride là bằng 2. Sau khi thực hiện cái Pooling này thì cái kích thước của nó sẽ giảm xuống một nửa. Rồi, ngoài ra thì có Padding thì chúng ta sẽ để là same. Rồi, và chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": "0:12:55",
      "end_timestamp": "0:13:42"
    }
  },
  {
    "page_content": "thì chúng ta sẽ để là same. Rồi, và chúng ta sẽ truyền cái đầu vào cho nó chính là C1 và đầu ra sẽ là S2, giống như trong cái kiến trúc mạng, trong cái thiết kế ở đây. Rồi, đối với cái phép biến đổi Convolution tiếp theo chúng ta sẽ copy xuống. Nhưng mà khi copy thì cần phải lưu ý là sửa lại. Thay vì ở đây để là Input thì nó sẽ để là S2. S2. Rồi, và đầu ra sẽ là C3. Và số Convolution ở đây, số Filter ở đây, nó sẽ là Nconf2. Kích thước không thay đổi. Lưu ý là hồi nãy, kích thước là 3x3 và nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": "0:13:31",
      "end_timestamp": "0:14:16"
    }
  },
  {
    "page_content": "đổi. Lưu ý là hồi nãy, kích thước là 3x3 và nó sẽ tự biết cái Input S2, kích thước cái Depth là bao nhiêu thì nó sẽ chọn cái Filter cho phù hợp. Do đó chúng ta không cần phải tường minh để chỉ ra là kích thước 3x3 nhân bao nhiêu. Rồi, Activation thì chúng ta cũng tái sử dụng lại. Tiếp theo, nó sẽ chuyển sang cái phép là Pooling. Rồi, thì đầu vào chúng ta sẽ có là C3 và nó sẽ tạo ra là S4. Và cái cấu hình thì cũng tương tự. Cấu hình cũng sẽ tương tự. Rồi, bây giờ chúng ta sẽ tiếp tục cài đặt cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 19,
      "start_timestamp": "0:14:11",
      "end_timestamp": "0:15:18"
    }
  },
  {
    "page_content": "tự. Rồi, bây giờ chúng ta sẽ tiếp tục cài đặt cho cái phép biến đổi Fully Connected. Thì để thực hiện được cái Fully Connected này, chúng ta sẽ phải có một cái bước là Flatten. Thì chúng ta sẽ gọi cái đối tượng Flatten ở đây và truyền vào cái S4 để trả ra là FC. Ở đây thì nó sẽ đặt tên là FC4 đi ha. Rồi, tại vì thực sự mà nó phép Flatten nó không có biến đổi gì hết. Tiếp theo thì chúng ta sẽ thực hiện cái phép Fully Connected, nó chính là Dense. Rồi, và tham số đầu tiên là số lượng unit, tức là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 20,
      "start_timestamp": "0:15:06",
      "end_timestamp": "0:15:56"
    }
  },
  {
    "page_content": "Rồi, và tham số đầu tiên là số lượng unit, tức là số lượng output neuron sẽ trả ra. Thì chúng ta sẽ lấy cái tham số FC1 này đưa vào. Rồi, Activation thì chúng ta sẽ để là App Function. Rồi, use_bias là bằng true. Rồi, và chúng ta sẽ truyền vào cái biến đó là FC4. Thì trong cái sơ đồ ở đây, nó để là C5, nhưng mà để đúng với lại cái tên của nó, đó là Fully Connected, thì chúng ta sẽ đặt tên lại đó là FC5. Rồi, tương tự như vậy, cho cái biến đổi tiếp theo, chúng ta sẽ để đầu vào là FC5, đầu ra sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 21,
      "start_timestamp": "0:15:49",
      "end_timestamp": "0:16:34"
    }
  },
  {
    "page_content": "theo, chúng ta sẽ để đầu vào là FC5, đầu ra sẽ là FC6, và số neuron đầu ra sẽ là FC2. Rồi, cuối cùng, đó chính là output. Thì FC6 sẽ được truyền vào đây, và đầu ra sẽ là output. Và số neuron của mình sẽ là 10, tại vì mình biết trước, cái đầu ra của mình sẽ là 10 class. Riêng cái hàm Activation Function thì chúng ta sẽ phải để là softmax, tại vì đây là phân lớp đa lớp, chứ không phải là phân lớp nhị phân. Nếu mà phân lớp nhị phân thì chúng ta sẽ sử dụng Sigmoid. Rồi, cuối cùng thì chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 22,
      "start_timestamp": "0:16:30",
      "end_timestamp": "0:17:32"
    }
  },
  {
    "page_content": "sử dụng Sigmoid. Rồi, cuối cùng thì chúng ta sẽ đóng gói toàn bộ input và output trong cái biến tên là MODEL. self.model sẽ là bằng MODEL, rồi input và output. Rồi, như vậy thì chúng ta đã cài xong cho cái phần build mô hình. Đối với cái hàm TRAIN thì chúng ta sẽ sử dụng optimizer là ADAM. ADAM thì đây là một trong những cái optimizer rất là hiệu quả, nó giúp cho chúng ta thoát ra được những cái điểm cực tiểu cục bộ. Hàm Loss thì chúng ta sẽ sử dụng CROSS ENTROPY, CATEGORICAL CROSS ENTROPY, tức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 23,
      "start_timestamp": "0:17:23",
      "end_timestamp": "0:18:10"
    }
  },
  {
    "page_content": "CROSS ENTROPY, CATEGORICAL CROSS ENTROPY, tức là chúng ta thực hiện phân lớp nhiều lớp. Rồi, độ đo thì chúng ta sẽ sử dụng độ đo để đánh giá là Accuracy. Về Weights thì chúng ta sẽ trả về self.model.layers và chúng ta sẽ truyền vào cái chỉ số của cái layer mà mình muốn trả về, xong rồi gọi hàm GET Weights. Rồi, như vậy thì chúng ta đã cài xong cái mạng CNN. Và bước tiếp theo thì chúng ta sẽ khởi tạo các cái mô hình. Rồi, CNN.build và ở đây thì chúng ta sẽ copy xuống các cái tham số để tránh bị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 24,
      "start_timestamp": "0:18:03",
      "end_timestamp": "0:18:47"
    }
  },
  {
    "page_content": "ta sẽ copy xuống các cái tham số để tránh bị sơ sót. Đầu tiên input dimension thì cái ảnh này của mình nếu thông thường chúng ta sẽ để là 28,28. Tuy nhiên cái convolution, cái mô hình convolution nó chỉ có thể thực hiện được khi nó phải là 1 cái tensor 3 chiều. Do đó ở đây thì chúng ta sẽ để là 28,28.1. Và activation thì chúng ta sẽ để là sigmoid. Rồi, convolution số 1 chúng ta sẽ để là 6. Convolution số 2 thì chúng ta sẽ để là 16. Và FC ở đây chúng ta sẽ để là 1. FC lớp số 1 chúng ta sẽ để là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 25,
      "start_timestamp": "0:18:38",
      "end_timestamp": "0:19:25"
    }
  },
  {
    "page_content": "ta sẽ để là 1. FC lớp số 1 chúng ta sẽ để là 120. FC số 2 thì chúng ta sẽ để là 84. Và hàm activation ở đây thì chúng ta sẽ để là hàm sigmoid. Rồi, bây giờ chúng ta sẽ chạy thử. Và chương trình thì chạy được rồi. Bây giờ chúng ta sẽ xem coi là cái mạng CNN này chấm summary xem có thể thực hiện được hay không. Để xem cái kích thước, cái kiến trúc của cái mạng CNN này. Thì chúng ta có thể thấy trong cái mạng CNN này nó thỏa mãn được đúng như kiến trúc mà chúng ta mong muốn. Là bao gồm thực hiện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 26,
      "start_timestamp": "0:19:19",
      "end_timestamp": "0:20:14"
    }
  },
  {
    "page_content": "trúc mà chúng ta mong muốn. Là bao gồm thực hiện cái FC số 1 với 6 filter, thực hiện convolution số 2 với 16 filter. Rồi, và cái kích thước của các tensor thì cũng giảm dần. Đó là từ 28 xuống 14 xuống 7 giống như trong thiết kế ở đây. Và số neuron của mình sẽ là, xin lỗi số tham số của mình, nó sẽ là 100.000 tham số. 100.000 tham số. Bây giờ chúng ta sẽ tiến hành train. Chúng ta sẽ truyền vào 2 tham số đó là X_train và y_train. Tuy nhiên y_train nó phải ở dạng là one hot. Rồi, thì cái việc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 27,
      "start_timestamp": "0:20:07",
      "end_timestamp": "0:20:58"
    }
  },
  {
    "page_content": "nó phải ở dạng là one hot. Rồi, thì cái việc train này đâu đó nó có thể tốn. Ồ, ở đây chúng ta quên mất một cái việc. Đó là sau này để mà có thể vẽ được cái hàm loss, vẽ được cái giá trị loss theo số epoch. Chúng ta sẽ phải gán vào một cái biến, vâng, history. Rồi sau đó thì ở đây chúng ta mới có thể thực hiện được cái việc trực quan hóa này. Rồi, để trực quan hóa cho cái mô hình, thì chúng ta sẽ phải lấy ra các cái filter. Ở đây chúng ta sẽ lấy ra filter ở cái lớp đầu tiên. Đó chính là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 28,
      "start_timestamp": "0:20:48",
      "end_timestamp": "0:20:58"
    }
  },
  {
    "page_content": "sẽ lấy ra filter ở cái lớp đầu tiên. Đó chính là cnn.get_weights. get_weights ở đây chúng ta sẽ để cái layer số 1. Tại vì layer số 0 chính là cái input rồi. Layer số 1 chính là cái phép convolution. Rồi, chúng ta sẽ cùng quan sát. Nhưng mà đương nhiên là phải chờ cái mô hình này nó huấn luyện xong, thì chúng ta mới có thể thấy được cái hàm loss này nó chạy như thế nào. Ở đây thì chúng ta quan sát thấy là cái loss của mình nó đã giảm từ 0.18 trong cái epoch đầu tiên. Giảm xuống còn 0.13, giảm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cái epoch đầu tiên. Giảm xuống còn 0.13, giảm xuống còn 0.10. Và đến cái epoch thứ 25, 26 thì giảm xuống còn 0.01. Và hy vọng là đến cái epoch số 30 thì cái loss của mình nó đã giảm xuống còn 0.007. Và accuracy cho tập dữ liệu train nó đã lên đến 99.85%. Rồi, chúng ta quan sát thì cái loss giảm rất là tốt. Chúng ta quan sát cái train loss này giảm rất là tốt. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2NThga7SQ-I",
      "filename": "2NThga7SQ-I",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 1)",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Mô hình đầu tiên chúng ta sẽ cùng tìm hiểu trong nhóm Vision Language Model là clip trong bài báo Learning Transferable Visual Model from Natural Language Supervision Đây có thể nói là một trong những mô hình ngôn ngữ thị giác đầu Cho đến hiện nay thì clip vẫn được sử dụng khá phổ biến trong nhiều tác vụ của các bài toán thị giác máy tính Thì đầu tiên chúng ta sẽ phát biểu vấn đề của các mô hình thị giác trước đây Các mô hình thị giác trước đây đều được huấn luyện trên những tập dữ liệu lớn Ví",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:58"
    }
  },
  {
    "page_content": "đều được huấn luyện trên những tập dữ liệu lớn Ví dụ như tập dữ liệu nổi tiếng mà hiện nay vẫn còn được sử dụng đó là tập ImageNet Tập dữ liệu ImageNet này thì nó sẽ có số lượng rất lớn lên đến hàng triệu mẫu Và nó bao gồm một tập là ảnh cộng với lại một cái nhãn Thì cái nhãn này nó sẽ ở dạng ngôn ngữ tự nhiên Tuy nhiên thực tế thì chúng ta hành xử với cái nhãn này nó giống như là với một cái con số nhiều hơn là ngôn ngữ Tại vì khi nói về ngôn ngữ thì chúng ta sẽ phải nói đến câu cú Chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:39"
    }
  },
  {
    "page_content": "ngữ thì chúng ta sẽ phải nói đến câu cú Chúng ta phải nói đến câu, phải nói đến đoạn văn Phải nói đến khái niệm là mô tả chi tiết Còn cái nhãn ở đây thì nó mới chỉ dừng lại là đối tượng của chúng ta ở đây là đối tượng gì Ví dụ ở trong hình bên dưới chúng ta có hình một con chó thì cái nhãn của chúng ta là con chó Tuy nhiên khi chúng ta xây dựng cái mô hình này xong, huấn luyện cái mô hình này xong thì khi chúng ta đưa vào một cái hình thuộc cái domain khác Ví dụ như hình hoặc hình hoặc là hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:33",
      "end_timestamp": "0:02:12"
    }
  },
  {
    "page_content": "domain khác Ví dụ như hình hoặc hình hoặc là hình con chó robot Thì liệu cái mô hình của mình nó có còn dự đoán đây là con chó nữa hay không Chúng ta để cái dấu chấm hỏi ở đây ha Đó chính là cái vấn đề bất cập của các cái mô hình huấn luyện mà dựa trên cái loại dữ liệu hình ảnh và nhãn Đó là vì chúng ta đang hành xử với cái nhãn của mình như là một con số mà chúng ta chưa thực sự xem nó như là một cái yếu tố ngôn ngữ mô tả Vậy thì với tập dữ liệu ImageNet này thì chúng ta thấy là nó có lên đến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:10",
      "end_timestamp": "0:02:51"
    }
  },
  {
    "page_content": "ImageNet này thì chúng ta thấy là nó có lên đến hàng ngàn class Và dữ liệu đầu ra của chúng ta là cái vector 1000 chiều Tức là chúng ta vẫn xem các cái nhãn này như là một cái vector số học Và nó không có sự liên kết giữa các cái nhãn với nhau Nó không cho biết là con chó và con mèo thì nó có sự giống nhau ra sao Rồi cái hành vi của nó tương tự như nhau như thế nào Thế thì chính vì cái cách mà chúng ta đang huấn luyện mô hình như vậy Và cách chúng ta sử dụng tập dataset ImageNet dẫn đến là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:46",
      "end_timestamp": "0:03:28"
    }
  },
  {
    "page_content": "ta sử dụng tập dataset ImageNet dẫn đến là cái mô hình của mình sẽ bị giới hạn bởi số lượng class của mình Tức là nếu chúng ta xây dựng một cái mô hình mà có 1000 chiều tương ứng với 1000 lớp đối tượng Thì sau này khi có những cái đối tượng mới thì nó sẽ ít có cái khả năng học ra được hoặc là nhận biết ra được Ví dụ như ở đây chúng ta thấy là cũng là con chó nhưng mà theo một cái phong cách khác thì cái mô hình của mình nó sẽ bị lúng túng Và nó không có cái tính gọi là độc lập cũng như là tạm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "00:03:19",
      "end_timestamp": "0:04:06"
    }
  },
  {
    "page_content": "không có cái tính gọi là độc lập cũng như là tạm gọi là sáng tạo để mà suy nghĩ Thế thì ý tưởng chính của clip đó là thay vì chúng ta huấn luyện dựa trên mối liên kết giữa hình ảnh và nhãn Nghĩa là nhãn hoặc là label thì chúng ta sẽ dựa vào, chúng ta sẽ huấn luyện dựa vào cái mối liên kết giữa hình ảnh và cái văn bản mô tả Rõ ràng là trong các câu khẩu ngữ trước đây người ta hay có câu đó là một hình ảnh thì là bằng 1000 lời nói Tức là trong tấm ảnh của mình nó sẽ có rất nhiều thông tin chứ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "00:03:52",
      "end_timestamp": "0:04:57"
    }
  },
  {
    "page_content": "tấm ảnh của mình nó sẽ có rất nhiều thông tin chứ không phải là nó chỉ có một cái nhãn không Thì thì nếu chúng ta chỉ có một thông tin của một cái nhãn nó sẽ giới hạn cái nội dung trong tấm ảnh đó, giới hạn cái nội dung nghĩa Dẫn đến là mô hình của mình nó sẽ không có khai thác được hết cái dữ liệu của mình Ví dụ như trong tấm hình này thì lẽ ra là chúng ta sẽ phải nói chi tiết hơn, ví dụ như là con chó màu trắng và nằm cạnh một con mèo màu nâu ở trong tấm chăn sọc và trên một cái giường Tức là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:04:48",
      "end_timestamp": "0:05:32"
    }
  },
  {
    "page_content": "trong tấm chăn sọc và trên một cái giường Tức là ở đây chúng ta thấy nó có rất nhiều những thuộc tính, đối tượng, rồi cái giường Rõ ràng là một tấm hình nó sẽ có rất nhiều cái thông tin như vậy Thì nếu như chúng ta có một cái mô hình mà có khả năng vừa học được hình ảnh và vừa học được cái nội dung mô tả để mà khai thác được các cái thông tin đó thì rõ ràng là cái mô hình của mình nó sẽ thông minh hơn và chúng ta cũng sẽ đỡ tốn kém hơn trong cái việc là gán nhãn dữ liệu Thì cái mô hình ngôn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:24",
      "end_timestamp": "0:06:10"
    }
  },
  {
    "page_content": "cái việc là gán nhãn dữ liệu Thì cái mô hình ngôn ngữ, cái mô tả ngôn ngữ nó sẽ chứa nhiều thông tin hơn là một cái nhãn đơn lẻ Thì đó chính là một trong những cái key idea, ý tưởng chính để khiến chúng ta xây dựng một cái mô hình thay vì huấn luyện trên ảnh và nhãn thì chúng ta sẽ huấn luyện trên hình ảnh và văn bản Và cái này thì thích hợp để sử dụng làm cái thông tin giám sát quá trình học Tức là cái văn bản của chúng ta nó có thể là một cái dạng thức, là một cái loại dữ liệu Để giúp chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:04",
      "end_timestamp": "0:06:46"
    }
  },
  {
    "page_content": "dạng thức, là một cái loại dữ liệu Để giúp chúng ta giám sát cái quá trình học, tức là nó vẫn nằm trong cái dạng học và giám sát Vậy thì câu hỏi đặt ra đó là làm sao để mà có thể học được mối liên kết giữa hình ảnh và văn bản Để mà nó có thể khai thác được tốt cái thông tin này Thì chúng ta sẽ sử dụng cái hướng tiếp cận đó là Contrastive Learning, tức là học tương phản Thế thì học tương phản là gì? Mục đích của học tương phản đó là chúng ta sẽ học một cái bộ mã hóa văn bản Và bộ mã hóa văn bản,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:06:42",
      "end_timestamp": "0:07:24"
    }
  },
  {
    "page_content": "một cái bộ mã hóa văn bản Và bộ mã hóa văn bản, tức là Text Encoder Và một cái bộ mã hóa hình ảnh, tức là Image Encoder Thế thì ở trong cái ví dụ ở đây, cái này không phải là ví dụ mà là cái mô hình ở đây Chúng ta thấy là khi chúng ta huấn luyện thì nó sẽ đi một cặp Nó sẽ đi một cặp là hình ảnh và văn bản Và hai cái cặp ảnh và văn bản này khi chúng ta chiếu lên trên cái không gian latent Nó sẽ gần nhau, tại vì đây là cái cặp nội dung đi chung với nhau Trong cái không gian latent, cái biểu diễn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:07:20",
      "end_timestamp": "0:08:01"
    }
  },
  {
    "page_content": "nhau Trong cái không gian latent, cái biểu diễn của văn bản này và ảnh này nó phải gần nhau Và tương tự như vậy, hai cái văn bản và hình ảnh này thì nó cũng phải gần nhau Các cái hình ảnh và văn bản mà có cái nội dung không giống nhau thì nó sẽ phải xa nhau Ví dụ như chúng ta thấy cái cặp ảnh và văn bản ở đây Có thể là nó có chứa một cái nội dung khác hoàn toàn thì nó sẽ nằm xa nhau Như vậy thì cái không gian đặc trưng của chúng ta ở đây là một cái không gian đặc trưng mà đa kiểu dữ liệu Hay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:07:55",
      "end_timestamp": "0:08:44"
    }
  },
  {
    "page_content": "cái không gian đặc trưng mà đa kiểu dữ liệu Hay còn là đa thể thức Và đa thể thức Rồi, thế thì chúng ta sẽ có một cái hình ảnh minh họa bên lề cho cái việc học tương phản Đó là ở trên đây chúng ta sẽ thấy là x1 và x2, đó là cùng một cái giống chó Nhưng mà nó ở trong những cái bối cảnh khác nhau, ví dụ như đây là một cái bãi cỏ Còn ở đây là một cái vùng nền đen Thế thì những cái đối tượng nào mà giống nhau thì nó sẽ nằm ở gần nhau Và chúng ta thấy là giữa hai cái ảnh đầu tiên thì nó có cái sự",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "00:08:37",
      "end_timestamp": "0:09:32"
    }
  },
  {
    "page_content": "là giữa hai cái ảnh đầu tiên thì nó có cái sự tương đồng rất là cao Do đó khi chúng ta biểu diễn lên trên cái không gian Latent Space thì hai cái điểm này là gần nhau Và những cái đối tượng này đều có cùng một cái mô tả đó là French Bulldog Tức là một cái giống chó bulldog của Pháp thì nó sẽ nằm ở trong một cái cụm Rồi, còn cái con chó x2 thì nó cũng là con chó đó Nhưng mà nó trong cái background màu đen thì nó sẽ nằm ở ngoài rìa Sở dĩ tại sao nó nằm ngoài rìa như thế này là vì nó có cái nền nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "00:09:26",
      "end_timestamp": "0:10:04"
    }
  },
  {
    "page_content": "nằm ngoài rìa như thế này là vì nó có cái nền nó khác đi Vậy thì khi chúng ta xây dựng cái mô hình học tương phản thì nó sẽ phải đảm bảo đó là Hai cái đối tượng mà tương tự nhau thì nó sẽ nằm gần nhau Còn hai cái đối tượng ví dụ như là chó và mèo đó là hai cái class rất là xa nhau Thì ở đây nó sẽ nằm hai cái không gian rất là xa Rồi, thậm chí là trong cái giống chó thì Brittany thì nó là một cái giống chó khác Thì nó sẽ nằm ở một cái khu vực khác Còn cái giống chó French Bulldog thì nó sẽ nằm ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "00:09:58",
      "end_timestamp": "0:10:43"
    }
  },
  {
    "page_content": "Còn cái giống chó French Bulldog thì nó sẽ nằm ở một khu vực khác Nó sẽ bị xa nhau ra như thế này Thì đó chính là cái ý tưởng, đó là những đối tượng nào mà gần nhau, giống nhau thì nó sẽ nằm gần nhau Còn đối tượng nào mà xa nhau, không giống nhau thì nó sẽ cách xa ở trên cái không gian latent Và cái việc này thì nó cũng hoàn toàn tương tự khi chúng ta làm việc trên cái loại dữ liệu là văn bản Nó cũng hoàn toàn tương tự như trên hình ảnh Vậy thì cái bài báo Clip Contrastive Language, viết tắt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:10:35",
      "end_timestamp": "0:11:37"
    }
  },
  {
    "page_content": "cái bài báo Clip Contrastive Language, viết tắt của chữ là Contrastive Language Image Pre-training Từ cái bài báo này, thì chúng ta thấy là có tô màu, các cái màu ở đây Và chúng ta sẽ cùng giải nghĩa ý nghĩa của các cái từ này Đầu tiên đó là Transferable Visual Model, đó là mô hình có thể sử dụng linh hoạt cho nhiều cái bài toán khác nhau Nghĩa là cái mô hình Clip sau khi chúng ta đã xây dựng được rồi, thì chúng ta có thể Transfer Learning cho các cái bài toán liên quan đến thị giác máy tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": "0:11:17",
      "end_timestamp": "0:12:16"
    }
  },
  {
    "page_content": "các cái bài toán liên quan đến thị giác máy tính khác nhau Ví dụ như chúng ta có thể dùng nó cho bài toán phân loại hình ảnh, có thể dùng nó cho bài toán segmentation, phân đoạn ngữ nghĩa, có thể dùng nó cho bài toán detection Nhưng mà đương nhiên cái cách chúng ta sử dụng như thế nào thì nó sẽ có những cái cách thức khác nhau, một phương pháp khác nhau Rồi, cái cụm từ thứ hai đó là Natural Language Supervision, tức là trái với những cái mô hình trước đây ví dụ như là VIT hoặc là mô hình CNN",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": "00:11:54",
      "end_timestamp": "0:12:55"
    }
  },
  {
    "page_content": "trước đây ví dụ như là VIT hoặc là mô hình CNN như là ResNet v.v. thì cái supervision của nó đó là Label Còn ở đây, cái mà khiến để giúp chúng ta giám sát quá trình học đó là ngôn ngữ tự nhiên, nó không phải là Label, Label chỉ là một trường hợp đặc biệt của ngôn ngữ tự nhiên Ví dụ Label của chúng ta đó là Dog hoặc là Cat, còn Natural Language Supervision đó là chúng ta sẽ có một câu ví dụ như là Red Car on a street, ví dụ vậy, thì đây là một cái ngôn ngữ mô tả Như vậy thì quá trình huấn luyện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 19,
      "start_timestamp": "0:12:42",
      "end_timestamp": "0:13:37"
    }
  },
  {
    "page_content": "ngôn ngữ mô tả Như vậy thì quá trình huấn luyện sẽ dựa trên ngôn ngữ tự nhiên và đây là ngôn ngữ để mô tả cho tấm ảnh của mình Và cái cụm từ tiếp theo đó là từ Contrastive, thì cái Contrastive này nó nằm trong cái nhóm đó là Contrastive Learning hay là học tương phản, thì đây là một công cụ chính mà chúng ta sẽ sử dụng để huấn luyện cái mô hình clip này Cái cách làm của Contrastive Learning đó là chúng ta sẽ có hai cái cặp, có các cái cặp, ví dụ như cặp gần nhau và cái cặp xa nhau Thì nếu hai",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 20,
      "start_timestamp": "0:13:20",
      "end_timestamp": "0:14:43"
    }
  },
  {
    "page_content": "như cặp gần nhau và cái cặp xa nhau Thì nếu hai cái đối tượng mà cùng nhóm với nhau, có cái nội dung giống nhau thì nó sẽ kéo về gần nhau, nhưng mà hai cái đối tượng mà nó có cái nội dung khác xa nhau thì cái khoảng cách của nó sẽ càng xa, nó sẽ đẩy ra Thì đó là cái tư tưởng của Contrastive Learning và đây chính là cái công cụ chính cho cái mô hình clip để huấn luyện Cái từ Pre-training có nghĩa là tiền huấn luyện, tức là huấn luyện sẵn, thì đây là một cái mô hình được huấn luyện sẵn và có khả",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 21,
      "start_timestamp": "0:14:15",
      "end_timestamp": "0:15:17"
    }
  },
  {
    "page_content": "là một cái mô hình được huấn luyện sẵn và có khả năng suy luận không cần cái dữ liệu huấn luyện, tức là Zero Shot Inference Và chút nữa thì chúng ta sẽ nói là tại sao cái khái niệm Zero Shot ở đây được sử dụng, và ở đây là không huấn luyện trên cái không gian đặc trưng, đa thể thức của mình đã được huấn luyện sẵn Trong bên tay phải của chúng ta, đó là hình ảnh minh họa, nếu như chúng ta sử dụng tập dữ liệu ImageNet và với mô hình ResNet 101, thì clip sẽ cho clip với backbone, đó là ViT-L, cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 22,
      "start_timestamp": "0:15:00",
      "end_timestamp": "0:16:13"
    }
  },
  {
    "page_content": "clip sẽ cho clip với backbone, đó là ViT-L, cho độ chính xác cao hơn Ví dụ như đây là 76.2 thì là tương đương với 76.2 của ResNet 101, nhưng các dataset khác như ImageNet V2, khó hơn phức tạp hơn và đối tượng của mình lẫn lộn nhiều hơn, clip ViT cho kết quả là 70 so với lại 64.3 Và ImageNet Rendition, tức là những tập ImageNet mà được tạo ra bằng render hoặc là bằng các phương pháp tạo sinh, không phải là ảnh thật, thì chúng ta thấy sự khác biệt này càng chênh lệch hơn nữa Còn tập dữ liệu không",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 23,
      "start_timestamp": "0:16:00",
      "end_timestamp": "0:16:57"
    }
  },
  {
    "page_content": "này càng chênh lệch hơn nữa Còn tập dữ liệu không có thật này thì khi áp dụng với ImageNet ResNet 101 thì độ chính xác chỉ có 37%, tương tự như vậy Và đối với tập dữ liệu cuối cùng thì chúng ta thấy là gần như là clip hơn tuyệt đối, do cái tính phức tạp của nó, cái tính phức tạp rất là cao Thì ở những tập dataset ở trên thì chúng ta thấy nó khá là đơn giản và dễ, nhưng càng xuống dưới thì các dataset này thuộc domain khác và không có nhiều mẫu dữ liệu để huấn luyện Rồi ZeroShot nên dẫn đến là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 24,
      "start_timestamp": "0:16:43",
      "end_timestamp": "0:17:49"
    }
  },
  {
    "page_content": "dữ liệu để huấn luyện Rồi ZeroShot nên dẫn đến là độ chính xác khi chúng ta sử dụng mô hình ResNet 101 thì độ chính xác của chúng ta rất là thấp, còn clip thì nó rất là cao Vậy thì ý tưởng của clip đó là gì? Đối với quá trình huấn luyện, clip sẽ có hai phần, phần huấn luyện và phần inference, tức là phần sử dụng mô hình Bước số 1, đó là chúng ta sử dụng học tương phản và chúng ta sẽ huấn luyện đồng thời hai cái module, module thứ nhất đó chính là textencoder này Và module số 2, đó là module",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 25,
      "start_timestamp": "0:17:35",
      "end_timestamp": "0:18:20"
    }
  },
  {
    "page_content": "là textencoder này Và module số 2, đó là module imageencoder, cái module mã hóa hình ảnh mục tiêu của nó, đó là biến một tấm ảnh thành một cái vector, thành một cái vector biểu diễn Còn text, cái module mã hóa văn bản hay là textencoder thì mục tiêu của nó là biến một cái câu thành một cái vector biểu diễn Mục tiêu của chúng ta đó là làm sao để cho sự tương đồng của những cặp ảnh mà giống nhau thì nó sẽ là cao nhất Ví dụ như chúng ta thấy là trong các cái, ví dụ ở trên thì các cái cặp ảnh là I1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 26,
      "start_timestamp": "0:18:14",
      "end_timestamp": "0:19:12"
    }
  },
  {
    "page_content": "các cái, ví dụ ở trên thì các cái cặp ảnh là I1 và T1, đó là những cái cặp ảnh và text và văn bản là thuộc cùng một cái chủ đề Thì nó sẽ hướng cái ma trận này về cái ma trận đơn vị, tức là đương nhiên một cách hoàn hảo thì là như vậy Còn các cái cặp ảnh và văn bản mà không liên quan với nhau, ví dụ như là image 2 và text 1 thì nó sẽ là tiến về 0 Nhưng mà đương nhiên thì trong quá trình huấn luyện chắc chắn các cái giá trị này nó sẽ không về cái ma trận đơn vị một cách tuyệt đối Nhưng mà định",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 27,
      "start_timestamp": "0:19:05",
      "end_timestamp": "0:19:51"
    }
  },
  {
    "page_content": "ma trận đơn vị một cách tuyệt đối Nhưng mà định hướng của chúng ta sẽ là khiến cho cái việc so khớp giữa các cái ảnh và văn bản thuộc cùng một cái chủ đề là nó sẽ bằng một và càng cao càng tốt Còn các cái ảnh và văn bản mà không có cùng nội dung thì nó sẽ càng thấp Thì mục tiêu vậy, huấn luyện mô hình có khả năng mã hóa để tối đa hóa cái độ tương đồng Và nếu mà chúng ta dùng cái độ tương đồng ở đây dạng cosine thì nó sẽ tiến về 1 giữa các cái vector biểu diễn của một cặp ảnh và văn bản Và ngược",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 28,
      "start_timestamp": "0:19:40",
      "end_timestamp": "0:20:33"
    }
  },
  {
    "page_content": "biểu diễn của một cặp ảnh và văn bản Và ngược lại có nghĩa là những cái ảnh và văn bản không cùng một đối tượng thì nó sẽ cho cái độ tương đồng thấp hơn Chúng ta sẽ sang cái quá trình gọi là Inference hay là sử dụng cái mô hình của mình Thì cụ thể đó là cái mô hình clip khi đã được Retraining clip có thể phân lớp hình ảnh mà không cần huấn luyện Bởi cái mô hình chúng ta đã huấn luyện theo cái cách này, đó là chúng ta mapping một cái cặp hình ảnh và câu mô tả Rõ ràng là nó không phục vụ cho cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 29,
      "start_timestamp": "0:20:25",
      "end_timestamp": "0:21:07"
    }
  },
  {
    "page_content": "và câu mô tả Rõ ràng là nó không phục vụ cho cái task là phân loại hình ảnh, nhưng nó vẫn có thể sử dụng cho cái việc đó là phân loại hình ảnh Thì gọi là Zero Shot Classification, thì phân loại hình ảnh không cần thông qua cái 2 bước, không cần huấn luyện Thì thông qua 2 bước, bước số 1, đó là chúng ta sẽ tạo một cái câu mô tả ứng với một lớp Ví dụ như chúng ta có một cái tập dữ liệu là Plane, Car, Dog, Bird v.v. và chúng ta muốn phân biệt xem cái ảnh này là cái con vật nào Thì chúng ta sẽ tạo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 30,
      "start_timestamp": "0:20:58",
      "end_timestamp": "0:22:03"
    }
  },
  {
    "page_content": "ảnh này là cái con vật nào Thì chúng ta sẽ tạo ra cái câu mô tả cho mỗi lớp, ví dụ như là a Photo of a class, thì ví dụ như a Photo of a Car, a Photo of a Dog, a Photo of a Plane Và chúng ta lấy cái câu mô tả này, chúng ta đưa qua cái Text Encoder, thì đưa qua cái Text Encoder chúng ta sẽ ra được cái T1, T2, T3 và TN Và đây là cái Embedding, cái Vector biểu diễn của N, cái đối tượng chúng ta cần mã hóa, giả sử ở đây chúng ta có N đối tượng Rồi, với N đối tượng chúng ta cần mã hóa ở đây, thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 31,
      "start_timestamp": "0:21:52",
      "end_timestamp": "0:22:35"
    }
  },
  {
    "page_content": "với N đối tượng chúng ta cần mã hóa ở đây, thì chúng ta sẽ có N Embedding, ở đó chúng ta thấy là không hề huấn luyện gì hết Và đây là cái Pre-trained, cái model này đã được Pre-trained Clip Tương tự như vậy, bước số 3, ở đây bước 1, bước 2, bước 1 là cái bước học tương phản rồi ha Còn ở đây chúng ta đang nói là bước số 2 là tạo một cái bộ phân lớp, bước số 3 đó là tiến hành phân lớp bằng cách đó là chúng ta sẽ đưa cái tấm ảnh này vào một cái Image Encoder Và cái Image Encoder này cũng đã được",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 32,
      "start_timestamp": "0:22:25",
      "end_timestamp": "0:22:51"
    }
  },
  {
    "page_content": "Encoder Và cái Image Encoder này cũng đã được Pre-trained, cũng đã được Pre-trained trước đó, chúng ta huấn luyện cái mô hình này trước đó rồi Rồi, thì chúng ta sẽ huấn luyện cái model này Rồi, sau đó thì chúng ta sẽ tiến hành so sánh 2 cái Vector biểu diễn Rồi, sau đó thì chúng ta sẽ thấy là trong một loạt các cái đối tượng, thì Plane, Car, Dog cũng mất Thì khi chúng ta lấy cái Vector T1, T2, T3 và TN, chúng ta đi tích vô hướng với lại cái Y, Y1, đây là ảnh số 1 Đây là một cái ảnh của cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 33,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Y, Y1, đây là ảnh số 1 Đây là một cái ảnh của cái image, cái image của cái ảnh bên đây Chúng ta nhân tích vô hướng, thì chúng ta thấy là giả sử như cái Y1 và T3 này là cho cái Vector, cho cái giá trị độ tương đồng là cao nhất Thì chứng tỏ đó là, và nếu như cái T3 này tương ứng là Dog, T3 chính là Dog, thì a Photo of a Dog Thế thì chúng ta sẽ kết luận rằng đây chính là Photo of a Dog, thì đó chính là cái idea của clip trong cái việc là Zero Shot Image Classification Chúng ta không hề vấn đề, mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 34,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Image Classification Chúng ta không hề vấn đề, mà chúng ta chỉ hình thành cái Prompt và lấy cái Embedding của Photo of an Object để mà chúng ta đi so với cái Embedding của tấm ảnh Thì đó chính là cái idea Hãy subscribe cho kênh Ghiền Mì Gõ để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=2s07XUliDHY",
      "filename": "2s07XUliDHY",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 1)",
      "chunk_id": 35,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với một cái cải tiến cũng theo hướng đó là Adaptive Learning Rate, đó là ADAM. ADAM đã cải tiến so với lại phiên bản đó là Root Mean Square Propagation và cũng dựa trên Momentum. Trong Root Mean Square Propagation, chúng ta thấy là có thành phần alpha chia cho căn của epsilon cộng cho r. Đây là thành phần chuẩn hóa của Learning Rate. Nhưng sau đó chúng ta lại đi nhân với lại g là thành phần gradient và g này thì lại bằng đạo hàm của g theo theta, tức là một cái thành phần",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:10"
    }
  },
  {
    "page_content": "hàm của g theo theta, tức là một cái thành phần gradient nguyên bản, nó chưa có áp dụng momentum vào g, chưa có momentum cho gradient. Thì chúng ta sẽ có một cái cải tiến cho ở chỗ này. Cái thứ hai, nó sẽ có một cái hiện tượng đó là tại những cái giai đoạn đầu tiên. Thì chúng ta thấy là cái thành phần momentum của mình là ví dụ như ở đây là r là bằng 0, đúng không? Là bằng 0. Rồi sau đó sang cái vòng lặp tiếp theo thì r sẽ là bằng beta nhân với r cộng cho 1 trừ beta nhân với lại g.g. Thì dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:01:54"
    }
  },
  {
    "page_content": "r cộng cho 1 trừ beta nhân với lại g.g. Thì dẫn đến đó là ở đây beta là bằng 90% của r mà r của mình nó đang bằng 0. Thì dẫn đến cái thằng này là bằng 0 và thằng này thì chỉ có là 10% của cái đạo hàm hiện tại thôi. Tức là ở trong 4 cái vòng lặp đầu tiên, 3 cho đến 4 vòng lặp, thì cái r này rất nhỏ. R này rất nhỏ, thì gây ra cái hiện tượng gì? Là nó sẽ không phản ánh đúng cái đạo hàm của mình. Nó không phản ánh đúng cái đạo hàm, tức là cái độ dốc của mình. Dẫn đến là cái quá trình cập nhật rất",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 2,
      "start_timestamp": "0:01:45",
      "end_timestamp": "0:02:42"
    }
  },
  {
    "page_content": "của mình. Dẫn đến là cái quá trình cập nhật rất là chậm. Vì nó bé mà nên nó sẽ là chậm. Do đó thì chúng ta sẽ tìm cách chuẩn hóa sao cho với 3-4 vòng lặp đầu tiên thì nó sẽ boost cái momentum của mình lên. Chúng ta sẽ có một cái biến thể là cải tiến ở chỗ là những vòng lặp đầu tiên thì nó sẽ boost momentum lên để cho nó cập nhật nhanh hơn, không bị chậm ở những bước đầu. Chi tiết của thuật toán ADAM Adaptive Moment Estimation là nằm ở đây. Chúng ta đầu tiên cũng sẽ khởi tạo là alpha là bằng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 3,
      "start_timestamp": "0:02:33",
      "end_timestamp": "0:03:15"
    }
  },
  {
    "page_content": "ta đầu tiên cũng sẽ khởi tạo là alpha là bằng 0.1. Đối với cái Decay Rate thì bình thường trong cái Root Mean Square Propagation chúng ta chỉ có duy nhất một cái beta. Ở đây chúng ta sẽ có hai cái beta là beta 1 và beta 2. Trong đó beta 1 là cái hệ số momentum là cái Decay Rate cho cái momentum của gradient cho cái việc cập nhật cái momentum của gradient. Còn cái beta 2 sẽ là cho cái việc cập nhật cái hệ số chuẩn hóa, hệ thành phần chuẩn hóa. Chuẩn hóa cái Learning Rate. Rồi, và chúng ta sẽ,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 4,
      "start_timestamp": "0:03:11",
      "end_timestamp": "0:04:14"
    }
  },
  {
    "page_content": "Chuẩn hóa cái Learning Rate. Rồi, và chúng ta sẽ, ngoài R thì chúng ta sẽ có thêm S. S chính là cái thành phần momentum cho gradient. Thành phần momentum cho gradient. Thì đây chính là cái momentum cho cái beta gradient của mình và công thức của mình là bình thường là trong cái phần Root Mean Square Propagation thì S của mình nó chính là chỉ bằng G thôi. Còn bây giờ S của mình nó sẽ là bằng cái thành phần quá khứ, nhân với lại, cộng với lại cái thành phần gradient hiện tại. Đây là hiện tại. Còn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 5,
      "start_timestamp": "0:04:00",
      "end_timestamp": "0:04:45"
    }
  },
  {
    "page_content": "phần gradient hiện tại. Đây là hiện tại. Còn đây là cái thành phần quá khứ. Rồi, và nó sẽ là bằng 90% của quá khứ cộng cho 10% của hiện tại. Và như hồi nãy chúng ta đã lập luận thì cái việc mà lấy quá nhiều cho cái quá khứ nó sẽ khiến cho những cái bước cập nhật đầu tiên rất là chậm. Thì chúng ta sẽ có cái thành phần chuẩn hóa ở phía sau. Chúng ta sẽ giải thích sau. S mũ chính là cái thành phần chuẩn hóa cho cái S ở phía trên. Thế thì tại sao cái việc chuẩn hóa với cái công thức này thì những",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 6,
      "start_timestamp": "0:04:37",
      "end_timestamp": "0:05:19"
    }
  },
  {
    "page_content": "việc chuẩn hóa với cái công thức này thì những cái vòng lặp đầu tiên của mình nó sẽ có cái giá trị không quá bé. Thì bây giờ chúng ta giả sử S ban đầu của mình là một cái con số rất là bé. Nhưng khi chúng ta giả sử S ban đầu của mình là một cái con số rất là bé. Như đã giải thích S sẽ là bằng quá khứ là bằng 90% của cái S ban đầu là bằng 0. Tức là cái thành phần này là bằng 0. Tức là ở những cái vòng lặp đầu tiên là ban đầu. Thì S sẽ là bằng quá khứ là bằng 0 cộng cho 10% của G. Thì cái thành",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 7,
      "start_timestamp": "0:05:13",
      "end_timestamp": "0:06:10"
    }
  },
  {
    "page_content": "khứ là bằng 0 cộng cho 10% của G. Thì cái thành phần này rất là bé. Nhưng khi chúng ta chia cho căn của 1 trừ beta mũ T với T là số thứ tự. T là cái bước lặp của mình. Thì ở cái vòng lặp đầu tiên tức là T bằng 1. Vòng lặp đầu tiên T bằng 1. Thì khi đó S sẽ là bằng 1 trừ cho beta 1 của mình là 0.9 mũ 1. 0.9 mũ 1 tức là là 0.9. Thì 1 trừ 0.9 tức là 0.1. Thì S mà chia cho 0.1 tương đương với S chúng ta sẽ nhân lên 10 lần. Thì ban đầu S của mình rất là thấp. Nó chỉ bằng khoảng 0.9 cái đạo hàm góc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 8,
      "start_timestamp": "0:06:05",
      "end_timestamp": "0:06:39"
    }
  },
  {
    "page_content": "là thấp. Nó chỉ bằng khoảng 0.9 cái đạo hàm góc của mình thôi. Nhưng mà chúng ta chia cho 0.1 tức là nhân 10 lên. Thì có phải là S lúc này của mình nó tương đương với cái đạo hàm tại cái thời điểm đó không? Tại cái thời điểm ban đầu. Thì nó đã được boost lên 10 lần. Thì cái công thức này sẽ giúp chúng ta boost tại những cái thời điểm đầu tiên. Thế thì khi T mà càng lớn, đương nhiên không thể nào mà T tiến đến vô cùng được. T chỉ là khoảng 10, 20 ví dụ vậy. Cỡ 10 cho đến 20 đi. Thì khi đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 9,
      "start_timestamp": "0:06:34",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "20 ví dụ vậy. Cỡ 10 cho đến 20 đi. Thì khi đó là beta 1 mũ T. Không phải beta 1 mũ T vì beta 1 là 1 con số bé hơn 1 lớn hơn 0. Nên nó sẽ tiến đến, nó sẽ tiến về 0. Do đó 1 trừ beta 1 mũ T, nó sẽ tiến về 1. 1 trừ 0 tức là 1. Tức là khi đó S mũ của chúng ta, nó sẽ xấp xỉ bằng S chia cho 1. Tức là nó sẽ bằng cái nguyên bản của cái momentum ban đầu của mình. Thì khi T mà càng lớn thì gần như nó không cần boost lên nữa. Còn khi T của mình nhỏ khoảng 1, 2 thì nó sẽ boost lên rất là nhiều lần. Thì đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 10,
      "start_timestamp": "0:07:17",
      "end_timestamp": "0:07:59"
    }
  },
  {
    "page_content": "1, 2 thì nó sẽ boost lên rất là nhiều lần. Thì đó là ý nghĩa của công thức chuẩn hóa này. Tương tự như vậy, cho cái thành phần để cập nhật chuẩn hóa của learning rate, chúng ta cũng sẽ dùng cái công thức này để giúp cho cái việc mà tại những thời điểm đầu tiên nó không quá bé. Nó sẽ xấp xỉ bằng với lại cái đạo hàm của mình luôn. Và ý nghĩa của công thức này như tương tự như trong cái Root Mean Square Propagation, mục tiêu của nó là để tách ra T vì là một cái vector nên nó sẽ tách ra thành những",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 11,
      "start_timestamp": "0:07:54",
      "end_timestamp": "0:08:39"
    }
  },
  {
    "page_content": "là một cái vector nên nó sẽ tách ra thành những cái learning rate riêng khi chúng ta cập nhật vô cái thành phần đạo hàm. Và nó làm theo cái nguyên tắc đó là thành phần đạo hàm nào ở bên đây, của g mà càng nhỏ thì cái learning rate sẽ càng lớn. Thành phần nào của cái g này mà lớn thì cái learning rate của nó sẽ nhỏ. Như vậy là Gradient, Adam nó đã có những cái cải tiến chính. Đó là nó có thêm cái momentum cho cái vector Gradient. Nó có thêm cái thành phần chuẩn hóa để những cái vòng lặp đầu tiên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 12,
      "start_timestamp": "0:08:35",
      "end_timestamp": "0:09:17"
    }
  },
  {
    "page_content": "phần chuẩn hóa để những cái vòng lặp đầu tiên nó sẽ không quá nhỏ, cái thành phần đạo hàm của mình nó sẽ không quá bé hoặc là cái phần chuẩn hóa đạo hàm cũng không quá bé. Nó bị sai lệch so với lại cái đạo hàm tại cái thời điểm đó. Và trong cái sơ đồ này thì chúng ta sẽ có cái trực quan hóa để cho thấy cái tốc độ hội tụ của từng thuật toán. Thì ở đây AdaDelta, đó chính là cái Adam của mình. Đó là cái đường màu vàng. Đó là cái đường màu vàng này. Rồi, và chúng ta thấy là cái đường màu vàng thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 13,
      "start_timestamp": "0:09:10",
      "end_timestamp": "0:09:51"
    }
  },
  {
    "page_content": "Rồi, và chúng ta thấy là cái đường màu vàng thì nó sẽ rớt xuống rất là nhanh, nó sẽ hội tụ rất là nhanh. Khi đến cái khu vực mà gọi là Saddle Point và đồng thời là có cái valley, là cái thung lũng chúng ta thấy là có hai cái thành, giảm độ dốc, đi ngang, xong rồi lại đi lên, đó gọi là valley thì cái Adam của chúng ta rớt xuống nhanh nhất, nó rớt xuống rất là nhanh. Còn cái thuật toán mà Root Mean Square Propagation là cái đường màu đen thì chúng ta thấy là nó sẽ rớt chậm hơn. Còn Stochastic",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 14,
      "start_timestamp": "0:09:45",
      "end_timestamp": "0:10:21"
    }
  },
  {
    "page_content": "ta thấy là nó sẽ rớt chậm hơn. Còn Stochastic Gradient Descent thì đối với Stochastic Gradient Descent là cái chấm màu đỏ nè là chúng ta thấy nó bị dao động qua lại và nó đứng yên luôn, nó không thoát ra được cái chỗ này luôn. Momentum thì khá hơn một chút xíu là cái đường, cái điểm màu xanh lá. Chúng ta thấy là khi Momentum nó rớt xuống nó cũng sẽ chao đảo qua lại. Nhưng mà vì có một số kiểu tối ưu nên nó sẽ dần dần dần dần nó thoát ra được và nó đến được cái rảnh này nó di chuyển. Trong khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 15,
      "start_timestamp": "0:10:17",
      "end_timestamp": "0:11:04"
    }
  },
  {
    "page_content": "nó đến được cái rảnh này nó di chuyển. Trong khi các cái phương pháp cải tiến khác thì nó cũng bị cái hiện tượng là dao động qua lại rất là nhiều. Nó bị hiện tượng dao động qua lại, bật và bật lại. Còn Adam là cái đường màu vàng thì nó sẽ rớt thẳng xuống luôn. Nó sẽ đi theo cái đường cập nhật hoàn hảo, cái đường cập nhật mà tối ưu ở đây. Bên phải thì đó là cái sơ đồ về giá trị của hàm loss khi chúng ta sử dụng các thuật toán khác nhau. Thì Adam là cái đường màu tím, nó cho cái giá trị hàm loss",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 16,
      "start_timestamp": "0:10:57",
      "end_timestamp": "0:11:32"
    }
  },
  {
    "page_content": "là cái đường màu tím, nó cho cái giá trị hàm loss hội tụ nhanh hơn và nó thấp nhất. Loss càng thấp càng tốt, thì training loss của mình càng thấp càng tốt. Thì chúng ta thấy là nó hội tụ nhanh hơn nhiều so với lại các thuật toán như là Root Mean Square, AdaDelta, AdaGrad v.v. Thì kết luận đó là một số cái phương pháp tối ưu, mô hình học sâu bằng cách. Trong cái phần này thì chúng ta đã được thảo luận qua những cái cách để mà tùy chỉnh learning rate cho từng cái tham số. Và thuật toán, câu hỏi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 17,
      "start_timestamp": "0:11:23",
      "end_timestamp": "0:12:07"
    }
  },
  {
    "page_content": "rate cho từng cái tham số. Và thuật toán, câu hỏi là thuật toán nào sẽ được chọn khi muốn luyện? Thì câu trả lời đó là không chắc chắn. Nó sẽ tùy thuộc vào cái dữ liệu của các bạn như thế nào. Nó phụ thuộc vào cái mô hình của mình nó có phức tạp hay không? Ví dụ, đối với những cái mô hình phức tạp mà nhiều tham số, thì khi đó chúng ta sẽ phải dùng các cái thuật toán ví dụ như là Root Mean Square Propagation, hoặc là Adam. Nhưng đối với những cái mô hình mà ít tham số, thì khi đó Adam và Root",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 18,
      "start_timestamp": "0:12:03",
      "end_timestamp": "0:12:37"
    }
  },
  {
    "page_content": "mô hình mà ít tham số, thì khi đó Adam và Root Mean Square là không cần thiết. Mà chúng ta chỉ cần Stochastic Gradient Descent là đủ. Rồi nếu mà dữ liệu của mình không quá phức tạp, thì chúng ta có thể dùng Stochastic Gradient Descent. Nhưng nếu mà phức tạp thì chúng ta sẽ dùng hai cái thuật toán bên đây. Thì đa số các cái thuật toán đều có cái sự phổ biến nhất định của mình. Và được lựa chọn tùy theo cái sự quen thuộc của người dùng. Như vậy thì đến đây chúng ta đã tìm hiểu qua hai cái biến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 19,
      "start_timestamp": "0:12:32",
      "end_timestamp": "0:12:43"
    }
  },
  {
    "page_content": "thì đến đây chúng ta đã tìm hiểu qua hai cái biến thể rất là nổi tiếng của Adaptive Learning Rate, đó là Root Mean Square Propagation và Adam. Thì cái Root Mean Square Propagation, nó là một cái tiền đề để cho Adam có thể cải tiến. Và Adam nó có một cái cải tiến khá là quan trọng, đó là chuẩn hóa để giúp cho những cái bước cập nhật đầu tiên của mình nó không quá chậm. Và đây chính là những cái thuật toán Optimizer được sử dụng trong rất nhiều những cái mô hình học sâu, những cái mô hình mà dựa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 20,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cái mô hình học sâu, những cái mô hình mà dựa trên Gradient về sau. Và nó sẽ là tiền đề cho chúng ta đi tiếp.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=3TT7y2Nz-vc",
      "filename": "3TT7y2Nz-vc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Vậy thì bây giờ chúng ta sẽ lấy một cái ví dụ có tính chất số học để cho các bạn có thể dễ dàng tính toán thử nghiệm. Còn ví dụ ở trên thì nó mang tính chất về lý thuyết. Ở đây chúng ta sẽ chọn ra m và n là hai con số đủ nhỏ để chúng ta có thể tính tay một cách dễ dàng. Còn một cách tổng quát thì ở trong slide trước chúng ta đã đề cập rồi. Ví dụ như ở đây m là bằng 2, như vậy là mô hình của mình sẽ bao gồm có m cộng 1 tham số, đó là theta 0, theta 1 và theta 2. Và giả sử cái số mẫu dữ liệu train",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:03"
    }
  },
  {
    "page_content": "1 và theta 2. Và giả sử cái số mẫu dữ liệu train của chúng ta là chỉ có n bằng 2, tức là chỉ có hai mẫu thôi, thì khi đó là n sẽ bé hơn m cộng 1, tại vì 2 thì bé hơn 2 cộng 1 là bằng 3. Và giả sử như cái hai cái mẫu dữ liệu này chúng ta có là đây là x thứ nhất, đây là x thứ hai, rồi đây là y thứ nhất và đây là y thứ hai, thì chúng ta có hai mẫu dữ liệu. X1, Y1, X2, Y2, thì đồng thời chúng ta sẽ có một cái mẫu dữ liệu test sau khi huấn luyện mô hình, thì chúng ta chỉ được phép sử dụng cái dữ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:45",
      "end_timestamp": "0:01:38"
    }
  },
  {
    "page_content": "hình, thì chúng ta chỉ được phép sử dụng cái dữ liệu Xtest và Ytest này sau khi huấn luyện xong thôi. Cái này sẽ không tham gia vào cái quá trình huấn luyện. Về nguyên tắc là chúng ta không được phép cho tập test tham gia vào huấn luyện. Thì từ cái dữ liệu train chúng ta đã có ở đây, đây là dữ liệu train. Chúng ta sẽ thế vào cái mô hình của mình, thì trong cái mô hình ở trên đây, đó là một cái công thức tuyến tính, thì khi thế vào chúng ta sẽ có theta 0 trừ 1, tức là trừ theta 1. Thế là 1, 1,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:22",
      "end_timestamp": "0:02:33"
    }
  },
  {
    "page_content": "theta 0 trừ 1, tức là trừ theta 1. Thế là 1, 1, tức là cộng cho theta 2 và tất cả là bằng 1, thì số 1 ở đây. Rồi, cái phương trình thứ 2 đó là theta 0 cộng cho 2 theta 1 và trừ theta 2 và tất cả sẽ là bằng 2. Thế thì đây là một cái hệ phương trình ba ẩn nhưng mà chỉ có hai phương trình thôi. Thế thì sau khi chúng ta tìm cách chúng ta giải cái hệ phương trình này và rõ ràng cái hệ phương trình này là có vô số nghiệm. Nhưng khi chúng ta huấn luyện cái mô hình xong thì chúng ta chỉ được phép chọn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:20",
      "end_timestamp": "0:03:03"
    }
  },
  {
    "page_content": "cái mô hình xong thì chúng ta chỉ được phép chọn ra đúng một bộ tham số của mình, sao cho nó tối ưu nhất. Vì vậy, thì giả sử chúng ta có cái bộ tham số là theta 0 là bằng 0, theta 1 là bằng 3 và theta 2 là bằng 6, thì chúng ta dễ dàng thế được cái bộ 3 cái giá trị này vào cái công thức ở trên thì nó đúng cho cả hai phương trình. Ví dụ với theta 0 là bằng 0, rồi thì ở đây sẽ là trừ theta 1, tức là trừ 3 cộng cho theta 2 là bằng 4, thì nó đúng là bằng 1. Tương tự như vậy cho cái phương trình số 2",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:02:56",
      "end_timestamp": "0:03:54"
    }
  },
  {
    "page_content": "1. Tương tự như vậy cho cái phương trình số 2 khi chúng ta thế vào, 0 cộng cho 2 nhân 3 là bằng 6, trừ cho 4, thế theta 2 là bằng 4, là bằng 2. Ví dụ như vậy là cái phương trình này cũng đúng, như vậy thì khi thế vào cái tập train, khi thế vào cái mô hình chúng ta đã chọn ra ở đây vào tập train, thì chúng ta đúng 2 trên 2 mẫu, tức là đúng 100%. Đây là một cái biểu hiện đầu tiên của overfitting, đó chính là độ chính xác trên tập train rất cao. Nhưng khi chúng ta lấy cái bộ tham số của mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:03:44",
      "end_timestamp": "0:04:38"
    }
  },
  {
    "page_content": "Nhưng khi chúng ta lấy cái bộ tham số của mô hình này thế vào cái mẫu dữ liệu test, thì chúng ta thấy nó không có đúng nữa. Tại vì sao? Tại vì khi thế vào thì chúng ta sẽ có là 0 cộng cho 3 nhân với lại 2 là bằng 6, cộng cho theta 2 là bằng 4, thì là 6 cộng 4 là bằng 10, rõ ràng là nó khác 3. Do đó thì tập dữ liệu test của mình là sai và chúng ta hoàn toàn có thể ngẫu nhiên chọn ra các mẫu test khác, thì cái xác suất để mà cái nghiệm này nè, cái nghiệm mà chúng ta đã huấn luyện, đã tìm ra được",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:04:20",
      "end_timestamp": "0:05:25"
    }
  },
  {
    "page_content": "nghiệm mà chúng ta đã huấn luyện, đã tìm ra được với chỉ có 2 phương trình thì xác suất của nó, đúng cái mẫu dữ liệu test là cực kỳ thấp. Như vậy thì ở đây là chúng ta đúng 0%. Như vậy thì tập Train thì đúng đến 100% rất cao nhưng mà cái tập Test thì chỉ có 0% thôi, tức là rất thấp. Thì đây chính là cái hiện tượng Overfit, nó Overfit trên tập Train. Thì hy vọng là qua cái ví dụ này chúng ta có thể hình dung được cái hiện tượng Overfitting là gì, và một cái ví dụ minh họa cũng như là sử dụng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:05:14",
      "end_timestamp": "0:06:05"
    }
  },
  {
    "page_content": "gì, và một cái ví dụ minh họa cũng như là sử dụng kiến thức toán cấp 3 để hình dung cái hiện tượng Overfitting. Thế thì nguyên nhân và giải pháp thì nguyên nhân của cái hiện tượng Overfitting này chính là cái số tham số của mình nó quá nhiều. Cụ thể trong cái ví dụ trước là chúng ta có 3 tham số nhưng cái số mẫu chúng ta lưu ý là ở đây phải có mệnh đề và, nó nhiều nhưng mà đồng thời là cái số mẫu dữ liệu của mình nó phải ít. Thì ở đây là 3 tham số nhưng mà chỉ có 2 mẫu dữ liệu. Thì đây là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:05:52",
      "end_timestamp": "0:06:46"
    }
  },
  {
    "page_content": "số nhưng mà chỉ có 2 mẫu dữ liệu. Thì đây là cái vấn đề xảy ra đồng thời là và. Ví dụ vừa rồi nó đã nêu một cái tình huống là xảy ra đồng thời là số tham số và nhiều hơn số mẫu. Vậy thì giải pháp đó là gì? Chúng ta sẽ có thể tiếp cận một cách trực tiếp hoặc gián tiếp để giải quyết cái hiện tượng Overfitting. Và chúng ta sẽ làm như sau. Vì cái tham số nhiều nên ở đây chúng ta sẽ tìm cách giảm số tham số xuống. Hay nói cách khác đó là chúng ta làm cho mô hình của mình đơn giản hơn. Đơn giản hóa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:06:39",
      "end_timestamp": "0:07:31"
    }
  },
  {
    "page_content": "cho mô hình của mình đơn giản hơn. Đơn giản hóa mô hình. Và cái nguyên nhân đó là do dữ liệu của mình nó ít. Thì bây giờ chúng ta sẽ tìm cách là đẩy cái dữ liệu lên, tăng cái số mẫu dữ liệu huấn luyện. Ở đây chúng ta sẽ là bổ sung thêm dữ liệu. Và ở đây chúng ta sẽ dùng cái mệnh đề hoặc. Tức là dùng một trong hai cách. Ở trên là và, ở dưới là hoặc. Và một số kỹ thuật cụ thể, ví dụ như là Dropout, Regularization, tăng cường. Sửa lỗi Regularization là chính quy hóa và tăng cường dữ liệu. Thì đối",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:07:26",
      "end_timestamp": "0:08:08"
    }
  },
  {
    "page_content": "là chính quy hóa và tăng cường dữ liệu. Thì đối với kỹ thuật Regularization thì cái hàm lỗi của mình là bên cạnh cái sai số giữa giá trị dự đoán và cái giá trị ground truth thì chúng ta có thể bổ sung thêm thành phần chính quy hóa. Trong cái công thức hàm lỗi ở đây chúng ta thấy loss của y, ngã và y, đây chính là cái sai số giữa giá trị dự đoán và ground truth. Và thành phần chính quy hóa mà chúng ta đang muốn đề cập chính là ở đây. Thì cái mục tiêu của chúng ta thêm cái thành phần chính quy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "0:08:00",
      "end_timestamp": "0:08:38"
    }
  },
  {
    "page_content": "tiêu của chúng ta thêm cái thành phần chính quy hóa này đó là gì? Thì khi quá trình huấn luyện chúng ta tìm min, tìm min của z, tức là chúng ta đang muốn cái giá trị này nó giảm xuống. Thì bên cạnh là cái loss giảm, tức là cái sai số giữa y và y, ngã nó giảm. Thì đồng thời, đây là dấu cộng, là đồng thời chúng ta cũng sẽ cho cái thành phần chính quy này giảm xuống luôn. Mà khi cái thành phần chính quy này giảm xuống thì điều này có nghĩa là gì? Đó là cái theta y của mình nó sẽ giảm xuống. Và cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:08:28",
      "end_timestamp": "0:09:23"
    }
  },
  {
    "page_content": "là cái theta y của mình nó sẽ giảm xuống. Và cái hàm bình phương này, cái hàm theta y bình phương này mà đạt được giá trị nhỏ nhất khi theta y của mình nó tiến đến 0. Mà khi theta y của mình nó tiến đến 0, tức là nó khuyến khích mô hình giảm bớt tham số một cách gọi là không tường minh, giảm bớt. Tham số. Thế thì một cái tham số mà được gắn bằng 0, tức là cái trọng số này là gần như không đáng kể, và không có ảnh hưởng đến cái mô hình của mình, không tham gia vào cái quyết định, dự đoán của mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:09:17",
      "end_timestamp": "0:09:54"
    }
  },
  {
    "page_content": "không tham gia vào cái quyết định, dự đoán của mô hình của mình. Thì đây là cái cách thức giảm bớt tham số một cách không tường minh. Bên cạnh cái hướng tiếp cận đó là giảm một cách tường minh. Đó là chúng ta sẽ nghiên cứu về mặt mô hình làm sao đó, để cho theta y của mình giảm bớt số lượng theta y. Còn ở đây giả sử chúng ta có số lượng theta y là bằng m cộng một. Thì ở đây là chạy từ 0 cho đến m. Thì ở đây là chúng ta có m cộng một tham số, thì chúng ta không giảm xuống là một con số nhỏ hơn,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "0:09:49",
      "end_timestamp": "0:10:35"
    }
  },
  {
    "page_content": "chúng ta không giảm xuống là một con số nhỏ hơn, Thì ở đây là chúng ta có m cộng một tham số, thì chúng ta không giảm xuống là một con số nhỏ hơn, một cách tường minh chúng ta sẽ thêm cái thành phần Regularization này, để khi mà tối ưu cái mô hình này xong, thì đâu đó sẽ có các tham số theta y tiến về 0. Thì một số cái mô hình trong hồi quy có sử dụng cái thành phần Regularization và hướng đến cái việc là theta y tiến giảm về 0, đó chính là mô hình Lasso. Thì đây là một trong những mô hình rất",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": "0:10:27",
      "end_timestamp": "0:11:08"
    }
  },
  {
    "page_content": "Lasso. Thì đây là một trong những mô hình rất là nổi tiếng dùng trong cái việc đó là giảm bớt cái độ phức tạp của mô hình. Như vậy, bản chất ở đây chính là chúng ta đã ngầm giảm tham số của mô hình, hay nói cách khác đó là giảm một cách không tường minh. Kỹ thuật tiếp theo đó là Dropout. Thì tại một cái vòng lặp huấn luyện, ví dụ chúng ta set một cái mạng Neural Network, thì chúng ta sẽ loại bỏ bớt một số Neuron và không tham gia vào quá trình huấn luyện. Bên trái là một cái mạng Neural Network",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 16,
      "start_timestamp": "0:11:01",
      "end_timestamp": "0:11:39"
    }
  },
  {
    "page_content": "luyện. Bên trái là một cái mạng Neural Network đầy đủ, nhưng mà khi huấn luyện, đây là khi huấn luyện thôi. Chúng ta bỏ bớt hai cái Neuron này, và khi chúng ta bỏ bớt hai Neuron này thì vô hình chung các cái trọng số, tức là các cái cạnh nối đến các cái Neuron này cũng được loại bỏ đi. Thì chúng ta thấy là so với lại cái mô hình bên trái thì cái số lượng tham số khi chúng ta huấn luyện, khi chúng ta huấn luyện tại cái thời điểm này là ít hơn hẳn so với lại cái mạng Neural Network. Thì đây cũng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 17,
      "start_timestamp": "0:11:33",
      "end_timestamp": "0:12:16"
    }
  },
  {
    "page_content": "so với lại cái mạng Neural Network. Thì đây cũng là một cái kỹ thuật mà chúng ta ngầm giảm bớt cái số lượng tham số đi. Bản chất là chúng ta đã ngầm thực hiện cái việc này. Và lưu ý là cái cách này là chúng ta chỉ thực hiện khi quá trình huấn luyện thôi, nhưng mà sau khi huấn luyện xong, chúng ta sẽ hoàn trả lại cái mô hình của mình đúng với các cái trọng số này. Với mỗi một cái iteration thì chúng ta sẽ ngẫu nhiên chọn ra một vài cái Neuron, thì cái việc này sẽ giúp cho chúng ta không có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 18,
      "start_timestamp": "0:12:11",
      "end_timestamp": "0:12:50"
    }
  },
  {
    "page_content": "thì cái việc này sẽ giúp cho chúng ta không có khuyến khích mô hình học thuộc. Không khuyến khích mô hình học thuộc. Tại vì nếu như chúng ta để nguyên cái số tham số này, thì nó cứ lặp đi lặp lại các cái mẫu đó thì nó sẽ học thuộc. Còn vô tình chúng ta bỏ cái Neuron này ra thì nó sẽ không có phụ thuộc vào hai cái Neuron này. Tại vì hai cái Neuron này có khả năng là hai cái Neuron là phụ trách cái việc học thuộc. Và kỹ thuật cuối cùng đó là tăng cường dữ liệu. Đây là một kỹ thuật rất là nổi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 19,
      "start_timestamp": "0:12:45",
      "end_timestamp": "0:13:26"
    }
  },
  {
    "page_content": "cường dữ liệu. Đây là một kỹ thuật rất là nổi tiếng và nó đơn giản. Nó rất là đơn giản. Tại vì nó dễ thực hiện. Nhưng mà cái gì đơn giản thì nó sẽ có cái mặt hạn chế của nó, đó là cái chi phí cao. Cái chi phí nó cao. Nếu chúng ta thu thập bằng tay thì có thể chúng ta sẽ phải tốn cái chi phí để thuê người gán nhãn. Trong hai cái lĩnh vực xử lý hình ảnh và văn bản, chúng ta có hai cái kỹ thuật tăng cường dữ liệu. Một đó là đối với hình ảnh thì chúng ta có thể sử dụng các phép biến đổi. Ví dụ như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 20,
      "start_timestamp": "0:13:16",
      "end_timestamp": "0:13:56"
    }
  },
  {
    "page_content": "ta có thể sử dụng các phép biến đổi. Ví dụ như là thay đổi cái texture, giảm bớt cái texture của đối tượng đi, loại bỏ đi cái yếu tố màu sắc để ra cái ảnh mức xám. Rồi chúng ta tăng cường cái biên cạnh lên. Hoặc là chúng ta lấy cái salient, tức là những cái biên cạnh mà nổi bật nhất. Hoặc là chúng ta làm các cái thao tác là transformation. Tức là cái thao tác biến đổi về mặt hình học, như flip, quay, tỷ lệ, tịnh tiến, v.v. Từ đó, từ một ảnh mức xám, thì từ một ảnh chúng ta sẽ tạo ra N ảnh và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 21,
      "start_timestamp": "0:13:50",
      "end_timestamp": "0:14:36"
    }
  },
  {
    "page_content": "xám, thì từ một ảnh chúng ta sẽ tạo ra N ảnh và cái N ảnh này thì N ảnh phiên bản khác nhau. Còn đối với lĩnh vực về xử lý ngôn ngữ tự nhiên, thì chúng ta cũng có một số kỹ thuật. Trong đó đơn giản và dễ hiểu nhất đó chính là kỹ thuật Back Translation. Tức là với cái văn bản gốc, thì chúng ta chuyển nó dịch nó sang cái ngôn ngữ khác. Thí dụ như là tiếng Anh, sau đó chúng ta dịch ngược trở lại, sang trở lại tiếng Anh. Thì từ tiếng Anh sang tiếng Pháp, xong rồi từ tiếng Pháp dịch ngược lại tiếng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Pháp, xong rồi từ tiếng Pháp dịch ngược lại tiếng Anh, thì chúng ta đã có một cái phiên bản mới. Đây là một cái phiên bản mới cho cái ngôn ngữ của mình. Như vậy là trong bài này chúng ta đã cùng tìm hiểu về nguyên lý của hiện tượng Overfitting và nguyên lý của cái việc là chống lại cái hiện tượng Overfitting. Đó là giảm tham số xuống hoặc là chúng ta giảm cái độ phức tạp của mình xuống và tăng cường cái dữ liệu lên. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=5Wpw2EsSz40",
      "filename": "5Wpw2EsSz40",
      "title": "[CS315 - Chương 2] Overfitting (Phần 2)",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Trong phần tiếp theo, chúng ta sẽ cùng trực quan hóa quá trình thuật toán này đã chạy như thế nào Đầu tiên chúng ta sẽ tiến hành vẽ hàm số Để vẽ đồ thị hàm số, chúng ta phải dùng một thư viện, đó là matplotlib.pyplot.plt Sau đó chúng ta sẽ khởi tạo các giá trị theo trục hoành và trục tung Để khởi tạo các giá trị theo trục hoành, chúng ta không sử dụng lại biến theta nữa, tại vì đó là tham số của một mô hình cần huấn luyện Chúng ta chỉ cần lấy một cái biến x là bằng np.arange, chúng ta sẽ cho nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:08"
    }
  },
  {
    "page_content": "cái biến x là bằng np.arange, chúng ta sẽ cho nó chạy từ trừ 10 cho đến 10 và có thể bước nhảy đó là 0.5 Sau đó chúng ta sẽ chạy plt.plot.x và J của x Sau đó là plt.show, bây giờ chúng ta sẽ xem thử chương trình này chạy như thế nào Chúng ta thấy nó đã bị lệch đi một phần, để cho nó cân đối hơn, chúng ta sẽ cho giá trị bên phải là 13 hoặc là 12 để cho nó trùng với giá trị Bây giờ chúng ta sẽ lưu lại và chạy, nó đã cân đối hơn Bây giờ chúng ta sẽ vẽ điểm theta lên trên đồ thị Lưu ý, khi chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:56",
      "end_timestamp": "0:02:16"
    }
  },
  {
    "page_content": "vẽ điểm theta lên trên đồ thị Lưu ý, khi chúng ta vẽ điểm này, chúng ta sẽ dùng một cái màu khác, chúng ta sẽ dùng một cái điểm màu đỏ và ký hiệu điểm này sẽ là một dấu chấm, chúng ta sẽ để chữ o, chúng ta sẽ lưu và chạy Thì nó đã vẽ được tham số chúng ta khởi tạo là bằng 12 Bây giờ chúng ta sẽ trực quan hóa, trong vòng lặp cập nhật theta này, cứ mỗi lần cập nhật theta mới chúng ta sẽ vẽ đồ thị và điểm theta của mình lên Thế thì ở đây chúng ta sẽ đóng gói cái này lại thành một cái hàm, đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:02:02",
      "end_timestamp": "0:03:09"
    }
  },
  {
    "page_content": "sẽ đóng gói cái này lại thành một cái hàm, đó là plot J Sau đó chúng ta sẽ đưa toàn bộ cái này vào bên trong cái hàm plot J Theta ở đây thì đang để là tham số toàn cục, chúng ta sẽ cục bộ hóa nó bằng cách truyền một cái biến theta và nó sẽ lấy từ cái biến từ bên ngoài truyền vào để cho nó tổng quát Sau đó chúng ta sẽ trực quan hóa là gọi hàm plot J, chúng ta sẽ truyền biến theta vào và lưu rồi chạy Thế thì ở đây khi chúng ta vào trong vòng lặp, nó đã vẽ lên, chúng ta đóng cái cửa sổ này lại Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:03:00",
      "end_timestamp": "0:03:49"
    }
  },
  {
    "page_content": "đã vẽ lên, chúng ta đóng cái cửa sổ này lại Thì nó sẽ mở cửa sổ mới để vẽ những cái điểm tiếp theo, thực hiện vòng lặp Như vậy thì nó sẽ hơi bị mất công, do đó chúng ta sẽ không có dùng cái hàm PLT show mà chúng ta sẽ cho nó tạm dừng thôi, tạm dừng khoảng 0.5 giây, chúng ta dùng cái hàm pause Sau đó chúng ta lưu lại và chạy Thế thì nó đã tạo ra được cái animation rồi, tuy nhiên mỗi lần lặp thì cái đường này đã dùng một cái màu mới Do đó để cố định nó, chúng ta sẽ dùng một cái màu đó là màu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:03:43",
      "end_timestamp": "0:04:30"
    }
  },
  {
    "page_content": "định nó, chúng ta sẽ dùng một cái màu đó là màu xanh, là B Thế thì ở đây chúng ta vẽ đường nên chúng ta sẽ không có cái ký hiệu của thứ hai giống như ở bên dưới, ở bên dưới là chúng ta chỉ vẽ một điểm thôi, đó là ro Còn ở phía trên chúng ta vẽ đường nói tiếp nhau, do đó chúng ta để cái tham số là B, tức là blue Rồi, và bây giờ chúng ta sẽ chạy Thì quan sát cái kết quả chúng ta thấy là Ban đầu chúng ta thấy là vì cái độ dốc của cái hàm của mình đó rất là cao Thì khi đó cái điểm màu đỏ của mình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:04:25",
      "end_timestamp": "0:05:02"
    }
  },
  {
    "page_content": "đó rất là cao Thì khi đó cái điểm màu đỏ của mình nó rớt xuống rất là nhanh Cái điểm màu đỏ rớt xuống, các bạn thấy là cái khoảng cách này rất là dài Nhưng mà càng xuống dưới các bạn thấy là cái khoảng cách bắt đầu càng nhỏ dần Và đến đây là nó chi chít các điểm luôn, thì nguyên nhân đó là do đâu? Nguyên nhân đó là vì khi chúng ta càng xuống dưới điểm cực tiểu cục bộ Thì cái giá trị đạo hàm của mình nó sẽ càng lúc càng tiến về 0 Tại vì nó càng lúc nó càng song song với lại cái trục hoành Đúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:04:57",
      "end_timestamp": "0:05:34"
    }
  },
  {
    "page_content": "lúc nó càng song song với lại cái trục hoành Đúng không? Ban đầu nó ở trên nó rất là dốc, nhưng mà xuống dưới nó bớt dốc đi Nên cái việc cập nhật của mình cũng sẽ chậm hơn Tại vì trong cái công thức của mình thì chúng ta thấy đó là Chúng ta sẽ phải đi tính đạo hàm Mà đạo hàm càng xuống dưới càng nhỏ, tức là cái biến derivative này càng nhỏ Biến derivative này càng nhỏ thì dẫn đến theta Sẽ là bằng theta trừ cho cái đại lượng rất là nhỏ Thì dẫn đến đó là nó sẽ cập nhật rất là chậm Thì đó chính là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:05:29",
      "end_timestamp": "0:06:04"
    }
  },
  {
    "page_content": "đó là nó sẽ cập nhật rất là chậm Thì đó chính là cái đặc điểm của Gradient Descent khi mà nó càng tiến gần đến Cái điểm cực tiểu cục bộ Và đó cũng là cái lý do khiến cho cái thuật toán của mình Thuật toán của mình nó sẽ không thoát ra khỏi được cái điểm cực tiểu Do đó để giải quyết vấn đề này thì chúng ta sẽ dùng thuật toán momentum",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=6VIywjiErJs",
      "filename": "6VIywjiErJs",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Vấn đề tiếp theo thì chúng ta sẽ bàn về độ phân giải. Do sao thì các mô hình tạo sinh ảnh nếu mà muốn có ứng dụng được thì nó phải có thể tạo ra được những cái ảnh mà có kích thước lớn. Vậy thì với mô hình cascade diffusion thì chúng ta sẽ denoise, chúng ta thêm nhiễu rồi sau đó chúng ta sẽ khử nhiễu ở trên cùng một độ phân giải khác nhau. Ví dụ như ở đây chúng ta thấy là đây là mô hình diffusion gốc, thì kích thước của noise của mình đúng bằng kích thước của ảnh mà chúng ta sẽ decode. Và cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:04"
    }
  },
  {
    "page_content": "kích thước của ảnh mà chúng ta sẽ decode. Và cái quá trình mà chúng ta huấn luyện mô hình thì đây là một cái mô hình để mà tạo ra một cái ảnh với điều kiện cho trước là cái Y. Và cái này nó sẽ được thực hiện đi, thực hiện lại là T, 1 bước. Và khi sang cái mô hình cascade diffusion mode thì chúng ta không chỉ text-to-image diffusion, tức là đây là cái mô hình gốc ban đầu nè. Nó sẽ có kết hợp với các mô hình để thực hiện việc super resolution, tức là tăng kích độ phân giải lên. Và ở trong hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:40"
    }
  },
  {
    "page_content": "là tăng kích độ phân giải lên. Và ở trong hình bên dưới chúng ta thấy đó là ban đầu cái ảnh của mình nó sẽ có kích thước là 64 x 64. Và đây là cái mô hình diffusion gốc. Sau khi chúng ta kết thúc text-to-image diffusion, nó sẽ tạo ra tấm hình giống như thế này. Thì chúng ta sẽ train một cái mô hình super resolution thứ 2 để tăng kích thước của tấm ảnh lên. Và nó đã tăng lên 256 x 256. Rồi sau đó chúng ta lại tiếp tục chạy qua một cái mô hình super resolution diffusion mode để tăng lên là 1024 x",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 2,
      "start_timestamp": "0:01:32",
      "end_timestamp": "0:02:24"
    }
  },
  {
    "page_content": "resolution diffusion mode để tăng lên là 1024 x 1024. Như vậy thì với cái mô hình cascade diffusion này chúng ta thấy, đó là cái quá trình huấn luyện này là nó độc lập nhau. Text-to-image và super resolution diffusion 1 và 2 thì không có, nói chung là huấn luyện độc lập với nhau. Và nó không có end to end, tức là không có huấn luyện từ đầu đến cuối. Và nó sẽ dễ gây ra cái hiện tượng đó là lan truyền lỗi. Ví dụ điều gì xảy ra nếu như cái ảnh 64 x 64 này nó có những cái artifact, tức là những cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 3,
      "start_timestamp": "0:02:17",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "64 này nó có những cái artifact, tức là những cái dấu hiệu để mà không có được đẹp và có những cái lỗi trong hình ảnh. Vì vậy thì nó sẽ lan truyền cái lỗi đó đến những cái ảnh sau mà không có cái cơ chế, nó không có cơ chế để sửa lỗi. Thế thì cái mô hình này cascade diffusion này thì nó sẽ không có phù hợp để mà có thể ứng dụng được. Lý do đó là vì thứ nhất là nó sẽ lan truyền lỗi. Cái thứ hai đó là cái sự cồng kềnh. Mình mong muốn khi setup thì nó sẽ chỉ có duy nhất một mô hình thôi, còn ở đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 4,
      "start_timestamp": "0:02:56",
      "end_timestamp": "0:03:40"
    }
  },
  {
    "page_content": "nó sẽ chỉ có duy nhất một mô hình thôi, còn ở đây nó có đến 3 cái mô hình thực hiện cùng một lúc. Như vậy thì chúng ta sẽ sang một cái phiên bản tiếp theo để có thể giải quyết được cái mô hình, cái điểm yếu của mô hình cascade diffusion này. Đó chính là cái mô hình latent diffusion. Thì latent diffusion là chúng ta sẽ thực hiện cái diffusion, chúng ta thực hiện cái bước là denoise và add noise ở trên cái không gian latent. Thì đầu tiên chúng ta train một cái mô hình VAE để ánh xạ từ cái ảnh có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 5,
      "start_timestamp": "0:03:32",
      "end_timestamp": "0:04:28"
    }
  },
  {
    "page_content": "train một cái mô hình VAE để ánh xạ từ cái ảnh có độ phân giải cao ví dụ như là 1024 về cái không gian latent z của mình, ví dụ như là 64 x 64. Rồi, sau đó với cái độ phân giải thấp này, cái ảnh độ phân giải thấp này chúng ta sẽ decode ra để tạo ra cái ảnh gốc. Và chúng ta sẽ có một cái reconstruction loss, tức là cái loss để kiểm tra xem cái ảnh chúng ta tái tạo có giống với ảnh ban đầu hay không. Rồi sau đó chúng ta cũng sẽ có cái phần regularization loss để cho cái latent z này nó tuân theo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 6,
      "start_timestamp": "0:04:21",
      "end_timestamp": "0:05:04"
    }
  },
  {
    "page_content": "loss để cho cái latent z này nó tuân theo một cái phân bố là, tuân theo một cái prior distribution mong muốn, ví dụ như là phân bố Gauss. Ngoài ra thì còn có thêm cái adversarial loss của gan để giúp cho chúng ta có thể tạo ra những cái tấm ảnh có chất lượng cao với độ sắc nét chi tiết. Và chúng ta sẽ sử dụng cái mô hình VAE này để là cái bước đầu tiên để nén, chúng ta sẽ nén cái ảnh x này qua VAE encoder. Chúng ta sẽ tạo ra cái vector latent z, sau đó chúng ta sẽ áp dụng cái mô hình diffusion",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 7,
      "start_timestamp": "0:04:51",
      "end_timestamp": "0:05:57"
    }
  },
  {
    "page_content": "sau đó chúng ta sẽ áp dụng cái mô hình diffusion trên chính cái không gian latent này, thay vì trên không gian gốc chúng ta sẽ tạo ra d, đây là d, d1 hoặc là d0 đi ha, d2, rồi cho đến dt, thì đây là cái quá trình encode. Sau đó chúng ta sẽ tiến hành là decode là từ dt, denoise ra dt trừ 1 v.v. về d0 mũ, và với d0 mũ này sau đó chúng ta áp dụng cái decoder của VAE, thì nó đã tạo ra một cái tấm hình, giống như ở đây, thì đây là cái cách thức để chúng ta huấn luyện một cái mô hình latent",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 8,
      "start_timestamp": "0:05:47",
      "end_timestamp": "0:06:47"
    }
  },
  {
    "page_content": "để chúng ta huấn luyện một cái mô hình latent diffusion. Cái ý tưởng lớn nhất của cái latent diffusion này, thứ nhất đó là một cái end-to-end model. Và cái thứ hai, đó là thay vì chúng ta diffusion, chúng ta encode và decode hoặc là chúng ta add noise hoặc denoise ha, encode và decode. Nhưng chúng ta không làm trên không gian ảnh mà chúng ta làm trên không gian latent. Mà không gian latent thì chúng ta biết rằng cái kích thước của nó bé hơn rất nhiều so với lại cái không gian của cái ảnh gốc,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 9,
      "start_timestamp": "0:06:35",
      "end_timestamp": "0:07:22"
    }
  },
  {
    "page_content": "nhiều so với lại cái không gian của cái ảnh gốc, do đó thì nó sẽ tiết kiệm được cái chi phí tính toán. Đó là cái đầu tiên chúng ta có thể thấy chi phí tính toán. Và trong cái không gian nhỏ hơn thì chúng ta sẽ tiết kiệm được cái số tham số. Và khi chúng ta tiết kiệm được số tham số thì nó sẽ đỡ được cái hiện tượng overfitting. Và huấn luyện nó cũng sẽ ổn định hơn. Thì đó chính là cái điều khiến cho latent diffusion model là một trong những cái mô hình tạo sinh hình ảnh mà được rất nhiều cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 10,
      "start_timestamp": "0:07:12",
      "end_timestamp": "0:07:29"
    }
  },
  {
    "page_content": "mô hình tạo sinh hình ảnh mà được rất nhiều cái trích dẫn và được rất nhiều các cái bài báo cũng như là các cái nghiên cứu gần đây họ sử dụng để phát triển.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=79WZow7G8fE",
      "filename": "79WZow7G8fE",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 7",
      "chunk_id": 11,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "VGG đã có những cải tiến gì? so với AlexNet đó là thay thế các cái filter có kích thước lớn ví dụ như là 5577 trở lên bằng các cái bộ lọc 3x3 được thực hiện một cách liên tiếp thì như đã nói trong phần trước là việc thực hiện các cái bộ lọc 33 liên tiếp thì nó sẽ có cái receptive field tương ứng với lại các cái vùng là 5x5 hoặc là 7x7 sau đó thì VGG thì ta tìm cách vì việc thay các kernel kích thước là 5 x 5 và 7 x 7 bằng các kernel có kích thước là 3 x 3 liên tiếp thì dẫn đến là nó sẽ khiến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:00"
    }
  },
  {
    "page_content": "là 3 x 3 liên tiếp thì dẫn đến là nó sẽ khiến mạng của mình sẽ sâu hơn khi mạng của mình càng sâu hơn thì các tác giả mới nhận thấy rằng là từ VGG 11 tăng lên VGG 13 Độ chính xác tăng lên, lên VGG16 độ chính xác tăng lên, đến 19 thì cũng vậy. Tuy nhiên nó sẽ có vấn đề đó là sự tăng này dần bão hòa. Vì việc dần bão hòa có nguyên nhân gì thì chúng ta sẽ cùng giải thích trong phần tiếp theo. Trong sơ đồ này chúng ta thấy là những layer, những đặc trưng mà màu hồng đó là những lần chúng ta down",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:56",
      "end_timestamp": "0:01:48"
    }
  },
  {
    "page_content": "trưng mà màu hồng đó là những lần chúng ta down sampling xuống, pooling để giảm số chiều, giảm kích thước của ảnh xuống và trước đó chúng ta thấy có 2 cái layer liên tiếp, 2 cái layer liên tiếp nó đặt tương đương với lại 1 cái vùng có kích thước là receptive field là 5x5 do chúng ta sử dụng 2 cái filter là 3x3 liên tiếp Sau đó, chúng ta thấy là có vùng là 4 đặc trưng, 1, 2, 3, 4 đặc trưng 3 x 3 liên tiếp Thì như vậy là nó làm cho chúng ta tạo ra các đặc trưng mà có receptive field lớn Để hy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:38",
      "end_timestamp": "0:02:44"
    }
  },
  {
    "page_content": "ra các đặc trưng mà có receptive field lớn Để hy vọng rằng các đặc trưng có thể bao quát trên vùng có diện tích lớn để có tính toàn cục Đó chính là những cải tiến lớn của VGG Rồi, thế thì một cái cải tiến tiếp theo đó chính là ResNet, Residual Network và nó giải quyết cái vấn đề gì của kiến trúc mạng trước đó là VGG đó là khi tăng số layer lên, cụ thể là trên 16 layer thì độ chính xác nó không còn tăng đáng kể Tức là nó có tăng nhưng mà nó tăng không đáng kể và không đáng kể so với lại số lượng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:40",
      "end_timestamp": "0:03:28"
    }
  },
  {
    "page_content": "đáng kể và không đáng kể so với lại số lượng tham số cũng như là công tính toán của mình Thậm chí là khi tăng hơn 20 layer thì nó có dấu hiệu là có thể giảm Vì vậy thì nguyên nhân ở đây là gì? Đó là do hiện tượng tiêu biến đạo hàm mà chúng ta đã đề cập trong những phần trước Khi số lớp biến đổi càng nhiều thì hiện tượng tiêu biến đạo hàm nó sẽ xảy ra càng mạnh mẽ hơn mặc dù là chúng ta đã sử dụng Rectify Linear Unit nhưng đây không phải là một liều thuốc toàn năng mà có thể giải quyết được",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:03:26",
      "end_timestamp": "0:04:13"
    }
  },
  {
    "page_content": "liều thuốc toàn năng mà có thể giải quyết được triệt để vấn đề vanishing gradient tại vì nó vẫn sẽ có... với Rectify Linear Unit tức là của hàm Z, là bằng max của 0 và Z khi đó đạo hàm của Relu, thì nó sẽ hoặc là bằng 0 hoặc là bằng 1 thì một cách trung dung sẽ có những tình huống lớn hơn không sẽ có tình huống bằng 0 hoặc là bằng 1 do đó thì một cách trung dung sẽ là con số ở giữa là khoảng 0.5 Như vậy thì cách làm này nó sẽ còn chưa đạt được một cách triệt để trong việc là cái đạo hàm của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:04:05",
      "end_timestamp": "0:04:59"
    }
  },
  {
    "page_content": "một cách triệt để trong việc là cái đạo hàm của Relu là một cái con số ổn định và con số là hài hòa cân bằng. Thì cái cải tiến lớn nhất của Residual Neural Network, ResNet nó chính là tạo ra các cái nối tắt hay còn gọi là Skip Connection để hạn chế hiện tượng vanishing gradient thì cái này chúng ta đã đề cập ở trong phần vanishing gradient rồi nhờ có cái hàm hx là bằng fx fx này tức là cái thao tác mà rút trích đặc trưng của mình rồi sau đó chúng ta sẽ cộng thêm cho x thì khi chúng ta tính đạo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:04:55",
      "end_timestamp": "0:05:49"
    }
  },
  {
    "page_content": "ta sẽ cộng thêm cho x thì khi chúng ta tính đạo hàm thì nó sẽ là bằng f và x Cộng cho 1, cho dù thành phần này nó có lớn hay nhỏ hơn không, thì khi chúng ta tính một cách trung bình thì h-x này sẽ dao động xoay xung quanh con số 1, nó có thể bên trái và bên phải số 1 nhưng mà một cách trung dung và hài hòa nhất thì nó sẽ xoay xung quanh số 1 dẫn đến ổn định đạo hàm Để ổn định đạo hàm Còn đối với Relu, chúng ta thấy trung dung nhất là 0.5, vẫn là một con số bé hơn 1 Rồi, chúng ta sẽ cùng đến với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:05:39",
      "end_timestamp": "0:06:42"
    }
  },
  {
    "page_content": "một con số bé hơn 1 Rồi, chúng ta sẽ cùng đến với một biến thể nữa, đó là MobileNet MobileNet, khi nói đến từ Mobile này, chúng ta sẽ hình dung ngay là nó nhằm cải tiến tốc độ để hy vọng rằng các mạng convolution neural network có thể chạy được trên các thiết bị di động chạy được trên di động Thế thì làm sao có thể cải tiến được? Đó là do chúng ta phải phân tích vấn đề của nó là nguyên nhân tại sao chúng ta chọn Đó là cùng một receptive field là 3x3xD, nhưng số lượng tham số và tính toán của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:06:30",
      "end_timestamp": "0:07:34"
    }
  },
  {
    "page_content": "là 3x3xD, nhưng số lượng tham số và tính toán của mình là lớn số lượng tham số tính toán và số lượng tham số và số phép toán là lớn MobileNet sẽ thay convolution bằng Depth-wise Separable Convolution DSC Thì Depth-wise Separable Convolution sẽ gồm 2 bước tính toán Bước đầu tiên là Depth-wise thì chúng ta sẽ có một cái filter và chúng ta sẽ thực hiện nó trên toàn bộ cái độ sâu của cái feature này thì chúng ta thấy là khi chúng ta áp dụng cái Depth-wise Convolution thì cái kích thước của cái độ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:28",
      "end_timestamp": "0:08:13"
    }
  },
  {
    "page_content": "Convolution thì cái kích thước của cái độ sâu này không thay đổi thì trước và sau nếu như ở trước là d chiều là có độ sâu ở d thì phía sau độ sâu cũng là d trong khi đó nếu chúng ta áp dụng cái phép biến đổi convolution bình thường thì rõ ràng là nó sẽ đưa về một cái feature map có cái depth là bằng một thì ở đây cái depth này của mình là giữ nguyên depth này là giữ nguyên Còn phép convolution bình thường thì depth của mình nó sẽ đưa về bằng 1 Rồi, thì ở đây chúng ta sẽ thấy có một cái lợi điểm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:08:09",
      "end_timestamp": "0:08:53"
    }
  },
  {
    "page_content": "thì ở đây chúng ta sẽ thấy có một cái lợi điểm nữa đó là số lượng tham số Vì chúng ta thực hiện depth-wise convolution nên cái filter này nó sẽ không có depth Nó không có độ sâu, nó chỉ có kích thước là 3 x 3 thôi, ví dụ vậy Sau khi chúng ta đã thực hiện ra được, tạo ra được các feature map này Thì chúng ta sẽ tiến đến cái bước là Point-wise convolution và chúng ta sẽ stack, chúng ta trồng các feature map này lên và tiến hành 1 nhân 1 convolution nhân với 1 nhân 1 convolution để tạo ra 1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "00:08:38",
      "end_timestamp": "0:09:48"
    }
  },
  {
    "page_content": "nhân với 1 nhân 1 convolution để tạo ra 1 feature map mới thì cái 1 nhân 1 này, bề ngang và bề cao của mình nó sẽ có kích thước là 1 đều có kích thước là 1 nhưng mà cái độ sâu của mình thì lúc này nó sẽ là d thì nếu như chúng ta áp dụng ca cái filter 1x1 convolution thì ở đây depth của mình nó sẽ ra là ca như vậy thì chúng ta sẽ xem giữa 2 cách thì cách thông thường sẽ là đâu đó xấp xỉ Ví dụ như chúng ta cho input là 32 kênh, output là 64 kênh, kernel của mình kích thước là 3 x 3, số tham số sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:09:33",
      "end_timestamp": "0:10:45"
    }
  },
  {
    "page_content": "của mình kích thước là 3 x 3, số tham số sẽ là bao nhiêu? đối với phép Convolution bình thường, chúng ta sử dụng kernel có kích thước 3 x 3 và số kênh đầu vào là 32, nên depth sẽ là 32 và chúng ta muốn cái output của mình có 64 kênh thì chúng ta phải nhân cái này lên 64 lần do đó thì là... convolution thường nó sẽ tốn cái số lượng tham số là 32 x 3 x 3 x 4 thì đâu đó là khoảng 18.000 tham số nếu chúng ta áp dụng DSC thì ở lớp biến đổi đầu tiên chỉ có kích thước là 3x3 đối với phép biến đổi thứ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:10:42",
      "end_timestamp": "0:12:02"
    }
  },
  {
    "page_content": "có kích thước là 3x3 đối với phép biến đổi thứ 2, đó là Point-wise Convolution thì chúng ta sẽ có input của mình là depth là 32 vẫn là 32 nhưng mà chúng ta sẽ nhân với convolution 1 nhân 1 và chúng ta muốn output có 64 kênh thì khi đó chúng ta sẽ nhân với 64 thì cái kết quả ở đây đâu đó nó sẽ ra khoảng là 2003 rồi thì Vì có 32 kênh, thì có 32 kênh Chia ra tỷ lệ là 2.000 x 18.000 là 1.9% hay nói cách khác, đó là chúng ta có thể giảm được 9 lần tốc độ tính toán xin lỗi 1 lần, là giảm 9 lần số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "0:11:56",
      "end_timestamp": "0:12:50"
    }
  },
  {
    "page_content": "tốc độ tính toán xin lỗi 1 lần, là giảm 9 lần số phép toán và giảm được 9 lần số tham số thế thì chúng ta sẽ đến với 1 kiến trúc hiện đại hơn, đó là ConvNeXt ConvNeXt đã ra đời từ sau năm 2000 Khi vào thời điểm 2020, khi kiến trúc Transformer đã tương đối trưởng thành khi nó đã có được 3 năm phát triển ConvNeXt mục tiêu của nó là muốn kế thừa những thành tựu của Transformer nhưng vẫn giữ kiến trúc cũ của Convolution nó chỉ mượn những cái trick, những cái mẹo huấn luyện của Transformer để đưa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": "0:012:46",
      "end_timestamp": "0:13:29"
    }
  },
  {
    "page_content": "những cái mẹo huấn luyện của Transformer để đưa vào cái mạng CNN thì đó chính là những cái vấn đề thứ nhất đó là cái Relu của mình nó sẽ bị triệt tiêu đạo hàm khi tín hiệu của mình có cái đầu vào là âm tại vì chúng ta nhìn thấy cái sơ đồ của cái hàm Relu thì với những cái đặc trưng mà dương thì nó sẽ nhận giá trị đúng bằng x của mình luôn nhưng đối với đặc trưng âm thì nó sẽ triệt tiêu, cái đường nằm ngang này là triệt tiêu thế thì ReLU nó sẽ không khai thác được những gradient của đặc trưng âm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 16,
      "start_timestamp": "0:013:23",
      "end_timestamp": "0:14:12"
    }
  },
  {
    "page_content": "khai thác được những gradient của đặc trưng âm và nếu như chúng ta chỉ bám vào những mạng CNN thì chúng ta không kế thừa được những mẹo khi huấn luyện các mô hình với transformer 4 nổi đình nổi đám với độ chính xác rất là cao và nó sẽ có 1 biến thể cho lĩnh vực về thị giác máy tính đó là VIT là Vision Transformer Vậy thì ConvNeXt đã có những cái cải tiến gì? Đầu tiên đó là ở hàm kích hoạt thay vì chúng ta sử dụng Relu tức là cái đường màu cam chúng ta thấy nó bị gãy ở đây thì chúng ta dùng Relu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 17,
      "start_timestamp": "0:013:59",
      "end_timestamp": "0:15:00"
    }
  },
  {
    "page_content": "ta thấy nó bị gãy ở đây thì chúng ta dùng Relu nó sẽ tạo ra đường màu xanh này, nó sẽ là mượt mà hơn sẽ khiến cho việc huấn luyện của mình dễ dàng hơn và nó chống được hiện tượng vanishing gradient Cái việc huấn luyện của mình nó cũng sẽ trơn tru và dễ dàng hơn. Thế thì, đồng thời là cũng sẽ khai thác một cái loại optimizer mới vào những năm 2000. Đó chính là Adam W. Adam W là một cái biến thể khác của Adam nhưng mà được sử dụng trong lĩnh vực xử lý ngôn ngữ tự nhiên với cái kiến trúc là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 18,
      "start_timestamp": "0:14:46",
      "end_timestamp": "0:15:33"
    }
  },
  {
    "page_content": "vực xử lý ngôn ngữ tự nhiên với cái kiến trúc là Transformer. Thế thì cái mạng ConvNeXt này nó cũng đã thay Adam bằng Adam W Đồng thời cũng sử dụng những phương pháp tăng cường dữ liệu hiện đại hơn Ví dụ như random augment, mixup, cutmix thì đây là 2 kỹ thuật để mà blend các đặc trưng lại với nhau và tạo ra những đối tượng mà có tính outlier rất là cao tức là để tăng tính phổ quát của đặc trưng, tạo ra những cái hard sample, mẫu dữ liệu khó để khiến cho phân bố của dữ liệu càng mở rộng để hồng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 19,
      "start_timestamp": "0:15:26",
      "end_timestamp": "0:16:17"
    }
  },
  {
    "page_content": "cho phân bố của dữ liệu càng mở rộng để hồng giúp cho mô hình của mình có tính tổng quát hơn. Hay nói cái khác, đó là nó sẽ giúp cho chúng ta chống được hiện tượng Overfitting, chống Overfitting một cách hiệu quả hơn. Ngoài ra thì nó sẽ thay thế các BatchNorm bằng LayerNorm Tại vì khi chúng ta sử dụng BatchNorm thì đối với những patchsize nhỏ, đặc biệt khi chúng ta làm với dữ liệu lớn thì patchsize nhỏ sẽ khiến cho gradient của mình bị phập phù Tức là nó sẽ không ổn định Nó sẽ là không ổn định",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 20,
      "start_timestamp": "0:16:13",
      "end_timestamp": "0:17:27"
    }
  },
  {
    "page_content": "Tức là nó sẽ không ổn định Nó sẽ là không ổn định Cái Gradient khi cái Batch của mình bé Thì cái việc mà dùng BatchNorm này nó sẽ khiến cho cái việc huấn luyện nó không có tính ổn định Khi Batch lớn thì tốt nhưng khi BatchSize mà nhỏ thì Gradient nó thiếu tính ổn định Do đó thì chúng ta thay bằng LayerNorm và ngoài ra nó sẽ hơi ngược với lại VGG đó là sẽ dùng kernel kích thước là 7 x 7 để hy vọng rằng là nó học được bối cảnh xa hơn trong sơ đồ ở đây chúng ta thấy bên trái là ResNet Block và bên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 21,
      "start_timestamp": "0:17:17",
      "end_timestamp": "0:18:19"
    }
  },
  {
    "page_content": "đây chúng ta thấy bên trái là ResNet Block và bên phải là Convolution ConvNeXt Block sự khác biệt nữa của ConvNet so với ResNet đó chính là ResNet thì chúng ta sẽ tìm cách đi reduce, tức là chúng ta đi co lại các feature map chúng ta giảm các số lượng đặc trưng lại vì chúng ta áp dụng cái 1 nhân 1 Convolution sẽ khiến feature map co lại và đặc trưng co sẽ tạo ra bottleneck Trái ngược lại, ConnextBlock dùng kernel kích thước 7x7 và vẫn giữ nguyên Độ sâu là 96, kênh đầu vào của mình là 96, qua",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 22,
      "start_timestamp": "0:18:10",
      "end_timestamp": "0:19:07"
    }
  },
  {
    "page_content": "Độ sâu là 96, kênh đầu vào của mình là 96, qua lớp biến đổi đầu tiên nó vẫn giữ nguyên Điểm co lại ở bên ResNet thì đã được đảo ngược lại Thay vì chúng ta đưa từ 256 chiều, rớt xuống còn 64 thì ở đây, ConvNeXt làm điều ngược lại trước, đó là chúng ta từ 96, chúng ta tăng lên 384, tức là tăng cái số đặc trưng lên. Thì theo giải thích của các tác giả, khi chúng ta nới rộng cái số đặc trưng lên, nó tạo ra cái không gian của mình nó thoáng hơn và khi đó cái Gradient của mình nó truyền, nó sẽ hiệu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 23,
      "start_timestamp": "0:19:01",
      "end_timestamp": "0:19:55"
    }
  },
  {
    "page_content": "đó cái Gradient của mình nó truyền, nó sẽ hiệu quả hơn, không có bị hiện tượng Vanishing Gradient. Còn nếu chúng ta co bóp nó lại để còn có 64, thì khi gradient của mình đi qua những khu vực bottleneck thì nó sẽ bị nghẽn, nghẽn gradient và dẫn đến là gradient của mình được lan truyền không có hiệu quả. Đối với ResNet, chúng ta thực hiện công việc đó là giảm xong rồi từ 64 chúng ta lại tăng lên là thành 256, giảm xong tăng. hoặc là giảm rồi mở rộng còn ConvNeXt thì làm điều ngược lại, đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 24,
      "start_timestamp": "0:19:43",
      "end_timestamp": "0:20:29"
    }
  },
  {
    "page_content": "rộng còn ConvNeXt thì làm điều ngược lại, đó là chúng ta tăng trước sau đó có nhiều dư địa rồi thì chúng ta sẽ giảm lại sau giảm sau từ 96 lên 384 rồi từ 344 về lại 96 Đây là 2 chiến lược đối lược nhau và một trong những tính chất hiệu quả đó chính là dùng inverted residual block này. Tức là nó làm điều ngược lại sau với ResNet. Như vậy thì trong phần này chúng ta đã cùng tìm hiểu qua những biến thể của mạng CNN theo chuỗi lịch sử. và với mỗi một cái kiến trúc mạng thì đâu đó nó sẽ có những cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 25,
      "start_timestamp": "0:20:21",
      "end_timestamp": "0:20:29"
    }
  },
  {
    "page_content": "cái kiến trúc mạng thì đâu đó nó sẽ có những cái vấn đề cơ bản cần giải quyết và đề xuất ra một cái giải pháp phù hợp. Thì cái biến thể ConvNeXt là một trong những cái biến thể khá là hiện đại và gần đây và nó khai thác được rất nhiều những cái thành tựu của các cái mô hình trước đây. đặc biệt là nó sẽ kết hợp với lại mẹo huấn luyện của Transformer để tạo ra tổ hợp, những ưu điểm vừa giải quyết được hiện tượng Overfitting và vừa giải quyết được hiện tượng Vanishing Gradient. Trong phần này,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "hiện tượng Vanishing Gradient. Trong phần này, chúng ta đã áp dụng các kỹ thuật để giải quyết hiện tượng Overfitting và Vanishing Gradient cho vanishing gradient vào các biến thể của vanishing gradient để chúng ta thấy được sự tiến hóa của nó và có những lý do của nó.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=7SZcwTvSzO4",
      "filename": "7SZcwTvSzO4",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 2)",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chào các bạn, chúng ta sẽ cùng đến với chủ đề đầu tiên trong môn máy học nâng cao, đó chính là mô hình dựa trên Gradient. Tại sao chúng ta cần phải tìm hiểu mô hình dựa trên Gradient? Thì hiện nay các mô hình hiện đại và có rất nhiều những ứng dụng trong thực tế, ví dụ như các mô hình ngôn ngữ lớn, các GPT, các mô hình sinh ảnh như là Diffusion Model, thì đều được huấn luyện dựa trên một phương pháp dựa trên Gradient, tức là chúng ta tính đạo hàm. Và cái phương pháp này, nguyên lý của nó là gì?",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:52"
    }
  },
  {
    "page_content": "Và cái phương pháp này, nguyên lý của nó là gì? Và tại sao nó có những ưu điểm để các mô hình hiện đại đều tập trung để sử dụng Gradient làm nền tảng để huấn luyện? Chúng ta sẽ cùng tìm hiểu trong bài học ngày hôm nay. Đầu tiên chúng ta sẽ cùng tìm hiểu về ý tưởng của mô hình dựa trên Gradient. Ý tưởng của mô hình dựa trên Gradient thì chúng ta sẽ nhận dữ liệu đầu vào là x. Thì x này có thể là bất cứ loại dữ liệu nào. Ví dụ như nó có thể là dữ liệu dạng vector, nó cũng có thể là dữ liệu dạng ma",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:45",
      "end_timestamp": "0:01:44"
    }
  },
  {
    "page_content": "dạng vector, nó cũng có thể là dữ liệu dạng ma trận hoặc là tensor. Với hai loại là vector hoặc là ma trận hoặc là tensor, chúng ta có thể biểu diễn rất nhiều dữ liệu khác nhau. Ví dụ như có thể biểu diễn dữ liệu văn bản, dữ liệu dạng hình ảnh, video. Và khi chúng ta đưa qua mô hình thì mô hình của mình sẽ được ký hiệu bằng một cái hàm, đó là hàm x. Nhưng mà chúng ta lưu ý là đối với hàm fx ở đây nó sẽ có một cái tham số, đó là tham số theta. Cũng tương tự như trong cái toán phổ thông của chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:31",
      "end_timestamp": "0:02:27"
    }
  },
  {
    "page_content": "tương tự như trong cái toán phổ thông của chúng ta, chúng ta có cái việc đó là ví dụ như chúng ta giải tìm m, tìm cái tham số m sao cho cái phương trình bậc 2. Ví dụ như là x bình trừ m x cộng 3 m bình trừ 1 bằng 0 có 2 nghiệm. Ví dụ vậy, thì đây là cái toán mà hồi phổ thông chúng ta được làm qua. Tham số ở đây nó chính là cái m của mình và cái dạng thức của cái hàm của mình đó là một cái hàm bậc 2. Ở đây chúng ta có hoàn toàn có thể ký hiệu đó là f của m x bằng 0, trong đó fmx là cái công thức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:15",
      "end_timestamp": "0:03:32"
    }
  },
  {
    "page_content": "f của m x bằng 0, trong đó fmx là cái công thức ở cái vế bên tay trái như thế này. Thế thì ở đây cũng như tương tự như vậy. Chúng ta xác định được cái dạng thức của cái hàm f rồi, tuy nhiên trong đó chúng ta sẽ có nhiều cái tham số để quyết định xem là cái việc dự đoán mô hình chính xác đến mức độ nào. Thì chúng ta sẽ phải tìm cái tham số sao cho cái hàm fx nó thỏa mãn cái việc đó là dự đoán chính xác. Thì cái đầu ra của cái hàm fx này nó chính là y ngã và đây sẽ là cái giá trị mà chúng ta được",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:03:16",
      "end_timestamp": "0:04:10"
    }
  },
  {
    "page_content": "y ngã và đây sẽ là cái giá trị mà chúng ta được dự đoán từ cái mô hình. Và đương nhiên là việc dự đoán cái một cái giá trị nào đó thì chúng ta luôn mong muốn là nó sẽ xấp xỉ với lại cái giá trị thực tế. Thì giá trị thực tế thì chúng ta sẽ ký hiệu là bằng y và để cho cái giá trị dự đoán mà xấp xỉ được với cái giá trị thực tế thì chúng ta sẽ phải có một cái hàm. Hàm đó gọi là hàm lỗi và ký hiệu là chữ j. Rồi, hàm lỗi này thì nó sẽ có cái biến số, lúc này nó không phải là x nữa mà biến số của mình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:59",
      "end_timestamp": "0:04:46"
    }
  },
  {
    "page_content": "này nó không phải là x nữa mà biến số của mình lúc này nó sẽ là theta. Biến số của nó sẽ là theta và x,y của mình nó sẽ đóng vai trò giống như là tham số. Nó sẽ khác so với lại hồi xưa, khi mà chúng ta đặt cái tên biến mà là x,y thì nó sẽ ngầm hiểu đó là biến số. Còn trong trường hợp này thì cái hàm lỗi của mình x,y sẽ là tham số và nó chính là cái dữ liệu huấn luyện. Đó chính là cái dữ liệu huấn luyện. Rồi, và mình sẽ phải tìm cái biến số theta làm sao cho cái việc dự đoán này là chính xác",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:39",
      "end_timestamp": "0:05:28"
    }
  },
  {
    "page_content": "làm sao cho cái việc dự đoán này là chính xác nhất. Và cái việc tìm cái giá trị theta cho cái này chính xác nhất thì nó sẽ tương đương với việc chúng ta đi tìm một cái hàm min. Tìm theta sao cho hàm lỗi là đạt giá trị nhỏ nhất. Thế thì ba cái công việc chúng ta cần phải làm khi xây dựng một cái mô hình dựa trên Gradient. Một, đó là chúng ta sẽ xác định xem cái hàm fx của mình nó sẽ có cái dạng thức như thế nào. Thứ hai, đó là chúng ta sẽ thiết kế cái hàm lỗi là g theta x sao cho cái việc mà dự",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:05:21",
      "end_timestamp": "0:06:06"
    }
  },
  {
    "page_content": "cái hàm lỗi là g theta x sao cho cái việc mà dự đoán càng chính xác thì cái lỗi của mình thấp. Nhưng đó chưa phải là một cái tiêu chí để thiết kế một cái hàm lỗi. Càng chính xác nè thì càng nhỏ. Nhưng cái đó chưa phải là một cái tiêu chí duy nhất mà chúng ta sẽ còn rất nhiều những cái tiêu chí khác. Mình có thể kể một vài cái tiêu chí ví dụ như là nó có thể hoạt động tốt khi chúng ta làm việc hoạt động tốt. Với dữ liệu mà mất cân bằng. Tức là cái y này của mình nó sẽ có nhiều class ví dụ vậy và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:56",
      "end_timestamp": "0:06:54"
    }
  },
  {
    "page_content": "y này của mình nó sẽ có nhiều class ví dụ vậy và có những class thì xuất hiện rất nhiều nhưng có những cái class rất ít. Thì cái hàm lỗi này nó phải làm sao để cho hướng cái mô hình đến cái việc là kể cả những mẫu dữ liệu mà ít thì vẫn có thể được cho cái vai trò ngang bằng với lại những cái mẫu như nhiều. Rồi ngoài ra thì chúng ta sẽ có những cái tiêu chí nữa ví dụ như hàm lỗi như thế nào để cho cái việc huấn luyện nhanh, hội tụ, huấn luyện nhanh. Tức là nó sẽ mau chóng để mà tìm ra được cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:45",
      "end_timestamp": "0:07:34"
    }
  },
  {
    "page_content": "Tức là nó sẽ mau chóng để mà tìm ra được cái tham số tốt nhất. Rồi cái việc thiết kế hàm mô hình cũng vậy nó cũng sẽ dựa trên cái tính chất của y, cái giá trị thực tế vx để mà chúng ta sẽ thiết kế. Ví dụ như nếu y mà phụ thuộc một cách tuyến tính vx thì chúng ta sẽ có các cái hàm tuyến tính. Nhưng nếu mà y phụ thuộc một cách phi tuyến với là x thì chúng ta sẽ có các cái hàm là phi tuyến tính. Rồi sau này là tùy thuộc vx của mình, đó là dữ liệu dạng vector, dạng ma trận hay là dữ liệu như thế",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:07:22",
      "end_timestamp": "0:08:12"
    }
  },
  {
    "page_content": "dạng vector, dạng ma trận hay là dữ liệu như thế nào đó mà chúng ta cũng sẽ có những cái kiểu thiết kế khác nhau. Và cái công việc cuối cùng khi chúng ta làm với một cái mô hình mà dựa trên Gradient, đó chính là chúng ta sẽ tìm một cái tham số tối ưu của hàm mô hình. Tức là chúng ta sẽ đi tìm cái theta sao, sao cho cái lỗi ở đây là nhỏ nhất, thì lỗi mà nhỏ nhất là cái dự đoán càng chính xác. Thì so với lại các cái mô hình khác, chúng ta sẽ có rất nhiều những cái mô hình mà không dựa trên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:08:04",
      "end_timestamp": "0:08:44"
    }
  },
  {
    "page_content": "có rất nhiều những cái mô hình mà không dựa trên Gradient. Ví dụ như mô hình là k-nearest neighbor, thì thực sự mô hình này nó không phải là huấn luyện mà nó sẽ dựa trên các cái mẫu gần nhất. Để nó giống như là cái cơ chế là voting, tức là chúng ta sẽ lấy ra những cái mẫu gần nhất, rồi dựa trên nhãn của những cái mẫu gần nhất, chúng ta sẽ đưa ra cái phán đoán. Cái mô hình theo đó là Naive Bayes là dựa trên xác suất, đây là một cái hàm để mà ước lượng cái tham số một cách tường minh. Rồi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:08:33",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "mà ước lượng cái tham số một cách tường minh. Rồi decision tree, ví dụ như thuật toán ID3, rồi C4.5 thì ở đây là sẽ dựa trên luật để chia các cái nhánh quyết định. Random forest sẽ kết hợp nhiều mô hình cây thành phần, tức là nhiều cái mô hình cây ở trên để tạo thành một cái random forest. Các cái thuật toán mà họ không giám sát, ví dụ như là K-means, DBScan, vân vân là lặp lại cái việc cập nhật cái tâm cụm, nhưng mà nó là lặp lại không có dựa trên Gradient. Thế thì chúng ta sẽ so sánh những",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:09:13",
      "end_timestamp": "0:09:56"
    }
  },
  {
    "page_content": "trên Gradient. Thế thì chúng ta sẽ so sánh những cái khía cạnh giữa cái mô hình dựa trên Gradient và mô hình không có dựa trên Gradient. Thì đối với cái khía cạnh là về cái cơ chế tối ưu, thì mô hình dựa trên Gradient sẽ dựa trên cái thuật toán là Gradient descent. Và đây sẽ là một trong những cái thuật toán chính mà chúng ta sẽ cùng tìm hiểu sắp tới, cũng như là những cái biến thể của Gradient descent, ví dụ như là Stochastic Gradient descent Adam, hoặc là RMSProp. Còn đối với cái thuật toán",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:09:42",
      "end_timestamp": "0:10:45"
    }
  },
  {
    "page_content": "Adam, hoặc là RMSProp. Còn đối với cái thuật toán mà không dựa trên Gradient thì nó sẽ dùng công thức tường minh, hoặc là những chiến thuật như là Greedy, Chiến thuật tham lam, Heuristic, ví dụ như thuật toán Naive Bayes, Decision Tree và K-Nearest Neighbor. Và cái khả năng diễn giải, tức là cái khả năng giải thích, cái khả năng giải thích của mô hình đó. Thì ở thuật toán, cái mô hình dựa trên Gradient thì thường là ở dạng Black Box, thì đây có thể nói là một cái điểm yếu. Đây có thể nói là một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:10:25",
      "end_timestamp": "0:11:07"
    }
  },
  {
    "page_content": "nói là một cái điểm yếu. Đây có thể nói là một điểm yếu của các cái mô hình dựa trên Gradient là vì cái tính giải thích của nó sẽ là không cao, không cao bằng so với các cái mô hình dễ giải thích kết quả, ví dụ như là Decision Tree, Naive Bayes. Và đối với các cái tác vụ, nó sẽ hiệu quả trên các tác vụ phức tạp nào, thì mô hình Gradient Descent rất phù hợp cho cái kết quả rất tốt khi mà chúng ta làm trên những lĩnh vực như là Thị giác Máy Tính, Xử lý ngôn ngữ tự nhiên, khi mà cái dữ liệu của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:10:55",
      "end_timestamp": "0:11:38"
    }
  },
  {
    "page_content": "Xử lý ngôn ngữ tự nhiên, khi mà cái dữ liệu của mình nó là ở dạng không cấu trúc, không có cấu trúc. Còn thuật toán các mô hình mà không dựa trên Gradient thì nó sẽ tốt trên những cái loại dữ liệu là dữ liệu bảng và dữ liệu nhỏ. Về chi phí huấn luyện thì cái chi phí huấn luyện của mô hình dựa trên Gradient thì thường là cao và cần phải có GPU hoặc TPU với các cái mô hình lớn. Còn mô hình không dựa trên Gradient thì thường là ít tốn kém hơn. Vì vậy thì chúng ta thấy là với cái bảng này, chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": "0:11:30",
      "end_timestamp": "0:12:24"
    }
  },
  {
    "page_content": "thì chúng ta thấy là với cái bảng này, chúng ta thấy là điểm yếu của Gradient, mô hình dựa trên Gradient có vẻ như là nhiều hơn, ví dụ như là cần tài nguyên tính toán nhiều hơn. Rồi và nó là ít có khả năng diễn giải hơn. Tuy nhiên cái điểm mạnh của nó là chính là nằm ở việc là nó có thể làm được trên rất nhiều những cái loại dữ liệu không có cấu trúc. Mà chúng ta biết rằng là hiện nay cái dữ liệu của mình đại đa số sẽ là ở dạng không có cấu trúc. Do đó thì chính cái điểm mạnh này mà nó khiến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": "0:12:18",
      "end_timestamp": "0:12:59"
    }
  },
  {
    "page_content": "Do đó thì chính cái điểm mạnh này mà nó khiến cho cái mô hình Gradient gần đây được chú ý là vì nó khai thác được một cái lượng dữ liệu khổng lồ trên mạng internet. Còn cái mô hình dựa trên Gradient muốn mà hoạt động được thì chúng ta sẽ phải cấu trúc nó. Mà cái chi phí để mà cấu trúc hóa cái dữ liệu của mình thì rất là tốn kém và cái khối lượng dữ liệu của mình nó sẽ không nhiều. Vì đó chính là lý do tại sao các cái mô hình mà dựa trên Gradient gần đây được quan tâm. Và đây sẽ là một vài cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 19,
      "start_timestamp": "0:12:52",
      "end_timestamp": "0:13:37"
    }
  },
  {
    "page_content": "gần đây được quan tâm. Và đây sẽ là một vài cái hình ảnh để minh họa. Nếu như trước đây từ năm 2012 cái khối lượng dữ liệu huấn luyện của các cái mô hình học sâu thì thường là khoảng tầm vài triệu mẫu. Nhưng mà trong hai năm, ba năm gần đây thì là đã lên đến hàng trăm triệu mẫu. Và gần đây nhất thì là có tập dữ liệu LAION 5B thì nó đã lên đến năm tỷ ảnh. Đó là một cái khối lượng thật sự lớn. Và với cái khối lượng mà dữ liệu càng nhiều như thế này thì để mà có thể huấn luyện được hiệu quả thì nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 20,
      "start_timestamp": "0:13:29",
      "end_timestamp": "0:13:37"
    }
  },
  {
    "page_content": "thì để mà có thể huấn luyện được hiệu quả thì nó cũng cần phải có những cái tài nguyên mạnh. Thì cũng may mắn đó là các cái phần cứng, cụ thể là các cái GPU hiện nay nó đã ngày càng trở nên rẻ hơn và sức mạnh của nó ngày càng cao hơn. Đồng thời là về mặt khoa học thì các cái mô hình học sâu hiện nay là nó đã ngày càng hoàn thiện hơn. Khiến cho chúng ta có thể học tốt hơn và nhanh hơn, khai thác được những cái kho dữ liệu lớn và sức mạnh tính toán lớn. Hãy subscribe cho kênh Ghiền Mì Gõ Để không",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "lớn. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=80PUcgaI5Y0",
      "filename": "80PUcgaI5Y0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 1)",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ mở rộng cài đặt của Autoencoder cho Variational Autoencoder Trong phần trước, chúng ta đã cài hai cái module đó là Encode và Decode Trong phần Variational Autoencoder, chúng ta nhận thấy cái kiến trúc này, phần Encode thì nó khác một chút ở cái bước cuối Còn phần Decode thì cũng từ một cái vector z Chúng ta giải nén ra và biến thành cái vector từ 2,5,12 lên 784 Hoàn toàn giống với cái kiến trúc từ 2,5,2,7,84 của Autoencoder Do đó chúng ta sẽ tái sử dụng lại cái hàm này Ở đây chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:07"
    }
  },
  {
    "page_content": "ta sẽ tái sử dụng lại cái hàm này Ở đây chúng ta sẽ chạy lại Rồi Và chúng ta sẽ tái sử dụng lại cái hàm Decoder này Đối với phần Encode thì chúng ta sẽ thấy, thay vì chúng ta tạo ra một vector z gọi là Xác Định, tức là Cố Định Thì ở đây chúng ta sẽ tạo ra hai cái giá trị đó là Mu và Sigma Từ Mu và Sigma này thì chúng ta sẽ sampling để tạo ra một vector z theo phân bố Đó là z là bằng phân bố Gaussian của Mu và Sigma Và ở đây chúng ta cũng sẽ sử dụng một cái kỹ thuật đó là Reparameterization, tức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 1,
      "start_timestamp": "0:01:04",
      "end_timestamp": "0:01:56"
    }
  },
  {
    "page_content": "một cái kỹ thuật đó là Reparameterization, tức là tái tham số Thế thì trước tiên chúng ta sẽ cài cái Variational Encoder Thì đối với cái Variational Autoencoder này thì chúng ta sẽ sử dụng tương tự như vậy Chúng ta sẽ có cell.linear Thì cái linear này là linear1 và sẽ là bằng Neural Network.linear Đầu vào là 784 và đầu ra sẽ là 512 Rồi tương tự như vậy chúng ta sẽ có cái kỹ thuật đó là từ 512 về... Ở đây là lớp linear số 2 Thì cái lớp linear số 2 này là từ 512 về cái phía vector Mu Thì Mu của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 2,
      "start_timestamp": "0:01:52",
      "end_timestamp": "0:02:47"
    }
  },
  {
    "page_content": "2 này là từ 512 về cái phía vector Mu Thì Mu của mình sẽ có kích thước là 2 Tuy nhiên ở đây chúng ta sẽ không có hardcode mà chúng ta sẽ để Latent Dim ở đây Rồi tương tự như vậy chúng ta sẽ có cái linear số 3 Thì ở đây chúng ta sẽ tương tự nhưng có điều là chúng ta phải đặt tên lớp là lớp khác Tại vì đây sẽ là dành cho Mu Còn đây sẽ là dành cho Sigma Rồi và đối với cái phần mà forward thì chúng ta cũng sẽ có các cái bước tương tự Một đó là chúng ta sẽ flatten Thì chúng ta sẽ để là x sẽ được gán",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 3,
      "start_timestamp": "0:02:42",
      "end_timestamp": "0:03:42"
    }
  },
  {
    "page_content": "ta sẽ flatten Thì chúng ta sẽ để là x sẽ được gán ngược trở lại là bằng torch.flatten X và dim là bằng một Rồi sau đó chúng ta sẽ gọi đến cái bước đầu tiên Bước biến đổi đầu tiên đó chính là chúng ta sẽ đưa qua cái lớp linear Chúng ta sẽ đưa qua cái lớp linear và có một cái activation function Thì ở đây activation function chúng ta có thể sử dụng đó là một cái hàm là relu Thì đây là f.relu của cái self.linear1 Rồi và chúng ta sẽ truyền vào cái biến x và nó sẽ trả ra là x Rồi tiếp theo thì chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 4,
      "start_timestamp": "0:03:37",
      "end_timestamp": "0:04:35"
    }
  },
  {
    "page_content": "x và nó sẽ trả ra là x Rồi tiếp theo thì chúng ta sẽ qua cái lớp thứ 2 Sau cái lớp 6 thì nó đã biến thành một cái vector 512 Bây giờ chúng ta sẽ chia nó ra làm hai nhánh Thì Mu sẽ là bằng self.linear2 của x Rồi và sẽ tạo ra là Mu Và trong trường hợp này thì chúng ta cũng không có sử dụng cái activation function Lý do đó là vì cái Mu của mình Thì nó có thể từ giá trị âm cho đến giá trị dương Trong khi nếu chúng ta dùng relu thì nó bị bó hẹp lại cái output của mình là phải từ không trở lên Trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 5,
      "start_timestamp": "0:04:27",
      "end_timestamp": "0:05:10"
    }
  },
  {
    "page_content": "output của mình là phải từ không trở lên Trong khi Mu của mình nó hoàn toàn có thể là nó là tâm của một cái phân bố xác suất Nó có thể là số âm hay số dương được Do đó ở đây chúng ta sẽ không có để cái activation function relu Về sigma thì sigma của chúng ta là chúng ta sẽ để là self.linear Và truyền vào x Thế thì chúng ta muốn cái sigma của mình nó phải là một cái con số dương Con sigma của mình là con số dương Thì chúng ta có thể để relu ở đây cũng được Còn nếu chúng ta muốn một cách khác Ví",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 6,
      "start_timestamp": "0:05:01",
      "end_timestamp": "0:05:54"
    }
  },
  {
    "page_content": "cũng được Còn nếu chúng ta muốn một cách khác Ví dụ chúng ta để một cái hàm miễn sao nó trả ra là số dương Ví dụ như hàm torch.exp Thì nó sẽ ép cái giá trị có thể là từ âm vô cùng đến dương vô cùng về một con số dương Sigma thì bắt buộc phải là con số dương Bước tiếp theo chúng ta sẽ sampling Thế thì như trong slide lý thuyết chúng ta không thể nào mà sampling trực tiếp z Với cái phân bố Gaussian mà có Mu và sigma Giống như ở trên được Tại vì nếu làm như vậy thì nó sẽ không có back propagation",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 7,
      "start_timestamp": "0:05:48",
      "end_timestamp": "0:06:42"
    }
  },
  {
    "page_content": "làm như vậy thì nó sẽ không có back propagation được Giờ ở đây chúng ta sẽ dùng cái kỹ thuật reparameterization trick Thì để là Mu cộng cho cái code ở đây nó cũng đã gợi ý ra nè Nhân với lại cái n_sample Thế thì ở đây cái n_sample nó là cái gì Nó chính là cái các cái giá trị đã được lấy theo cái phân bố chuẩn Rồi sau đó thì chúng ta sẽ nhân với lại cái thành phần sigma này Và kích thước của mình thì nó sẽ là bằng Mu.shape luôn Tức là Mu và sigma này sẽ cùng kích thước nhau và cụ thể luôn Trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 8,
      "start_timestamp": "0:06:39",
      "end_timestamp": "0:07:23"
    }
  },
  {
    "page_content": "này sẽ cùng kích thước nhau và cụ thể luôn Trong cái ví dụ này thì size của nó là bằng 2 Thì đây chính là reparameterization trick Tiếp theo thì chúng ta sẽ tính cái KL divergence Thì sau khi chúng ta đã có được cái phân bố Mu và sigma rồi Chúng ta sẽ làm một cái thành phần nó gọi là chính quy hóa Thế thì dựa trên cái công thức của cái trang web Ở đây chúng ta có thể tham khảo ha Thì cái công thức của cái KL divergence Nó sẽ là bằng sigma bình phương cộng cho Mu bình phương Trừ cho log của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 9,
      "start_timestamp": "0:07:20",
      "end_timestamp": "0:08:15"
    }
  },
  {
    "page_content": "phương cộng cho Mu bình phương Trừ cho log của sigma Trừ 1 phần 2 Rồi trừ cho torch.log của sigma Tất cả trừ cho 1 phần 2 Rồi sau đó tất cả cái thành phần này chúng ta sẽ đi lấy tổng Tại vì nó có rất nhiều mẫu Thì chúng ta sẽ lấy tổng Rồi sau đó chúng ta sẽ chỉ return z thôi Còn không return KL divergence để cho cái bước sau là qua decode Còn KL divergence thì chúng ta sẽ để lại Để chút nữa chúng ta sẽ đưa vào bên trong cái hàm loss Rồi như vậy thì chúng ta sẽ tạo cái Variational Encoder Để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 10,
      "start_timestamp": "0:08:11",
      "end_timestamp": "0:08:56"
    }
  },
  {
    "page_content": "thì chúng ta sẽ tạo cái Variational Encoder Để chúng ta chạy cái code này Rồi sau đó chúng ta sẽ tạo cái lớp variational autoencoder Trong đó encoder thì lấy từ variational encoder chúng ta vừa mới lập trình xong Còn decoder thì chúng ta sẽ lấy lại lớp mà chúng ta đã cài đặt Ở trong cái phần autoencoder ở phía trước Tức là cái class này Rồi thì bây giờ chúng ta sẽ tạo Và z là cái kết quả của encode Sau đó z được truyền vào cho decode để trả kết quả cuối cùng Và đây chính là cái x mũ Thì chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 11,
      "start_timestamp": "0:08:52",
      "end_timestamp": "0:09:44"
    }
  },
  {
    "page_content": "quả cuối cùng Và đây chính là cái x mũ Thì chúng ta luôn mong muốn cái x mũ xấp xỉ với cái x đầu vào bắt đầu Thế thì để cái chuyện đó xảy ra Thì chúng ta sẽ có một cái hàm gọi là hàm loss Thì hàm loss này nó sẽ là bằng sai số của cái x hat Trừ cho x tất cả mũ 2 Rồi, sau đó thì chúng ta sẽ có thêm cái phần là tính tổng nữa Rồi cái này thì để cho chắc thì chúng ta sẽ để cái dấu mọi thứ đúng không ạ Tức là cái tổng sai số Rồi sau đó chúng ta sẽ đi cộng cho cái thành phần KL divergence Thì nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 12,
      "start_timestamp": "0:09:39",
      "end_timestamp": "0:10:42"
    }
  },
  {
    "page_content": "cộng cho cái thành phần KL divergence Thì nó sẽ lấy ra từ cái auto, cái mô hình là autoencoder này Tại vì nó chỉ nằm trong encoder thôi Chứ không nằm trong cái lớp tức là autoencoder KL thì nó nằm ở trong cái encoder Encoder là con của KL Rồi bây giờ chúng ta sẽ chạy cái thuật toán này Chạy cái hàm này và huấn luyện Latent Dim thì chưa được define Rồi Ok, thì cái Latent Dim này là bằng 2 Rồi thì chúng ta sẽ khởi tạo trực tiếp ở đây Chúng ta tách 2 cái đoạn code này ra Data is not defined Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 13,
      "start_timestamp": "0:10:35",
      "end_timestamp": "0:11:37"
    }
  },
  {
    "page_content": "2 cái đoạn code này ra Data is not defined Thì cái code của cái phần data là chúng ta sẽ lấy trong cái tập dữ liệu MNIST Do đó thì chúng ta gọi cái hàm của scikit-learn để lấy cái data về Đây Autoencoder is not defined Nó sẽ lấy từ torch, không phải từ scikit-learn Rồi util.latch Và đưa về cái thư mục data Và data lúc này của mình thì sẽ chứa dữ liệu Cả nhãn và không có nhãn Thế thì là có cái phần train nhưng mà chưa được gọi Rồi thì ở đây chúng ta không cần phải chạy lại cái hàm train của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 14,
      "start_timestamp": "0:11:34",
      "end_timestamp": "0:12:23"
    }
  },
  {
    "page_content": "ta không cần phải chạy lại cái hàm train của autoencoder Cái chúng ta cần đó là cái hàm lấy data ở đây Chúng ta sẽ mượn lại đem xuống Và chờ cái mô hình này nó train xong Thì có thể nó tốn của chúng ta là khoảng 2 phút Thế thì chúng ta sẽ cùng xuống dưới để xem cái kết quả Rồi Thì ở đây chúng ta sẽ tạm xóa cái kết quả cũ đã chạy trước đây Để xem tại vì với mỗi lần random có thể ra những cái con số khác nhau Thì cái phần trực quan hóa, cái latent space này Thì chúng ta sẽ dùng cái hàm Là Plot",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 15,
      "start_timestamp": "0:12:13",
      "end_timestamp": "0:13:06"
    }
  },
  {
    "page_content": "space này Thì chúng ta sẽ dùng cái hàm Là Plot latent Tương tự như của autoencoder Nhưng có điều cái mô hình ở đây chúng ta truyền sẽ là cái mô hình của VAE Và cái data của mình sẽ là lấy cái data của toàn bộ dataset Và chúng ta sẽ in ra cái biểu đồ của cái không gian latent Thì ở đây chúng ta sẽ có một cái thí nghiệm đó là chúng ta sẽ interpolate Tức là sẽ quét trong toàn bộ cái không gian của ảnh Và sau đó thì chúng ta sẽ xác định xem là cái kết quả sau khi chúng ta decode ra Là cái ảnh của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 16,
      "start_timestamp": "0:13:01",
      "end_timestamp": "0:13:56"
    }
  },
  {
    "page_content": "kết quả sau khi chúng ta decode ra Là cái ảnh của mình nó nhìn như thế nào Thì nó sẽ nằm trong cái interpolate Và cái interpolate này thì nó sẽ chạy từ x1 cho đến x2 Với x1, x2 là một cái điểm nào đó mà chúng ta lấy Ví dụ như là x1 thì được lấy từ một cái điểm ảnh có cái nhãn là 1 là số 1 x2 thì tương ứng là một cái x có cái y là bằng 0 Tức là chúng ta lấy một cái con số 0 ra x1 chính là số 1 và x2 chính là một cái hình của con số 0 Và sau đó chúng ta sẽ plot trên toàn bộ các cái vector z",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 17,
      "start_timestamp": "0:13:51",
      "end_timestamp": "0:14:52"
    }
  },
  {
    "page_content": "đó chúng ta sẽ plot trên toàn bộ các cái vector z Vector ẩn từ x1 cho đến x2 Thì chúng ta sẽ bàn chi tiết hơn về cái cách thức mà nó chạy Ngoài ra thì chúng ta có cung cấp thêm một cái ảnh gif để cho tạo cái hình động Và cuối cùng chúng ta có thể thử nghiệm với lại các độ dài của các latent space khác nhau Rồi thì sau khoảng 2 phút thì đã đã kết thúc cái quá trình train Và chúng ta sẽ plot cái hàm plot này chúng ta chưa lấy từ ở phía trên xuống Chúng ta có một cái câu hỏi đó là nhận xét gì về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 18,
      "start_timestamp": "0:14:45",
      "end_timestamp": "0:15:23"
    }
  },
  {
    "page_content": "Chúng ta có một cái câu hỏi đó là nhận xét gì về cái kết quả này Thì chúng ta thấy nếu như ở trong cái không gian latent ở trên thì chúng ta thấy là nó bị hở khá là nhiều Và cái đường đi của mình nó không phải là dạng hình tròn một cái phân bố Gaussian mà nó đi một cái dạng vòng cung như thế này Trong khi đó ở bên dưới thì chúng ta thấy là nó tròn hơn Đương nhiên nó sẽ có một số cái khu vực Ví dụ như màu số 8 thì nó sẽ là nó hơi dẹp Thực ra là dẹp hay không chúng ta cũng không biết Tại vì nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 19,
      "start_timestamp": "0:15:18",
      "end_timestamp": "0:16:18"
    }
  },
  {
    "page_content": "hay không chúng ta cũng không biết Tại vì nó sẽ ẩn nó bị chồng lên ở đằng sau Lý do tại sao nó bị chồng lên ở khu vực này Đó là vì cái không gian của chúng ta là chọn là 2 chiều Nên nó khá là chật chội dẫn đến là cái mô hình của mình nó có thể bị chồng lấp Nhưng riêng số 1 và số 7 thì nó ít bị chồng lấp hơn Chúng ta thấy là nó nằm ngoài ra ngoài rìa và ít bị chồng lấp hơn Thì số 1 nó có hình thù khá là khác biệt so với những cái con số còn lại Tương tự như vậy số 7 Còn các con số ví dụ như là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 20,
      "start_timestamp": "0:16:10",
      "end_timestamp": "0:17:23"
    }
  },
  {
    "page_content": "Tương tự như vậy số 7 Còn các con số ví dụ như là số 8 hoặc là số 3 chẳng hạn Thì chúng ta thấy là nó có những cái nét trùng nhau Vì vậy như số 8 chúng ta bỏ đi cái phần bên tay trái thì sẽ ra số 3 Sau đó chúng ta sẽ tìm cách trực quan hóa Thế thì trong cái hình này chúng ta sẽ trực quan hóa trong đoạn từ trừ 3 cho đến 3 Thì chúng ta sẽ dùng công cụ snip để cắt cái màn hình này ra Rồi, và trong cái sơ đồ này chúng ta sẽ thấy là Cái khu vực là từ trừ 3 cho đến 3 Rồi, thì cái trục hoành của mình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 21,
      "start_timestamp": "0:17:11",
      "end_timestamp": "0:18:02"
    }
  },
  {
    "page_content": "trừ 3 cho đến 3 Rồi, thì cái trục hoành của mình là từ trừ 3 cho đến 3 Thì đâu đó là khoảng giá trị ở đây Giá trị ở đây cho đến 3, giá trị là ở đây Còn trục tung là từ trừ 3 cho đến 3 thì nó cũng sẽ là từ đây cho đến đây Rồi thì chúng ta chiếu lên Thì nó sẽ là nằm ở đây Thì đây là cái ô vuông mà chúng ta sẽ trực quan Rồi, và chúng ta cũng sẽ chia lưới ra là 12 đường, 12 phần Và với mỗi điểm trên cái mắt lưới này thì chúng ta sẽ đi vẽ ra để xem cái ảnh của nó là như thế nào Thì đó là cái ý tưởng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 22,
      "start_timestamp": "0:17:54",
      "end_timestamp": "0:18:51"
    }
  },
  {
    "page_content": "ảnh của nó là như thế nào Thì đó là cái ý tưởng của cái hàm plot reconstructed Thì chúng ta thấy là phía trên bên trái nó sẽ gần với lại số 8 là đúng rồi Tại vì đây là cái khu vực màu vàng lá mạ Thì ở trong cái sơ đồ này là nó gần với lại số 8 Nên nó sẽ vẽ ra là số 8 Rồi, từ trái sang phải thì chúng ta sẽ thấy là đi vào cái khu vực nó khá là hỗn loạn Nó vừa có màu vàng lá mạ, vừa có màu nâu của số 5 và màu đỏ của số 3 Nên chúng ta thấy là nó có bóng dáng của số 3 Nhưng mà một cách trực quan thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 23,
      "start_timestamp": "0:18:47",
      "end_timestamp": "0:19:53"
    }
  },
  {
    "page_content": "dáng của số 3 Nhưng mà một cách trực quan thì chúng ta thấy là từ trái sang phải nó đã có cái sự biến đổi Cái đường nét của số 8 nó dần mất 2 cái nét cong ở bên tay trái để chuyển dần thành số 3 Rồi ra đây nó sẽ dần dần hòa lại để thành số 0 Thì số 0 của mình là màu xanh bên tay phải đây Rồi, và từ trên xuống thì chúng ta thấy là nó đã dần chuyển hóa từ số 8 sang số 1 Từ số 8 sang số 1 Thì nó đang là đi vào từ vùng màu vàng xuống cái vùng màu cam, màu cam tương ứng với số 1 Và nó đi cũng khá là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 24,
      "start_timestamp": "0:19:48",
      "end_timestamp": "0:20:37"
    }
  },
  {
    "page_content": "màu cam tương ứng với số 1 Và nó đi cũng khá là mượt Rồi, tiếp theo thì chúng ta sẽ tìm cách trực quan hóa một chuỗi các con số mà được lấy từ 2 cái vector Từ 1 cho đến 0 Thì chúng ta thấy là nó đã có sự dịch chuyển Ban đầu chúng ta sẽ có x1 là hình số 1 như thế này Và trong cái không gian latent z thì ở đây chúng ta sẽ tìm cách trực quan Rồi, thì cái số 1 này thì ở bên trong cái không gian latent nó sẽ nằm ở đây Số 0 này trong không gian latent thì nó nằm ở đây Và cái ý nghĩa của cái hàm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 25,
      "start_timestamp": "0:20:31",
      "end_timestamp": "0:21:09"
    }
  },
  {
    "page_content": "thì nó nằm ở đây Và cái ý nghĩa của cái hàm interpolate này, nội suy này là từ 2 cái điểm này chúng ta sẽ lấy mẫu đều Và với mỗi điểm này chúng ta sẽ vẽ lên Giống như trên Rồi, thì chúng ta thấy là cái đường đi của nó cũng khá là mượt Rồi, và chúng ta có thể sử dụng cái code interpolate.gif để mà Thay vì chúng ta vẽ thành một giải như thế này thì nó sẽ tạo ra thành một ảnh thôi Và khi chúng ta chạy cái này thì nó sẽ tạo ra một cái file.gif Thì chúng ta có thể tải cái file.gif này về và nhìn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 26,
      "start_timestamp": "0:21:02",
      "end_timestamp": "0:21:09"
    }
  },
  {
    "page_content": "chúng ta có thể tải cái file.gif này về và nhìn thấy được cái sự dịch chuyển của nó Từ số 1 chuyển sang số 0 theo dạng là hoạt hình Và bài tập thực hành tiếp theo cho chúng ta, đó chính là chúng ta thử nghiệm điều gì xảy ra nếu như cái Latent Dimension của mình là bằng 1, tức là cái không gian của mình nó kéo về rất là chật hẹp Ở đây chúng ta mới chọn một cái không gian 2 chiều để mà chúng ta có thể trực quan được thôi Trên cái mặt phẳng đó thì nó sẽ có một cái điểm yếu đó là nó bị chật quá và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "nó sẽ có một cái điểm yếu đó là nó bị chật quá và dẫn đến kéo các con số lại gần nhau như thế này Nhưng mà nhìn chung thì các cái phân bố này là đều dễ hiểu và nó có giống như cái prior distribution đó là dạng Gaussian Rồi và nếu chúng ta đưa về cái không gian 1 chiều thì điều gì sẽ xảy ra thì đó chính là cái bài tập thêm cho chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=8a4DWVmabDg",
      "filename": "8a4DWVmabDg",
      "title": "[CS315 - Chương 3] Tutorial - VAE",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cài đặt thuật toán RadarLesson và cài đặt biến thể nâng cao của RadarLesson, đó là Momentum Trong thuật toán RadarLesson, chúng ta dùng 1 hàm chỉ có 1 điểm cực tiểu thôi, do đó nó sẽ không thể minh họa được cho tình huống Momentum Chúng ta sẽ dùng 1 hàm có nhiều hơn 1 điểm cực tiểu, và cụ thể đó là hàm có 2 điểm cực tiểu Thì cái hàm này chúng ta có thể chọn là 1 công thức là 1 hàm bậc 4, là bằng theta mũ 4 cộng cho theta mũ 3 trừ cho 5 theta bình cộng 3 Thì ở đây nó sẽ có 2 điểm cực",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:03"
    }
  },
  {
    "page_content": "5 theta bình cộng 3 Thì ở đây nó sẽ có 2 điểm cực tiểu, và cái giá trị mình khởi tạo ở đây thì nó là 1 cái giá trị đủ nhỏ thôi Tại vì nếu vì cái hàm này là hàm bậc 4, nếu chúng ta để con số là 12 thì con số nó sẽ rất là lớn Do đó chúng ta sẽ chọn 1 con số đủ nhỏ, theta khởi tạo ban đầu có thể là bằng 4 thôi Và alpha cũng tương tự như vậy, alpha là 1 cái con số rất là lớn, trong trường hợp này là 0.5 là 1 con số rất là lớn Chúng ta có thể sử dụng 1 cái alpha khoảng là 0.01 để cho nó đủ nhỏ Tại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 1,
      "start_timestamp": "0:00:56",
      "end_timestamp": "0:01:43"
    }
  },
  {
    "page_content": "1 cái alpha khoảng là 0.01 để cho nó đủ nhỏ Tại vì khi chúng ta làm với cái hàm lớn như thế này thì dùng con số alpha lớn nó sẽ khiến cho mình bị phân kỳ Tiếp theo là chúng ta sẽ cài đặt các công thức ở đây Thì đầu tiên chúng ta sẽ sửa lại cái hàm của mình, hàm j là theta mũ 4 cộng cho theta mũ 3 trừ cho 5 nhân theta bình phương cộng 3 Và sẽ sửa lại cái hàm đạo hàm, 4 nhân theta mũ 3 cộng cho 3 nhân theta bình phương trừ cho 10 nhân theta Sau đó chúng ta sẽ tiến hành cài đặt, theta ban đầu là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 2,
      "start_timestamp": "0:01:36",
      "end_timestamp": "0:02:58"
    }
  },
  {
    "page_content": "chúng ta sẽ tiến hành cài đặt, theta ban đầu là 12, nó sẽ rất là lớn, ở đây chúng ta sẽ sửa lại nó phải bằng 4 thôi Rồi alpha là 0.1 và v ban đầu sẽ được gán bằng 0, rồi delta là 0.1 và beta là 0.9 Trong cái công thức cập nhật thì chúng ta vẫn sẽ tính đạo hàm nhưng mà chúng ta sẽ có thêm alpha là bằng alpha nhân với delta Tức là cứ mỗi một lần lặp là nó sẽ giảm xuống 10 lần, tuy nhiên thì con số này chúng ta sẽ tìm cách chúng ta tune nó để cho nó trực quan được Thứ 2 là v sẽ là bằng beta nhân",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 3,
      "start_timestamp": "0:02:42",
      "end_timestamp": "0:03:34"
    }
  },
  {
    "page_content": "nó trực quan được Thứ 2 là v sẽ là bằng beta nhân với lại v quá khứ, tức là v trước đó, cộng cho alpha nhân với lại đạo hàm Thì đạo hàm ở đây chúng ta đã được tính sẵn trong cái biến đó là derivative, dẫn đến là chúng ta không cần phải tính lại nữa Và ở đây theta sẽ là bằng theta trừ cho v Rồi bây giờ chúng ta sẽ trực quan hóa nó Rồi để trực quan hóa thì chúng ta sẽ run ở đây Vì cái khoảng giá trị của mình là rất là lớn nên nếu chúng ta để cái biên trái và biên phải là trừ 10 và 12 như ở đây Vì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 4,
      "start_timestamp": "0:03:28",
      "end_timestamp": "0:04:27"
    }
  },
  {
    "page_content": "trái và biên phải là trừ 10 và 12 như ở đây Vì vậy chúng ta sẽ phải sửa lại khoảng giá trị là từ trừ 4 cho đến 4 thôi Khi chạy chúng ta thấy là cái đồ thị của mình nhìn nó có vẻ hơi không có được mượt mà nó bị gấp khúc Thì để giảm cái hiện tượng này chúng ta sẽ cho cái khoảng lấy mẫu nhỏ xuống đó là khoảng 0.1 Rồi sau đó chúng ta sẽ chạy lại Chúng ta thấy là cái hàm của mình đã cái đường thẳng của mình nhìn nó mượt hơn Và khi chạy thì chúng ta thấy là Đó đến đây thì nó lại rất là chậm Nó là rất",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 5,
      "start_timestamp": "0:04:19",
      "end_timestamp": "0:05:06"
    }
  },
  {
    "page_content": "là Đó đến đây thì nó lại rất là chậm Nó là rất là chậm Thì nguyên nhân đó là do đâu? Nguyên nhân đó là do cái decay rate của alpha Alpha tại một thời điểm cứ mỗi một vòng lặp Thì alpha là bằng alpha nhân với lại delta Tức là alpha là bằng alpha nhân 0.1 Hay nói cách khác đó là alpha chia 10 đi Alpha ban đầu của mình đã đủ nhỏ rồi mà mình còn chia 10 nữa Đúng không? Thì dẫn đến đó là đến đây nó gần như không có sự tham gia của đạo hàm hiện tại Dẫn đến là tại những vị trí này Đạo hàm hiện tại nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 6,
      "start_timestamp": "0:05:04",
      "end_timestamp": "0:05:52"
    }
  },
  {
    "page_content": "đến là tại những vị trí này Đạo hàm hiện tại nó rất là bé Do đó thì mình sẽ sửa lại cái hệ số này Nâng nó lên Delta là bằng 0.2 Tức là giảm vừa thôi Rồi chúng ta lưu và chạy Thì chúng ta thấy là nó nhảy xa hơn Lý do đó là vì nó lấy được cái đạo hàm thực sự tại cái vị trí này Còn nếu mà chúng ta chia cho 10 thì cái phần đạo hàm Mà nó cập nhật vô cái bước nhảy của mình rất là ít Ban đầu đã là 0.01 là tương đối nhỏ là vừa Nhưng mà lần sau lại chia 10 Rồi lần tiếp theo lại chia 10 nữa Thì cái phần",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 7,
      "start_timestamp": "0:05:50",
      "end_timestamp": "0:06:23"
    }
  },
  {
    "page_content": "10 Rồi lần tiếp theo lại chia 10 nữa Thì cái phần đạo hàm tại vị trí này nó gần như không tham gia vô Vì do đó chúng ta giảm nó bớt bớt thôi là khoảng 0.2 Và khi chúng ta giảm xuống Thì chúng ta thấy là tại cái vị trí này Nó đã thoát ra được khỏi cái điểm cực tiểu cục bộ Nó đã thoát khỏi được cái điểm cực tiểu cục bộ ở đây Và nó trượt xuống đây để mà nó chạm được đến cái điểm cực tiểu Thứ 2 thì đây chính là cái ý nghĩa của thuật toán Momentum Bây giờ nếu chúng ta sửa lại thêm một chút xíu Là ví",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 8,
      "start_timestamp": "0:06:19",
      "end_timestamp": "0:07:18"
    }
  },
  {
    "page_content": "giờ nếu chúng ta sửa lại thêm một chút xíu Là ví dụ như ở đây chúng ta để là cho Delta này lên 0.3 Thì điều gì sẽ xảy ra Nếu cho Delta lên 0.3 À Delta lên 0.3 Thì nó cũng sẽ thoát ra được Nhưng đến đây là nó vẫn còn quá mạnh Dẫn đến là nó sẽ cứ thế mà đi lên tiếp luôn Do là cái thành phần Delta của mình Là nó nhận được cái alpha Cho cái thành phần alpha ban đầu của mình là một con số chưa có đủ nhỏ Do đó muốn để cho nó là 0.3 ở đây Thì chúng ta phải giảm tiếp alpha nữa Tức là một khi chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 9,
      "start_timestamp": "0:07:14",
      "end_timestamp": "0:08:03"
    }
  },
  {
    "page_content": "phải giảm tiếp alpha nữa Tức là một khi chúng ta tăng Delta lên thì chúng ta phải giảm alpha để cho nó cân bằng Ví dụ ở đây sẽ là 0.01 Rồi, chúng ta sẽ chạy lại Nếu chúng ta giảm nhỏ quá Alpha mà bé quá Thì đến đây là cái thành phần đạo hàm nó không còn đóng góp gì nhiều vô nữa Nó không còn đóng góp gì nhiều vô nữa Và đến đây là nó bị dừng luôn Với những cái ví dụ này chúng ta thấy việc tune các siêu tham số rất là quan trọng Nếu như chúng ta tune mà không đúng Một số quá nhỏ, một số quá lớn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 10,
      "start_timestamp": "0:08:00",
      "end_timestamp": "0:08:45"
    }
  },
  {
    "page_content": "tune mà không đúng Một số quá nhỏ, một số quá lớn Thì dẫn đến đó là hai tình huống Tình huống đầu tiên là như chúng ta thấy ở đây Khi alpha quá nhỏ Thì cái thành phần đạo hàm ở đây Nó tham gia vô cái việc mà cập nhật tham số cũng rất là ít Và nó mau chóng nó bị tiêu biến đi Dẫn đến là nó sẽ bị đứng ở đây luôn Rồi, do đó chúng ta phải chọn alpha vừa đủ để có thể bắt đầu được Rồi, khi chúng ta chọn alpha vừa đủ rồi Nhưng mà cái delta của mình nó lại quá lớn Thì dẫn đến đó là nó sẽ lấy cái giá trị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 11,
      "start_timestamp": "0:08:42",
      "end_timestamp": "0:09:28"
    }
  },
  {
    "page_content": "quá lớn Thì dẫn đến đó là nó sẽ lấy cái giá trị đạo hàm Nó không có giảm đủ nhanh Nó không có giảm alpha đủ nhanh Dẫn đến là nó còn kế thừa cái thành phần đạo hàm rất là lớn ở trên đây Để mà nó kéo qua đây và cập nhật tiếp Do đó thì ở đây chúng ta phải giảm xuống là khoảng 0.2 Giảm xuống là khoảng 0.2 Và chúng ta sẽ chạy lại Giảm xuống 0.2 thì có vẻ như là vừa đủ để nó vừa thoát ra khỏi điểm cực tiểu Chúng ta vừa thoát ra khỏi điểm cực tiểu cục bộ Và tiến đến một điểm cực tiểu tốt hơn Thì là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 12,
      "start_timestamp": "0:09:24",
      "end_timestamp": "0:10:10"
    }
  },
  {
    "page_content": "bộ Và tiến đến một điểm cực tiểu tốt hơn Thì là khi chúng ta chọn alpha và delta vừa đủ Còn nếu chúng ta chọn delta mà nhỏ quá Thì cái việc giảm alpha này quá nhanh Cái việc giảm alpha quá nhanh dẫn đến đó là những cái vòng lặp sau Nó sẽ bị dừng trước lúc thoát ra khỏi điểm cực tiểu Đến đây là bắt đầu nó sẽ không thoát ra khỏi được điểm cực tiểu cục bộ ở đây rồi Thì đó chính là cái điểm yếu của mình Khi chúng ta chọn tham số quá nhiều Khi một thuật toán của mình mà nó có quá nhiều tham số Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 13,
      "start_timestamp": "0:10:06",
      "end_timestamp": "0:10:56"
    }
  },
  {
    "page_content": "toán của mình mà nó có quá nhiều tham số Thì cái thuật toán Adam là một cái thuật toán mà Nó khá là bền vững và ổn định với các cái siêu tham số Khi chúng ta chọn những cái alpha và theta mặc định ban đầu Thì nó có thể là ra một cái thuật toán tốt hơn Tuy nhiên Adam nó sẽ phù hợp cho những cái mô hình Mà có nhiều tham số Còn Adam và root mean square propagation Thì nó lại phù hợp cho những cái mô hình mà có nhiều hơn hai tham số Rồi như vậy thì ở đây chúng ta sẽ trả lại cái tham số để mà có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 14,
      "start_timestamp": "0:10:53",
      "end_timestamp": "0:11:34"
    }
  },
  {
    "page_content": "đây chúng ta sẽ trả lại cái tham số để mà có thể chạy được Đó chính là 0.2 và alpha là bằng 0.1 Rồi thì chúng ta thấy là nó đã di chuyển rất là nhanh ở cái điểm cực tiểu cục bộ đầu tiên Và sau đó thì nó sẽ vượt qua được Thì đối với cái thuật toán này chúng ta sẽ có một cái chú ý Đó là vì ở đây nó may mắn nó không chạm được đến cái điểm mà đủ nhỏ Tức là cái điểm mà đạo hàm đủ nhỏ Chứ nếu nó chạm vô được cái điểm đủ nhỏ này Mà nó gặp cái lệnh if này thì nó sẽ thoát ra khỏi cái chương trình của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 15,
      "start_timestamp": "0:11:30",
      "end_timestamp": "0:12:24"
    }
  },
  {
    "page_content": "này thì nó sẽ thoát ra khỏi cái chương trình của mình luôn Do đó đa số các cái thuật toán momentum Và huấn luyện các cái optimizer không có dùng cái điều kiện này Mà họ sẽ chạy với một số vòng lặp nhất định Tại vì nếu vô tình chúng ta chạm được cái điểm cực tiểu cục bộ Thì nó sẽ thoát ra khỏi cái chương trình của mình luôn Do đó thì mình sẽ sửa lại một lần nữa Thay vì chúng ta dùng cái điều kiện này Thì chúng ta sẽ cho một cái vòng lặp ở đây là for in range Của chúng ta cho nó chạy khoảng 100",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 16,
      "start_timestamp": "0:12:19",
      "end_timestamp": "0:13:01"
    }
  },
  {
    "page_content": "for in range Của chúng ta cho nó chạy khoảng 100 lần Rồi chúng ta sẽ dừng Và ở đây chúng ta sẽ bỏ qua cái biến epsilon Thì đây chính là cái biến thể momentum Và thuật toán nó vẫn chạy được Cho đến khi nào mà nó gặp đủ 200 vòng lặp Thì nó sẽ kết thúc cái thuật toán momentum của mình Rồi, trong phần này chúng ta đã cùng cài đặt thuật toán momentum Và cho thấy được cái hiệu quả của nó Thoát ra khỏi điểm cực tiểu cục bộ Nhưng mà nó sẽ có một vấn đề đó là cái siêu tham số của mình Chúng ta sẽ phải",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 17,
      "start_timestamp": "0:12:56",
      "end_timestamp": "0:13:16"
    }
  },
  {
    "page_content": "đó là cái siêu tham số của mình Chúng ta sẽ phải chọn những cái siêu tham số cho phù hợp Mặc định ban đầu đó là alpha của mình nên là con số đủ nhỏ Đối với những hàm đa thức trên thế này là 0.01 Nhưng mà sau này khi chúng ta làm với các mô hình học sâu Thì alpha nó có thể nhỏ hơn nữa Ví dụ như là 0.0001 tức là 10 mũ trừ 4 Và các learning rate, các hệ số này Thì chúng ta những biến thể sau nó cũng đã cải tiến Để cho kể cả khi ban đầu V bằng 0 Nhưng mà cái thuật toán của mình nó vẫn có thể chạy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "mà cái thuật toán của mình nó vẫn có thể chạy nhanh ở những vòng lặp đầu tiên Vì vậy thì chúng ta kết thúc cái bài thực hành momentum ở đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=BTw0GqL0YK0",
      "filename": "BTw0GqL0YK0",
      "title": "[CS315 - Chương 1] Tutorial - Momentum",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với một cái biến thể tiếp theo, đó chính là Adam, Adaptive Moment Optimization. Trong phần trước, chúng ta đã cùng tìm hiểu về biến thể Root Mean Square Propagation trên kỹ momentum Và công thức cập nhật của momentum của mình sẽ là bằng alpha chia cho căn của epsilon cộng cho r, tất cả nhân cho g G này sẽ được tính là bằng đạo hàm của hàm loss theo theta Rõ ràng chúng ta thấy nó chưa có sử dụng momentum Chúng ta chỉ mới sử dụng momentum trong công thức của r này mà thôi Cụ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:08"
    }
  },
  {
    "page_content": "momentum trong công thức của r này mà thôi Cụ thể là như thế nào? Trong công thức này, r sẽ bằng beta nhân với r R trong đó beta là một hệ số để kết hợp của r quá khứ Cụ thể đây beta là bằng 0.9 R là bằng 0.9r, tức là quá khứ của mình là 90% quá khứ của mình Cộng cho 1 trừ beta tất cả nhân cho g G bình phương, g nhân g Trong công thức này chúng ta thấy với beta mà bằng 0.9, tức là chúng ta lấy 90% thông tin của quá khứ kết hợp với 1 trừ beta tức là 10% thông tin của quá khứ Thì thành phần này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 1,
      "start_timestamp": "0:01:06",
      "end_timestamp": "0:01:58"
    }
  },
  {
    "page_content": "là 10% thông tin của quá khứ Thì thành phần này quá ít dẫn đến là tại những vòng lặp đầu tiên Ví dụ đây là hàm loss của mình Tại những vòng lặp đầu tiên, r sẽ là bằng 90% của số 0 Do đó thành phần này sẽ là bằng 0 Cộng cho 10% của g nhân g Thế thì thành phần này quá bé tại những vòng lặp đầu tiên Mặc dù thế năng của nó tại vị trí này chúng ta thấy rất là tốt, ở vị trí rất là cao do đó đạo hàm của mình rất dốc Nhưng nó chỉ được lấy có 10% thôi Như vậy thì ở những bước đầu tiên của Root Mean",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 2,
      "start_timestamp": "0:01:52",
      "end_timestamp": "0:02:52"
    }
  },
  {
    "page_content": "Như vậy thì ở những bước đầu tiên của Root Mean Square Propagation, nó sẽ đi rất chậm Thì Adam Adaptive Moment Optimization đã cải tiến ở 2 chỗ 1 là sẽ đưa momentum vào trong thành phần này 2 là r thì chúng ta cũng sẽ chuẩn hóa Chúng ta sẽ chuẩn hóa để tại những vị trí đầu tiên nó sẽ không bị bias Nó sẽ không bị phụ thuộc vào r khởi tạo ban đầu là một con số khá là bé Và cái thuật toán Adaptive Moment Optimization Adam Thì thường là ổn định với siêu tham số hyperparameter mặc định nghĩa là sao",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 3,
      "start_timestamp": "0:02:47",
      "end_timestamp": "0:03:33"
    }
  },
  {
    "page_content": "siêu tham số hyperparameter mặc định nghĩa là sao Nếu như các phương pháp trước thì siêu tham số chúng ta phải tune khá là nhiều để mà có thể hiệu quả Thì Adam với siêu tham số mặc định của mình Chúng ta cũng có thể chạy ra được một cái thuật toán mà nó ổn định Và đó chúng ta không cần phải chú ý để mà tune quá nhiều với cái siêu tham số này Thì chi tiết cái thuật toán Adam nó như thế nào thì chúng ta sẽ tìm hiểu trong những slide tiếp theo Và chi tiết của cái thuật toán Adam Adaptive Moment",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 4,
      "start_timestamp": "0:03:29",
      "end_timestamp": "0:04:06"
    }
  },
  {
    "page_content": "chi tiết của cái thuật toán Adam Adaptive Moment Optimization là nằm ở đây Chúng ta đầu tiên cũng sẽ khởi tạo là alpha là bằng 0.1 Đối với cái Decay Rate thì bình thường trong cái Root Mean Square Propagation chúng ta chỉ có duy nhất một cái beta Thì ở đây chúng ta sẽ có hai cái beta là beta 1 và beta 2 Trong đó beta 1 là cái hệ số momentum là cái Decay Rate cho cái momentum của gradient Cho cái việc cập nhật cái momentum của gradient Còn cái beta 2 sẽ là cho cái việc cập nhật cái hệ số chuẩn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 5,
      "start_timestamp": "0:04:00",
      "end_timestamp": "0:05:03"
    }
  },
  {
    "page_content": "2 sẽ là cho cái việc cập nhật cái hệ số chuẩn hóa, cái thành phần chuẩn hóa Chuẩn hóa cái Learning Rate Và chúng ta sẽ yr thì chúng ta sẽ có thêm s, s chính là cái thành phần momentum cho gradient Thành phần momentum cho gradient Thì đây chính là cái momentum cho cái beta gradient của mình Và công thức của mình là bình thường là trong cái phần Root Mean Square Propagation thì s của mình chính là chỉ bằng g thôi Còn bây giờ s của mình nó sẽ là bằng cái thành phần quá khứ Nhân với lại, cộng với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 6,
      "start_timestamp": "0:04:59",
      "end_timestamp": "0:05:44"
    }
  },
  {
    "page_content": "cái thành phần quá khứ Nhân với lại, cộng với lại cái thành phần gradient hiện tại Đây là hiện tại Còn đây là cái thành phần quá khứ Và nó sẽ là bằng 90% của quá khứ cộng cho 10% của hiện tại Và như hồi nãy chúng ta đã lập luận thì cái việc mà lấy quá nhiều cho cái quá khứ Nó sẽ khiến cho những cái bước cập nhật đầu tiên rất là chậm Thì chúng ta sẽ có cái thành phần chuẩn hóa ở phía sau, chúng ta sẽ giải thích sau Đây, s mũ, đó chính là cái thành phần chuẩn hóa cho cái s ở phía trên Thế thì tại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 7,
      "start_timestamp": "00:05:41",
      "end_timestamp": "0:06:21"
    }
  },
  {
    "page_content": "phần chuẩn hóa cho cái s ở phía trên Thế thì tại sao cái việc chuẩn hóa với cái công thức này thì những cái vòng lặp đầu tiên của mình Nó sẽ có cái giá trị không quá bé Thì bây giờ chúng ta giả sử, s ban đầu của mình là một cái con số rất là bé Như đã giải thích, s sẽ là bằng quá khứ là bằng 90% của cái s ban đầu là bằng 0 Tức là cái thành phần này là bằng 0 Tức là ở những cái vòng lặp đầu tiên là ban đầu Thì s sẽ là bằng quá khứ là bằng 0 Cộng cho 10% của g thì cái thành phần này rất là bé",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 8,
      "start_timestamp": "00:06:17",
      "end_timestamp": "0:07:08"
    }
  },
  {
    "page_content": "cho 10% của g thì cái thành phần này rất là bé Nhưng khi chúng ta chia cho căn của 1 trừ beta mũ t với t là số thứ tự t là cái bước lặp của mình Thì ở cái vòng lặp đầu tiên, tức là t bằng 1 Vòng lặp đầu tiên t bằng 1 Thì khi đó s sẽ là bằng 1 trừ cho beta mũ của mình là 0.9 mũ 1 0.9 mũ 1 tức là 0.9 Thì 1-0.9 tức là 0.1 Thì s mà chia cho 0.1 tương đương với s chúng ta sẽ nhân lên 10 lần Thì ban đầu s của mình rất là thấp Nó chỉ bằng khoảng 0.9 cái đạo hàm gốc của mình thôi Nhưng mà chúng ta chia",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 9,
      "start_timestamp": "0:07:05",
      "end_timestamp": "0:07:52"
    }
  },
  {
    "page_content": "đạo hàm gốc của mình thôi Nhưng mà chúng ta chia cho 0.1 tức là nhân 10 lên Thì có phải là s của mình tương đương với đạo hàm tại thời điểm ban đầu Thì nó đã được boost lên 10 lần Thì công thức này sẽ giúp chúng ta boost tại những thời điểm đầu tiên Thế thì khi t mà càng lớn, đương nhiên không thể nào mà t tiến đến vô cùng được T chỉ là khoảng 10-20, ví dụ vậy, cỡ 10 cho đến 20 đi Thì khi đó là beta 1 mũ t Beta 1 là một con số bé hơn 1, lớn hơn 0 Nên nó sẽ tiến đến, nó sẽ tiến về 0 Do đó 1 trừ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 10,
      "start_timestamp": "00:07:49",
      "end_timestamp": "0:08:34"
    }
  },
  {
    "page_content": "0 Nên nó sẽ tiến đến, nó sẽ tiến về 0 Do đó 1 trừ beta 1 mũ t, nó sẽ tiến về 1 1 trừ 0 tức là bằng 1 Tức là khi đó s mũ của chúng ta sẽ xấp xỉ bằng s chia cho 1 Tức là nó sẽ bằng nguyên bản của momentum ban đầu của mình Thì khi t mà càng lớn thì gần như không cần boost lên nữa Còn khi t của mình nhỏ, khoảng 1-2 thì nó sẽ boost lên rất là nhiều lần Đó là ý nghĩa của công thức chuẩn hóa này Tương tự như vậy, cho thành phần để cập nhật chuẩn hóa của learning rate Chúng ta cũng sẽ dùng công thức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 11,
      "start_timestamp": "0:08:29",
      "end_timestamp": "0:09:19"
    }
  },
  {
    "page_content": "của learning rate Chúng ta cũng sẽ dùng công thức này để giúp cho việc mà tại những thời điểm đầu tiên Nó không quá bé, nó sẽ xấp xỉ bằng với lại đạo hàm của mình luôn Và ý nghĩa của công thức này, tương tự như trong root mean square propagation Mục tiêu của nó là để tách ra, tìm ra là 1 cái vector Nên nó sẽ tách ra thành những learning rate riêng khi chúng ta cập nhật vô thành phần đạo hàm Và nó làm theo nguyên tắc, thành phần đạo hàm nào ở bên đây Của g mà càng nhỏ thì learning rate sẽ càng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 12,
      "start_timestamp": "00:09:13",
      "end_timestamp": "0:10:04"
    }
  },
  {
    "page_content": "đây Của g mà càng nhỏ thì learning rate sẽ càng lớn Thành phần của g này lớn thì learning rate sẽ nhỏ Như vậy là Adam đã có những cải tiến chính Đó là nó có thêm momentum cho vector gradient Nó có thêm thành phần chuẩn hóa để những vòng lặp đầu tiên không quá nhỏ Thành phần đạo hàm của mình không quá bé, hoặc là cái phần chuẩn hóa đạo hàm cũng không quá bé Nó bị sai lệch so với lại đạo hàm tại thời điểm đó Trong sơ đồ này thì chúng ta sẽ có trực quan hóa để cho thấy tốc độ hội tụ của từng thuật",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 13,
      "start_timestamp": "0:09:58",
      "end_timestamp": "0:10:51"
    }
  },
  {
    "page_content": "quan hóa để cho thấy tốc độ hội tụ của từng thuật toán Ở đây Adam là đường màu vàng của mình Đường màu vàng này Đường màu vàng sẽ rớt xuống rất nhanh, hội tụ rất nhanh Khi đến khu vực saddle point và valley thung lũng Thung lũng có 2 cái thành, giảm từ dốc, đi ngang, xong rồi lại đi lên, đó gọi là valley Adam rớt xuống nhanh nhất, rất nhanh Còn thuật toán root mean square propagation là đường màu đen Chúng ta thấy nó sẽ rớt chậm hơn Còn stochastic gradient descent, đối với stochastic gradient",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 14,
      "start_timestamp": "0:10:46",
      "end_timestamp": "0:11:29"
    }
  },
  {
    "page_content": "gradient descent, đối với stochastic gradient descent là cái chấm màu đỏ Chúng ta thấy nó bị dao động qua lại và nó đứng yên luôn Nó không thoát ra được chỗ này luôn Momentum thì khá hơn một chút xíu là cái điểm màu xanh lá Chúng ta thấy là khi momentum rớt xuống nó cũng sẽ dao động qua lại Nhưng mà vì có một số kiểu tối nhiễu nên nó sẽ dần dần thoát ra được Và nó đến được cái rảnh này nó di chuyển Trong khi các phương pháp cải tiến khác thì nó cũng bị hiện tượng dao động qua lại rất nhiều Nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 15,
      "start_timestamp": "0:11:22",
      "end_timestamp": "0:12:05"
    }
  },
  {
    "page_content": "cũng bị hiện tượng dao động qua lại rất nhiều Nó bị hiện tượng dao động qua lại Bật qua bật lại Còn Adam là cái đường màu vàng thì nó sẽ rớt thẳng xuống luôn Nó sẽ đi theo cái đường cập nhật hoàn hảo Cái đường cập nhật mà tối ưu ở đây Bên phải thì đó là cái sơ đồ về giá trị của hàm loss khi chúng ta sử dụng các thuật toán khác nhau Thì Adam là cái đường màu tím Nó cho cái giá trị hàm loss hội tụ nhanh hơn và nó thấp nhất Loss càng thấp càng tốt Thì cái training loss của mình càng thấp càng tốt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 16,
      "start_timestamp": "0:11:59",
      "end_timestamp": "0:12:40"
    }
  },
  {
    "page_content": "Thì cái training loss của mình càng thấp càng tốt Thì chúng ta thấy là nó hội tụ nhanh hơn nhiều so với lại các thuật toán Như là root mean square, AdaDelta, AdaGrad, v.v. Thì kết luận đó là một số phương pháp tối ưu mô hình học sâu bằng cách Trong cái phần này chúng ta đã được thảo luận qua những cách để tùy chỉnh learning rate Cho từng cái tham số Và thuật toán, câu hỏi là thuật toán nào sẽ được chọn khi huấn luyện Thì câu trả lời đó là không chắc chắn Nó sẽ tùy thuộc vào cái dữ liệu của các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 17,
      "start_timestamp": "0:12:37",
      "end_timestamp": "0:13:09"
    }
  },
  {
    "page_content": "chắc chắn Nó sẽ tùy thuộc vào cái dữ liệu của các bạn như thế nào Nó phụ thuộc vào cái mô hình của mình nó có phức tạp hay không Ví dụ đối với những cái mô hình phức tạp mà nhiều tham số Thì khi đó chúng ta sẽ phải dùng các cái thuật toán ví dụ như là Root Mean Square, Prop, Propagation hoặc là Adam Nhưng đối với những cái mô hình mà ít tham số Thì khi đó Adam và Root Mean Square là không cần thiết Mà chúng ta chỉ cần Stochastic Gradient Descent là đủ Rồi nếu mà dữ liệu của mình không quá phức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 18,
      "start_timestamp": "0:13:03",
      "end_timestamp": "0:13:38"
    }
  },
  {
    "page_content": "là đủ Rồi nếu mà dữ liệu của mình không quá phức tạp Thì chúng ta có thể dùng Stochastic Gradient Descent Nhưng nếu mà phức tạp thì chúng ta sẽ dùng 2 cái thuật toán bên đây Thì đa số các cái thuật toán đều có cái sự phổ biến nhất định của mình Và được lựa chọn tùy theo cái sự quen thuộc của người dùng Như vậy thì đến đây chúng ta đã tìm hiểu qua 2 cái biến thể rất là nổi tiếng của Adaptive Learning Rate Đó là Root Mean Square, Propagation và Adam Thì cái Root Mean Square, Propagation là một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Adam Thì cái Root Mean Square, Propagation là một cái tiền đề để cho Adam có thể cải tiến Và Adam nó có một cái cải tiến khá là quan trọng Đó là chuẩn hóa để giúp cho những cái bước cập nhật đầu tiên của mình nó không quá chậm Và đây chính là những cái thuật toán Optimizer được sử dụng trong rất nhiều những cái mô hình học sâu Những cái mô hình mà dựa trên Gradient về sau Và nó sẽ là tiền đề cho chúng ta đi tiếp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=B_yXn7nINWM",
      "filename": "B_yXn7nINWM",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 7 (New)",
      "chunk_id": 20,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với một trong những kiến trúc mạng rất là nổi tiếng, nổi bật và ý tưởng của nó cũng rất là hay và thú vị là chính là mạng tạo sinh đối kháng GAN. Chúng ta sẽ đến với ý tưởng của mạng GAN. Đối với các kiến trúc trước, chúng ta sẽ phải có một công đoạn đó là nén dữ liệu hay là encode dữ liệu. Từ một con số hoặc từ một tấm ảnh, chúng ta sẽ có một giai đoạn đó là biến nó và nén thành một VectorZ. Thế thì cái GAN nó xuất phát ý tưởng đó là mình chỉ muốn lấy mẫu, tức là chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:06"
    }
  },
  {
    "page_content": "đó là mình chỉ muốn lấy mẫu, tức là chúng ta chỉ lấy mẫu và sau đó chúng ta tạo ra một tấm ảnh mới mà không có công đoạn nén này. Tại vì mục tiêu của mình không phải là để nén ảnh, mà mục tiêu của mình là để sinh ảnh. Các mạng tạo sinh của mình mình hướng đến là công dụng là sinh ảnh chứ không phải là để nén ảnh. Nén ảnh thì chúng ta có thể sử dụng các thuật toán nén chuyên biệt, có hiệu suất rất là cao. Vậy thì mong muốn đó là chúng ta chỉ muốn lấy mẫu để mà từ đó chúng ta tạo ra ảnh mới mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:39"
    }
  },
  {
    "page_content": "lấy mẫu để mà từ đó chúng ta tạo ra ảnh mới mà không cần cái công việc nén ảnh tại vì đây là cái công việc thừa. Ừm không, thì cái ý tưởng đó là chúng ta sẽ không cần mô hình hóa cái không gian ẩn một cách tường minh mà chỉ cần lấy mẫu để tạo ảnh mới. Như vậy thì GAN sẽ xuất phát điểm đó là không có cái công đoạn nén này mà từ cái vector z chúng ta sẽ tạo ra tấm ảnh mới luôn. Ở đây chúng ta sẽ phải có một cái mạng nó gọi là mạng tạo sinh z hay viết tắt của chữ là generator. Với cái generator",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:24",
      "end_timestamp": "0:02:34"
    }
  },
  {
    "page_content": "viết tắt của chữ là generator. Với cái generator này, từ một cái vector nhiễu, một cái vector noise z, nó qua cái mạng G thì nó sẽ tạo ra một cái tấm ảnh x và mình mong muốn cái ảnh giả này nè, dùng cái từ tức là từ fake là cái ảnh giả này nè, thu được từ cái mô hình, học được cái phân bố của dữ liệu thật, tức là cái x fake này nè, nó sẽ nằm trong cái phân bố của dữ liệu thật này của mình. Vậy thì vấn đề ở đây đó là chúng ta không lấy mẫu trực tiếp từ một cái phân phối phức tạp tại vì chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:20",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "từ một cái phân phối phức tạp tại vì chúng ta không tạo ảnh hay là còn không tạo ảnh mong muốn. Vậy thì bây giờ giải pháp đó là gì? Đó là chúng ta sẽ lấy mẫu từ một vector đơn giản, đó là một cái vector nhiễu, rồi sau đó chúng ta học cái cách biến đổi sang cái phân phối dữ liệu. Vậy thì chúng ta sẽ lấy mẫu từ cái vector z là trong một cái vector nhiễu, rồi sau đó chúng ta sẽ, đây là một vector đơn giản, một vector nhiễu, rồi học cái cách biến đổi sang cái phân bố dữ liệu. Đây là cái phân bố x",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:54",
      "end_timestamp": "0:03:43"
    }
  },
  {
    "page_content": "sang cái phân bố dữ liệu. Đây là cái phân bố x của dữ liệu. Chúng ta sẽ tìm cái hàm ảnh xạ này. Chứ còn cái việc mà chúng ta lấy mẫu ngẫu nhiên trong cái không gian này là khó. Chúng ta bốc ra một cái lấy mẫu ngẫu nhiên trong cái không gian này sẽ là khó. Rất khó để mà chúng ta có thể lấy ra được một cái tấm ảnh mà có cái tính chất giống như cái ảnh thật mà chúng ta sẽ lấy mẫu theo một cái vector đơn giản nào đó và ngẫu nhiên hoàn toàn. Thì cái việc lấy mẫu ngẫu nhiên này là dễ. Lấy mẫu ngẫu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:32",
      "end_timestamp": "0:04:25"
    }
  },
  {
    "page_content": "việc lấy mẫu ngẫu nhiên này là dễ. Lấy mẫu ngẫu nhiên là dễ. Sampling, vector z, ngẫu nhiên thì dễ. Còn cái việc mà chúng ta lấy mẫu trong cái không gian phân bố ảnh này đó là một cái thao tác phức tạp. Tại vì mình không có cái mô hình nào có thể mô phỏng được cái phân bố phức tạp của x này. Thì đây là một cái phân bố phức tạp. Rồi, vậy thì cái kiến trúc của mạng GAN hay là viết tắt của Generative Adversarial Network hay là mạng tạo sinh đối kháng là một cái phương pháp để tạo ra một cái mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:12",
      "end_timestamp": "0:05:12"
    }
  },
  {
    "page_content": "kháng là một cái phương pháp để tạo ra một cái mô hình sinh bằng cách để hai cái mạng đối kháng với nhau. Thì ở cái bước đầu tiên đó là cái bước generator là bước tạo sinh. Thì đây là một cái mô hình tạo sinh generator. Nó sẽ từ một cái vector z là một vector nhiễu ngẫu nhiên. Nó sẽ tạo thành một cái dữ liệu giả là cái x fake này. Chính là cái dữ liệu giả để cố đánh lừa cái mô hình D này. Để cố đánh lừa cái mô hình D sao cho cái mô hình D này nó không phân biệt được cái ảnh thật và ảnh giả. Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:04:54",
      "end_timestamp": "0:05:59"
    }
  },
  {
    "page_content": "không phân biệt được cái ảnh thật và ảnh giả. Thì cái x real này là cái x mà chúng ta thu thập. Đây là cái dữ liệu chúng ta thu thập trong thực tế. Sau đó chúng ta sẽ đi huấn luyện từ cái x real và x fake này chúng ta sẽ đi huấn luyện cái D để làm sao cho nó có thể phân biệt được là ảnh thật và ảnh giả. Thì cái mô hình phân loại, mô hình D này là discriminator là sẽ cố gắng xác định xem dữ liệu thật và dữ liệu giả do z tạo ra. X fake này là do z tạo ra. Thì D nó sẽ tìm cách đi phân biệt hai",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:46",
      "end_timestamp": "0:06:32"
    }
  },
  {
    "page_content": "z tạo ra. Thì D nó sẽ tìm cách đi phân biệt hai này. Và tại sao chúng ta gọi là đối kháng? Tại vì nhiệm vụ của G và D là hai cái nhiệm vụ mà ngược nhau. G mục tiêu của mình đó là tạo ra cái dữ liệu không có, là tạo ra một cái dữ liệu nhìn giống thật nhất có thể. Trong khi đó D thì nhiệm vụ của nó lại là phân biệt hai cái mẫu dữ liệu này. Một bên thật và một bên giả. Nếu chúng ta đối chiếu nó với hình ảnh trong thực tế thì G nó giống như là một cái người in tiền giả. Còn D là cái cảnh sát, là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:25",
      "end_timestamp": "0:07:27"
    }
  },
  {
    "page_content": "cái người in tiền giả. Còn D là cái cảnh sát, là công an chống cái việc là in tiền giả. Thì hai người này sẽ thực hiện hai cái công việc ngược nhau. Một người tìm cách phát hiện và một người sẽ tìm cách đi làm giả. Vậy thì ở đây chúng ta sẽ có cái bản chất và ý tưởng của GAN đó là gì? Mô hình G là mô hình tạo sinh G sẽ cố gắng bắt đầu từ một cái dữ liệu nhiễu để bắt chước cái dữ liệu thật. Ở đây màu đỏ là chúng ta minh họa cho cái dữ liệu giả và dữ liệu fake. Và mô hình G này được từ các cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:07:14",
      "end_timestamp": "0:08:00"
    }
  },
  {
    "page_content": "và dữ liệu fake. Và mô hình G này được từ các cái vector nhiễu G1, G2, GN tạo ra các cái điểm dữ liệu giả này. Sau đó thì cái mô hình phân biệt, tức là mô hình D, Discriminator sẽ xem xét cả dữ liệu thật và dữ liệu giả được tạo ra. Dữ liệu thật sẽ được mô tả bởi màu xanh, còn dữ liệu giả là từ bên đây chúng ta đem qua. Là từ Cascade generator chúng ta đem qua. Ba cái điểm này. Thì Discriminator sẽ phải huấn luyện để mà phân biệt. Giả sử như chúng ta có một cái đường ở trên là cái xác suất để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:07:53",
      "end_timestamp": "0:08:35"
    }
  },
  {
    "page_content": "ta có một cái đường ở trên là cái xác suất để thuộc về dữ liệu thật. Và cao nhất của mình xác suất đó sẽ là bằng 100%. Thì ban đầu Discriminator của mình nó sẽ rất là yếu, nó sẽ không có chính xác. Nên chúng ta sẽ thấy là cái xác suất của những cái điểm dữ liệu giả của mình nó khá là cao. Nó sẽ xem xem. Nó sẽ xem xem với lại cái chiều cao, tức là cái xác suất của các điểm dữ liệu thật. Do đó chúng ta sẽ tìm cách để huấn luyện cho cái Discriminator này sẽ càng lúc nó sẽ có cái khả năng phân biệt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:08:32",
      "end_timestamp": "0:09:12"
    }
  },
  {
    "page_content": "này sẽ càng lúc nó sẽ có cái khả năng phân biệt tiền thật và tiền giả. Phân biệt mẫu dữ liệu thật, dữ liệu giả càng chính xác hơn. Thì khi chúng ta huấn luyện thì chúng ta thấy là cái xác suất của các điểm dữ liệu thật nó sẽ càng lúc càng được đẩy lên. Trong khi đó các mẫu dữ liệu giả xác suất của nó sẽ càng lúc bị đẩy xuống. Điều đó có nghĩa là cái Discriminator nó đang giỏi lên. Và đến được một cái mức đó là nó gần sắp sử dụng mô. Thì đó là cái mô hình của chúng ta đã hoạt động rất là tốt với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:09:04",
      "end_timestamp": "0:09:57"
    }
  },
  {
    "page_content": "mô hình của chúng ta đã hoạt động rất là tốt với cái mẫu dữ liệu thật và mẫu dữ liệu giả như thế này. Tuy nhiên chúng ta nhìn thấy là cái dữ liệu thật và dữ liệu giả là hiện giờ nó vẫn còn cách nhau khá là xa. Về mặt phân bố nó nằm ở xa nhau. Do đó nên cái Discriminator nó sẽ phân biệt rất là tốt. Do đó thì cái Generator này sẽ tìm cách học như thế nào đó để cho hai cái phân bố này nó sẽ tiến về lại gần nhau hơn. Tức là các điểm màu đỏ sẽ tiến về gần các điểm màu xanh hơn. Chúng ta thấy là nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:09:51",
      "end_timestamp": "0:10:31"
    }
  },
  {
    "page_content": "về gần các điểm màu xanh hơn. Chúng ta thấy là nó đã tiến về gần hơn. Rồi, và khi hai điểm màu đỏ và màu xanh nó đã tiến về gần hơn. Tức là cái mẫu dữ liệu giả này nó đã có vẻ thật hơn. Thì khi đó chúng ta đem qua Discriminator cũng cái dữ liệu này chúng ta đem qua đây. Thì chúng ta sẽ thấy là cái xác suất qua Discriminator thì cái xác suất của các điểm dữ liệu giả nó khá là cao. Nó không bằng cái điểm thật nhưng mà nó đã được đẩy lên rất là cao và gần với lại cái ngưỡng Peril là bằng 100%. Thế",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:10:27",
      "end_timestamp": "0:11:07"
    }
  },
  {
    "page_content": "và gần với lại cái ngưỡng Peril là bằng 100%. Thế là bằng 1 đây. Thì cái điều này là không tốt. Vậy đến là Discriminator sẽ tìm cách để cải thiện cái hiệu quả của mình bằng cách là học ra và đè cái phân bố này xuống. Chúng ta thấy là cái phân bố của nó sẽ càng lúc được đẩy xuống dưới. Và cái phân bố và cái xác suất của cái dự đoán của các điểm dữ liệu thật nó đã được đẩy lên gần sát với lại 100%. Thì khi đó là cái Discriminator của mình nó đã tốt lên. Và cái dữ liệu Generator này thì cũng tương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:11:01",
      "end_timestamp": "0:11:35"
    }
  },
  {
    "page_content": "lên. Và cái dữ liệu Generator này thì cũng tương tự như vậy. Nó sẽ tìm cách là đánh lừa Discriminator. Do đó thì cái mẫu dữ liệu mới nó được tạo ra. Nó đã càng lúc càng tiến sát vào bên trong gần với điểm dữ liệu thật hơn. Thì đến đây chúng ta đã thấy rằng cái phân bố của dữ liệu thật và dữ liệu giả nó đã hòa vào nhau. Nó càng tiến đến gần hơn. Và đến đây đó là 2 cái này gần như là trùng nhau. Thì đây chính là cái ý tưởng của Mạng GAN là Mạng tạo sinh đối kháng. Cảm ơn các bạn đã xem video. Hãy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "sinh đối kháng. Cảm ơn các bạn đã xem video. Hãy đăng ký kênh để xem video mới nhất.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CLsUzFx203A",
      "filename": "CLsUzFx203A",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng tìm hiểu về một số biến thể đơn giản của thuật toán Gradient Descent. Đến với biến thể đầu tiên, là Batch Gradient Descent, truyền toàn bộ dữ liệu vào mô hình của mình. Công thức cập nhật của Batch Gradient Descent là tính kỳ vọng trên toàn bộ dữ liệu. Đạo hàm của kỳ vọng của G theta, tức là kỳ vọng của toàn bộ các hàm lỗi. Chúng ta sẽ tính đạo hàm của trung bình lỗi của toàn bộ dữ liệu. Thay vì chúng ta tính hàm lỗi, giá trị sai số trên một mẫu dữ liệu, chúng ta sẽ tính trung",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:30"
    }
  },
  {
    "page_content": "số trên một mẫu dữ liệu, chúng ta sẽ tính trung bình sai số, trung bình lỗi trên toàn bộ dữ liệu của mình. Bên dưới là một đoạn mã giả, trong đó trung bình sai số sẽ duyệt qua số lượt dữ liệu. Khi chúng ta lặp đi lặp lại, chúng ta có thể huấn luyện 10, 20, 200, 300, 1000, 400, 500, 1000 dữ liệu. Mỗi một epoch là một lần chúng ta sẽ duyệt qua dữ liệu của mình. Nếu như khối này là biểu diễn cho toàn bộ dữ liệu, thì với mỗi epoch chúng ta sẽ xử lý trên toàn bộ dữ liệu của mình. Và data ở đây chính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 1,
      "start_timestamp": "0:01:20",
      "end_timestamp": "0:02:35"
    }
  },
  {
    "page_content": "toàn bộ dữ liệu của mình. Và data ở đây chính là phần chúng ta xử lý để huấn luyện trong một vòng lặp. Còn đối với thuật toán Stochastic Gradient Descent hay viết tắt là chữ SGD, chúng ta sẽ truyền từng mẫu huấn luyện vào. Lúc này thì công thức sẽ là theta bằng theta trừ cho đạo hàm của... đây là cái hàm lỗi của một mẫu dữ liệu. Và khi này thì mã giả của mình chúng ta sẽ duyệt qua mọi epoch và với mỗi epoch chúng ta sẽ shuffle data của mình. Tức là data của mình sẽ xáo trộn lên, do đó ở đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 2,
      "start_timestamp": "0:02:27",
      "end_timestamp": "0:03:26"
    }
  },
  {
    "page_content": "Tức là data của mình sẽ xáo trộn lên, do đó ở đây không phải là data mà là shuffle data. Sau đó thì, for each example, tức là với mỗi một example, thì ở đây chúng ta sẽ lấy ra đúng một mẫu thôi. Và mẫu này là random. Rồi sau đó chúng ta sẽ xác định cái lỗi và sau đó là tính cái gradient, rồi sau đó cập nhật lại cái tham số. Với mỗi một cái lượt này, thì đó là một cái data của mình. Đây sẽ là một cái example. Mỗi example sẽ là một mẫu dữ liệu. Và chúng ta sẽ truyền vào cái example, thay vì chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 3,
      "start_timestamp": "0:03:20",
      "end_timestamp": "0:04:00"
    }
  },
  {
    "page_content": "chúng ta sẽ truyền vào cái example, thay vì chúng ta truyền vào toàn bộ dữ liệu giống như trong slide trước. Trong slide trước là chúng ta truyền vào toàn bộ dữ liệu. Thì ở đây chúng ta chỉ truyền vào một mẫu thôi. Và một mẫu này sẽ được lấy random. Một mẫu random. Cái biến thể tiếp theo đó chính là mini-batch gradient descent hay viết tắt là MGD. Thì chúng ta thay vì truyền vào một mẫu, thì chúng ta sẽ truyền vào một khối hay batch. Cái mẫu huấn luyện. Và cái batch size ở đây, cái kích thước",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 4,
      "start_timestamp": "0:03:55",
      "end_timestamp": "0:04:39"
    }
  },
  {
    "page_content": "luyện. Và cái batch size ở đây, cái kích thước của cái mẫu, kích thước của cái khối là viết tắt của chữ batch size. Đây là kích thước của khối. Thì với cái kích thước khối thì thông thường nó là những con số chia hết cho, nó là con số lũy thừa của 2. Ví dụ như là 1, 2, 4, 8, 16 v.v. Và cái công thức của mình lúc này thì nó sẽ là theta bằng theta trừ cho đạo hàm của hàm loss được tính trên một khối. Đây là một batch. Và cái batch này có kích thước là n. Lưu ý là từ i cho đến i, i cộng n thì có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 5,
      "start_timestamp": "0:04:33",
      "end_timestamp": "0:05:26"
    }
  },
  {
    "page_content": "là n. Lưu ý là từ i cho đến i, i cộng n thì có thể chúng ta sẽ hiểu là nó có n cộng 1 giá trị. Nhưng mà nếu mà chiếu theo cái cú pháp của python thì là từ i cho đến giá trị ngay trước i cộng n thì nó sẽ là có n phần tử. Và cái mã giả của mình nó sẽ là mini-batch GD là chúng ta sẽ lặp qua số epoch và với mỗi lần lặp, với mỗi epoch thì chúng ta sẽ shuffle data, chúng ta sẽ random dữ liệu. Thì đây sẽ là shuffle data. Rồi sau đó sau khi chúng ta đã shuffle data xong thì chúng ta sẽ lấy một batch,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 6,
      "start_timestamp": "0:05:18",
      "end_timestamp": "0:06:08"
    }
  },
  {
    "page_content": "shuffle data xong thì chúng ta sẽ lấy một batch, lấy một batch thì chúng ta sẽ có một cái hàm get_batch. Get_batch này nó sẽ chia cái data của mình ra làm nhiều phần. Ví dụ như mỗi cái phần này nó sẽ là một batch. Chúng ta sẽ duyệt qua hết các cái batch trong cái shuffle data này. Bắt đầu chúng ta sẽ train trên dữ liệu này sau đó chúng ta sẽ train trên dữ liệu tiếp theo, cái batch tiếp theo. Sau đó chúng ta sẽ train trên cái phần tiếp theo. Rồi sau đó chúng ta sẽ train trên cái phần cuối cùng.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 7,
      "start_timestamp": "0:06:03",
      "end_timestamp": "0:06:47"
    }
  },
  {
    "page_content": "sau đó chúng ta sẽ train trên cái phần cuối cùng. Thì for batch in get_batch thì nó sẽ là duyệt qua tất cả cái batch của cái dữ liệu đã được xáo trộn ngẫu nhiên này. Và ở đây thay vì chúng ta truyền vào data hoặc là example thì ở đây chúng ta sẽ không có truyền data, không truyền example mà truyền vào nguyên một khối dữ liệu. Thế thì bây giờ chúng ta sẽ cùng tìm hiểu xem là cái ưu khuyết điểm của từng cái phương pháp này là gì. Thì đối với cái batch gradient descent thì số mẫu dữ liệu chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 8,
      "start_timestamp": "0:06:40",
      "end_timestamp": "0:07:22"
    }
  },
  {
    "page_content": "gradient descent thì số mẫu dữ liệu chúng ta huấn luyện là chúng ta sẽ tính trên toàn bộ mẫu dữ liệu. Do đó đương nhiên chi phí tính toán của mình nó sẽ rất là cao. Chi phí tính toán cao do tại một thời điểm chúng ta sẽ phải tính hết trên toàn bộ dữ liệu. Trong khi đó stochastic gradient descent thì tại một thời điểm huấn luyện chúng ta chỉ lấy ra một mẫu dữ liệu để tính toán. Và stochastic gradient descent thì nó sẽ khiến cho cái thời gian tính toán nó chậm. Lý do đó là vì trong Python nếu mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 9,
      "start_timestamp": "0:07:13",
      "end_timestamp": "0:08:03"
    }
  },
  {
    "page_content": "toán nó chậm. Lý do đó là vì trong Python nếu mà chúng ta tính theo khối, tính theo một cái lượng lớn dữ liệu thì nó sẽ nhanh hơn chúng ta sẽ tính lẻ trên từng dữ liệu. Và mini-batch gradient descent là một cái thuật toán mà nó sẽ trung hòa ở giữa. Tức là chi phí tính toán thì nó không lớn như batch gradient descent, tức là tính trên hết toàn bộ mẫu dữ liệu. Nhưng mà thời gian tính toán thì nó cũng sẽ không có chậm như là với stochastic gradient descent. Tức là chúng ta sẽ phải tính đi tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 10,
      "start_timestamp": "0:07:55",
      "end_timestamp": "0:08:35"
    }
  },
  {
    "page_content": "descent. Tức là chúng ta sẽ phải tính đi tính lặp, chúng ta sẽ thực hiện việc cập nhật cho một epoch là chúng ta phải thực hiện nhiều lần. Thì đó là về mặt chi phí tính toán cũng như là thời gian tính toán. Còn về hàm lỗi, cái dạng thức của hàm lỗi, đối với batch gradient descent thì nó sẽ ra một cái đường nó rất là mượt. Hay tiếng Anh nó gọi là smooth. Trong khi đó thì cái hàm lỗi khi chúng ta huấn luyện qua từng cái vòng lặp, đối với stochastic gradient descent thì chúng ta sẽ thấy nó rất là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 11,
      "start_timestamp": "0:08:20",
      "end_timestamp": "0:09:26"
    }
  },
  {
    "page_content": "gradient descent thì chúng ta sẽ thấy nó rất là giật cục, nó rất là không ổn định, unstable. Nhưng nhìn chung thì cái loss của mình mặc dù nó đi lên đi xuống nhưng mà nó vẫn sẽ là đi xuống hết. Khi mà chúng ta lặp đủ nhiều thì loss của mình cũng sẽ giảm xuống. Còn đối với cái mini-batch gradient descent thì nó cũng sẽ trung hòa giữa cả hai. Một, đó là nó cũng tương đối mượt nhưng mà nó cũng sẽ có những cái giật cục nhất định nhưng mà nó sẽ không có bất ổn định giống như là stochastic gradient",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 12,
      "start_timestamp": "0:09:11",
      "end_timestamp": "0:09:56"
    }
  },
  {
    "page_content": "có bất ổn định giống như là stochastic gradient descent. Thì đây chính là cái mô hình mà, cái thuật toán nó sẽ trung bình trung hòa được cái điểm yếu của cả hai cái batch gradient descent và stochastic gradient descent. Thông thường thì khi chúng ta huấn luyện với deep learning thì chúng ta sẽ phải dùng một trong hai cái stochastic hoặc là mini-batch. Lý do đó là vì trong deep learning thì cái dữ liệu của mình thường rất là lớn. Cái data set của mình nó thường gọi là large scale data set. Và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 13,
      "start_timestamp": "0:09:46",
      "end_timestamp": "0:10:31"
    }
  },
  {
    "page_content": "mình nó thường gọi là large scale data set. Và khi đó thì cái bộ nhớ mà mình lưu trữ cái dữ liệu thôi nó cũng đã không đủ rồi. Chứ đừng có nói là lưu cái mô hình và tính toán trên cái mô hình. Còn các cái data set lớn thì nó sẽ rất là phù hợp cho cái stochastic và mini-batch. Nếu như chúng ta không biết, bắt đầu chúng ta thử thì chúng ta nên thử với stochastic gradient descent tại vì nó chắc chắn là ít tốn bộ nhớ nhất. Nhưng mà khi chúng ta thấy là nó vẫn còn dư dả cái dung lượng bộ nhớ thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 14,
      "start_timestamp": "0:10:21",
      "end_timestamp": "0:10:31"
    }
  },
  {
    "page_content": "là nó vẫn còn dư dả cái dung lượng bộ nhớ thì chúng ta sẽ tăng nó lên là thành mini-batch. Thì đó là một số cái ưu khuyết điểm của các cái phiên bản, các cái biến thể của gradient descent, những cái biến thể đơn giản đầu tiên.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CtOfKuiy_uc",
      "filename": "CtOfKuiy_uc",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)",
      "chunk_id": 15,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với một chủ đề rất là hot trong thời gian gần đây, đó là mô hình ngôn ngữ thị giác. Xuất phát điểm ý tưởng của mô hình ngôn ngữ thị giác đó là các bài toán của chúng ta hiện nay đòi hỏi có sự tham gia của nhiều thể thức dữ liệu hay còn gọi là multimodality model. Mô hình ngôn ngữ thị giác có thể gồm các modalities là văn bản, hình ảnh, âm thanh và video. Thế thì tại sao các mô hình của mình có sự tham gia của các loại thể thức dữ liệu khác nhau, đó là do nhu cầu ứng dụng của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CYB6T-bfSCg",
      "filename": "CYB6T-bfSCg",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:09"
    }
  },
  {
    "page_content": "dữ liệu khác nhau, đó là do nhu cầu ứng dụng của mình. Ví dụ như chúng ta hiện nay chúng ta thấy các ứng dụng của AI hiện giờ là cho phép chúng ta có thể điều khiển hoặc là giao tiếp bằng giọng nói. Nhưng mà ứng với cái giọng nói đó thì chúng ta có thể tạo ra các hình ảnh hoặc là chúng ta có thể trò chuyện với hình ảnh. Thì những ứng dụng kiểu như vậy đòi hỏi có sự tham gia của nhiều thể thức khác nhau. Thế thì trong phạm vi của bài giảng hôm nay chúng ta sẽ cùng tìm hiểu về mô hình ngôn ngữ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CYB6T-bfSCg",
      "filename": "CYB6T-bfSCg",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:57",
      "end_timestamp": "0:01:46"
    }
  },
  {
    "page_content": "nay chúng ta sẽ cùng tìm hiểu về mô hình ngôn ngữ thị giác. Trong đó có sự tham gia của hai thể thức đó là văn bản và hình ảnh. Thì nội dung chính của chúng ta trong phần này chính là vai trò của mô hình ngôn ngữ thị giác hay là Vision Language Model. Và một số mô hình ngôn ngữ thị giác nổi bật, đầu tiên ví dụ như là Clip, Clip, Blip và Visual Programming. Đây là một trong những bài báo rất là thú vị. GPT4V thì đây là một trong những mô hình của OpenAI với mục tiêu đó là đưa mọi thể thức từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CYB6T-bfSCg",
      "filename": "CYB6T-bfSCg",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:40",
      "end_timestamp": "0:02:27"
    }
  },
  {
    "page_content": "của OpenAI với mục tiêu đó là đưa mọi thể thức từ hình ảnh văn bản về cùng một mô hình để xử lý. Thì chúng ta sẽ cùng tìm hiểu qua các mô hình này.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=CYB6T-bfSCg",
      "filename": "CYB6T-bfSCg",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:02:23",
      "end_timestamp": "0:02:27"
    }
  },
  {
    "page_content": "Chúng ta sẽ tiến hành cài đặt một cái mạng Neural Network. Đặc tính của cái mạng Neural Network là nó sẽ giúp chúng ta giải quyết được các bài toán non-linear. Và trong trường hợp này, chúng ta sẽ lấy tình huống đơn giản nhất của non-linear đó chính là các tập điểm hình tam giác và hình tròn. Thì hai tập điểm này không thể nào chia tách ra được bởi một đường thẳng. Do đó thì đường đúng sẽ phải là một đường tròn như thế này, thì nó mới có thể phân ra làm hai phần riêng biệt được. Thì đây là một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:56"
    }
  },
  {
    "page_content": "ra làm hai phần riêng biệt được. Thì đây là một cái bài toán phi tuyến. Và để giải quyết bài toán này thì chúng ta cũng không cần thiết phải sử dụng một cái mạng Neural Network quá phức tạp. Thì ở đây nó chỉ cần có một lớp ẩn thôi. Ở đây là một hidden layer. Cái mạng Neural Network đúng của chúng ta thì nó có thể có một, hai hoặc là rất nhiều hidden layer. Nhưng trong trường hợp này thì chúng ta chỉ cần minh họa với một hidden layer. Cái thứ hai đó là tập điểm này chỉ có hai thành phần. Do đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 1,
      "start_timestamp": "0:00:54",
      "end_timestamp": "0:01:32"
    }
  },
  {
    "page_content": "đó là tập điểm này chỉ có hai thành phần. Do đó thì ở đây chúng ta sẽ có duy nhất một cái node Output cuối cùng. Ở đây là chúng ta sẽ có một lớp input, một cái hidden layer và một cái Output. Và cái Output này thì do là cái giá trị của mình nó chỉ có một, nó chỉ có một phần lớp, xin lỗi nó có hai phần lớp. Nên ở đây chúng ta không có sử dụng hàm SIP, mà chúng ta sẽ sử dụng một cái hàm SIGMOID. Tại vì SIGMOID nó sẽ đưa cái miền giá trị của mình về cái đoạn từ 0 cho đến 1. Và lúc này thì cái giá",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 2,
      "start_timestamp": "0:01:26",
      "end_timestamp": "0:02:13"
    }
  },
  {
    "page_content": "cái đoạn từ 0 cho đến 1. Và lúc này thì cái giá trị Y và Y ngã này thì mình sẽ sử dụng cái độ đo là Binary Cross entropy. Thì đây là một cái biến thể đơn giản của mạng Neural Network. Tiếp theo thì chúng ta sẽ tiến hành cài đặt cho cái ví dụ này. Rồi thì cũng tương tự chúng ta sẽ có cái đoạn code để khởi tạo cho các tập điểm nằm trong và nằm bên ngoài hình tròn. Thì ở đây chúng ta có một cái thư viện là Scikit-learn. Nó sẽ có cái hàm make_circles. Và cái hàm make_circles này thì nó sẽ giúp cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 3,
      "start_timestamp": "0:02:09",
      "end_timestamp": "0:02:59"
    }
  },
  {
    "page_content": "Và cái hàm make_circles này thì nó sẽ giúp cho chúng ta tạo ra các cái điểm nằm trong và nằm ngoài hình tròn. Rồi, các cái điểm nằm trong thì chúng ta sẽ được đánh dấu bằng màu đỏ. Và các cái điểm nằm trong thì được đánh dấu bằng các cái điểm màu xanh lá. Và cái điểm nằm ngoài thì được đánh dấu bằng các điểm màu đỏ. Và những cái điểm nào màu đỏ thì được sẽ gắn nhãn là bằng 0. Và những cái điểm nào màu xanh lá thì sẽ được gắn nhãn là bằng 1. Và tất cả thì đều được ép về kiểu số thật. Rồi, thì x",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 4,
      "start_timestamp": "0:02:54",
      "end_timestamp": "0:03:39"
    }
  },
  {
    "page_content": "cả thì đều được ép về kiểu số thật. Rồi, thì x của mình, tọa độ x của mình nó chính là tập dữ liệu tọa độ theo trục x1 và x2. Tức là 2 bao gồm 2 chiều. y thì nó sẽ là cái nhãn hoặc là nhận giá trị 0 hoặc là nhận giá trị là 1. Rồi, bây giờ về cái phần cài đặt thuật toán. Thì cũng tương tự cho các cái mô hình linear, logistic và softmax regression. Và ở đây thì chúng ta sẽ có 1 cái hàm nữa đó là hàm get_weights. Trên cái hàm get_weights này thì chúng ta sẽ phải viết lại so với cái linear",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 5,
      "start_timestamp": "0:03:35",
      "end_timestamp": "0:04:18"
    }
  },
  {
    "page_content": "thì chúng ta sẽ phải viết lại so với cái linear regression. Tại vì trong cái mạng neural network thì chúng ta sẽ có nhiều layer. Và như vậy thì nếu chúng ta muốn quan sát cái layer, cái tham số của layer nào, thì chúng ta phải truyền thêm cái chỉ số của layer đó vào. Vậy thì chúng ta sẽ có thêm 1 cái phương thức này nữa. Viết lại cái phương thức này. Rồi, bây giờ đối với build thì ở đây chúng ta sẽ có input và output dimension. Thì chúng ta cũng tương tự sẽ cài đặt là input với shape là bằng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 6,
      "start_timestamp": "0:04:14",
      "end_timestamp": "0:05:07"
    }
  },
  {
    "page_content": "tương tự sẽ cài đặt là input với shape là bằng input. Tiếp theo, đó là chúng ta sẽ có cái lớp hidden layer. Chúng ta sẽ có 1 cái lớp hidden layer. Như vậy ở đây sẽ để là hidden. Rồi, lớp hidden layer này thì nó sẽ được thực hiện bởi một cái phép biến đổi là fully connected. Tại vì từ cái lớp input sang cái lớp hidden này thì nó được kết nối đầy đủ. Và chúng ta lưu ý là activation của mình thì chúng ta sẽ sử dụng hàm sigmoid. Và đồng thời là chúng ta có sử dụng bias. Vậy thì ở đây sẽ là layer,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 7,
      "start_timestamp": "0:05:02",
      "end_timestamp": "0:06:01"
    }
  },
  {
    "page_content": "ta có sử dụng bias. Vậy thì ở đây sẽ là layer, sẽ là dense. Rồi, output của mình thì nó sẽ có nhiều nodes. Giả sử ở đây chúng ta có 8 nodes thôi. Số nodes ở giữa ở đây chúng ta có 8 nodes. Rồi, activation thì chúng ta sẽ để là sigmoid. Rồi, use bias thì chúng ta sẽ để là true. Và chúng ta sẽ phải truyền cái lớp input cho nó chính là input ở đây. Rồi, chúng ta sẽ có cái output là hidden. Và với output là hidden, chúng ta lại một lần nữa, chúng ta... Một lần nữa thì chúng ta sẽ đưa qua cái lớp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 8,
      "start_timestamp": "0:05:58",
      "end_timestamp": "0:06:46"
    }
  },
  {
    "page_content": "ta... Một lần nữa thì chúng ta sẽ đưa qua cái lớp biến đổi là fully connected. Tại vì bản chất ở đây tất cả các cái node đầu vào và cái node đầu ra thì nó kết nối đầy đủ với nhau. Do đó thì ở đây nó cũng là một cái dense. Và cái dense này thì cái output của mình nó chỉ có duy nhất một node. Tại sao một node? Tại vì ở đây chúng ta phân lớp nhị phân. Rồi, ở đây sẽ có là output là bằng dense. Trong đó chỉ có một node activation thì chúng ta sẽ để là sigmoid. Rồi, sử dụng bias bằng true. Và input",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 9,
      "start_timestamp": "0:06:39",
      "end_timestamp": "0:07:45"
    }
  },
  {
    "page_content": "là sigmoid. Rồi, sử dụng bias bằng true. Và input của nó chính là cái hidden ở phía trước. Rồi, bây giờ chúng ta sẽ đóng gói cả cái này vào trong cái biến là model. Và chúng ta sẽ trả về cho cell.model. Ở đây thì chúng ta sẽ không cần phải return cái gì ra bên ngoài. Rồi, tương tự như vậy ở đây chúng ta sẽ có optimizer sẽ là bằng tf.keras.optimizer.stochastic gradient descent Với learning rate là bằng 0.1 để train cho nó nhanh. Và ở đây chúng ta sẽ có sử dụng momentum",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Ds8mbsbarxs",
      "filename": "Ds8mbsbarxs",
      "title": "[CS315 - Chương 1] Tutorial - Neural Network",
      "chunk_id": 10,
      "start_timestamp": "0:07:41",
      "end_timestamp": "0:07:45"
    }
  },
  {
    "page_content": "Bây giờ chúng ta sẽ đến với một cái ví dụ cụ thể để chúng ta có thể dễ dàng hình dung hơn. Thì ở đây chúng ta set một cái mạng Neural Network gồm cụ thể đó là 10 lớp biến đổi. Và các cái hàm kích hoạt của mình ở đây chúng ta sẽ sử dụng cùng một hàm kích hoạt đó là hàm sigmoid. Thì công thức của cái hàm sigmoid đó là bằng một phần một cộng e mũ trừ x. Thì đây là cái công thức của sigmoid. Và khi chúng ta huấn luyện cái mạng Neural Network này thì chúng ta sẽ đi tính cái hàm loss. Đây là hàm lỗi.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:55"
    }
  },
  {
    "page_content": "chúng ta sẽ đi tính cái hàm loss. Đây là hàm lỗi. Và chúng ta sử dụng cái binary cross entropy tại vì ở đây chúng ta dùng hàm kích hoạt là sigmoid. Nên cái giá trị đầu ra của mình là con số từ 0 cho đến 1. Và chúng ta sẽ đi so với cái giá trị e này. Sau đó thì khi chúng ta tính đạo hàm, ở đây là chúng ta sẽ tính đạo hàm theo cái biến theta. Thế thì cái công thức này chúng ta sẽ triển khai như thế nào? Đối với cái mạng Neural Network mà có 10 lớp, thì ở cái lớp đầu tiên chúng ta sẽ có bộ hệ số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:46",
      "end_timestamp": "0:01:45"
    }
  },
  {
    "page_content": "thì ở cái lớp đầu tiên chúng ta sẽ có bộ hệ số đó là theta 1. Theta 1. Sau đó chúng ta sẽ nhân với cái x là cái dữ liệu đầu vào. Và ngay sau đó chúng ta sẽ thực hiện cái hàm kích hoạt để tạo ra cái giá trị đầu ra. Thì sigmoid của theta 1 x, thì đây chính là cái lớp biến đổi đầu tiên là layer số 1. Sau đó chúng ta lại tiếp tục lan truyền đến cái layer thứ 2. Và cũng tương tự như vậy chúng ta sẽ có cái tham số là theta 2. Thì theta 2 sẽ nhân với cái đầu ra của cái lớp trước đó chính là, ở đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:40",
      "end_timestamp": "0:02:27"
    }
  },
  {
    "page_content": "cái đầu ra của cái lớp trước đó chính là, ở đây theta 2 sẽ nhân với lại cái đầu ra trước đó. Và sau đó chúng ta qua cái hàm sigmoid. Qua cái hàm sigmoid. Thì đây chính là cái kết quả của layer số 2. Cứ như vậy, cho đến cái sigmoid của theta 10, tức là chúng ta đang tiến đến theta 10. Thì theta 1 tương ứng layer 1, theta 2 tương ứng layer số 2, và theta 10 tương ứng layer số 10. Thì đây chính là cái công thức của cái hàm mà chúng ta cần phải tối ưu hóa hàm j, hàm lỗi. Thì nhìn trong cái công",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:24",
      "end_timestamp": "0:03:07"
    }
  },
  {
    "page_content": "ưu hóa hàm j, hàm lỗi. Thì nhìn trong cái công thức này, chúng ta sẽ đi tính đạo hàm của j theo từng thành phần của tham số theta. Lưu ý là theta là một tập hợp các cái tham số. Là một tập hợp các cái tham số. Nó sẽ bao gồm là theta 1. Trong theta 1 nó lại gồm có nhiều cái thành phần con nữa. Đó là cái trọng số tương ứng với cái cạnh nối của lớp trước với lớp sau. Thì đây là tập hợp các cái tham số. Rồi. Và chúng ta sẽ đi tính đạo hàm từng phần là đạo hàm của delta j chia cho delta theta i. Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:03:05",
      "end_timestamp": "0:03:46"
    }
  },
  {
    "page_content": "đạo hàm của delta j chia cho delta theta i. Thì nó sẽ là bằng công thức của đạo hàm của bce theo cái hàm sigmoid. Đạo hàm của sigmoid theo cái hàm p10. Thì cái p10 này nó chính là cái thao tác nhân của theta 10 với lại cái thành phần còn lại. Đây chính là cái phép nhân của theta 10. Với lại cái thành phần còn lại. Đây chính là cái phép nhân. Hàm p là product, viết tắt của chữ product. Tức là phép nhân của theta 10, cái tham số 10 với lại cái kết quả đầu ra trước đó. Thì p10 và p1 chính là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:03:40",
      "end_timestamp": "0:04:32"
    }
  },
  {
    "page_content": "quả đầu ra trước đó. Thì p10 và p1 chính là cái phép này. Đây chính là p1. Thế thì cái phép theta 1 nhân vx thì đây chính là cái hàm p1. Rồi. Thế thì chúng ta triển khai cái chain rule ra thì chúng ta sẽ có cái công thức như trên. Và chúng ta để ý đó là cái hàm đạo hàm của sigmoid được thực hiện đi thực hiện lại 10 lần. Chúng ta có bao nhiêu cái lớp biến đổi thì sẽ có bấy nhiêu hàm sigmoid. Thì ở đây chúng ta có tất cả là 10 lớp biến đổi. Do đó nó sẽ có 10 lần cái đạo hàm của sigmoid. P1 cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:04:25",
      "end_timestamp": "0:05:16"
    }
  },
  {
    "page_content": "nó sẽ có 10 lần cái đạo hàm của sigmoid. P1 cho đến p10. Và mặt khác thì chúng ta lại có cái công thức của đạo hàm. Ở đây chúng ta có hàm sigmoid là cái công thức như trên. Thì hoặc là chúng ta có thể tính nháp bằng tay để chứng minh được đạo hàm của sigmoid là bằng sigmoid nhân với 1 trừ sigmoid. Hoặc là chúng ta có thể tra cứu các tài liệu học thuật online để có được xác nhận công thức này. Và cơ bản thì công thức này cũng rất dễ chứng minh. Lý do đó là vì trong cái đạo hàm này, trong cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:05:08",
      "end_timestamp": "0:05:50"
    }
  },
  {
    "page_content": "Lý do đó là vì trong cái đạo hàm này, trong cái công thức của hàm sigmoid này nó có e mũ x. Mà e mũ x là một cái hàm rất dễ tính đạo hàm. Rồi thì bây giờ chúng ta xem như chúng ta đã biết cái đạo hàm của sigmoid bằng sigmoid nhân với 1 trừ sigmoid. Thì chúng ta áp dụng cái bất đẳng thức Cô-si. Ở đây là dấu bé hơn hoặc bằng. Chúng ta áp dụng cái bất đẳng thức Cô-si. Đó là đạo hàm của sigmoid x nhân cho 1 trừ cho sigmoid x. Thì nó sẽ bé hơn hoặc bằng tổng của 2 phần tử này. Tất cả bình chia 4.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:05:41",
      "end_timestamp": "0:06:48"
    }
  },
  {
    "page_content": "bằng tổng của 2 phần tử này. Tất cả bình chia 4. Tức là sigmoid x cộng cho 1 trừ sigmoid x. Tất cả bình phương. Rồi chia cho 4. Thì sigmoid cộng 1 trừ sigmoid khử. Thì chúng ta sẽ còn là 1. Như vậy đó sẽ là bằng 1 phần tư. Như vậy thì áp dụng cái bất đẳng thức Cô-si thì chúng ta thấy là đạo hàm của sigmoid sẽ bé hơn 1 phần tư. Tức là 0.25. Vậy thì với cái đạo hàm này mà bằng 0.25 thì điều gì xảy ra? Với cái công thức đạo hàm của G theo theta y, nó có đến sự xuất hiện của đạo hàm sigmoid đến 10",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:06:34",
      "end_timestamp": "0:07:30"
    }
  },
  {
    "page_content": "nó có đến sự xuất hiện của đạo hàm sigmoid đến 10 lần. Tức là ngoài các thành phần kia thì chúng ta sẽ thấy là thành phần đạo hàm sigmoid sẽ bé hơn hoặc bằng 0.25. Vậy là 0.25 là mũ 10. Rồi xong đó nhân với cái thành phần đạo hàm còn lại. Vậy thì bây giờ chúng ta sẽ xem xét cái 0.25 mũ 10 này nếu chúng ta lấy máy tính bấm thì nó sẽ xấp xỉ là bằng 0. Nó là 1 con số rất là bé. 0.0001 ví dụ vậy. Và với cái khả năng biểu diễn của máy tính thì thậm chí đó là cái con số này có thể tự động được làm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:07:22",
      "end_timestamp": "0:08:10"
    }
  },
  {
    "page_content": "chí đó là cái con số này có thể tự động được làm tròn bằng số 0. Là vì cái khả năng biểu diễn nó không có khả năng biểu diễn những con số quá bé. Thì không nhân với bao nhiêu cũng sẽ là bằng 0. Do đó thì cái đạo hàm này nó sẽ được tiến về 0. Và đây chính là cái cốt lõi gây ra cái hiện tượng vanishing gradient. Tức là đạo hàm của thằng G hàm lỗi theo theta y bằng 0. Thì khi đó cái việc cập nhật theta y bằng theta y trừ cho alpha nhân cho đạo hàm. Thì cái giá trị này xấp xỉ bằng 0. Nên cái bước",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "0:08:06",
      "end_timestamp": "0:09:04"
    }
  },
  {
    "page_content": "Thì cái giá trị này xấp xỉ bằng 0. Nên cái bước cập nhật này sẽ gần như xấp xỉ bằng y. Tức là không cập nhật. Gần như không cập nhật. Cái tham số. Gần như nó không cập nhật tham số. Thì đây là một cái ví dụ trực quan. Và đây là một cái ví dụ mà có số liệu tính toán. Để cho chúng ta hình dung là tại sao cái công thức đạo hàm của mình nó sẽ tiến về 0. Khi có quá nhiều cái hàm kích hoạt chập lại. Và cái hàm kích hoạt này có cái đạo hàm bé hơn 1. Vì vậy nó sẽ tiến cho tích này của chúng ta nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:08:52",
      "end_timestamp": "0:09:52"
    }
  },
  {
    "page_content": "Vì vậy nó sẽ tiến cho tích này của chúng ta nó sẽ mau chóng tiến về 0. Và Lưu ý, đó là cái việc tính đạo hàm này nó sẽ đặc biệt đó là dễ tiến về 0 khi cái theta y của mình gần lớp số 1. Còn nếu như cái theta y của mình nằm trong cái nhóm theta 10 thì cái công thức này nó sẽ ít hơn. Nó sẽ ít bị ảnh hưởng hơn. Chúng ta có một cái theta z là thuộc cái tham số của theta 10. Theta z là thuộc cái theta 10. Tức là tập hợp các cái tham số ở lớp cuối cùng. Thế thì cái công thức này của chúng ta theta z,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:09:44",
      "end_timestamp": "0:10:30"
    }
  },
  {
    "page_content": "Thế thì cái công thức này của chúng ta theta z, delta z trên theta z. Thế thì sẽ là bằng đạo hàm của binary cross entropy theo sigmoid. Sau đó sẽ là đạo hàm của hàm sigmoid theo cái biến theta z này. Tại vì chúng ta chỉ tính đến cái theta z này là chúng ta sẽ dừng. Do đó thì chúng ta chỉ việc tính cái giá trị đạo hàm của sigmoid này đúng có một lần thôi. Cho dù cái giá trị này nó bé hơn 0.25 nhưng mà chúng ta chỉ nhân có một lần thì nó sẽ không có ảnh hưởng. Còn những cái theta y nào mà nó nằm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "0:10:20",
      "end_timestamp": "0:11:06"
    }
  },
  {
    "page_content": "có ảnh hưởng. Còn những cái theta y nào mà nó nằm ở cái lớp đầu tiên. Lưu ý là ở đây chúng ta đang xét cái theta y thuộc những cái layer đầu tiên. Thì nó sẽ phải kéo từ cái phép biến đổi sigmoid thứ 10, thứ 9 và cho đến cái hàm sigmoid thứ 9. Và cho đến cái hàm sigmoid số 1. Rồi thì đây là một cái giải thích thêm cho cái việc đó là tại sao cái tham số mà càng gần cái layer đầu thì dễ bị hiện tượng vanishing gradient. Tức là nó cập nhật chậm. Còn những cái tham số ở những cái lớp cuối cùng thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "những cái tham số ở những cái lớp cuối cùng thì ít bị hiện tượng vanishing gradient hơn. Vì nó đã cập nhật đến những cái tham số cuối cùng thì nó sẽ dừng ở đó. Và nó không có thực hiện cái phép nhân nhiều lần. Nhân đạo hàm nhiều lần.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=DSmR6JSwx5I",
      "filename": "DSmR6JSwx5I",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 2)",
      "chunk_id": 16,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với phần thực hành thuật toán Radiant Ascent Đây là sơ đồ thuật toán của Radiant Ascent phiên bản đầu tiên Tham số là theta Theta có một giá trị ngẫu nhiên, tình hình như số 1, số 12, v.v. Chúng ta sẽ sử dụng hàm một biến là J theta Hàm này là một dạng hàm mà có một điểm cực tiểu Khi sang tình huống phức tạp hơn, chúng ta sẽ cài đặt bằng biến thể momentum Vì vậy, chúng ta sẽ chọn một hàm đơn giản để thực hành Vì vậy, chúng ta sẽ chọn một hàm đơn giản để thực hành Sau đó,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:38"
    }
  },
  {
    "page_content": "ta sẽ chọn một hàm đơn giản để thực hành Sau đó, chúng ta sẽ tiến hành lập trình Trong quá trình lập trình, chúng ta sẽ có một số tham số mạng lưới Ví dụ như là tham số alpha Đây là siêu tham số Alpha cũng khởi tạo bằng một con số khá bé, ví dụ như là 0.01 Chúng ta thấy có xuất hiện hai biến là theta new và theta old Thực ra, chúng ta không cần tạo hai biến new và biến old này Theta là bằng theta trừ cho alpha nhân cho đạo hàm Thì nó đã tự động cập nhật biến theta vào trong giá trị mới cho biến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:01:33",
      "end_timestamp": "0:02:21"
    }
  },
  {
    "page_content": "nhật biến theta vào trong giá trị mới cho biến theta Bây giờ, chúng ta sẽ tiến hành những bước lập trình đầu tiên Chúng ta sẽ qua giao diện code Chúng ta sẽ import Chúng ta sẽ tạo ra một file tên là GradientDescent Import NumPy SNP Chúng ta sẽ có một bước khởi tạo các tham số và siêu tham số Chúng ta sẽ có theta bằng số 12 Alpha là 0.01 Trong sơ đồ, chúng ta sẽ phải khởi tạo hàm j Chúng ta sẽ có thêm hàm j của theta Chúng ta sẽ return là 5 nhân cho theta mũ 2 trừ cho 8 nhân cho theta cộng 3 Sau",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:02:16",
      "end_timestamp": "0:03:44"
    }
  },
  {
    "page_content": "theta mũ 2 trừ cho 8 nhân cho theta cộng 3 Sau đó, chúng ta sẽ đến bước tính đạo hàm Chúng ta đã xong bước này rồi Chúng ta sẽ đến bước tính đạo hàm Thì tính đạo hàm của hàm ở trên sẽ có công thức luôn Thay vì chúng ta dùng công thức định nghĩa đạo hàm Chúng ta vẫn dùng các bảng tra, các công thức tính đạo hàm cho hàm đa thức, hàm hợp, v.v. Để chúng ta tính trực tiếp J' cho nó đơn giản J' sẽ là bằng 10 theta trừ cho 8 Sau đó, chúng ta sẽ tiến hành cài đặt hàm J' Chúng ta sẽ return là 10 nhân",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:03:41",
      "end_timestamp": "0:04:45"
    }
  },
  {
    "page_content": "hành cài đặt hàm J' Chúng ta sẽ return là 10 nhân cho theta trừ cho 8 Sau đó, chúng ta sẽ tiến hành cập nhật tham số Chúng ta thấy là bản chất là một vòng lặp lặp đi lặp lại tính đạo hàm thực hiện đi thực hiện lại bước này Chúng ta sẽ tạo một vòng lặp while Chúng ta không biết trước số vòng lặp nên chúng ta sẽ để while True Mình sẽ gọi hàm tính đạo hàm là derivative là bằng J' của theta Sau đó, chúng ta sẽ có công thức là theta là bằng theta trừ cho alpha nhân với lại đạo hàm Vòng lặp này khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:04:43",
      "end_timestamp": "0:05:40"
    }
  },
  {
    "page_content": "cho alpha nhân với lại đạo hàm Vòng lặp này khi nào thì nó dừng Khi tham số của mình tiến về điểm cực tiểu Khi tiến về điểm cực tiểu, đạo hàm của j là xấp xỉ bằng không Tại vì đạt điểm cực tiểu thì hệ số góc này là song song với lại trục ox Tức là đạo hàm xấp xỉ bằng không Vì vậy, điều kiện dừng của mình là if theta is derivative là đủ nhỏ Tại vì nó không thể nào bằng không được Tại vì trong quá trình tính toán, nó sẽ có sai số Và ở đây chúng ta sẽ phải dùng trị tuyệt đối Tại vì nó sẽ có tình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:05:33",
      "end_timestamp": "0:06:20"
    }
  },
  {
    "page_content": "sẽ phải dùng trị tuyệt đối Tại vì nó sẽ có tình huống là đạo hàm nó âm và đạo hàm nó dương Nhưng mà nó tiến về số 0 Do đó mình phải dùng trị tuyệt đối Và ở đây chúng ta sẽ xuất hiện thêm một cái biến nữa Đó là biến epsilon Và ở đây chúng ta sẽ xuất hiện 1 break Và ở đây chúng ta sẽ xuất hiện 1 break Rồi, thì ở đây chúng ta sẽ thêm một biến nữa là eps là bằng 0.001 là một con số rất là nhỏ Rồi, bây giờ chúng ta sẽ in cái kết quả ra Đó là theta tối ưu Thì nó sẽ là in ra cái theta Rồi, bây giờ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:06:18",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "tối ưu Thì nó sẽ là in ra cái theta Rồi, bây giờ chúng ta sẽ chạy cái đoạn code này Chúng ta sẽ chạy cái đoạn code này Bằng cách đó là chúng ta Ctrl+Shift+P chọn cái interpreter là conda Rồi, sau đó chúng ta sẽ run Thì ở đây là chưa có cái thư viện NumPy Do đó thì chúng ta sẽ pip install Rồi, sau đó chúng ta sẽ chạy cái code này lại Thì chúng ta thấy là cái theta tối ưu chạy rất là nhanh Và theta tối ưu là xấp xỉ bằng 8 Thế thì bây giờ chúng ta làm sao kiểm tra xem cái theta này có đúng là bằng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:07:09",
      "end_timestamp": "0:08:09"
    }
  },
  {
    "page_content": "sao kiểm tra xem cái theta này có đúng là bằng 8 hay không Thì chúng ta sẽ quay trở lại cái slide của mình Trong cái công thức ở trên thì cái giá trị nhỏ nhất Đó là đạt được khi bằng b chia cho 2a Tức là bằng trừ b chia cho 2a Tức là bằng trừ của trừ 8 chia cho 2a A ở đây là 5, 2 x 5 là bằng 10 Tức là bằng 8 phần 10 tức là bằng 0.8 Như vậy thì cái đáp số của mình là hoàn toàn chính xác Sau khi chúng ta chạy với thuật toán Radiant Descent",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FCZXP4oCiFc",
      "filename": "FCZXP4oCiFc",
      "title": "[CS315 - Chương 1] Tutorial - Gradient Descent (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:08:04",
      "end_timestamp": "0:08:12"
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với bài tutorial bài thực hành về mạng GAN. Trên hình là một số thành tựu của GAN trong vài năm gần đây. Nếu như năm 2014, chất lượng hình ảnh của mình rất tệ và không màu, sau 1 năm sau đó hình ảnh của mình đã có màu. Và đến năm 2018, hình ảnh của mình đã có độ phân giải rất cao và gần như là thật. Với công nghệ Insight Cogam, nó cũng có thể cho phép chúng ta chuyển đổi qua lại giữa 2 cái thế giới ảnh, 2 cái không gian ảnh khác nhau. Ví dụ như chuyển từ phong cách ảnh Monet",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:57"
    }
  },
  {
    "page_content": "nhau. Ví dụ như chuyển từ phong cách ảnh Monet sang ảnh đời thực, hoặc là chuyển từ ảnh ngựa vằn sang ngựa bình thường, cũng như là chuyển từ ngựa bình thường sang ngựa vằn. Hoặc là biến ảnh từ mùa hè sang mùa đông. Trên đây là 1 số thành tựu của mạng GAN. Về kiến trúc, tổng thể của GAN sẽ bao gồm 2 mô-đun chính, đó là Generator và Discriminator. Generator sẽ nhận đầu vào 1 vector latent z và tạo ra 1 fake sample. Kết hợp với real sample ở đây, chúng ta sẽ qua Discriminator để huấn luyện nhằm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:01:38"
    }
  },
  {
    "page_content": "chúng ta sẽ qua Discriminator để huấn luyện nhằm làm sao có thể phân biệt được ảnh real, ảnh thật và ảnh giả. Và sau đó thì chúng ta sẽ có một loss để huấn luyện 2 cái mạng này. Thế thì chi tiết chúng ta có thể đọc thêm ở đây. Và cài đặt thì chúng ta sẽ khởi tạo 1 số cái hàm và đối tượng của torch phục vụ cho những cái phần cài đặt phía sau. Về chi tiết của cái kiến trúc mạng GAN thì nó sẽ có kiến trúc như sau. Đầu tiên đó là cái vector z, là cái random noise của mình sẽ là 1 vector 100 chiều",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 2,
      "start_timestamp": "0:01:34",
      "end_timestamp": "0:02:28"
    }
  },
  {
    "page_content": "random noise của mình sẽ là 1 vector 100 chiều theo cái phân bố Gaussian. Và nó sẽ biến thành cái vector 128 chiều rồi 784 chiều. Thì 784 chiều này chính là cái kích thước mà khi chúng ta flatten từ 1 cái tấm ảnh hoặc là kích thước 28 x 28. Về discriminator thì chúng ta sẽ từ vector 784 xuống vector 128 và xuống vector 1 chiều. Hay là scalar. Tại sao lại như vậy? Tại vì ở đây discriminator chỉ phân biệt 2 trạng thái là real or fake. Do đó chúng ta chỉ cần 1 neuron là có thể đưa về 2 trạng thái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 3,
      "start_timestamp": "0:02:18",
      "end_timestamp": "0:03:02"
    }
  },
  {
    "page_content": "ta chỉ cần 1 neuron là có thể đưa về 2 trạng thái là 0 và 1 là được rồi. Thế thì bây giờ chúng ta sẽ tiến hành cài đặt cái discriminator. Thì cái discriminator là cái phần màu xanh ở đây. Đầu vào sẽ là 1 cái ảnh có kích thước là 784. Và nó sẽ biến thành vector 128 chiều thông qua cái lớp linear. Sau đó thì chúng ta sẽ có 1 cái hàm activation function. Nó như đây là Leaky ReLU. Tạo ra 1 cái vector 128 chiều. Rồi vector 128 chiều sẽ biến thành 1 cái neuron 1 chiều. Thông qua cái lớp biến đổi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 4,
      "start_timestamp": "0:02:58",
      "end_timestamp": "0:03:49"
    }
  },
  {
    "page_content": "1 cái neuron 1 chiều. Thông qua cái lớp biến đổi linear luôn. Thế thì cái hàm forward của mình nhận đầu vào là x là 1 cái tấm ảnh. Thì nó sẽ chuyển đổi về cái vector là 784. Thành vector 784. Và BS ở đây chính là cái batch size của mình. Đây chính là cái batch size của mình. Là số mẫu dữ liệu được huấn luyện tại 1 thời điểm. Sau đó chúng ta chuyển x vào cái lớp FC1 và non-linearity để tạo ra h. Thì h trong trường hợp này là vector 128 chiều. H sau đó được nối tiếp và qua cái FC để tạo ra cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 5,
      "start_timestamp": "0:03:46",
      "end_timestamp": "0:04:30"
    }
  },
  {
    "page_content": "sau đó được nối tiếp và qua cái FC để tạo ra cái output. Cái output này sau đó sẽ được qua cái hàm sigmoid để đưa về cái không gian xác suất từ 0 cho đến 1. Sau đó chúng ta sẽ return cái output. Thì cái output của mình nó sẽ là cái xác suất để cho biết có thuộc về lớp số 1 hay không. Đối với generator thì chúng ta làm hoàn toàn cũng tương tự. Chúng ta sẽ có cái lớp FC để từ cái zdim. Cụ thể ở đây zdim là bằng 100. Biến thành vector 128. Vector 128 sau đó sẽ qua cái Leaky ReLU. Rồi sau đó sẽ là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 6,
      "start_timestamp": "0:04:18",
      "end_timestamp": "0:05:13"
    }
  },
  {
    "page_content": "sau đó sẽ qua cái Leaky ReLU. Rồi sau đó sẽ là biến thành vector 784. Thì đây là cái hàm forward. Từ cái input của mình là cái latent z. Sau đó sẽ qua cái FC và non-linearity. Rồi sau đó qua cái FC2 và hàm tanh. Thì hàm tanh ở đây là dải giá trị từ trừ 1 cho đến 1. Nó có chứa cái giá trị từ 0 cho đến 1. Tức là cái miền giá trị của cái ảnh của mình. Không có nghĩa là đen và 1 không có nghĩa là sáng. Rồi sau đó chúng ta sẽ biến thành cái ảnh kích thước 28x28 và trả về. Thì chúng ta sẽ chạy 2 cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 7,
      "start_timestamp": "0:05:07",
      "end_timestamp": "0:05:58"
    }
  },
  {
    "page_content": "thước 28x28 và trả về. Thì chúng ta sẽ chạy 2 cái code block này. Rồi sau khi chạy xong thì chúng ta sẽ tiến hành load dữ liệu MNIST. Và chúng ta sẽ show 1 cái tấm hình. Ví dụ như chúng ta show cái hình là 1, 4, 5. Thì đây là 1 chiếc giày. Ví dụ như là 1, 2, 3. Đây là chiếc áo. Rồi tiếp theo thì chúng ta sẽ kiểm tra xem cái batch size của mình. À cái discriminator của mình là có ổn hay không. Chúng ta sẽ truyền vào cái batch và xem cái kích thước. Thì cái batch size của mình nó sẽ có kích thước",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 8,
      "start_timestamp": "0:05:54",
      "end_timestamp": "0:06:40"
    }
  },
  {
    "page_content": "Thì cái batch size của mình nó sẽ có kích thước đó là 64. Và ảnh của mình đó là 28x28. Rồi sau khi chúng ta qua cái discriminator thì nó sẽ tạo ra 1 cái tensor có kích thước là 64. Trong đó 64 chính là batch size. Và 1 chính là cái kích thước ảnh của mình. Rồi, xin lỗi ảnh. 1 chính là cái output, cái xác suất của mình. Rồi sau đó chúng ta sẽ show cái tấm ảnh này lên. Thì đây là cái dataset. Và những cái ảnh mà có cái vật phẩm thời trang. Ví dụ như là giày, quần, áo, quần. Thế thì bây giờ chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 9,
      "start_timestamp": "0:06:34",
      "end_timestamp": "0:07:24"
    }
  },
  {
    "page_content": "là giày, quần, áo, quần. Thế thì bây giờ chúng ta sẽ tiến hành huấn luyện 1 cái mạng GAN. Thì mạng GAN của mình, lý thuyết đó chính là bài toán Mini-Max Game. Thì đây là cái công thức của cái hàm biến đổi để huấn luyện. Đầu tiên cái vế bên trong cùng đó là hàm max. Tức là chúng ta sẽ đi huấn luyện D trước. Tức là Discriminator trước. Discriminator nó phải có khả năng phân biệt đối tượng 1 cách chắc chắn. Thì khi đó nó mới có thể thách thức cái G. Sao cho nó khó được. Do đó thì ở đây chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 10,
      "start_timestamp": "0:07:20",
      "end_timestamp": "0:08:05"
    }
  },
  {
    "page_content": "Sao cho nó khó được. Do đó thì ở đây chúng ta sẽ sử dụng, ở đây nhìn chung. Nhìn chung đó là chúng ta công thức tương tự như công thức của Binary Cross entropy. Là so sánh giữa cái giá trị dự đoán và giá trị thực tế. Thì chúng ta sẽ sử dụng cái hàm Criterion này để huấn luyện cái mô hình ở bên dưới. Rồi, bây giờ chúng ta sẽ kiểm tra xem cái thiết bị của mình ở đây. Đó là thiết bị gì? Thì đây là GPU. Và mỗi chúng ta sẽ tạo ra đối tượng đó là Discriminator và Generator. Và đẩy nó vào GPU. Rồi,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 11,
      "start_timestamp": "0:07:57",
      "end_timestamp": "0:08:49"
    }
  },
  {
    "page_content": "và Generator. Và đẩy nó vào GPU. Rồi, với mỗi một cái optimizer G và D, chúng ta sẽ đi train cho G và D ở đây. Tức là mỗi một cái mô-đun Discriminator và Generator sẽ dùng một cái optimizer riêng, chứ không phải dùng chung. Và dữ liệu label real và label fake. Label real thì sẽ có nhãn là 1 và label fake thì sẽ có nhãn là 0. Sau đó thì chúng ta sẽ fix cái noise của mình. Là cái random noise là từ... là 64 và kích thước đó là 100. Epoch là 10. Thì ở đây chúng ta sẽ lần lượt huấn luyện. Step số 1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 12,
      "start_timestamp": "0:08:43",
      "end_timestamp": "0:09:34"
    }
  },
  {
    "page_content": "ở đây chúng ta sẽ lần lượt huấn luyện. Step số 1 là chúng ta sẽ đi tối ưu Discriminator trước. Tức là huấn luyện cho bộ phân loại này có khả năng phân loại được ảnh thật và ảnh giả trước. Sau đó chúng ta mới sang Step số 2 để đi huấn luyện cho Generator. Rồi, thì ở đây chúng ta sẽ lấy ra cái Xreel và truyền vào GPU. Rồi sau đó chúng ta sẽ khởi tạo cái optimizer D. Và chúng ta sẽ truyền cái Xreel này vào cái Discriminator. Thì đây chính là cái xác suất. Đây chính là cái xác suất thuộc về lớp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 13,
      "start_timestamp": "0:09:23",
      "end_timestamp": "0:10:16"
    }
  },
  {
    "page_content": "xác suất. Đây chính là cái xác suất thuộc về lớp Reel. Và lossD của Reel tức là cái giá trị loss cho cái Discriminator. Đối với cái phần dữ liệu Reel là dữ liệu thật thì chúng ta sẽ truyền vào cái giá trị dự đoán và cái nhãn của mình là label Reel. Thì mục tiêu là làm sao cho cái giá trị này là nhỏ nhất. Mặt khác thì chúng ta sẽ truyền cái dữ liệu giả vào. Và dữ liệu giả này từ đâu ra? Nó là từ 1 random noise, batch size là 64 và vector random noise này có kích thước là 100 chiều. Rồi sau đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 14,
      "start_timestamp": "0:10:10",
      "end_timestamp": "0:10:59"
    }
  },
  {
    "page_content": "noise này có kích thước là 100 chiều. Rồi sau đó chúng ta sẽ gọi cái hàm G để tạo ra cái X_fake. Vì cái X_fake của mình trong trường hợp này đó chính là cái... X_fake của mình đó chính là cái ảnh fake. Rồi, bây giờ chúng ta sẽ truyền cái X_fake này vào Discriminator. Thì cái DGZ này chính là cái xác suất thuộc về cái lớp Reel. Và khi tính hàm loss thì chúng ta sẽ... Cái hàm loss cho Fake thì chúng ta sẽ truyền vào DGZ và truyền vào cái label Fake. Thì cái nhãn của mình sẽ là nhãn Fake. Và mục",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 15,
      "start_timestamp": "0:10:50",
      "end_timestamp": "0:11:43"
    }
  },
  {
    "page_content": "Thì cái nhãn của mình sẽ là nhãn Fake. Và mục tiêu của mình sẽ là làm sao cho cái loss này là nhỏ nhất. Kết hợp với cái loss ở trên, chúng ta sẽ có cái loss tổng là D. Thế thì câu hỏi là tại sao ở trong cái công thức này thì người ta lại đi tìm Max. Mà phía dưới thì chúng ta lại đi tìm Min. Tại vì chúng ta dùng cái hàm loss Binary Cross entropy. Thì bản chất ở đây là một, khi chúng ta tìm Max cái công thức loss này... Thì nó tương đương với cái việc là Cross entropy của hai cái thành phần Reel",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 16,
      "start_timestamp": "0:11:37",
      "end_timestamp": "0:12:21"
    }
  },
  {
    "page_content": "việc là Cross entropy của hai cái thành phần Reel và Fake bên dưới là thấp nhất. Khi cái thằng này, loss D này càng tiến về 1, xác suất 1 thì cái loss này sẽ càng tiến về 0. Và ngược lại, cái thành phần này cũng vậy. Tiến về 0 thì 1 trừ cho 0 sẽ là bằng 1. Tức là cái loss này cũng bằng 0. Thì thay vì tìm Max ở cái trạng thái như thế này để mà nó đạt được là bằng 0. Vì vậy chúng ta sẽ tìm Min với Binary Cross entropy. Tức là chúng ta đi tìm cái ngược lại của nó. Do đó cái công thức này nó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 17,
      "start_timestamp": "0:12:18",
      "end_timestamp": "0:13:28"
    }
  },
  {
    "page_content": "ngược lại của nó. Do đó cái công thức này nó là hoàn toàn tương đương. Và chúng ta sẽ chạy thuật toán Backpropagation và cập nhật lại cái tham số cho D. Sau đó chúng ta sẽ sang bước số 2 là khởi tạo optimizer cho G, generator. Bước đầu tiên đó là chúng ta sẽ tạo ra cái dữ liệu từ noise. Thì chúng ta sẽ bắt chước cái code ở trên. Chúng ta sẽ bắt chước cái code ở trên. Rồi, thì ở đây chúng ta sẽ có là xgen là bằng G của noise. Rồi, chấm detach. Ở đây thì chúng ta chưa có detach. Rồi, sau đó thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 18,
      "start_timestamp": "0:13:23",
      "end_timestamp": "0:14:07"
    }
  },
  {
    "page_content": "đây thì chúng ta chưa có detach. Rồi, sau đó thì chúng ta sẽ tạo ra cái kết quả dự đoán dựa trên dữ liệu. Thì ở đây chúng ta sẽ gọi cái hàm đó là D của xgen và nó chính là D của G của noise. Đấy, giống như cái công thức ở đây. Sau đó chúng ta sẽ truyền vào. Thế thì cái sự khác biệt ở đây là gì? Nếu như ở trên là chúng ta tìm cách phân biệt đúng và sai. Thì ở phía dưới cũng là binary cross entropy nhưng mà chúng ta sẽ phải đảo ngược lại cái nhãn. Ở đây là dữ liệu fake nhưng mà chúng ta muốn ép",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 19,
      "start_timestamp": "0:14:05",
      "end_timestamp": "0:14:57"
    }
  },
  {
    "page_content": "Ở đây là dữ liệu fake nhưng mà chúng ta muốn ép cái mô hình G. Ép cái mô hình G tạo ra cái dữ liệu giống thật nên chúng ta sẽ cho cái nhãn của mình là nhãn thật. Đây chính là cái sự khác biệt. Và ngoài ra thì trong cái công thức ở trên chúng ta thấy là có cái thành phần log của D. Nhưng mà khi chúng ta tối ưu G thì D ở đây nó là hằng số. Nó không phải là một cái hàm cố định nên nó sẽ không tham gia vào cái quá trình huấn luyện G. Do đó chúng ta có thể bỏ đi cái thành phần này. Rồi, do đó loss G",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 20,
      "start_timestamp": "0:14:44",
      "end_timestamp": "0:15:39"
    }
  },
  {
    "page_content": "thể bỏ đi cái thành phần này. Rồi, do đó loss G nó chỉ có thành phần là dGz tức là cái loss cho cái dữ liệu của mình, dữ liệu fake của mình. Rồi sau đó chúng ta sẽ gọi hàm backpropagation và chúng ta train. Thì cái quá trình train này nó có thể tốn của chúng ta khoảng 5-10 phút. Tùy vào cái sức mạnh tính toán của cái máy của mình. Rồi thì sau khi đã huấn luyện xong đầy đủ với 10 epoch thì nó sẽ ra được cái ảnh như thế này. Thì chúng ta thấy là cái ảnh mà khi chúng ta tái tạo lại thì chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 21,
      "start_timestamp": "0:15:30",
      "end_timestamp": "0:16:18"
    }
  },
  {
    "page_content": "cái ảnh mà khi chúng ta tái tạo lại thì chúng ta thấy cái bóng dáng của áo, của quần, của giày, v.v. Thì bây giờ để trực quan chúng ta sẽ show cái quá trình mà huấn luyện từ đầu cho đến lúc mà chúng ta dừng cái quá trình huấn luyện. Thì ở những cái vòng lặp đầu tiên chúng ta thấy là nó sẽ ra cái random noise, giống như thế này. Nó sẽ ra cái random noise. Sau đó thì sang vòng lặp tiếp theo thì nó đã ra có hình thù hơn. Có điều là một số khu vực nó vẫn còn mờ. Sau đó đến những epoch cuối cùng thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 22,
      "start_timestamp": "0:16:08",
      "end_timestamp": "0:16:44"
    }
  },
  {
    "page_content": "vẫn còn mờ. Sau đó đến những epoch cuối cùng thì chúng ta đã thấy là nó ra hình hài tốt hơn. Có giày, có quần áo. Thì ở trong cái ví dụ này là cho chúng ta thấy cái mạng GAN nó đã dần học được phân bố của dữ liệu thật của mình. Thế thì để cải tiến cái mạng GAN này chúng ta có rất nhiều giải pháp như là cải tiến các siêu tham số hoặc là thay đổi cái kiến trúc hàm. Nhưng mà một trong những cái cải tiến mà quan trọng chúng ta cần phải cài đặt đó là chúng ta sử dụng cái CNN. Cụ thể là chúng ta sử",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chúng ta sử dụng cái CNN. Cụ thể là chúng ta sử dụng cái 2D Transposed Convolution để làm cái Generator và sử dụng mạng CNN cho cái Discriminator. Thì chúng ta sẽ tham khảo thêm trong các link ở đây để có thể hoàn tất và cài đặt cái phần cài đặt của cái mạng GAN khi sử dụng cái Convolution Neural Network. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=fiDM76zR6UY",
      "filename": "fiDM76zR6UY",
      "title": "[CS315 - Chương 3] Tutorial - GAN",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với vấn đề thứ 2 khi huấn luyện với một mô hình học sâu đó chính là Vanishing-Gradient. Nếu như cái vấn đề về overfitting hay là quá khớp với dữ liệu thì nó rất tổng quát cho các mô hình máy học. Mọi mô hình máy học đều sẽ gặp những vấn đề về overfitting. Còn vấn đề về Vanishing-Gradient thì thường chỉ dành cho các mô hình học sâu. Vậy thì cơ chế của cái hiện tượng Vanishing-Gradient là gì và làm sao để khắc phục được vấn đề này? Chúng ta sẽ cùng đến trong những phần tiếp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:47"
    }
  },
  {
    "page_content": "này? Chúng ta sẽ cùng đến trong những phần tiếp theo. Đầu tiên, như đã nói đây là một mô hình chỉ dành cho các deep learning model. Khi chúng ta làm với các deep model thì chúng ta mới cần xem xét đến vấn đề này. Và hiện tượng thể hiện của nó đó chính là mô hình của mình sẽ hội tụ chậm hoặc là thậm chí không hội tụ sau vài vòng lặp. Tức là có thể ở những vòng lặp đầu tiên thì nó sẽ hội tụ rất tốt. Nhưng mà sau vài vòng lặp thì nó sẽ không còn hội tụ được nữa hoặc là tốc độ hội tụ của mình rất",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:44",
      "end_timestamp": "0:01:30"
    }
  },
  {
    "page_content": "tụ được nữa hoặc là tốc độ hội tụ của mình rất chậm. Vậy thì bây giờ chúng ta sẽ cùng lý giải xem cái bản chất bên trong của hiện tượng Vanishing-Gradient là gì. Và chúng ta sẽ sử dụng các mô hình toán học để giải thích cho nó. Đầu tiên chúng ta giả sử hàm lỗi của mô hình đó chính là hàm J theta. Và như chúng ta biết là các mô hình học sâu thì nó sẽ rất phức tạp và có nhiều layer biến đổi liên tiếp nhau. Do đó thì cái hàm lỗi của mình nó sẽ là một cái dạng hàm hợp, nó là một cái hàm hợp gồm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:23",
      "end_timestamp": "0:02:11"
    }
  },
  {
    "page_content": "một cái dạng hàm hợp, nó là một cái hàm hợp gồm nhiều hàm thành phần. Ví dụ như ở đây chúng ta có hàm J theta là bằng Fn trừ 1 cho đến F2, F1 và theta. Và gradient theo tham số của mình nó sẽ được tính theo cái công thức này. Lưu ý là cái theta của mình nó sẽ là vector hoặc là một tập hợp các cái tham số thành phần. Ví dụ như chúng ta xét trên cái tham số thành phần là theta i. Thì khi đó đạo hàm của J theo theta i nó sẽ là bằng đạo hàm của Fn theo Fn trừ 1, nhân với đạo hàm của Fn trừ 1 theo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:01",
      "end_timestamp": "0:03:03"
    }
  },
  {
    "page_content": "theo Fn trừ 1, nhân với đạo hàm của Fn trừ 1 theo Fn trừ 2, nhân cho đạo hàm F2 theo F1 và nhân đạo hàm của F1 theo theta i. Thì đây là một cái dạng quy tắc gọi là nối tiếp, quy tắc chuỗi trong cái việc là khai triển đạo hàm hay gọi là chain rule. Rồi, thế thì cái hiện tượng vanishing gradient sẽ được giải thích dựa trên cái công thức chain rule này. Đó là trong cái mô hình học sâu thì chúng ta mặc dù là nó có rất nhiều những cái layer biến đổi, nhưng mà đâu đó những cái hàm ở đây sẽ là những",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:53",
      "end_timestamp": "0:03:42"
    }
  },
  {
    "page_content": "nhưng mà đâu đó những cái hàm ở đây sẽ là những cái hàm được thực hiện lặp đi lặp lại nhiều lần. Thì đó là có những cái hàm xuất hiện nhiều lần. Ví dụ trong mô hình học sâu thì activation function hàm kích hoạt là một trong những hàm mà xuất hiện nhiều lần. Tại vì chúng ta có một cái nguyên tắc đó là ngay sau cái phép biến đổi tuyến tính là một cái hàm kích hoạt. Và đây là hàm phi tuyến. Thế thì tại sao chúng ta lại phải có một cái hàm kích hoạt? Tại vì nếu không có hàm kích hoạt thì chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:34",
      "end_timestamp": "0:04:30"
    }
  },
  {
    "page_content": "Tại vì nếu không có hàm kích hoạt thì chúng ta chỉ có phi tuyến tính. Thế thì sau cái phép biến đổi tuyến tính mà là một phép biến đổi tuyến tính thì bản chất đó là một tổ hợp tuyến tính. Do đó thì nó cũng chỉ có thể giải quyết được các cái bài toán đơn giản. Khi chúng ta chèn vào một cái hàm phi tuyến ở giữa thì nó sẽ giúp chúng ta giải quyết được các cái bài toán phức tạp hơn. Và giá trị đạo hàm, lưu ý thứ nhất đó là nó sẽ có một số loại hàm xuất hiện nhiều lần. Và đồng thời đó là cái giá trị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:22",
      "end_timestamp": "0:05:06"
    }
  },
  {
    "page_content": "hiện nhiều lần. Và đồng thời đó là cái giá trị đạo hàm của nó nó nhỏ hơn một. Thì tại sao cái giá trị nhỏ hơn một thì nó sẽ gây ra hiện tượng vanishing gradient? Thì đó là do nếu như ở trong số các cái hàm ở đây mà có cái đạo hàm bé hơn một thì chúng ta hồi xưa cấp ba chúng ta đã học một cái hàm đó là chúng ta học một cái công thức đó lim của a mũ n khi n tiến đến vô cùng. Đó là bằng 0 nếu a lớn hơn 0 và nhỏ hơn một. Tức là một cái con số nhỏ hơn một. Rồi thì hay nói cách khác đó là những con",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:04:59",
      "end_timestamp": "0:06:02"
    }
  },
  {
    "page_content": "một. Rồi thì hay nói cách khác đó là những con số mà nhỏ hơn một khi nhân với nhau thì thay vì nó tăng lên thì nó giảm xuống. Lấy ví dụ như là 0.9 chúng ta nhân với 0.9 thì nó sẽ ra là 0.81 thì 0.81 nó nhỏ hơn 0.9 tức là càng nhân nó sẽ càng nhỏ. Rồi cứ như vậy 0.9 mà mũ 3 thì sẽ là bằng 0.81 nhân 0.9 thì đâu đó nó xấp xỉ là 0.72 tức là nó còn nhỏ hơn cả con số 0.81 nữa. Và cứ như vậy thì cái con số này khi n của mình mà tiến đến vô cùng thì cái con số này nó sẽ tiến về 0. Thì khi n đủ lớn thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:37",
      "end_timestamp": "0:06:38"
    }
  },
  {
    "page_content": "con số này nó sẽ tiến về 0. Thì khi n đủ lớn thì trong mô hình học sâu của mình sẽ có rất nhiều những cái hàm hợp và có nhiều lớp biến đổi thực hiện đi thực hiện lại nhiều lần. Các mô hình của mình đã được chứng minh là càng sâu thì nó sẽ cho khả năng phi tuyến tính hóa càng cao. Do đó n sẽ có xu hướng lớn. Thế thì nếu như trong công thức đạo hàm này có những cái hàm lặp đi lặp lại và cái đạo hàm đó ví dụ như cái đạo hàm này là có cái giá trị tuyệt đối nó bé hơn 1. Thì khi đó các cái hàm, các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:24",
      "end_timestamp": "0:07:15"
    }
  },
  {
    "page_content": "đối nó bé hơn 1. Thì khi đó các cái hàm, các cái giá trị nhỏ hơn 1 nhân với nhau thì nó sẽ tiến về 0. Nó sẽ kéo toàn bộ cái giá trị đạo hàm này về 0. Thì đó là cái vấn đề về Vanishing Gradient, tức là đạo hàm của mình càng lúc càng bị tiến về 0. Và đặc biệt đó là các cái tham số mà càng xa cái bước tính Loss thì cái đạo hàm của mình càng dễ bị tiêu biến. Thế thì thế nào là các cái tham số mà càng xa các cái bước tính Loss thì nó càng dễ tiêu biến. Ví dụ như chúng ta có một cái mạng Neural như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:07:12",
      "end_timestamp": "0:08:13"
    }
  },
  {
    "page_content": "Ví dụ như chúng ta có một cái mạng Neural như thế này. Rồi, thì cái quy trình tính toán của chúng ta đó là những cái tham số ở cái layer số 1, layer số 2 và layer số 3. Rồi sau đó chúng ta sẽ đi tính, ở đây chúng ta sẽ đi so sánh một cái Loss. Chúng ta sẽ đi tính một cái Loss giữa giá trị dự đoán và giá trị thực tế. Thì cái định nghĩa xa gần đó là trong cái ví dụ của mạng Neural Network thì cái bộ tham số theta 3 là gần với cái bước tính Loss. Nhưng mà các cái tham số theta 1 và theta 2 thì nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:08:06",
      "end_timestamp": "0:08:53"
    }
  },
  {
    "page_content": "mà các cái tham số theta 1 và theta 2 thì nó sẽ xa hơn. Và cụ thể ở đây xa nhất chính là theta 1 thì đây là cái khoảng cách gọi là xa. Thì các cái tham số mà càng xa cái bước tính Loss, tức là các cái tham số càng về cái lớp đầu tiên của cái mô hình học sâu, cụ thể đó là theta 1 hoặc là theta 2. Thì cái giá trị đạo hàm sẽ càng dễ bị tiêu biến. Còn những cái giá trị mà ở đầu thì nó sẽ ít bị tiêu biến hơn. Nguyên nhân đó là khi chúng ta chạy thuật toán lan truyền ngược về thuật toán Back",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:08:44",
      "end_timestamp": "0:09:25"
    }
  },
  {
    "page_content": "thuật toán lan truyền ngược về thuật toán Back Propagation lan truyền ngược, thì khi chúng ta tính đến những cái tham số đạo hàm của những cái tham số theta 3 thì nó sẽ ít cái số phép biến đổi hơn. Số cái phép biến đổi là phép nhân hơn. Trong khi đó, khi chúng ta lan truyền ngược cái loss về cái tham số ở càng xa, tức là ở những lớp đầu tiên, thì chúng ta sẽ thực hiện cái thuật toán Back Propagation, chúng ta thực hiện cái phép nhân càng lúc càng nhiều. Mà cái việc phép nhân càng nhiều mà gặp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:09:20",
      "end_timestamp": "0:10:13"
    }
  },
  {
    "page_content": "nhiều. Mà cái việc phép nhân càng nhiều mà gặp những cái con số, đặc biệt là cái đạo hàm của các activation function mà nhỏ, nhỏ hơn 1, thì khi đó các con số nhỏ hơn 1 nó nhân nhiều lần với nhau, nó sẽ tiến về về 0. Còn những cái trọng số ở những lớp cuối, thì số lần chúng ta thực hiện phép nhân đạo hàm của chain rule này, nó ít, kể cả khi cái giá trị đạo hàm của các hàm kích hoạt này mà nhỏ, thì số lần nhân của nó nó ít hơn. Do đó thì các cái tham số càng xa thì nó càng dễ bị tiêu biến. Và thế",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:10:04",
      "end_timestamp": "0:10:59"
    }
  },
  {
    "page_content": "số càng xa thì nó càng dễ bị tiêu biến. Và thế thì nếu mà cái đạo hàm của G theo thetaG mà nó tiêu biến, tức là nó sẽ tiến về 0, thì vấn đề gì xảy ra? Chúng ta phải quay trở lại cái công thức cập nhật tham số của thuật toán Gradient Descent, đó là thetaG, thì sẽ là bằng thetaG trừ cho alpha nhân cho đạo hàm của G theo thetaG. Vì cái đại lượng mà đạo hàm ở đây xấp xỉ 0 nên alpha nhân với nó sẽ xấp xỉ 0, alpha là một con số còn nhỏ hơn 1 nữa, nó có thể là 0.001 nữa, và càng nhỏ hơn. Thế thì cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:10:50",
      "end_timestamp": "0:11:32"
    }
  },
  {
    "page_content": "có thể là 0.001 nữa, và càng nhỏ hơn. Thế thì cái con số này sẽ càng tiến về 0, thế thì thetaI bằng thetaI trừ 0, tức là xấp xỉ với lại con số thetaI hay nói cái khác thetaI không cập nhật, tức là gần như không cập nhật. Thì nó giải thích cho cái hiện tượng đó là hội tụ chậm, tại vì nó không có cập nhật tham số thì lấy đâu mà nó hội tụ? Hoặc thậm chí đó là không hội tụ luôn, hội tụ chậm hoặc thậm chí là không hội tụ. Rồi, như vậy thì ở đây chúng ta đã lý giải về mặt nguyên lý toán học của hiện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:11:25",
      "end_timestamp": "0:12:06"
    }
  },
  {
    "page_content": "ta đã lý giải về mặt nguyên lý toán học của hiện tượng vanishing gradient. Cái nguyên lý số 1 đó là trong mô hình học sâu có rất nhiều những cái hàm lặp đi lặp lại nhiều lần, cụ thể đó là cái hàm kích hoạt. Thì các cái hàm kích hoạt này đương nhiên là không chỉ hàm kích hoạt, nó có thể có những hàm khác tùy vào thiết kế của mô hình của mình. Các cái hàm kích hoạt này nếu chúng ta chọn lựa mà không tốt thì có khả năng cái đạo hàm của nó là một con số nhỏ hơn 1. Khi chúng ta thực hiện cái chain",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": "0:11:54",
      "end_timestamp": "0:12:06"
    }
  },
  {
    "page_content": "số nhỏ hơn 1. Khi chúng ta thực hiện cái chain rule này mà những cái đạo hàm nào thực hiện đi thực hiện lại nhiều lần, khi nhân nhiều lần với những con số nhỏ hơn 1 thì nó sẽ tiến về 0. Và đặc biệt cái hiện tượng này càng dễ thấy đối với những cái tham số mà ở những cái lớp đầu tiên của cái mạng học sâu, tức là nó xa cái bước tính loss.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FMhXMbROI-o",
      "filename": "FMhXMbROI-o",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Trên đây là mã giả cài đặt thuật toán clip, rất đơn giản Đầu tiên là image encoder này, chúng ta có thể lấy pre-trained model ví dụ như ResNet hoặc Vision Transformer là VIT Còn ResNet thì chúng ta có thể sử dụng các pre-trained model ví dụ như ResNet 101 Text Encoder thì chúng ta có thể sử dụng mô hình Continuous Belt Work là Work2Vac Hoặc là mô hình Text Transformer sử dụng BERT Đây là large pre-trained model sử dụng Transformer và được sử dụng rất nhiều trong lĩnh vực xử lý ngôn ngữ tự nhiên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:02"
    }
  },
  {
    "page_content": "rất nhiều trong lĩnh vực xử lý ngôn ngữ tự nhiên Một ảnh y khi đưa qua image encoder thì chúng ta sẽ ra được một feature là if, viết tắt của chữ feature representation và nó sẽ có cái kích thước đó là n, nhân di N là số ảnh của mình và di là số chiều của vector biểu diễn Mỗi text encoder và image encoder sẽ có số chiều khác nhau Do đó di tức là viết tắt của chữ image là dimension của image text encoder sẽ trả về biến tf là n, và mỗi mô tả sẽ được biểu diễn bởi vector dt t là viết tắt của chữ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:58",
      "end_timestamp": "0:02:12"
    }
  },
  {
    "page_content": "biểu diễn bởi vector dt t là viết tắt của chữ text, và t là số chiều của vector biểu diễn văn bản Và chúng ta sẽ có một chung multimodal embedding tức là chúng ta sẽ đưa cái di và dt này về cùng một cái không gian tức là đưa cùng về cùng một cái vector có cùng một kích thước Thế thì một cái vector di chiều chúng ta sẽ nhân dot product với lại một cái ma trận là w,i để chuyển từ một vector di chiều sang vector de chiều Thì hai cái thao tác này mục đích của mình đó là chuyển Cái không gian đặc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:02:08",
      "end_timestamp": "0:03:18"
    }
  },
  {
    "page_content": "mục đích của mình đó là chuyển Cái không gian đặc trưng của văn bản và hình ảnh về cùng một không gian Thế thì không gian ở đây cụ thể là không gian gồm có de chiều Và đương nhiên là chúng ta sẽ normalize nó lại để cho cái việc huấn luyện của mình dễ hơn và đỡ bị hiện tượng overfitting hơn Sau đó thì chúng ta sẽ đi tính scale dot product, chúng ta sẽ đi tính tích vô hướng Rồi có thêm một cái nhân thêm cái exp, tức là cái hàm e mũ t Thì mục tiêu của cái này đó là nằm trong cái công thức của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:03:10",
      "end_timestamp": "0:04:04"
    }
  },
  {
    "page_content": "của cái này đó là nằm trong cái công thức của contrastive loss Để mà có thêm cái tham số là t t ở đây chính là nó viết tắt của chữ là temperature Thì khi t của mình mà nó càng lớn thì nó sẽ khiến cho cái mô hình của mình nó sẽ nhọn hơn và nó sẽ phân biệt rất là rõ đối tượng này với đối tượng kia Nhưng mà thực tế thì chúng ta sẽ thấy có nhiều cái hình ảnh mà nó có sự giao thoa với nhau Ví dụ như trong cái ảnh đó nó sẽ có hai con vật vừa chó vừa mèo thì nó phải không nên quá gắt để mà đưa về một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:03:54",
      "end_timestamp": "0:04:43"
    }
  },
  {
    "page_content": "thì nó phải không nên quá gắt để mà đưa về một cái phân lớp nào đó hoặc là bản chất là thậm chí trong nếu mà chỉ có một con chó thôi thì chúng ta thấy là cái con chó nó cũng sẽ có cái hình thù đâu đó cũng sẽ giống con mèo do đó thì chúng ta không nên để cái t này tiến về một, mà chúng ta cho nó ở mức giữa đoạn đó là khoảng 0.2 ví dụ 0.1, 0.2, ví dụ vậy Còn nếu mà tiến về 0, thì tiến về 1, 1 thì nó sẽ quá gắt Còn nếu mà tiến về 0 thì nó lại quá mềm, nó lại quá mềm và nó sẽ không có sự phân biệt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:04:34",
      "end_timestamp": "0:05:21"
    }
  },
  {
    "page_content": "nó lại quá mềm và nó sẽ không có sự phân biệt rõ ràng giữa đối tượng này với đối tượng kia do đó t, chúng ta sẽ cho nó khoảng là ở mức giữa giữa và khi chúng ta đã tính được cái logit này rồi, tức là cái độ tương đồng giữa hai cái ảnh và văn bản này rồi Vì vậy, chúng ta sẽ tiến hành đi tính loss và ở đây sẽ có hai cái loại loss đối xứng với nhau Loss Y và Loss T Trong đó Y, tức là chúng ta sẽ lấy một cái ảnh, ví dụ trong cái ma trận của chúng ta ở đằng trước Trong cái ma trận của chúng ta, ví",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:05:13",
      "end_timestamp": "0:06:08"
    }
  },
  {
    "page_content": "ở đằng trước Trong cái ma trận của chúng ta, ví dụ chúng ta xét ở hàng này đi Chúng ta xét ở cái ma trận này và tại cái O này thì chúng ta sẽ có Y, có nghĩa là chúng ta sẽ lấy theo hàng tức là các cái giá trị loss theo hàng và Loss T, tức là chúng ta sẽ lấy theo hình ảnh Loss T chúng ta sẽ lấy theo cột như thế này Thì cái việc mà chúng ta tính cả loss theo hàng và theo cột thì để giúp cho cái mô hình của mình nó có cái tính đối xứng khi mà so sánh giữa hình ảnh với một loạt các cái văn bản so",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:06:03",
      "end_timestamp": "0:06:49"
    }
  },
  {
    "page_content": "giữa hình ảnh với một loạt các cái văn bản so sánh giữa hình ảnh nè với một loạt các cái văn bản là T1, T2, T3, Tn nhưng đồng thời nó cũng sẽ có sự so sánh giữa một văn bản với một loạt các hình ảnh một văn bản với một loạt các hình ảnh nó thể hiện ở cái cột này thì đó là cái sự tổng hợp Còn cái label ở đây thì nó sẽ có label range tức là 12012... cho đến n trừ 1 thì ý của nó là cái nhãn của các đối tượng của mình sẽ là đối với ảnh thứ nhất thì cái nhãn của mình sẽ là đối tượng đầu tiên ảnh thứ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:06:45",
      "end_timestamp": "0:07:24"
    }
  },
  {
    "page_content": "nhãn của mình sẽ là đối tượng đầu tiên ảnh thứ hai thì cái nhãn của mình sẽ là thứ hai thì ý của nó là nó đang muốn làm theo chạy đường chéo này của mình và khi chúng ta đã có cái loss này rồi thì chúng ta sẽ dùng thuật toán gradient descent các thuật toán optimizer dựa trên gradient descent để huấn luyện và vấn đề đó là làm sao chúng ta có được cái bộ dữ liệu để huấn luyện đó là một cái ảnh và một cái văn bản mô tả thế thì chúng ta sẽ lấy từ trên internet trên internet thì ví dụ như Instagram",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:19",
      "end_timestamp": "0:08:04"
    }
  },
  {
    "page_content": "internet trên internet thì ví dụ như Instagram là có khoảng hơn 3 tỷ ảnh và chúng ta có một số meta data ứng với cái mỗi ảnh đó thì cái tên file ảnh có thể chứa cái thông tin của nội dung ảnh chứa là đâu đó trên mạng xã hội của chúng ta cái nguồn dữ liệu mô tả này thì đã được người dùng người ta mô tả rồi và chúng ta chỉ việc là khai thác cái lượng dữ liệu này và OpenAI thì xây dựng một cái bộ dữ liệu là WIT là Web Image Text thì bao gồm là 400 triệu cặp dữ liệu ảnh và văn bản rồi 500 ngàn truy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:07:59",
      "end_timestamp": "0:08:55"
    }
  },
  {
    "page_content": "cặp dữ liệu ảnh và văn bản rồi 500 ngàn truy vấn dựa trên danh sách các từ xuất hiện trên Wikipedia tức là các ảnh này có cái nội dung về chủ đề gì thì cũng sẽ đa dạng hóa bằng cái việc đó là chúng ta sẽ truy vấn bằng 500 ngàn câu truy vấn được lấy từ trên nguồn bách khoa toàn thư để tăng tính đa dạng của data set và cái kết quả của clip đó là gì clip cho phép chúng ta có thể Zero-shot Transfer rất là hiệu quả và sau khi clip đã ra đời thì có rất nhiều mô hình khai thác clip để làm các mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "0:08:50",
      "end_timestamp": "0:09:43"
    }
  },
  {
    "page_content": "nhiều mô hình khai thác clip để làm các mô hình như là phân loại hình ảnh phát hiện đối tượng phân đoạn ngữ nghĩa đối tượng, bài toán captioning, bài toán mô tả hình ảnh rất là nhiều và cái sơ đồ trên đây là việc sử dụng contrastive loss cho sự hiệu quả gấp hơn rất nhiều lần so với các phương pháp huấn luyện khác cụ thể đó là để cho được độ chính xác trên Zero-shot đâu đó khoảng 15% thì tập dữ liệu của chúng ta chỉ cần là khoảng 33 triệu ảnh trong khi đó nếu như chúng ta sử dụng phương pháp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:09:39",
      "end_timestamp": "0:10:30"
    }
  },
  {
    "page_content": "trong khi đó nếu như chúng ta sử dụng phương pháp dạng prediction hoặc sử dụng một mô hình ngôn ngữ transformer để huấn luyện thì nó sẽ phải tốn lên đến 134 triệu và ở đây sẽ là 400 triệu như vậy thì cái ý của cái biểu đồ này cho biết là phương pháp huấn luyện của contrastive loss của clip cho sự hiệu quả rất là cao, gấp 4 lần ít nhất là gấp 4 lần tuy nhiên cái hạn chế của nó là nó sẽ kém trừu tượng nó sẽ kém hiệu quả trên các bài toán có tính trừu tượng cao trong đó có các đối tượng tương tác",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:10:25",
      "end_timestamp": "0:11:14"
    }
  },
  {
    "page_content": "tượng cao trong đó có các đối tượng tương tác với nhau chi tiết thì nó sẽ không có hiệu quả hoặc là những bài toán như là đếm vật thể những bài toán đếm, đó cũng là một bài toán nằm trong nhóm trừu tượng cao và cái kết quả kém trên dữ liệu có phân phối khác ví dụ như chúng ta huấn luyện trên tập dữ liệu trên mạng internet nhưng khi chúng ta sử dụng nó trên tập dữ liệu MNIST thì có thể kết quả nó lại không có tốt bằng và do đó chúng ta cần phải cẩn thận trong việc lựa chọn tập dữ liệu khi chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "thận trong việc lựa chọn tập dữ liệu khi chúng ta tiến hành đánh giá, đó chính là những điểm hạn chế của clip Cảm ơn các bạn đã xem video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=FVLj-OJBLyI",
      "filename": "FVLj-OJBLyI",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 2 (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ đến với mô hình hồi quy logistic hay còn gọi là mô hình hồi quy luận lý Nhánh đi của chúng ta là nằm trong nhánh tuyến tính và phân loại, nhưng cho bài toán phân loại nhị phân Tức là đầu ra của chúng ta sẽ có 2 phân lớp mà thôi Mô hình biểu diễn dưới dạng đồ thị của chúng ta sẽ là như sau Đầu vào của chúng ta sẽ bao gồm là 1 thành phần số 1 tượng trưng cho bias Tức là tất cả những đặc trưng nào chúng ta không biết, không kiểm soát được thì nó sẽ đưa nằm trong bias X1, X2, ..., Xm đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:58"
    }
  },
  {
    "page_content": "thì nó sẽ đưa nằm trong bias X1, X2, ..., Xm đó là những input feature Tức là những đặc trưng đầu vào để phục vụ cho việc dự đoán giá trị đầu ra Và mô hình của mình thì công thức của chúng ta sẽ có dạng như sau, đó là Fθx là bằng sigmoid của theta x Thế thì trong mô hình hồi quy tuyến tính thì công thức của chúng ta đó là theta chuyển vị nhân x Theta chuyển vị nhân x thì miền giá trị của mình đó là từ trừ vô cùng cho đến cộng vô cùng Trong khi đó đối với bài toán phân loại nhị phân thì đầu ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:01:44"
    }
  },
  {
    "page_content": "đó đối với bài toán phân loại nhị phân thì đầu ra của chúng ta chỉ có 2 phân lớp thôi Do đó chúng ta có thể mã hóa đầu ra của mình là bằng 2 giá trị đó là 0 và 1 Như vậy thì làm sao để mình có thể đưa một giá trị theta x từ miền giá trị trừ vô cùng cộng vô cùng Về khoảng từ 0 cho đến 1 thì chúng ta có cái hàm sigmoid Đồ thị của hàm sigmoid sẽ có dạng như sau Thì giá trị nhỏ nhất của mình đó là bằng 0 và giá trị lớn nhất của mình đó là khi bằng 1 Như vậy là nó đã ép miền giá trị của theta chuyển",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 2,
      "start_timestamp": "0:01:38",
      "end_timestamp": "0:02:31"
    }
  },
  {
    "page_content": "Như vậy là nó đã ép miền giá trị của theta chuyển vị x từ trừ vô cùng cộng vô cùng Về cái đoạn là từ 0 đến 1 thông qua hàm sigmoid này Mặt khác cái hàm sigmoid này thì nó cũng có một tính chất khá là thú vị đó là đạo hàm của nó tính cũng rất là dễ dàng Cụ thể là đạo hàm của sigmoid thì là bằng sigmoid z nhân với lại 1 trừ sigmoid z Thì cái công thức này nó cũng tương đối là gọn gàng Và hàm này nó cũng có một tính chất nữa đó là nó sẽ khả vi và liên tục Do đó thì việc chọn lựa cái hàm này nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 3,
      "start_timestamp": "0:02:24",
      "end_timestamp": "0:03:12"
    }
  },
  {
    "page_content": "tục Do đó thì việc chọn lựa cái hàm này nó sẽ đạt được 2 mục đích Vừa đưa về cái miền giá trị từ 0 đến 1 là trùng với lại cái nhãn mà chúng ta muốn cái output cho cái đầu ra Của một cái mô hình là hồi quy tuyến tính, mô hình phân loại nhị phân Và cái giá trị của cái hàm dự đoán của mình đó cũng là một cái hàm liên tục và có đạo hàm Sau khi chúng ta đã có được cái hàm dự đoán thì chúng ta sẽ tiến đến là thiết kế cái hàm lỗi Thì hàm lỗi của mình trong trường hợp này đó chính là hàm binary cross",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 4,
      "start_timestamp": "0:03:04",
      "end_timestamp": "0:04:05"
    }
  },
  {
    "page_content": "trong trường hợp này đó chính là hàm binary cross entropy là của sigmoid của theta x, y Thì cái công thức của binary cross entropy nếu mà chúng ta xem cái thành phần sigmoid của theta x là y ngã Thế thì cái công thức của mình nó sẽ là bằng trừ của y log y ngã cộng cho (1 trừ y) log của 1 trừ y ngã Và tất cả cái này thì đặt trong cái dấu ngoặc vuông Thế thì tại sao chúng ta lại có cái công thức này Thì cái công thức này nó sẽ giúp cho chúng ta khuếch đại được cái sai số khi y và y ngã khác nhau",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 5,
      "start_timestamp": "0:03:48",
      "end_timestamp": "0:04:46"
    }
  },
  {
    "page_content": "đại được cái sai số khi y và y ngã khác nhau Trong trường hợp mà y mà bằng y ngã ví dụ vậy thì cái sai số này nó là bằng 0 Ví dụ y bằng y ngã mà bằng 1 Thì khi chúng ta thế cái con số 1 này vào đây thì chúng ta thấy là cái binary cross entropy của 1 và 1 là bằng 0 Tức là nếu dự đoán đúng thì chúng ta sẽ không bị phạt cái gì Nhưng ngược lại nếu chúng ta đoán sai lấy ví dụ như y của chúng ta là bằng 1 nhưng mà y ngã của chúng ta thì lại bằng 0 Thì khi chúng ta thế vào cái công thức ở trên thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 6,
      "start_timestamp": "0:04:43",
      "end_timestamp": "0:05:23"
    }
  },
  {
    "page_content": "Thì khi chúng ta thế vào cái công thức ở trên thì binary cross entropy của 1, y ngã trước là số 0 Còn y phía sau là số 1 thì nó sẽ là bằng thế vào đây thì chúng ta có thể tính ra được là bằng cộng vô cùng Thì cái việc mà cái giá trị của BCE, cái sai số khi chúng ta dự đoán sai nó rất là lớn thì nó sẽ khuyến khích cho mô hình học nhanh hơn Và cái lý do đằng sau đó là vì cái đạo hàm của mình, cái độ dốc của đạo hàm của mình nó lớn Thì dẫn đến là khi chúng ta cập nhật theta là bằng theta trừ cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 7,
      "start_timestamp": "0:05:14",
      "end_timestamp": "0:06:05"
    }
  },
  {
    "page_content": "khi chúng ta cập nhật theta là bằng theta trừ cho alpha nhân cho đạo hàm của hàm loss theo theta Thì vì cái độ dốc của cái hàm BCE này nó lớn dẫn đến là cái giá trị này nó lớn Mà giá trị này lớn thì cái bước nhảy cập nhật của mình sẽ càng lớn hơn do đó nó sẽ cập nhật cái tham số chính xác hơn Như vậy tổng kết lại thì mô hình hồi quy logistic của chúng ta thì ở đây các trọng số của mô hình hồi quy logistic Ví dụ như ở đây chúng ta phân rã cái theta, cái vector theta này ra thì đó là bằng theta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 8,
      "start_timestamp": "0:05:56",
      "end_timestamp": "0:07:11"
    }
  },
  {
    "page_content": "cái vector theta này ra thì đó là bằng theta 0, theta 1, theta 2 và cho đến theta m Về mặt ý nghĩa các trọng số theta 0, theta 1 cho đến theta m ở đây nó chính là cái tham số của phương trình đường thẳng mà phân tách 2 tập này Cụ thể là phương trình đường thẳng nó sẽ có dạng là theta 0 cộng cho theta 1 x1 cộng cho theta 2 x2 là bằng 0 Và trong trường hợp này thì chúng ta có 2 cái biến là x1 và x2 còn một cách tổng quát Thì cái ý nghĩa của cái tham số này đó sẽ là cái tham số của phương trình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 9,
      "start_timestamp": "0:06:48",
      "end_timestamp": "0:07:36"
    }
  },
  {
    "page_content": "tham số này đó sẽ là cái tham số của phương trình đường thẳng là theta 0 cộng theta 1 x1 cộng cho theta 2 x2 và cộng cho... cho đến theta m xm là bằng 0 Thì đây là cái công thức phương trình đường thẳng tổng quát Thì những cái điểm màu xanh và những cái điểm màu cam khi chúng ta lấy cái tọa độ của nó chúng ta thế vào thì nó sẽ là cùng dấu với nhau đối với những cái điểm mà cùng một phân lớp Ví dụ như tất cả những cái điểm màu xanh ở đây nếu chúng ta lấy cái giá trị tọa độ, cái đặc trưng thế vào",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 10,
      "start_timestamp": "0:07:26",
      "end_timestamp": "0:08:06"
    }
  },
  {
    "page_content": "ta lấy cái giá trị tọa độ, cái đặc trưng thế vào thì nó sẽ cùng dương hết Ví dụ như đây là theta 0 cộng theta 1 x1 cộng cho theta 2 x2 thì đều cùng dương Thì nếu như những cái tọa độ này mà thế vào đây mà cùng dương thì những cái điểm màu cam khi chúng ta thế vào thì nó sẽ là cùng âm Đều vậy không? Và thì đây chính là cái tính chất về mặt toán học giải tích của cái mô hình hồi quy logistic",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=GRB4B1tWnEo",
      "filename": "GRB4B1tWnEo",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 2 (New)",
      "chunk_id": 11,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng vận dụng những lý thuyết về balancing gradient và overfitting đã được tìm hiểu ở những phần trước để lý giải cho sự tiến hóa của các mạng CNN. Các mạng CNN ở đây sẽ được khảo sát từ giai đoạn mới bắt đầu có ý tưởng của mạng CNN cho đến những mạng CNN hiện đại hơn. Đầu tiên đó chính là mô hình Logistic Regression hay là một cái Perceptron đơn giản. Ở đây chúng ta thấy mạng của chúng ta chỉ có duy nhất một node, duy nhất một neuron. Và ý nghĩa của mô hình này là nó sẽ phân chia",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:01"
    }
  },
  {
    "page_content": "Và ý nghĩa của mô hình này là nó sẽ phân chia không gian đặc trưng ra, làm thành một mặt phẳng. Cụ thể ở đây, các tham số theta 0, theta 1, theta 2 và theta m, thì đây chính là các tham số của phương trình đường thẳng. Và chính xác hơn là của mặt phẳng tại vì chúng ta sẽ xét trong không gian nhiều chiều. Và cái mặt phẳng này nó sẽ chia không gian ra làm hai phần, một cách tuyến tính. Và ví dụ như chúng ta có tập hợp các cái điểm như thế này, thì nếu như các điểm mà có thể phân chia được bởi một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:01:50"
    }
  },
  {
    "page_content": "nếu như các điểm mà có thể phân chia được bởi một cái siêu phẳng hay là một cái mặt phẳng, thì khi đó chúng ta có thể sử dụng cái mạng Logistic Regression hoặc là Perceptron. Tại vì với cái đường thẳng này thì nó sẽ tách ra làm hai, một cách dễ dàng đối với dữ liệu tuyến tính. Vấn đề xảy ra đó là mỗi một cái Perceptron thì nó chỉ có thể giải quyết được một cái bài toán tuyến tính. Trong khi đó sẽ có rất nhiều những cái bài toán phức tạp hơn và chúng ta không thể sử dụng một cái mạng Perceptron",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 2,
      "start_timestamp": "0:01:44",
      "end_timestamp": "0:02:22"
    }
  },
  {
    "page_content": "ta không thể sử dụng một cái mạng Perceptron để có thể giải quyết được. Chúng ta lấy một cái tình huống ví dụ đó là hai cái tập điểm nằm trong và nằm ngoài vòng tròn. Đó là hình tròn và dấu cộng, các điểm tròn và cộng như thế này. Thì chúng ta thấy là với một đường thẳng thì không thể nào tách ra làm hai phần được, mà chúng ta cần phải có một cái tổ hợp các cái đường thẳng. Cụ thể đó là chúng ta sẽ cần có cái tổ hợp này để mà chia ra làm hai. Thế thì để mà có thể phối hợp và tổng hợp được các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 3,
      "start_timestamp": "0:02:15",
      "end_timestamp": "0:03:09"
    }
  },
  {
    "page_content": "thì để mà có thể phối hợp và tổng hợp được các cái thông tin của một loạt các cái đặc trưng như thế này, thì nó đòi hỏi chúng ta không phải chỉ tăng theo cái chiều dọc như thế này. Tại vì với mỗi một cái neuron này thì chúng ta sẽ có một cái bộ phân loại yếu, đó là một cái mạng phẳng. Nhưng các cái mạng phẳng này muốn mà có thể giải quyết được bài toán vi tuyến thì nó đòi hỏi phải có một cái thao tác để tổng hợp. Và thao tác tổng hợp đó thì nó sẽ được đặt ở cái layer tiếp theo. Còn nếu không có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 4,
      "start_timestamp": "0:03:00",
      "end_timestamp": "0:03:48"
    }
  },
  {
    "page_content": "được đặt ở cái layer tiếp theo. Còn nếu không có cái layer này thì các cái neuron nó sẽ là độc lập nhau. Neuron số 1, neuron số 2 và neuron số 3 là độc lập. Nó sẽ không thể phối hợp với nhau. Nhưng nhờ có cái neuron số 4 ở cái layer tiếp theo, nó tổng hợp lại để phối hợp và tạo ra một cái đặc trưng mạnh hơn. Đó là ý nghĩa của việc mà chúng ta tăng thêm một cái layer, nó sẽ giúp chúng ta tạo ra một cái đặc trưng mới. Vì vậy, với một neuron thì đặc trưng của chúng ta quá đơn giản nên không giải",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 5,
      "start_timestamp": "0:03:39",
      "end_timestamp": "0:04:22"
    }
  },
  {
    "page_content": "trưng của chúng ta quá đơn giản nên không giải quyết được các bài toán phức tạp hoặc là bài toán vi tuyến. Vậy thì đến với cái mạng neural network, nhờ có các cái hidden layer, tức là các cái lớp ẩn. Các cái lớp ẩn này thì nó sẽ tổng hợp, ví dụ như một cái node ở đây, chúng ta thấy là kết nối với các cái node ở phía trước. Tức là nó đang tổng hợp đặc trưng. Các cái đặc trưng ở lớp trước, đó là những đặc trưng đơn giản. Nhưng mà qua cái quá trình tổng hợp ở đây thì nó sẽ tạo ra các cái đặc trưng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 6,
      "start_timestamp": "0:04:14",
      "end_timestamp": "0:05:08"
    }
  },
  {
    "page_content": "tổng hợp ở đây thì nó sẽ tạo ra các cái đặc trưng mới phức tạp hơn và nó phi tuyến hơn. Rõ ràng các cái đặc trưng phi tuyến tính, nó sẽ giúp cho chúng ta giải quyết được những cái bài toán phức tạp. Các cái đặc trưng phức tạp sẽ giúp cho chúng ta giải quyết được các cái bài toán phi tuyến tính. Và MLP, tức là cái mạng neural network của mình, một cái tên gọi khác của mạng neural network, nó sẽ tổng hợp đặc trưng phức tạp hơn từ các cái đặc trưng đơn giản qua các cái lớp ẩn. Với lớp ẩn này, tổng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 7,
      "start_timestamp": "0:05:02",
      "end_timestamp": "0:05:51"
    }
  },
  {
    "page_content": "đơn giản qua các cái lớp ẩn. Với lớp ẩn này, tổng hợp đặc trưng đơn giản để tạo ra thành các đặc trưng mới. Và khi chúng ta tổ hợp, chúng ta tạo ra càng thêm nhiều layer, thì các cái cấp độ đặc trưng của chúng ta cũng sẽ đa dạng hơn. Từ đơn giản cho đến trung bình, rồi sau đó sẽ đến là các cái đặc trưng cấp cao, hoặc phức tạp. Thì tổ hợp các cái đặc trưng này, nó sẽ phối hợp với nhau để có thể giải quyết được các bài toán khó. Vậy thì vấn đề của mạng neural network đó là gì? Đó là khi chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 8,
      "start_timestamp": "0:05:44",
      "end_timestamp": "0:06:24"
    }
  },
  {
    "page_content": "mạng neural network đó là gì? Đó là khi chúng ta xử lý trên cái dữ liệu lớn, có kích thước lớn, ví dụ như dữ liệu ảnh, thì số lượng tham số có thể bùng nổ. Chúng ta lấy ví dụ như ở đây chúng ta sẽ không dùng vector, chúng ta không dùng những cái vector mà có số chiều nhỏ, mà chúng ta sẽ dùng mạng neural network để xử lý trên cái ảnh có cái kích thước lớn. Thì ở đây giả sử chúng ta xét một cái ảnh có kích thước rất là tương đối là khiêm tốn, thực tế thì ảnh có thể lớn hơn, độ phân giải lớn hơn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 9,
      "start_timestamp": "0:06:18",
      "end_timestamp": "0:07:09"
    }
  },
  {
    "page_content": "tế thì ảnh có thể lớn hơn, độ phân giải lớn hơn. Thì 200 x 200 này, khi chúng ta flatten ra, thì nó sẽ tương đương với một cái vector mà có kích thước đó là 200 x 200, tức là 40 nghìn. Và giả sử như cái mạng neural network của chúng ta có một cái hidden layer có số chiều đúng bằng số chiều input, tức là đây là một cái kiến trúc mà tương đối là đơn giản, thực tế thì có thể là số lượng neuron của mình có thể nhiều hơn. Thế thì ở đây sẽ là có 40 nghìn neuron, vì ở đây chúng ta kết nối đầy đủ nên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 10,
      "start_timestamp": "0:06:58",
      "end_timestamp": "0:07:52"
    }
  },
  {
    "page_content": "neuron, vì ở đây chúng ta kết nối đầy đủ nên mỗi một cái neuron output sẽ kết nối với tất cả những neuron input. Như vậy thì chúng ta sẽ có tất cả là 40 nghìn nhưng 40 nghìn thì đâu đó là cỡ 1.6 tỷ tham số. Và với cái mô hình mà có cái số lượng tham số bùng nổ như thế này, thì trong hồi trước chúng ta đã giới thiệu đó là nó gây ra cái hiện tượng overfitting, do không thể nào mà thu thập được một cái lượng dữ liệu mà xấp xỉ lên đến hàng tỷ mẫu như thế này. Cái quy mô nó quá lớn. Vậy thì từ đó nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 11,
      "start_timestamp": "0:07:40",
      "end_timestamp": "0:08:42"
    }
  },
  {
    "page_content": "thế này. Cái quy mô nó quá lớn. Vậy thì từ đó nó sẽ cho ra đời là cái mạng CNN. Mạng CNN thì bản chất là nó có một cái phần rút trích đặc trưng riêng, riêng đó là dùng cái phép biến đổi convolution. Thì các lớp convolution và relu hoặc là sigmoid, hoặc một hàm kích hoạt là sigmoid, thì mục đích của nó đó là để rút trích ra đặc trưng ảnh. Và đặc trưng này nó sẽ được sắp xếp từ đơn giản cho đến phức tạp. Và các lớp MLP phía sau thì mục đích của nó là để phân lớp đặc trưng. Còn ở cái lớp phía",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 12,
      "start_timestamp": "0:08:33",
      "end_timestamp": "0:09:23"
    }
  },
  {
    "page_content": "nó là để phân lớp đặc trưng. Còn ở cái lớp phía trước mục tiêu của nó đó là chúng ta sẽ rút trích đặc trưng. Và các đặc trưng này thì sẽ được đi từ thấp cho đến cao, từ đặc trưng level thấp cho đến đặc trưng level cao. Vậy thì với một cái mạng CNN thì chúng ta sẽ tìm hiểu xem ý nghĩa của nó là gì. Ví dụ như trong phần trước, chúng ta đã tìm hiểu ý nghĩa của một cái mạng Neural network. Đây là mỗi cái node này tổng hợp đặc trưng ở lớp trước đó. Vậy thì CNN thì sao? Với mỗi một cái lát cắt ở đây,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 13,
      "start_timestamp": "0:09:16",
      "end_timestamp": "0:10:11"
    }
  },
  {
    "page_content": "thì CNN thì sao? Với mỗi một cái lát cắt ở đây, với ảnh dữ liệu đầu vào, chúng ta thấy ở đây sẽ có 3 chiều. Trong đó chiều ngang và chiều dọc chính là chiều không gian là width và height. Đây là hai chiều không gian. Còn chiều này sẽ là chiều độ sâu d. Đây chính là chiều của đặc trưng. Rồi, tức là số lượng đặc trưng của mình. Ví dụ trong cái feature map ở đây, thì mỗi một cái lát cắt ở đây nó sẽ là một cái đặc trưng của cái input đầu vào. Trên hình chúng ta thấy là một cái vùng màu đen, thì đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 14,
      "start_timestamp": "0:10:03",
      "end_timestamp": "0:10:54"
    }
  },
  {
    "page_content": "chúng ta thấy là một cái vùng màu đen, thì đây sẽ là một cái feature. Và feature này là của một cái lát cắt đầu tiên. Chúng ta sẽ có rất nhiều những cái lát cắt. Và với mỗi cái lát cắt này, nó sẽ là một cái feature, một cái đặc trưng. Thì nhiều cái đặc trưng chúng ta tổng hợp lại, thì nó sẽ giúp cho chúng ta có cái góc nhìn đa chiều về đối tượng của mình. Và sau đó thì chúng ta hoàn toàn có thể sử dụng các cái đặc trưng này để phục vụ cho cái tác vụ phía sau. Như vậy thì cái xu hướng phát triển",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 15,
      "start_timestamp": "0:10:44",
      "end_timestamp": "0:11:42"
    }
  },
  {
    "page_content": "vụ phía sau. Như vậy thì cái xu hướng phát triển chung của cái mạng CNN, đó là đầu tiên, đó là tăng độ sâu. Nếu như ở những cái layer đầu tiên thì cái độ sâu của mình khá là thấp. Ví dụ như ảnh đầu vào của mình thì có thể độ sâu là 3. Rồi sau đó đến các cái đặc trưng cấp thấp thì cái độ sâu của mình có thể từ 64 cho đến khoảng 128. Nhưng mà càng về sau, chúng ta sẽ càng có nhiều cái layer. Ví dụ như ở đây chúng ta có thêm các cái layer ở giữa. Tương ứng là các cái đặc trưng cấp thấp, cấp vừa và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 16,
      "start_timestamp": "0:11:26",
      "end_timestamp": "0:12:23"
    }
  },
  {
    "page_content": "ứng là các cái đặc trưng cấp thấp, cấp vừa và cấp cao. Và càng tiến đến về các cái đặc trưng cấp cao thì cái độ sâu của mình, cái độ sâu của đặc trưng cũng sẽ càng tăng. Tăng về độ sâu của đặc trưng. Hay nói cách khác, đó là số lượng đặc trưng cấp cao, đặc trưng mà cấp cao, 2 levels cũng sẽ tăng lên. Và nhờ có nhiều cái đặc trưng cấp cao này thì giúp cho chúng ta phân loại được dễ dàng hơn cho các bước sau. Thì ở đây chúng ta thấy là nó sẽ tăng dần về độ sâu. Tại vì ở những cái đặc trưng lớp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 17,
      "start_timestamp": "0:12:13",
      "end_timestamp": "0:13:26"
    }
  },
  {
    "page_content": "dần về độ sâu. Tại vì ở những cái đặc trưng lớp đầu là những cái đặc trưng cấp thấp thì nó rất là đơn giản và ít. Ví dụ như có đặc trưng biên cạnh hay chiều dọc, đặc trưng biên cạnh hay chiều ngang, rồi đặc trưng về đường sọc, đường chéo, rồi đặc trưng về màu, màu xanh, màu đỏ, màu vàng v.v. Thì cái số lượng đặc trưng đó rất là ít, nhưng mà khi lên các đặc trưng cấp cao, nó là tổ hợp, tổ hợp tổng hợp các đặc trưng ở lớp trước đó. Ví dụ một cái lát cắt này, nó sẽ là tổ hợp của một loạt các lát",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 18,
      "start_timestamp": "0:13:04",
      "end_timestamp": "0:14:07"
    }
  },
  {
    "page_content": "lát cắt này, nó sẽ là tổ hợp của một loạt các lát cắt ở trước đó để có thể tổ hợp ra một cái lát cắt này. Do đó thì ở phía sau nó sẽ là tổ hợp của những đặc trưng ở phía trước nên số lượng chắc chắn nó sẽ nhiều hơn, số lượng tổ hợp đặc trưng. Tăng dần. Và khi đến cái lớp cuối cùng thì cái đặc trưng của mình là đặc trưng cấp cao nhất rồi, thì nó sẽ hỗ trợ cho cái việc phân biệt và các cái đặc trưng này đã đủ để có thể tuyến tính và đủ thông tin để có thể giúp cho chúng ta giải quyết cái tác vụ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 19,
      "start_timestamp": "0:13:55",
      "end_timestamp": "0:14:33"
    }
  },
  {
    "page_content": "để có thể giúp cho chúng ta giải quyết cái tác vụ của mình. Và đi kèm cùng với sự tăng về độ sâu thì chúng ta sẽ thấy là các cái mạng CNN của mình nó sẽ lần lượt giải quyết các cái vấn đề mà chúng ta thường gặp phải khi chúng ta tăng cái độ sâu này. Tức là khi tăng độ sâu thì có thể thấy ngay một cái vấn đề đầu tiên đó chính là vấn đề về overfitting là khi bùng nổ số lượng đặc trưng, số lượng tham số của mô hình thì dẫn đến là overfitting. Đồng thời là các cái phép biến đổi này là hàm hợp lồng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 20,
      "start_timestamp": "0:14:17",
      "end_timestamp": "0:14:51"
    }
  },
  {
    "page_content": "thời là các cái phép biến đổi này là hàm hợp lồng nhau rất là nhiều thì có những cái kiến trúc mạng mà lên đến là 20, 30, thậm chí là 100 layer. Tức là số layer này lên đến hàng trăm thì nó sẽ gây ra cái hiện tượng là vanishing gradient như chúng ta đã giải thích trong phần trước. Do đó thì các cái mạng CNN của mình bên cạnh cái việc tăng độ sâu để tạo ra các đặc trưng đa dạng từ đơn giản trung bình đến phức tạp thì chúng đồng thời là cũng tìm cách giải quyết những cái vấn đề khi mà tăng cái độ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "giải quyết những cái vấn đề khi mà tăng cái độ sâu này lên. Thì đó chính là cái xu hướng phát triển chung của mạng CNN. Hãy subscribe cho kênh Ghiền Mì Gõ để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HKbzvh4rDw0",
      "filename": "HKbzvh4rDw0",
      "title": "[CS315 - Chương 2] Xu hướng chung của CNN",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với lý thuyết về mô hình tạo sinh dựa trên không gian xác suất. Đó là, chúng ta sẽ tìm ra một cái hàm để ánh xạ một cái phân bố gaussian. Về một cái phân bố cho ảnh trong thực tế để sinh dữ liệu. Thế thì, cái mục tiêu của chúng ta, đó chính là chúng ta làm sao xác định được cái hàm decoder này. Hàm này gọi là hàm decoder và tham số của cái mô hình này sẽ là theta. Và hàm này sẽ nhận cái đầu vào là một cái giá trị nhiễu z, được lấy mẫu ở trong cái không gian gaussian, trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:58"
    }
  },
  {
    "page_content": "lấy mẫu ở trong cái không gian gaussian, trong cái phân bố gaussian. Với cái nhiễu này, chúng ta sẽ tạo ra một cái nội dung của một cái tấm ảnh. Và cái ảnh này thì cái phân bố của cái ảnh đầu ra là P theta x, được ký hiệu bởi P theta x. Thì nó có cái dạng là màu cam giống như thế này. Tuy nhiên cái phân bố ảnh trong thực tế thì nó sẽ phức tạp, nó sẽ rất là phức tạp. Và chúng ta luôn mong muốn cái P theta này sẽ gần với cái phân bố ảnh trong thực tế nhất có thể. Thế thì, để ký hiệu cho cái phân",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:47",
      "end_timestamp": "0:01:39"
    }
  },
  {
    "page_content": "tế nhất có thể. Thế thì, để ký hiệu cho cái phân bố ảnh trong thực tế thì chúng ta sẽ ký hiệu đó là P của data x. Thì đây chính là cái data distribution, tức là cái phân bố ảnh trong thực tế. Và mục tiêu là làm sao cái hàm decoder của chúng ta, nó có thể tạo ra cái P theta x giống với lại P data x nhất có thể. Tức là đem cái phân bố của P theta x về tiến về cái P của data. Tuy nhiên chúng ta thì lại không biết cái phân bố của dữ liệu trong thực tế. Chúng ta không thể biết trước cái phân bố dữ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:29",
      "end_timestamp": "0:02:21"
    }
  },
  {
    "page_content": "tế. Chúng ta không thể biết trước cái phân bố dữ liệu trong thực tế. Dẫn đến là chúng ta sẽ không thể một cách tường minh, chúng ta tìm ra được cái hàm P theta x sao cho cái P theta x xấp xỉ với P data. Chứ còn nếu cái P của data này mà chúng ta đã biết trước cái công thức của nó thì cái hàm này sẽ rất là dễ. Vậy thì chúng ta làm sao có thể tạo ra được cái hàm decoder này thì chúng ta sẽ phải thực hiện cái công việc đó gọi là lấy mẫu dữ liệu. Tức là chúng ta có thể lấy mẫu dữ liệu 1, dữ liệu 2,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:02:12",
      "end_timestamp": "0:02:54"
    }
  },
  {
    "page_content": "là chúng ta có thể lấy mẫu dữ liệu 1, dữ liệu 2, dữ liệu 3, dữ liệu 4 thì đây là toàn bộ những cái ảnh trong ảnh thực tế. Và làm sao từ cái ảnh thực tế này chúng ta có thể đi ước lượng được cái hàm decoder. Tìm sao chúng ta ước lượng được hàm decoder. Vậy thì chúng ta sẽ ước lượng bằng cách đó là dùng maximum likelihood. Giả sử như cái dữ liệu của mình đó là x1, x2 cho nên xm được lấy mẫu. Cái ký hiệu này là ký hiệu lấy mẫu ha. Được lấy mẫu từ cái phân bố dữ liệu trong thực tế. Và chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:48",
      "end_timestamp": "0:03:35"
    }
  },
  {
    "page_content": "cái phân bố dữ liệu trong thực tế. Và chúng ta sẽ tìm cách để xấp xỉ cái maximum likelihood bằng cái công thức này. Đó là chúng ta sẽ đi tìm cái theta sao cho cái maximum likelihood. Thứ nữa là cái tích của các xác suất P theta XA là cao nhất, là lớn nhất. Vậy thì làm sao để có thể làm được việc này? Thì chúng ta có thể đưa về cái phân bố, chúng ta ký hiệu bằng cái phân bố P theta X này. Và thay vì tính argument max của cái tích này thì chúng ta sẽ thêm cái log vào. Vậy thì cái việc thêm log",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:03:27",
      "end_timestamp": "0:04:17"
    }
  },
  {
    "page_content": "ta sẽ thêm cái log vào. Vậy thì cái việc thêm log vào nó sẽ giúp chúng ta đơn giản hóa cái công thức này. Vì log của tích sẽ đưa về cái hàm tổng. Khi chúng ta biến đổi nó sẽ dễ dàng hơn. Và nó sẽ tương đương với việc chúng ta tìm theta sao cho log tổng của các cái log này là lớn nhất. Log của tích là bằng tổng của các cái log thành phần. Vậy thì cái công thức này thì nó sẽ tương đương với cái việc đó là chúng ta, cái công thức tổng của log của P theta thì nó sẽ tương đương với cái việc là chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:04:11",
      "end_timestamp": "0:05:06"
    }
  },
  {
    "page_content": "theta thì nó sẽ tương đương với cái việc là chúng ta đi tính cái kỳ vọng. Chúng ta sẽ đi tính cái kỳ vọng khi lấy cái mẫu x xấp xỉ theo, lấy cái mẫu x, lấy mẫu x, lấy mẫu theo cái phân bố data. Và log của P theta x này là lớn nhất. Tức là trong công thức trước thì chúng ta lấy tổng của mẫu thứ nhất cho đến mẫu thứ m. Thì công thức này chúng ta sẽ viết gọn lại đó là cái kỳ vọng, kỳ vọng của x khi lấy mẫu trong cái không gian P theta. Và cái công thức này thì nó lại được đưa về cái công thức đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:04:49",
      "end_timestamp": "0:05:48"
    }
  },
  {
    "page_content": "thức này thì nó lại được đưa về cái công thức đó là tích phân. Tích phân của P data x nhân với lại log của P theta x dx. Thì ở trên là công thức kỳ vọng. Và ở dưới đó là cái công thức triển khai ra theo dạng là tích phân. Thì đây là cái xác suất của dữ liệu nhân với lại log của P theta x. Thì đây chính là cái công thức của kỳ vọng và dạng tích phân. Và chúng ta thấy rằng là ở đây cái tham số chúng ta cần phải ước lượng, chúng ta cần phải tìm. Đó là theta. Do đó chúng ta sẽ cùng trừng thêm một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:05:41",
      "end_timestamp": "0:06:27"
    }
  },
  {
    "page_content": "là theta. Do đó chúng ta sẽ cùng trừng thêm một cái đại lượng. Đó là tích phân của P data log P data x. Thì đó là trong cái vế sau này nè. Cái vế sau không có theta. Do đó cái việc tìm theta sao cho cái giá trị này max cũng tương đương với cái việc là tìm theta sao cho toàn bộ cái hiệu này là nhỏ nhất. Tại vì trong con mắt của theta thì đây là hằng số. Thế thì tại sao chúng ta lại thêm cái vế này vào? Chúng ta thêm cái vế này vào để sau này chúng ta biến đổi. Nó sẽ đưa về cái hàm trừ, ờ xà hàm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:06:19",
      "end_timestamp": "0:07:18"
    }
  },
  {
    "page_content": "ta biến đổi. Nó sẽ đưa về cái hàm trừ, ờ xà hàm chia. Chúng ta rút cái thừa số chung là P data và P data ở đây. Rút thừa số chung sau đó sẽ là log của P theta x trừ cho log của P data. Thì log của trừ, ờ trừ hai log thì chúng ta sẽ bằng log của P theta chia cho log của P data. Thì đây là cái công thức toán cấp 3 của mình. Và khi chúng ta đưa về cái công thức P của theta chia cho P của data rồi. Thì chúng ta sẽ tìm giá trị max, tìm giá trị min của nó. Ở đây thì là chúng ta đi tìm max. Ở đây là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:07:15",
      "end_timestamp": "0:07:58"
    }
  },
  {
    "page_content": "nó. Ở đây thì là chúng ta đi tìm max. Ở đây là đi tìm max. Nhưng mà chúng ta cái tham số, cái biến số mà chúng ta muốn tìm chính là cái theta ở trên. Vậy thì để tìm cái giá trị max này thì nó sẽ tương đương với cái việc chúng ta đi tìm min. Nhưng mà chúng ta đảo cái phân số này lại. Chúng ta đảo cái phân số, đưa cái data lên và đưa cái P của theta xuống. Thì tại sao chúng ta lại đảo xuống? Nó có cái dụng ý phía sau. Khi chúng ta đảo cái thứ tự nó xuống là tử thành mẫu mẫu thành tử. Thì cái công",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:07:52",
      "end_timestamp": "0:08:49"
    }
  },
  {
    "page_content": "xuống là tử thành mẫu mẫu thành tử. Thì cái công thức này, nó chính là cái công thức của KL diversion. Nó có thể hiểu là một cái khoảng cách giữa hai cái phân bố P data và P theta. Rồi, chú ý là ở phía trên là hàm max, thì ở phía dưới chúng ta sẽ làm hàm min. Khi đưa về min chúng ta đảo thứ tự cho nhau. Và chúng ta đã đưa nó về cái công thức của KL diversion. Thì đây là một cái công thức rất là nổi tiếng. Rồi, cái ý nghĩa của cái công thức này đó là gì? Đó là chúng ta sẽ tìm cách để cho cái P",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:08:42",
      "end_timestamp": "0:09:26"
    }
  },
  {
    "page_content": "đó là gì? Đó là chúng ta sẽ tìm cách để cho cái P theta này tiến về với P data. Hay là cái phân bố màu cam này nè. Nó sẽ tiến về cái phân bố màu xanh lá. Thì cái việc mà xấp xỉ cái dữ liệu tương ứng giúp tối thiểu cái độ tương đồng giữa cái phân bố đầu ra của cái mô hình của mình với lại cái phân bố của dữ liệu trong thực tế. Thì đây chính là cái ý nghĩa của cái công thức KL diversion. Nó rất là dễ hiểu. Tức là mục tiêu, tóm lại đó là mục tiêu của chúng ta là huấn luyện cái mô hình decoder làm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 13,
      "start_timestamp": "0:09:16",
      "end_timestamp": "0:10:08"
    }
  },
  {
    "page_content": "chúng ta là huấn luyện cái mô hình decoder làm sao Để cho khi chúng ta với một cái mẫu nhiễu ngẫu nhiên z truyền vào qua cái hàm decoder này thì nó sẽ ra được một cái điểm. Và khi chúng ta lấy mẫu trên toàn bộ cái Gaussian distribution này đưa qua cái hàm decoder thì nó sẽ ra cái phân bố là P theta. Và cái P theta này làm sao để cho xấp xỉ với lại cái P của data thì chúng ta sẽ dùng cái công thức KL diversion như thế này. Và cái việc mà tìm theta sao cho hai cái phân bố này tiến về nhau, cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 14,
      "start_timestamp": "0:09:58",
      "end_timestamp": "0:10:56"
    }
  },
  {
    "page_content": "sao cho hai cái phân bố này tiến về nhau, cái phân bố của P theta tiến về phân bố của data Nó sẽ tương đương với việc chúng ta tìm cái hàm nhỏ nhất, tức là tìm cái giá trị nhỏ nhất, tìm theta sao cho cái KL diversion này là nhỏ nhất. Thì đó chính là cái ý nghĩa về xác suất thống kê của cái mô hình tạo sinh hình ảnh. Tuy nhiên, làm sao chúng ta có thể tính được cái xác suất tích phân của tất cả các cái giá trị ẩn. Thế thì chúng ta thấy là trong cái công thức ở trên, chúng ta sẽ có cái log của P",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 15,
      "start_timestamp": "0:10:41",
      "end_timestamp": "0:11:37"
    }
  },
  {
    "page_content": "công thức ở trên, chúng ta sẽ có cái log của P theta. Trong công thức ở trên thì chúng ta sẽ có cái công thức là log của P theta. Thì cái log của P, thì nó sẽ có thể được đưa về cái công thức đó là log của tích phân Pxz với z là một cái vector trong không gian Gaussian, phân bố Gaussian. Chúng ta sẽ lấy trên toàn bộ cái z này, ở đây là dz, tức là chúng ta sẽ lấy trên toàn bộ cái không gian của mình. Vậy thì làm sao chúng ta có thể tính tích phân được cho tất cả các cái giá trị ẩn trên cái không",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 16,
      "start_timestamp": "0:11:24",
      "end_timestamp": "0:12:36"
    }
  },
  {
    "page_content": "được cho tất cả các cái giá trị ẩn trên cái không gian phân bố Gaussian. Thì đây là công việc rất là khó. Thế thì thay vì làm cái công việc này, thì chúng ta có thể đưa về cái công thức đó là log của Px. Ở đây chúng ta sẽ bỏ cái tham số theta ra để cho nó đơn giản. Còn ở đây ý nghĩa đó là chúng ta xác định cái phân bố Px khi theta của mình có tham gia vô. Ở đây chúng ta bỏ theta ra để cho nó dễ nhìn. Thì log của P sẽ là bằng log của Pxz, tức là log của Pxz chia cho Pxz. Vậy thì Pxz thì đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 17,
      "start_timestamp": "0:12:23",
      "end_timestamp": "0:13:10"
    }
  },
  {
    "page_content": "là log của Pxz chia cho Pxz. Vậy thì Pxz thì đây chính là cái công thức của Bayes. Đây là công thức của Bayes. Tức là xác suất của x và z. Khi chúng ta chia cho xác suất của z cho trước x thì đó chính là xác suất của P. Hay nói cách khác là khi chúng ta nhân lên thì Px nhân với lại Pz cho trước x thì đó chính là bằng Pxz. Tức là xác suất của x và z cùng xuất hiện thì nó sẽ là bằng xác suất x nhân với lại xác suất của z cho trước x. Thì đây là dựa trên địa lý của Bayes. Tuy nhiên dựa trên công",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 18,
      "start_timestamp": "0:12:59",
      "end_timestamp": "0:14:03"
    }
  },
  {
    "page_content": "trên địa lý của Bayes. Tuy nhiên dựa trên công thức này thì chúng ta lại có câu hỏi đó là làm sao chúng ta đã biết được cái này. Tức là làm sao chúng ta có thể biết được cái P của z khi cho trước x. Thì để làm được cái chuyện đó thì chúng ta sẽ sử dụng một cái hàm, đó là encoder. Tức là trong công thức này là cho trước x, cho trước x, làm sao chúng ta xác định được cái P của z cho trước x thì đây là một cái hàm phân bố. Vậy làm sao biết được cái P này? Thì chúng ta sẽ thêm vô một cái module là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 19,
      "start_timestamp": "0:13:46",
      "end_timestamp": "0:14:43"
    }
  },
  {
    "page_content": "P này? Thì chúng ta sẽ thêm vô một cái module là encoder để từ cái dữ liệu x mà chúng ta sampling trong thế giới thật P data. Qua cái hàm encoder này thì chúng ta sẽ xác định được cái Quy zx, tức là phân bố của z khi biết trước x. Tức là cho trước mẫu dữ liệu đầu vào và chúng ta xác định cái phân bố của z, của cái vector trong không gian tìm ẩn. Thế thì chúng ta có cái công thức đó là P của x là bằng log của Px. Thì nhân với lại cái tích phân của Quy z cho trước x nhân với dz thì cái công thức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 20,
      "start_timestamp": "0:14:33",
      "end_timestamp": "0:15:40"
    }
  },
  {
    "page_content": "Quy z cho trước x nhân với dz thì cái công thức này nó sẽ có cái giá trị là bằng một. Tại vì khi chúng ta cho z dựa trên toàn bộ cái không gian xác suất của nó thì Quy của z cho trước x thì tổng xác suất này là cái tích phân xác suất này là luôn là bằng một. Tại vì dz nó đã chạy, cái dz này nó chạy trên hết trong cái không gian xác suất của nó. Vậy thì chúng ta sẽ triển khai cái công thức này, đem cái tích phân ra ngoài. Thì sẽ có là Quy của zx cho trước x nhân với lại log của Px dz. Chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 21,
      "start_timestamp": "0:15:27",
      "end_timestamp": "0:16:31"
    }
  },
  {
    "page_content": "cho trước x nhân với lại log của Px dz. Chúng ta đưa cái tích phân ra ngoài. Thì cái công thức này nó sẽ tương đương với cái việc là chúng ta tính cái kỳ vọng của z, lấy mẫu trong cái z cho trước x. Rồi, như vậy thì chúng ta sẽ lấy hết cái phân bố này, sau đó chúng ta sẽ lấy cái xác suất đó, chúng ta nhân với lại log của Px. Thì cái công thức này nó sẽ tương đương với lại cái kỳ vọng ở đây. Và chúng ta sẽ cùng nhân sử dụng cái công thức Bayes thì Px, hồi nãy chúng ta đã ghi cái công thức này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 22,
      "start_timestamp": "0:16:22",
      "end_timestamp": "0:17:30"
    }
  },
  {
    "page_content": "thì Px, hồi nãy chúng ta đã ghi cái công thức này rồi. Px là bằng Px và z chia cho Pzx dựa trên cái luật Bayes. Và khi chúng ta áp dụng cái công thức này vào thì chúng ta cùng nhân cho tử và mẫu là Quy của z cho trước x. Rồi, sau đó chúng ta đảo thứ tự lại, chúng ta đem cái Quy qua và đem cái P qua đây. Thì khi đó chúng ta sẽ có là Px, nhân cho Quy của zx. Rồi, và từ cái công thức ở trên thì chúng ta sẽ có là log của tích, ở đây chúng ta có cái phép là phép nhân. Chúng ta có cái phép nhân, thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 23,
      "start_timestamp": "0:17:13",
      "end_timestamp": "0:17:51"
    }
  },
  {
    "page_content": "phép là phép nhân. Chúng ta có cái phép nhân, thì log của tích sẽ là bằng tổng 2 log. Rồi, thì là Px chia cho Quy của zx, còn ở đây sẽ là Quy của zx chia cho Px. Và chúng ta sẽ thấy đây chính là cái công thức để mà chúng ta có thể ước lượng được cái Px này. Và làm sao cho cái Px này nó tiến về cái P của data.x thì chúng ta sẽ dựa trên cái công thức này để chúng ta xây dựng cái mô hình. Và ở trong cái công thức này thì kỳ vọng của Quy zx, của cái công thức là log của Quy zx chia cho P của zx,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "công thức là log của Quy zx chia cho P của zx, thì đây chính là cái công thức của KL diversion. Đây chính là cái công thức của KL diversion. Ở trên đây là Quy zx, thì nó sẽ là KL diversion của Quy zx và Pzx, tức là cái khoảng cách giữa 2 cái phân bố này. Mà khoảng cách của 2 cái phân bố này thì đó là con số lớn hơn không. Tuy nhiên làm sao chúng ta có được cái này, làm sao chúng ta có được cái P của zx thì cái chuyện đó là rất là khó. Rất khó để chúng ta có thể xác định được cái phân bố thực tế",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chúng ta có thể xác định được cái phân bố thực tế của z cho trước x.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Hrmm1B6sR8g",
      "filename": "Hrmm1B6sR8g",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 2",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chào các bạn, chúng ta sẽ cùng đến với một trong những chủ đề rất là thú vị và có rất nhiều những ứng dụng trong thời gian gần đây, đó chính là Deep Generative Model hay là các mô hình tạo sinh học sâu. Trong phần 1, chúng ta sẽ cùng tìm hiểu về hai mô hình nền tảng, đó là Variational Autoencoder và GAN, đó là Generative Adversarial Network. Trong phần 2, chúng ta sẽ cùng tìm hiểu về kiến trúc của mô hình Diffusion Model, mô hình khuếch tán và khử nhiễu. Trong phần 3, chúng ta sẽ mở đầu bằng một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:09"
    }
  },
  {
    "page_content": "nhiễu. Trong phần 3, chúng ta sẽ mở đầu bằng một câu hỏi nhỏ như sau, đâu là gương mặt thật? Đáp án đó chính là tất cả những hình ở trong đây đều không phải là ảnh thật mà là ảnh được tạo ra bởi một mô hình tạo sinh, đó là mô hình dựa trên GAN. Thì nguồn của ảnh này được lấy từ trang This Person Does Not Exist và khi chúng ta vào trang web này thì nó sẽ tạo ra ngẫu nhiên một tấm hình nào đó. Thì cái này có rất nhiều ứng dụng trong thực tế, ví dụ như chúng ta cần minh họa về một cái người nào đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:48",
      "end_timestamp": "0:01:33"
    }
  },
  {
    "page_content": "như chúng ta cần minh họa về một cái người nào đó để chúng ta bàn về chủ đề nào đó để cần một cái người minh họa. Với những luật hiện đại hiện nay thì đã hạn chế việc chúng ta lấy hình ảnh ở trên mạng internet để chúng ta minh họa, nó sẽ ảnh hưởng đến vấn đề về quyền riêng tư của một người nào đó. Do đó việc chúng ta sử dụng một ảnh không có thật thì nó sẽ giúp chúng ta giải quyết được vấn đề này, đó là không vi phạm những vấn đề về quyền riêng tư. Và chúng ta thấy là ba tấm hình này thì gần",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:21",
      "end_timestamp": "0:02:10"
    }
  },
  {
    "page_content": "tư. Và chúng ta thấy là ba tấm hình này thì gần như là rất giống với ảnh thật và không có những cái nét nào mà khiến chúng ta cảm giác đó là ảnh không phải là người thật. Nếu để ý kỹ thì chúng ta mới có thể thấy được. Rồi, thế thì để mở đầu cho cái phần các cái mô hình liên quan đến tạo sinh thì chúng ta sẽ cùng nhắc lại về hai cái mô hình mà rất là phổ biến trong máy học. Đó chính là học có giám sát và học không có giám sát. Thế thì học có giám sát là gì? Là chúng ta sẽ học từ cái dữ liệu và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:01:56",
      "end_timestamp": "0:02:47"
    }
  },
  {
    "page_content": "sát là gì? Là chúng ta sẽ học từ cái dữ liệu và trong đó thì x là cái dữ liệu đầu vào và y là cái nhãn dữ liệu mà chúng ta cần phải huấn luyện để có thể dự đoán ra được. Thì đây là cái nhãn cần dự đoán. Và mục tiêu của cái học có giám sát đó chính là chúng ta sẽ phải đi ước lượng một cái hàm số để ánh xạ từ x sang y. Để sau này khi chúng ta có một cái x mới, ví dụ như chúng ta ánh xạ, chúng ta tìm ra được một cái ánh xạ này đúng không? Thì khi chúng ta có một cái x new thì qua cái hàm ánh xạ là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:02:45",
      "end_timestamp": "0:03:25"
    }
  },
  {
    "page_content": "ta có một cái x new thì qua cái hàm ánh xạ là f của x new thì chúng ta sẽ dự đoán được cái đầu ra là bao nhiêu? Thì cái ứng dụng của học có giám sát rất là nhiều. Chúng ta có thể dùng trong lĩnh vực về phân loại một cái đối tượng nào đó, bài toán hồi quy, dự đoán một cái giá trị có tính thứ tự nào đó. Rồi phát hiện đối tượng, phân đoạn ngữ nghĩa đối tượng v.v. thì học có giám sát nó đã đạt được những thành tựu hiện nay và có thể ứng dụng được rất là rộng rãi. Thế thì còn một cái mảng nữa đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:03:15",
      "end_timestamp": "0:03:56"
    }
  },
  {
    "page_content": "rất là rộng rãi. Thế thì còn một cái mảng nữa đó chính là học không có giám sát. Thì học không có giám sát đó là dữ liệu đầu vào chúng ta sẽ không có y mà chúng ta chỉ có duy nhất một biến x đầu vào. Chúng ta không có nhãn, thì đây chính là sự khác biệt lớn nhất giữa học không giám sát và học có giám sát. Mục tiêu của học không giám sát đó là chúng ta sẽ học từ cái cấu trúc ẩn của dữ liệu, hay là chúng ta sẽ đi học cái phân bố của dữ liệu. Phân bố của dữ liệu. Rồi, thì mình có thể lấy một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:03:49",
      "end_timestamp": "0:04:44"
    }
  },
  {
    "page_content": "bố của dữ liệu. Rồi, thì mình có thể lấy một cái ví dụ như sau để chúng ta hiểu thế nào là chúng ta đi học một cái cấu trúc ẩn và học một cái phân bố dữ liệu. Bằng cách đó là chúng ta sẽ trả lời cho cái câu hỏi sau. Một bạn học sinh có điểm trung bình là ví dụ như là 8,8 điểm. Thì theo các bạn đó là bạn này sẽ có cái học lực là giỏi, khá xuất sắc hay là dưới trung bình. Thì đa số đó là chúng ta sẽ không biết được cái điểm này là cao hay thấp khi chúng ta không đặt nó ở trong cái phân bố của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:04:34",
      "end_timestamp": "0:05:27"
    }
  },
  {
    "page_content": "khi chúng ta không đặt nó ở trong cái phân bố của những cái bạn còn lại trong lớp. Thì nếu như cái điểm của lớp mình mà có cái phân bố như sau, điểm 8,8 thì nằm ở cái khu vực này. Ví dụ như điểm 8,8 là nằm ở khu vực này. Thì bạn này là một bạn có học lực giỏi tại vì nhìn trong cái phân bố này bạn nằm ở cái top mà những người có điểm cao. Nhưng ngược lại nếu trong một cái phân bố khác, điểm 8,8 của bạn nó lại nằm ở đây. 8,8 thì khi đó là với cái phân bố này thì điểm của bạn là có học lực dưới",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:05:18",
      "end_timestamp": "0:06:02"
    }
  },
  {
    "page_content": "phân bố này thì điểm của bạn là có học lực dưới trung bình. Như vậy để kết luận được tính chất của dữ liệu x thì chúng ta phải học được cái phân bố. Vì vậy, trong cái phân bố chúng ta sẽ xác định được cái phân bố của dữ liệu và từ đó chúng ta hình thành được cái cấu trúc ẩn của dữ liệu. Ví dụ chúng ta chia cái không gian của mình ra làm 3 phần. Ví dụ vậy thì đây là những cái bạn mà có học lực kém. Đây là những bạn có học lực trung bình và đây là những bạn có học lực giỏi. Ví dụ vậy thì đây là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:05:58",
      "end_timestamp": "0:06:37"
    }
  },
  {
    "page_content": "những bạn có học lực giỏi. Ví dụ vậy thì đây là chúng ta đang cấu trúc hóa cái không gian ẩn của mình. Và những cái bài toán mà kinh điển liên quan đến cái học không giám sát đó chính là bài toán phân cụm, bài toán giảm chiều dữ liệu. Thì đó là chúng ta đã cùng ôn lại một vài cái khái niệm về học có giám sát và học không có giám sát. Và bây giờ chúng ta sẽ quay trở lại đến với cái chủ đề của chúng ta. Đó là mô hình tạo sinh hay còn gọi là generative model. Thì mục tiêu của cái mô hình tạo sinh",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 10,
      "start_timestamp": "0:06:31",
      "end_timestamp": "0:07:14"
    }
  },
  {
    "page_content": "model. Thì mục tiêu của cái mô hình tạo sinh đó là chúng ta sẽ lấy mẫu dữ liệu huấn luyện. Lấy mẫu dữ liệu huấn luyện đầu vào của một số cái phân bố, của một số cái phân phối. Và từ đó chúng ta có thể tái tạo lại các cái phân phối đó. Tức là chúng ta sẽ đi lấy mẫu. Đầu tiên đó là chúng ta lấy mẫu. Ví dụ chúng ta muốn tạo ra những cái ảnh mặt người giống với lại cái ảnh thật như vậy. Trong cái ví dụ ở slide đầu tiên thì chúng ta sẽ đi lấy mẫu. Và chúng ta sẽ lấy mẫu những cái người trong thế",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 11,
      "start_timestamp": "0:07:07",
      "end_timestamp": "0:07:53"
    }
  },
  {
    "page_content": "Và chúng ta sẽ lấy mẫu những cái người trong thế giới thực của mình. Đó là những cái ảnh thật. Kìa như vậy. Rồi sau đó chúng ta sẽ đưa vào một cái hàm. Và lưu ý là ở đây chúng ta không hề có cái nhãn dữ liệu. Chúng ta không có cái nhãn dữ liệu. Rồi sau đó chúng ta sẽ đi học cái phân phối này. Để huấn luyện cái đầu vào của một cái phân phối. Và sau khi chúng ta đã ra được một cái phân phối rồi, thì chúng ta sẽ đi tái tạo lại cái phân phối đó. Ví dụ như từ các cái ảnh này chúng ta sẽ học ra được",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 12,
      "start_timestamp": "0:07:45",
      "end_timestamp": "0:08:44"
    }
  },
  {
    "page_content": "dụ như từ các cái ảnh này chúng ta sẽ học ra được cái phân phối là như sau. Thì lấy mẫu là cái ảnh này tương ứng là nằm trong cái phân phối này. Ở vị trí này. Ảnh này thì tương ứng nằm ở vị trí này. Vân vân. Và sau đó thì chúng ta sẽ đi học để tái tạo lại phân phối đó. Từ đó có thể lấy mẫu một cái mẫu mới. Rồi sau đó chúng ta tạo ra một cái dữ liệu. Và cái dữ liệu này vì chúng ta đã học ra được cái phân phối của các cái không gian mà có chứa cái ảnh gương mặt. Nên khi chúng ta lấy mẫu trong cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 13,
      "start_timestamp": "0:08:33",
      "end_timestamp": "0:09:18"
    }
  },
  {
    "page_content": "ảnh gương mặt. Nên khi chúng ta lấy mẫu trong cái phân phối này thì khi chúng ta khôi phục, chúng ta tái tạo lại thì nó cũng sẽ ra ảnh một cái gương mặt. Và đó chính là cái ý nghĩa của cái mô hình tạo sinh. Tức là chúng ta sẽ đi lấy mẫu dữ liệu, huấn luyện nó vào để huấn luyện cho một cái phân phối. Và sau đó để học cái cách để mà chúng ta học để mà tái tạo lại. Đây là tái tạo. Chúng ta sẽ tái tạo lại cái tấm ảnh mới. Thì cái quá trình tái tạo này chính là cái quá trình tạo sinh ảnh. Thế thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 14,
      "start_timestamp": "0:09:08",
      "end_timestamp": "0:09:47"
    }
  },
  {
    "page_content": "này chính là cái quá trình tạo sinh ảnh. Thế thì cái mô hình tạo sinh ở giai đoạn đầu nó được sử dụng để phục vụ cho cái công việc đó là tăng cường dữ liệu. Tại vì các cái mô hình học máy chúng ta biết rằng là các cái mô hình học máy thì nó sẽ bị cái hiện tượng gọi là hiện tượng overfitting. Mà hiện tượng overfitting thì có hai cách để giải quyết. Một đó là giảm cái độ phức tạp của mô hình. Giảm cái số tham số hoặc là cái độ phức tạp của mô hình. Và hai là chúng ta đi tăng cường cái data lên.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 15,
      "start_timestamp": "0:09:42",
      "end_timestamp": "0:10:18"
    }
  },
  {
    "page_content": "Và hai là chúng ta đi tăng cường cái data lên. Nếu chúng ta không giảm thì chúng ta sẽ đi tăng cái data lên. Và để tăng data này thì chúng ta sẽ phải đi thu thập dữ liệu rất là nhiều. Thu thập dữ liệu rất là nhiều. Thế thì nhờ có các cái mô hình tạo sinh tạo ra các cái ảnh tự động. Chúng ta chỉ cần đi lấy mẫu một cái điểm trong cái phân phối này. Xong rồi chúng ta tái tạo lại thì chúng ta đã có một cái ảnh mới. Thì cái mô hình tạo sinh nó đã giúp cho chúng ta tự động tăng cường dữ liệu lên.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 16,
      "start_timestamp": "0:10:11",
      "end_timestamp": "0:10:53"
    }
  },
  {
    "page_content": "giúp cho chúng ta tự động tăng cường dữ liệu lên. Giúp cho cái việc huấn luyện mô hình gọi là đỡ bị hiện tượng overfitting hơn. Thì đó chính là cái động cơ của mô hình tạo sinh. Và giả sử như chúng ta có một cái mẫu dữ liệu. Chúng ta lấy mẫu dữ liệu để huấn luyện. Chúng ta lấy được cái mẫu này. Sau đó chúng ta xác định được cái phân phối của nó. Đây là ước lượng một cái hàm mật độ. Thì chúng ta thấy cái khu vực này là xuất hiện dày đặc. Nhưng mà nó hơi ít hơn so với cái khu vực bên tay phải.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 17,
      "start_timestamp": "0:10:41",
      "end_timestamp": "0:11:28"
    }
  },
  {
    "page_content": "mà nó hơi ít hơn so với cái khu vực bên tay phải. Khu vực này sẽ xuất hiện dày hơn. Còn ở cái khu vực ở giữa ở đây hoặc là ở ngoài rìa ở đây thì chúng ta thấy đó là khi lấy mẫu nó thưa hơn. Do đó khi chúng ta ước lượng ra cái hàm mật độ thì nó sẽ có cái dạng như thế này. Đó là hai đỉnh. Và khi chúng ta tạo sinh mẫu thì từ chúng ta sẽ tạo ra được những cái ảnh mới mà có cái tính chất giống như là cái tính chất của cái ảnh mà chúng ta đã lấy mẫu trước đó. Thì đây là, trong cái ví dụ này thì đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 18,
      "start_timestamp": "0:11:16",
      "end_timestamp": "0:12:10"
    }
  },
  {
    "page_content": "trước đó. Thì đây là, trong cái ví dụ này thì đây chính là cái mẫu đầu vào để huấn luyện. Đó là cái ảnh trong thế giới thực. Lấy lại các cái điểm này. Rồi. Và mẫu được tạo sinh thì chúng ta sẽ đi sampling liên tiếp trong cái không gian của mình. Những cái điểm màu xanh sẽ là những cái điểm chúng ta lấy mẫu trong thực tế. Còn cái điểm màu đỏ, ví dụ ở đây. Thì đây chính là một cái điểm chúng ta random sampling trong cái không gian. Và sau đó chúng ta tái tạo lại. Thì nó sẽ tạo ra các cái điểm ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 19,
      "start_timestamp": "0:11:59",
      "end_timestamp": "0:12:51"
    }
  },
  {
    "page_content": "ta tái tạo lại. Thì nó sẽ tạo ra các cái điểm ở đây. Nó sẽ tạo ra các cái mẫu mới. Thì đây là mẫu tạo sinh. Thì đối với cái mẫu đầu vào thì chúng ta sẽ ký hiệu đó là dữ liệu huấn luyện. Chúng ta sẽ sampling trong cái Pdata. Trong cái Pdata, tức là cái dữ liệu thế giới thực. Mẫu tạo sinh thì chúng ta sẽ đi sampling trong cái Pmodel. Tức là giả sử như chúng ta đã có cái model này rồi. Đây là cái model. Rồi thì chúng ta sẽ sampling trong cái dữ liệu trong cái không gian của cái mô hình mà mình ước",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 20,
      "start_timestamp": "0:12:36",
      "end_timestamp": "0:13:20"
    }
  },
  {
    "page_content": "trong cái không gian của cái mô hình mà mình ước lượng được. Đây là cái mô hình ước lượng được. Rồi từ đó chúng ta tái tạo lại. Và cái việc mà học một cái mô hình tạo sinh là chúng ta tìm cách nào đó để cho cái mô hình PmodelX nó sẽ có cái sự tương tự về mặt phân phối giống như là Pdata. Thì đây chính là cái mục tiêu của các cái mô hình tạo sinh. Pmodel phải xấp xỉ, phải tương tự với lại cái P của data. Vậy thì tại sao chúng ta cần phải có cái mô hình tạo sinh thì nó có khả năng là khám phá ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 21,
      "start_timestamp": "0:13:11",
      "end_timestamp": "0:13:57"
    }
  },
  {
    "page_content": "hình tạo sinh thì nó có khả năng là khám phá ra các đặc trưng cơ bản của dữ liệu. Ví dụ các đặc trưng về mặt màu da, các đặc trưng về tư thế đồng nhất. Ví dụ như chúng ta huấn luyện với các ảnh gương mặt khác nhau thì chúng ta lấy rất nhiều những ảnh thuộc rất nhiều những chủng tộc. Thì khi huấn luyện xong thì cái mô hình của mình nó vẫn có thể ý thức được cái vấn đề về màu da, màu da trắng, màu da đen, màu da vàng, ví dụ vậy. Hoặc là tư thế thì có thể là nhìn trực diện hoặc là nhìn nghiêng về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 22,
      "start_timestamp": "0:13:50",
      "end_timestamp": "0:14:32"
    }
  },
  {
    "page_content": "có thể là nhìn trực diện hoặc là nhìn nghiêng về bên trái, nhìn nghiêng về bên phải hoặc là ngẩng lên trên. Đó thì là các cái tư thế của mỗi gương mặt. Thì cái mô hình của mình nó ngầm, có thể học được cái đặc trưng cơ bản này của dữ liệu. Và khi chúng ta áp dụng trong thực tế thì cái màu da, tư thế và ánh sáng nó cực kỳ đa dạng. Rồi chúng ta thấy đây là những ảnh trong thực tế thì nó sẽ cực kỳ đa dạng. Và chúng ta luôn mong muốn là cái mô hình của mình nó sẽ xấp xỉ hai cái không gian này. Đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 23,
      "start_timestamp": "0:14:25",
      "end_timestamp": "0:15:03"
    }
  },
  {
    "page_content": "của mình nó sẽ xấp xỉ hai cái không gian này. Đây là mô hình P của Model và đây là P của Data. Và mình luôn mong muốn là hai cái thằng này nó sẽ tương tự nhau, tìm cách để đưa cái P Model về gần với lại P Data. Rồi, như vậy thì từ cái P Model này thì chúng ta làm sao có thể sử dụng được các cái thông tin này để tạo ra các cái dữ liệu cân bằng và có cái tính đại diện hơn. Thế thì chúng ta sẽ cùng thảo luận thế nào là cái sự cân bằng và có cái tính đại diện trong cái phần slide tiếp theo. Đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 24,
      "start_timestamp": "0:14:54",
      "end_timestamp": "0:15:36"
    }
  },
  {
    "page_content": "đại diện trong cái phần slide tiếp theo. Đó là những cái điểm trong cái phân bố của mình thì nó sẽ có những cái điểm, nó gọi là điểm Outlier hay là những cái điểm lạ, điểm dữ liệu lạ. Vấn đề đó là làm thế nào để khi gặp những cái đối tượng mới hoặc là hiếm trong dữ liệu. Rồi chiến lược đó là chúng ta sẽ tận dụng được các cái mô hình tạo sinh để phát hiện ra các điểm dữ liệu lạ trong cái phân bố. Rồi sau đó sử dụng các cái dữ liệu Outlier này để mà cho cái quá trình huấn luyện mô hình, nó sẽ cải",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 25,
      "start_timestamp": "0:15:34",
      "end_timestamp": "0:16:12"
    }
  },
  {
    "page_content": "cho cái quá trình huấn luyện mô hình, nó sẽ cải thiện được cái mô hình tốt hơn. Thì ở đây chúng ta sẽ dẫn nhập, giải thích cái ý này. Các cái mô hình của mình khi được huấn luyện thì lấy dữ liệu ở trong thực tế mà dữ liệu chúng ta sampling trong thực tế thì 95% Chúng ta lấy một cái ví dụ đó là dữ liệu mà lái xe trên đường. 95% dữ liệu mà chúng ta lái xe, tức là nó nằm ở trong cái khu vực này. Là trong cái khu vực này. Thì đó là những cái tình huống rất là bình thường. Đây là những cái tình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 26,
      "start_timestamp": "0:16:02",
      "end_timestamp": "0:16:46"
    }
  },
  {
    "page_content": "huống rất là bình thường. Đây là những cái tình huống bình thường. Tại vì chúng ta biết rồi là khi chúng ta đi lưu thông trên đường thì cái tình huống mà chúng ta gặp tai nạn rất là ít xảy ra. Do đó thì chúng ta lấy những cái tình huống đó khá là thấp. Mà đại đa số sẽ là những cái tình huống đẹp. Ví dụ như là trời nắng, ví dụ như là đi đường cao tốc, ít xe cộ qua lại, rồi ví dụ đường là thẳng, không có bị gồ ghề, gập ghềnh. Ví dụ vậy thì 95% dữ liệu là nó ở dạng bình thường. Và cái việc phát",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 27,
      "start_timestamp": "0:16:40",
      "end_timestamp": "0:17:17"
    }
  },
  {
    "page_content": "liệu là nó ở dạng bình thường. Và cái việc phát hiện các cái điểm dữ liệu ngoại vi hay là những cái điểm outlier đó. Trong cái quá trình mà huấn luyện để tránh được những cái tình huống không thể đoán được. Tại vì khi chúng ta muốn xây dựng cái dữ liệu cho cái hệ thống xe tự lái, chúng ta phải lường trước những cái tình huống mà xe sẽ gặp những cái tình huống mà hiếm xuất hiện. Ví dụ như có một người băng qua trước mặt, hoặc là đường thì gập ghềnh, đường bị quanh co, hoặc là thời tiết xấu. Thế",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 28,
      "start_timestamp": "0:17:11",
      "end_timestamp": "0:17:53"
    }
  },
  {
    "page_content": "đường bị quanh co, hoặc là thời tiết xấu. Thế thì cái mà chúng ta mong muốn có cái dữ liệu để cho mô hình của mình, để cải thiện cái mô hình của mình, đó là những cái tình huống là phân bố ở bên ngoại vi, tức là outlier. Đây là cái outlier mà chúng ta mong muốn có dữ liệu để cho mô hình nó học. Ví dụ đó là có cái giải phân cách, hoặc là có cái tình huống là máy bay lớn đi trên đầu, hoặc là thời tiết xấu, thời tiết cực đoan, ví dụ như là mưa to, bão tuyết, hoặc là có tình huống người đi bộ băng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 29,
      "start_timestamp": "0:17:45",
      "end_timestamp": "0:18:09"
    }
  },
  {
    "page_content": "bão tuyết, hoặc là có tình huống người đi bộ băng qua đột ngột trước mặt mình, hoặc là đùa giỡn, v.v. Thì đó chính là những cái tình huống ngoại vi mà chúng ta mong muốn có cái dữ liệu này để cho mô hình của mình nó học được. Thì đó chính là cái lý do tại sao chúng ta cần có mô hình tạo sinh, để khi chúng ta sampling với những cái tình huống ngoại lệ này, thì chúng ta sẽ có được những cái dữ liệu này, nó sẽ giúp cho cái bộ dữ liệu huấn luyện của chúng ta nó cân bằng hơn. Nó giúp cân bằng hơn và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chúng ta nó cân bằng hơn. Nó giúp cân bằng hơn và dẫn đến là mô hình của mình nó sẽ không bị bias vào 95% những cái dữ liệu mà đẹp, dữ liệu bình thường ở đây. Và một trong những cái hướng tiếp cận để mà tạo ra các cái mô hình tạo sinh, đó là chúng ta sẽ sử dụng mô hình là Latent Variable, tức là mô hình dựa trên biến tiềm ẩn và có hai cái mô hình chúng ta sẽ cùng tìm hiểu trong cái buổi ngày hôm nay, đó là mô hình về Autoencoder, đó là Autoencoder phiên bản gốc và Variational Autoencoder hay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 31,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "phiên bản gốc và Variational Autoencoder hay viết tắt là VAE và Generative Adversarial Network, tức là mô hình tạo sinh đối kháng GAN. Thì đây là hai cái mô hình dựa trên cái biến tiềm ẩn. Biến tiềm ẩn ở đây chính là cái VectorZ. Và chúng ta sẽ cùng tìm hiểu chi tiết trong những cái phần tiếp theo.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=hrxNKadDpw4",
      "filename": "hrxNKadDpw4",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 1",
      "chunk_id": 32,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng tìm hiểu về một số thách thức của thuật toán Gradient Descent khi chúng ta áp dụng vào trong thực tế huấn luyện các mô hình máy học. Nếu như trong những phần trước, chúng ta nhìn phác thảo hàm lỗi của mình hoặc là Log Landscape ở dưới dạng là một hàm đơn biến. Và hàm của mình cũng không có tính chất phức tạp. Với điểm khởi tạo màu đen, sau khi cập nhật và lặp, nó sẽ đến được điểm cực tiểu toàn cục. Tuy nhiên, điều này rất hiếm khi nào xảy ra trong thực tế mà thường nó gặp phải",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:09"
    }
  },
  {
    "page_content": "nào xảy ra trong thực tế mà thường nó gặp phải những thách thức rất phức tạp. Vì vậy, trong hình minh họa này, đây là một trực quan hóa cho hàm loss, hàm lỗi khi áp dụng trong thực tế, và thậm chí có thể còn phức tạp hơn. Vì vậy, giả sử như điểm khởi tạo của mình nằm ở đây, để mà đạt được điểm tối ưu toàn cục ở đây, thì trong quá trình di chuyển, nó sẽ phải đi qua rất nhiều những chướng ngại vật để mà có thể đến được điểm này. Thì những cái chướng ngại đó là gì và tại sao những cái điểm đó nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 1,
      "start_timestamp": "0:01:00",
      "end_timestamp": "0:01:59"
    }
  },
  {
    "page_content": "ngại đó là gì và tại sao những cái điểm đó nó lại gây ra cái việc huấn luyện khó khăn, thì chúng ta sẽ cùng lấy một số ví dụ. Cái chướng ngại đầu tiên đó là những cái điểm cực tiểu cục bộ hay còn gọi là local minimum. Vì vậy, giả sử như chúng ta bắt đầu tại cái điểm ở đây, thì trong cái quá trình di chuyển, nếu như hoàn hảo, thì chúng ta sẽ đạt được cái điểm này, đó là cái điểm global minimum. Nhưng mà thực tế thì không phải vậy. Nó hoàn toàn có khả năng là trong quá trình di chuyển, nó có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 2,
      "start_timestamp": "0:01:49",
      "end_timestamp": "0:02:35"
    }
  },
  {
    "page_content": "khả năng là trong quá trình di chuyển, nó có thể rớt vào một cái điểm ở cái điểm ở đây, tức là tương ứng ở đây. Vì đây chính là một cái điểm local minimum. Và khi chúng ta rớt vào cái điểm ở đây, thì nó sẽ bị bắt kẹt và nó sẽ không thoát ra được, để mà có thể đến được cái điểm tối ưu toàn cục. Cái tình huống thứ hai đó là cái điểm yên ngựa. Thì điểm yên ngựa là những cái điểm đặc biệt. Lấy ví dụ ở đây. Điểm yên ngựa thì nó sẽ có cái đạo hàm bằng không tại cái vị trí đó, và nó sẽ đạo hàm bằng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 3,
      "start_timestamp": "0:02:30",
      "end_timestamp": "0:03:17"
    }
  },
  {
    "page_content": "không tại cái vị trí đó, và nó sẽ đạo hàm bằng không tại nhiều hướng. Ví dụ như là theo cái hướng này, chúng ta thấy là nó đi xuống rồi đi lên, thì tại cái vị trí này là đạo hàm bằng không. Mặt khác, theo cái hướng trực giao với nó là hướng này. Chúng ta sẽ vẽ bằng một cái đường màu khác, xanh lá đi. Màu này sẽ không có hiển thị nổi bật. Rồi, thì khi chúng ta đi theo cái hướng khác, lấy ví dụ như là hướng này, thì nó sẽ có cái đạo hàm bằng không theo cái hướng màu đen, cái cung màu đen. Như vậy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 4,
      "start_timestamp": "0:03:08",
      "end_timestamp": "0:04:08"
    }
  },
  {
    "page_content": "theo cái hướng màu đen, cái cung màu đen. Như vậy thì điểm yên ngựa là những cái điểm mà nó sẽ có cái tính chất đó là nó sẽ có đạo hàm bằng không trên nhiều hướng. Cụ thể ở đây là hai hướng. Thì những cái điểm yên ngựa này nó sẽ gây ra cái hiện tượng gì? Nó sẽ gây ra cái hiện tượng đó là khi cái điểm của mình rớt đến cái điểm yên ngựa thì nó sẽ bị lừng chừng. Nó không biết là sẽ phải đi về hướng nào. Đó, ví dụ như rớt ở đây, rồi sau đó nó đi lên, sau đó lại rớt xuống. Nó không biết là phải đi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 5,
      "start_timestamp": "0:04:04",
      "end_timestamp": "0:04:51"
    }
  },
  {
    "page_content": "sau đó lại rớt xuống. Nó không biết là phải đi hướng nào. Tại vì đạo hàm ở nhiều hướng là bằng không. Tại vì đạo hàm theo cái hướng bên đây cũng bằng không nên nó sẽ không có đi rớt xuống đây, không đi về hướng bên này. Còn nó cũng không thể đi lên được tại vì đạo hàm ở đây bằng không thì theo cái hướng này nó cũng không thể đi lên. Thì đó chính là cái tình trạng mắc kẹt tại cái điểm Saddle Point. Và cái tình huống thứ ba, đó là cái tình huống mà ở những cái điểm thung lũng hay còn gọi là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 6,
      "start_timestamp": "0:04:44",
      "end_timestamp": "0:05:31"
    }
  },
  {
    "page_content": "mà ở những cái điểm thung lũng hay còn gọi là valley. Ở đây chúng ta thấy là nó sẽ có một cái thung lũng là cái rãnh. Nó là một cái rãnh. Tức là ở hai bên là nó sẽ là dốc cao. Còn ở giữa nó sẽ có một cái lõm cái rãnh ở đây. Thì đối với những cái điểm ở cái rãnh thì nó cũng tương tự như Saddle Point. Nhưng mà nó khác ở chỗ đó là thay vì một cái đường đi trực tiếp. Đi theo cái rãnh này để đi xuống thì nó sẽ đi zigzag. Thì chút nữa chúng ta sẽ cùng giải thích xem tại sao cái điểm thung lũng, tại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 7,
      "start_timestamp": "0:05:25",
      "end_timestamp": "0:06:10"
    }
  },
  {
    "page_content": "giải thích xem tại sao cái điểm thung lũng, tại sao tại cái vùng thung lũng thì nó khiến cho cái mô hình của mình nó đi zigzag. Và nó sẽ hội tụ chậm hơn so với lại những cái điểm vị trí khác. Thì chúng ta sẽ nhắc lại đến cái thuật toán đó là Batch Gradient Descent. Thì ưu điểm của nó đó là nó sẽ tính toán hiệu quả. Tức là tại một lần tính toán thì nó sẽ tính trên full toàn bộ dữ liệu của mình. Nó sẽ xử lý hết dữ liệu cùng một lúc. Và cái vector gradient của nó thì rất là ổn định. Dẫn đến là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 8,
      "start_timestamp": "0:06:06",
      "end_timestamp": "0:06:47"
    }
  },
  {
    "page_content": "của nó thì rất là ổn định. Dẫn đến là cái đường hội tụ của mình cũng sẽ là ổn định. Là vì nó được tính trên toàn bộ tập dữ liệu của mình. Khuyết điểm của nó đó là nó sẽ chậm. Lý do đó là vì tính toán trên nhiều dữ liệu. Thì tính trên một dữ liệu thì lúc nào nó cũng sẽ nhanh hơn tính trên full toàn bộ dữ liệu. Và đồng thời là nó sẽ tốn bộ nhớ. Tại vì nó phải nhớ hết các cái dữ liệu. Và nó có thể mắc kẹt ở những cái điểm cực tiểu cục bộ. Thì cái nguyên nhân đó là vì nó thiếu những cái bước nhảy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 9,
      "start_timestamp": "0:06:42",
      "end_timestamp": "0:07:30"
    }
  },
  {
    "page_content": "nguyên nhân đó là vì nó thiếu những cái bước nhảy vọt để thoát ra. Thì chút nữa chúng ta sẽ cùng phân tích là cái thiếu bước nhảy vọt này nó thể hiện như thế nào. Trong stochastic gradient descent thì nó có những cái ưu điểm vượt trội so với lại cái thuật toán Batch gradient descent. Tuy nhiên là cái điểm yếu của nó vẫn là nó phải tính toán nhiều lần. Nhưng mà bù lại thì nó sẽ là tính nhanh. Tại vì tại một thời điểm thì nó chỉ tính có trên một mẫu dữ liệu thôi. Thì tính toán trên một mẫu dữ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 10,
      "start_timestamp": "0:07:23",
      "end_timestamp": "0:08:14"
    }
  },
  {
    "page_content": "mẫu dữ liệu thôi. Thì tính toán trên một mẫu dữ liệu nó sẽ nhanh hơn. Nhưng mà nó sẽ chậm là ở yếu tố đó là nó sẽ chậm hội tụ hơn. Nó sẽ chậm hội tụ hơn. Cho cái vector gradient thì tại một thời điểm là nó sẽ tối ưu cho một mẫu dữ liệu ngẫu nhiên. Còn Batch gradient descent thì nó lại tối ưu cho toàn bộ dữ liệu. Nên nó sẽ hội tụ nhanh hơn và trơn tru hơn. Nhưng tuy nhiên mặc dù là nó hội tụ chậm nhưng mà bù lại là nó sẽ ưu tiên hội tụ về những điểm cực tiểu tốt hay gọi là generalization minimum",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 11,
      "start_timestamp": "0:07:56",
      "end_timestamp": "0:09:03"
    }
  },
  {
    "page_content": "cực tiểu tốt hay gọi là generalization minimum do yếu tố ngẫu nhiên. Tại sao lại như vậy? Thì chúng ta tham khảo một cái bài báo về On-Large Batch Training for Deep Learning. Ở đây sẽ xuất hiện hai khái niệm đó là flat minimum và sharp minimum. Flat minimum là chúng ta thấy là đây là một điểm cực tiểu. Tuy nhiên nó sẽ rộng. Cái khu vực này chúng ta thấy là nó sẽ rất rộng. Thì nó gọi là flat. Còn sharp minimum tức là nhọn thì vì nó nhọn nên cái khoảng cách từ bên trái sang bên phải này chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 12,
      "start_timestamp": "0:08:57",
      "end_timestamp": "0:09:53"
    }
  },
  {
    "page_content": "cách từ bên trái sang bên phải này chúng ta thấy nó rất là hẹp. Thì hai cái flat minimum và sharp minimum thì nó sẽ có cái tính chất gì? Ở đây chúng ta thấy là cái đường màu đen liên tục nó chính là cái đại diện cho cái hàm loss của tập dữ liệu training. Còn đối với tập dữ liệu test thì chắc chắn nó sẽ có một cái hiện tượng gọi là data shift. Thì nó shift từ tập training sang tập test. Tuy nhiên cái việc shift này thì chúng ta sẽ thấy rằng là đối với flat minimum thì chúng ta thấy rằng sai số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 13,
      "start_timestamp": "0:09:43",
      "end_timestamp": "0:10:36"
    }
  },
  {
    "page_content": "với flat minimum thì chúng ta thấy rằng sai số của nó sẽ là thấp khi mà shift từ tập training sang tập test. Còn đối với cái tập mà đối với cái khu vực mà sharp minimum thì chúng ta thấy là chỉ cần dịch chuyển một ít thôi. Chỉ cần dịch chuyển một ít thôi thì cái sai số của mình rất là lớn. Còn ở đây khi chúng ta dịch chuyển một ít thì cái sai số của mình ví dụ dịch qua trái một ít đúng không? Hoặc là dịch qua phải một ít thì chúng ta thấy rằng là gần như cái độ cao này, sự sai lệch về giá trị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 14,
      "start_timestamp": "0:10:26",
      "end_timestamp": "0:11:19"
    }
  },
  {
    "page_content": "là gần như cái độ cao này, sự sai lệch về giá trị độ lỗi này là rất là thấp. Trong khi đó ở đây chúng ta chỉ cần dịch chuyển một ít thì cái sai số của mình rất là cao. Vì vậy các mô hình máy học sẽ tìm cách là tiến đến những cái điểm flat minimum. Và nhờ có cái yếu tố ngẫu nhiên của các mẫu dữ liệu huấn luyện, khi chúng ta huấn luyện thì chúng ta sẽ random chọn ra các điểm dữ liệu. Chắc chắn trong đó nó sẽ có một cái đại lượng nhiễu thì nhờ cái nhiễu này nó sẽ giúp chúng ta nhảy ra và thoát ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 15,
      "start_timestamp": "0:11:09",
      "end_timestamp": "0:12:08"
    }
  },
  {
    "page_content": "nhiễu này nó sẽ giúp chúng ta nhảy ra và thoát ra khỏi local, cái sharp minimum. Ví dụ ban đầu chúng ta rớt vào đây, chúng ta rớt nơi đây, rồi. Thì chỉ cần một cái bước nhảy nhỏ thôi, chỉ cần một cái sai số nhỏ thôi, thì nó có thể thoát ra khỏi bên đây, tức là nó sẽ nhảy qua cái khu bên đây. Nhờ cái sai số đó chúng ta có thể thoát vào đây, hoặc chúng ta có thể thoát vào bên đây. Ví dụ như ở đây chúng ta lại có một cái hàm tối ưu ngoài, nó sẽ, vì nó là sharp minimum, thì khi chúng ta nhảy qua",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 16,
      "start_timestamp": "0:11:56",
      "end_timestamp": "0:12:55"
    }
  },
  {
    "page_content": "vì nó là sharp minimum, thì khi chúng ta nhảy qua đây, thì chiếu lên trên cái hàm loss, nó sẽ giúp cho chúng ta thoát ra khỏi được cái điểm sharp minimum này, và sau đó lại tiếp tục trượt xuống dưới. Và tóm lại, đó là stochastic gradient descent, nó sẽ khuyến khích cái tham số của mình, nó sẽ tiến về những cái khu vực flat minimum. Và với những cái khu vực mà flat minimum, thì cái mô hình của mình nó sẽ có cái tính tổng quát cao hơn. Tại sao nó tổng quát cao hơn? Tại vì chỉ cần có một cái sự",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 17,
      "start_timestamp": "0:12:43",
      "end_timestamp": "0:13:53"
    }
  },
  {
    "page_content": "tổng quát cao hơn? Tại vì chỉ cần có một cái sự dịch chuyển nhẹ của cái tham số, thì cái loss của mình nó cũng không thay đổi đáng kể. Các bạn thấy là dịch chuyển qua đây, hoặc là chúng ta dịch chuyển qua đây, thì cái cao độ của cái loss của mình trên cái tập test là rất là thấp, không đáng kể. Ý đó là cái mô hình của mình, khi chúng ta huấn luyện trên cái tập trend và sau đó test, thì cái sai số nếu có nó sẽ không có chênh lệch nhiều. Tức là nó không có bị overfitting, nếu trên tập trend độ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 18,
      "start_timestamp": "0:13:35",
      "end_timestamp": "0:14:25"
    }
  },
  {
    "page_content": "nó không có bị overfitting, nếu trên tập trend độ chính xác tốt, thì tập test độ chính xác cũng tốt. Nhưng đối với những cái sharp minimum, thì cái sai lệch này nó sẽ khiến cho cái độ chính xác trên cái tập test sẽ rất là đáng kể. Ví dụ chúng ta thấy là tại cái điểm local minimum của tập trend, khi chúng ta ánh xạ lên trên tập test, thì chúng ta thấy là cái độ cao này rất là cao. Trong khi đó, chúng ta sẽ nhắc lại. Trong khi đó, với cái điểm local minimum của tập trend khi chúng ta chiếu lên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 19,
      "start_timestamp": "0:14:14",
      "end_timestamp": "0:15:06"
    }
  },
  {
    "page_content": "minimum của tập trend khi chúng ta chiếu lên tập test, thì cái sai số này, cái độ cao này, độ chênh lệch này rất là thấp. Vì nó thấp, nên nó độ chính xác cho tập test sẽ là cao. Còn cái hàm độ lỗi của tập test, trong trường hợp là sharp minimum là cao, tức là cái độ chính xác của nó giảm đột ngột, giảm đáng kể so với tập trend. Và một cái thách thức đối với thuật toán stochastic gradient descent chính là khi nó rớt vào những cái vùng nó gọi là valley, tức là những cái vùng thung lũng, thì khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 20,
      "start_timestamp": "0:14:59",
      "end_timestamp": "0:15:46"
    }
  },
  {
    "page_content": "valley, tức là những cái vùng thung lũng, thì khi mà nó từ cái điểm trên cao rớt xuống thì thay vì là nó sẽ đi dọc theo cái thung lũng một cách nhanh chóng thì đằng này nó cứ dập qua dập lại. Nó dập qua dập lại dẫn đến cái việc mà cập nhật này rất là chậm. Thì ở đây đó chính là cái hiện tượng có cái độ dốc bất thường. Ở đây chúng ta thấy là có cái độ dốc đi xuống nè, nhưng ngay lập tức nó lại đi lên. Ngay lập tức nó lại đi lên thì đó chính là cái sự bất thường. Thì những cái, đây chính là những",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 21,
      "start_timestamp": "0:15:36",
      "end_timestamp": "0:15:46"
    }
  },
  {
    "page_content": "sự bất thường. Thì những cái, đây chính là những cái vùng mà có cái sự thay đổi lớn về độ dốc theo các cái chiều, theo các cái chiều. Và tham số của mình thì nó sẽ liên tục nhảy qua, và nó sẽ liên tục nhảy qua, rồi lại nhảy lại, nhảy qua, rồi lại nhảy lại. Khiến cho cái việc mà tiến đến cái việc, tiến đến cái điểm cực tiểu là chậm. Còn nếu như chúng ta đi theo một cách gọi là hoàn hảo thì chúng ta sẽ đi dọc theo cái rãnh này để tiếp tục đi, tìm đến cái điểm local minimum. Hãy subscribe cho kênh",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cái điểm local minimum. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=HWWlm40wQ-s",
      "filename": "HWWlm40wQ-s",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Giải pháp để giải quyết hiện tượng vanishing gradient này là gì? Chúng ta sẽ phải xem xét đến nguyên nhân. Trong nguyên nhân của mình là có những cái hàm được xuất hiện đi xuất hiện lại nhiều lần và giá trị đạo hàm của nó nhỏ hơn một. Thế thì khi chúng ta đang làm với các mô hình học sâu, thì cái việc mà một cái hàm lặp đi lặp lại nhiều lần đó là chuyện bắt buộc phải xảy ra rồi. Việc một cái hàm lặp đi lặp lại nhiều lần là một cái việc mà hoàn toàn là khó tránh khỏi. Do đó cái vế đầu tiên đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:07"
    }
  },
  {
    "page_content": "là khó tránh khỏi. Do đó cái vế đầu tiên đó là cái hàm của mình lặp đi lặp lại nhiều lần thì mình sẽ không can thiệp vào mà mình sẽ đưa đến cái giải quyết bằng cách đó là chúng ta sẽ chọn một cái hàm mà có cái giá trị đạo hàm không quá bé. Thế thì ở đây chúng ta sẽ tấn công vô cái hàm kích hoạt tức activation. Thì nếu như chúng ta không dùng cái hàm kích hoạt có đạo hàm nhỏ, thì chúng ta sẽ chọn những cái hàm kích hoạt mà có cái đạo hàm nó có tính chất cân bằng hơn. Cân bằng hơn tức là nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 1,
      "start_timestamp": "0:01:02",
      "end_timestamp": "0:01:47"
    }
  },
  {
    "page_content": "tính chất cân bằng hơn. Cân bằng hơn tức là nó sẽ gần bằng một. Hoặc là có thể lúc nó sẽ là số rất bé nhưng mà cũng có thể là số lớn, nó sẽ phải dao động xung quanh con số một. Còn với hàm sigmoid thì cho dù là hàm kích hoạt có đạo hàm nhỏ, cho dù là hàm của mình nó có kiến trúc gì đi chăng nữa, thì sigmoid của x luôn luôn là con số bé hơn một. Trong khi đó chúng ta không có dùng cái hàm này, không dùng hàm sigmoid nữa, mà chúng ta dùng hàm relu. Thì đạo hàm của hàm relu này thì nó sẽ là bằng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 2,
      "start_timestamp": "0:01:42",
      "end_timestamp": "0:02:36"
    }
  },
  {
    "page_content": "Thì đạo hàm của hàm relu này thì nó sẽ là bằng 0. Nếu z bé hơn 0 và bằng 1 nếu z lớn hơn 0, thì cái việc này nó sẽ giúp chúng ta cân bằng. Và chúng ta lưu ý đó là không phải lúc nào z khi chúng ta gọi hàm activation function, thì cái giá trị chúng ta truyền vô là đều bé hơn 0, nó sẽ có lúc bé hơn 0, có lúc lớn hơn 0, do đó nó tạo ra sự hài hòa và sự cân bằng cho mình. Đó là cái biểu hiện của tính cân bằng, là thể hiện cho đó. Nó sẽ lúc không, lúc bằng một, nhưng mà trung bình thì nó sẽ là xoay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 3,
      "start_timestamp": "0:02:31",
      "end_timestamp": "0:03:14"
    }
  },
  {
    "page_content": "bằng một, nhưng mà trung bình thì nó sẽ là xoay xung quanh con số một. Và với cái thao tác là đổi cái hàm sigmoid thành relu, thì AlexNet đã ghi một cái dấu ấn, đó là vào năm 2012, đó là khi lần đầu tiên trong một cuộc thi về phân loại hình ảnh, trên tập dữ liệu là ImageNet. Thì cái kiến trúc mạng CNN đã chiến thắng so với lại các giải pháp sử dụng đặc trưng handcrafted features, tức là lần đầu tiên mà deep learning có được cái độ chính xác vượt trội so với lại các mô hình sử dụng đặc trưng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 4,
      "start_timestamp": "0:03:09",
      "end_timestamp": "0:03:47"
    }
  },
  {
    "page_content": "trội so với lại các mô hình sử dụng đặc trưng được thu thủ công. Và một trong những cái tạo nên sự khác biệt của AlexNet đó chính là có sử dụng hàm relu, thay vì sử dụng hàm sigmoid thì họ dùng relu. Tuy nhiên họ sẽ còn những cái cải tiến khác, nhưng mà ứng với lại cái vấn đề về vanishing gradient thì họ đã có những cái cập nhật này. Cái giải pháp số 2, đó là chúng ta sẽ thêm các cái kết nối tắt, tức là chúng ta sẽ can thiệp vô cái kiến trúc, thay đổi cái kiến trúc của cái mô hình, học sâu. Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 5,
      "start_timestamp": "0:03:45",
      "end_timestamp": "0:04:28"
    }
  },
  {
    "page_content": "đổi cái kiến trúc của cái mô hình, học sâu. Thì đối với một cái mạng neural network bình thường, thì chúng ta sẽ thực hiện cái phép biến đổi là tính, weight layer, tức là chúng ta đang thực hiện phép biến đổi tuyến tính để rút trích đặc trưng, sau đó rồi chúng ta qua hàm relu, để phi tuyến hóa cái đặc trưng đó, rồi sau đó lại qua weight layer, tức là để rút trích đặc trưng, rồi lại đi relu. Thì đây là cái thao tác biến đổi một cách tuần tự. Và chúng ta ký hiệu nó là hx. Thì nếu như chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 6,
      "start_timestamp": "0:04:26",
      "end_timestamp": "0:05:01"
    }
  },
  {
    "page_content": "chúng ta ký hiệu nó là hx. Thì nếu như chúng ta dùng một cái kiến trúc mạng bình thường như thế này, mà không có cái kết nối tắt, kết nối tắt là gì thì chúng ta sẽ nói trong slide tiếp theo. Nhưng mà với cái kiến trúc thông lệ này, thì khi tác giả của cái bài báo là Deep Residual Learning for Image Recognition, bài này là viết tắt của cái kiến trúc mạng là ResNet, là tác giả Kaming Hair, thì khi chúng ta tăng số layer lên từ 20 lên 32 lên 46 lên 56, thì cái giá trị loss của mình nó lại càng lúc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 7,
      "start_timestamp": "0:04:57",
      "end_timestamp": "0:05:44"
    }
  },
  {
    "page_content": "56, thì cái giá trị loss của mình nó lại càng lúc càng cao. Khi mà tăng layer lên thì nó lại đi hội tụ chậm. Nó hội tụ chậm hơn so với lại những cái layer ít, so với lại những cái mạng mà ít layer hơn. Thì đây là một cái điều vô lý, tại vì nó sẽ khiến cho mô hình của mình không có tốt đối với những cái mạng có kiến trúc sâu. Mặc dù trước đó đã có một số công trình họ nghiên cứu và họ khái quát hóa rằng khi mạng càng sâu, thì nó sẽ càng tạo ra nhiều đặc trưng tốt, tạo ra càng nhiều đặc trưng, từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 8,
      "start_timestamp": "0:05:40",
      "end_timestamp": "0:06:27"
    }
  },
  {
    "page_content": "đặc trưng tốt, tạo ra càng nhiều đặc trưng, từ đặc trưng cấp thấp cho đến đặc trưng cấp cao và nó sẽ bổ trợ cho cái việc phân biệt đối tượng. Nhưng mà khi chúng ta tăng cái độ sâu lên, thì nó lại không còn hiệu quả nữa. Thì đây chính là cái quan sát đầu tiên của các tác giả của bài ResNet và họ đã đưa ra một số lý giải và đề xuất một cái giải pháp rất là đơn giản. Đó là chúng ta thêm một cái kết nối tắt như thế này. Thêm một cái kết nối tắt là cái đường này. Và chúng ta ý nghĩa của cái hàm kết",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 9,
      "start_timestamp": "0:06:25",
      "end_timestamp": "0:07:06"
    }
  },
  {
    "page_content": "đường này. Và chúng ta ý nghĩa của cái hàm kết nối tắt này đó là gì? Hx sẽ là bằng fx, hx là bằng fx, tức là các cái thao tác biến đổi tuần tự, cộng thêm chính x đầu vào. Chỉ là đơn giản như vậy thôi. Thế thì tại sao một cái thao tác biến đổi đơn giản này nó lại giúp cho chúng ta giải quyết được cái vấn đề balancing gradient? Đó là vì chúng ta khi chúng ta tính đạo hàm, thì bình thường là nếu như hx mà bằng fx, tức là các cái phép biến đổi tuần tự ở đây, thì khi chúng ta tính đạo hàm, các cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 10,
      "start_timestamp": "0:07:04",
      "end_timestamp": "0:07:38"
    }
  },
  {
    "page_content": "tự ở đây, thì khi chúng ta tính đạo hàm, các cái activation function này mặc dù đã được thiết kế, là đã có thể giảm thiểu được cái hiện tượng balancing gradient, nhưng mà cái việc huấn luyện thì các cái... càng về sau thì các cái đạo hàm của mình nó sẽ có xu hướng càng nhỏ và nó sẽ tiến về là nhỏ hơn một. Dẫn đến đó là cái mô hình của mình sẽ càng về sau, nó sẽ càng khó hội tụ hơn. Có thể ban đầu nó sẽ hội tụ tốt, nhưng về sau nó khó hội tụ hơn. Thì khi đó là đạo hàm của f này sẽ là... không",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 11,
      "start_timestamp": "0:07:36",
      "end_timestamp": "0:08:29"
    }
  },
  {
    "page_content": "Thì khi đó là đạo hàm của f này sẽ là... không có... nó sẽ mau tiến về không. Thế thì với cái việc chúng ta cộng thêm x thì đạo hàm... bên đây là đạo hàm của x, của h, là bằng đạo hàm của hàm f, tức là chúng ta vẫn lấy những cái đặc trưng bình thường. Đây là các cái đặc trưng bình thường. Nhưng mà chúng ta sẽ có thêm cái vế cộng x này, mà đạo hàm của x thì nó chính là bằng một. Như vậy thì nhờ có cái thao tác mà cộng thêm một này, thì kể cả sau này khi đạo hàm này có lớn hơn không, hay nhỏ hơn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 12,
      "start_timestamp": "0:08:23",
      "end_timestamp": "0:09:13"
    }
  },
  {
    "page_content": "này khi đạo hàm này có lớn hơn không, hay nhỏ hơn không, thì cái đạo hàm của h sẽ là dao động. Dao động quanh số 1, nó sẽ khiến cho cái mô hình của mình, nó sẽ càng cân bằng hơn. Cái đạo hàm của mình nó cân bằng hơn. Do cái h phải, tức là đạo hàm của h, lúc thì nó sẽ nhận số lớn hơn một, lúc nhận số nhỏ hơn một, tại vì nó tùy thuộc vô cái đạo hàm của f là có... nhưng mà trung dung nhất thì là h phải x sẽ nhận các cái giá trị vừa dao động xung quanh số 1. Khi chúng ta tính cái chain rule, các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 13,
      "start_timestamp": "0:09:09",
      "end_timestamp": "0:09:51"
    }
  },
  {
    "page_content": "quanh số 1. Khi chúng ta tính cái chain rule, các cái con số mà dao động quanh số 1 nó sẽ là cân bằng, dẫn đến là đạo hàm của mình sẽ không có giảm quá nhanh. Thì đó là cái lý thuyết lý giải về lý thuyết toán. Và đây là một cái phương pháp rất là đơn giản. Nhưng mà cực kỳ hiệu quả. Ở đây tôi nhấn mạnh đó là... dùng cái từ là cực kỳ hiệu quả. Và rất nhiều những cái bài báo về sau, họ đều có sử dụng cái ý tưởng kết nối tắt này. Ví dụ như trong kiến trúc ResNet, đối với kiến trúc VGG trước đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 14,
      "start_timestamp": "0:09:47",
      "end_timestamp": "0:10:27"
    }
  },
  {
    "page_content": "trúc ResNet, đối với kiến trúc VGG trước đó là VGG 19, là bao gồm 19 cái layer biến đổi này, thì nó đã đạt được cái ngưỡng bão hòa về độ chính xác, nó không thể tăng lên được nữa. Nó tăng lên là 20 lớp, 30 lớp là nó gần như nó bão hòa và nó không có... thậm chí là nó còn giảm. Nhưng ResNet bằng cái cơ chế Skip Connection, đây là cái Skip Connection, các cái kết nối tắt, thì ResNet đã có thể huấn luyện được với những cái mạng có số lượng layer lên đến là 34 lớp, và thậm chí là lên đến trên 100",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 15,
      "start_timestamp": "0:10:24",
      "end_timestamp": "0:11:09"
    }
  },
  {
    "page_content": "đến là 34 lớp, và thậm chí là lên đến trên 100 lớp. Nhưng mà độ chính xác của mình nó vẫn càng lúc càng cải tiến, càng tốt. Vậy thì nhờ có cái Skip Connection này, thì khi chúng ta tính ra cái giá trị Loss ở đây, nếu như bình thường, nếu như bình thường chúng ta tính Loss, và chúng ta muốn lan truyền đến những cái layer ở lớp đầu tiên, những cái layer số 1, số 2, thì khi chúng ta lan truyền cái độ lỗi về đến cái layer đầu tiên, thì cái Loss gần như đã bị triệt tiêu. Là cái đạo hàm của hàm j",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 16,
      "start_timestamp": "0:11:06",
      "end_timestamp": "0:11:52"
    }
  },
  {
    "page_content": "như đã bị triệt tiêu. Là cái đạo hàm của hàm j theo những cái tham số ở những cái lớp số 1 hoặc là số 2 gần như bằng 0. Vì chúng ta phải thực hiện các cái con số nhân này với 34, 34 cái đạo hàm của các cái con số, ờ, của các cái đạo hàm thành phần là do của 34 lớp. Nhưng nhờ có các cái Skip Connection này, thì khi chúng ta lan truyền cái lỗi, thì cái số bước nhảy này sẽ giúp chúng ta giảm bớt con đường để đi từ layer cuối về layer đầu. Ví dụ như trên hình này, chúng ta có là 1, 2, 3, 4, 5, 6,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 17,
      "start_timestamp": "0:11:47",
      "end_timestamp": "0:12:38"
    }
  },
  {
    "page_content": "trên hình này, chúng ta có là 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16. Tức là chúng ta chỉ còn 16 lần, 16 cái bước nhảy. Như vậy là nó đã tăng gấp đôi, nó đã tăng được tốc độ gấp đôi để lan truyền cái độ lỗi đó xuống. Đó thì chính là cái lý giải 1 cái góc nhìn khác về cái lý thuyết về mặt thông tin. Tức là cái sai số nếu bình thường chúng ta truyền qua các cái tuần tự, thì về đến đây là nó đã bị tiêu biến dần. Nhưng mà nhờ có các Skip Connection này thì cái sai số truyền qua cái đường",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 18,
      "start_timestamp": "0:12:27",
      "end_timestamp": "0:13:11"
    }
  },
  {
    "page_content": "này thì cái sai số truyền qua cái đường tắt. Thì đến đây nó chỉ có 16 bước thôi. Nó sẽ ít hơn nhiều so với 0.34 bước. Vì vậy là cái mô hình của mình sẽ đỡ hiện tượng vanishing gradient hơn. Và với cái sự thay đổi đó, thì ở phiên bản trước, đây là trước khi dùng Skip Connection. Và đây là sau. Sau khi dùng Skip Connection thì chúng ta thấy là Cái layer số 50, 6 và thậm chí là cái layer số 110 là cho cái loss thấp hơn so với lại cái loss của cái layer số 20. Trong khi đó bên đây là không có dùng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 19,
      "start_timestamp": "0:13:04",
      "end_timestamp": "0:13:50"
    }
  },
  {
    "page_content": "số 20. Trong khi đó bên đây là không có dùng thì 56, cái giá trị sai số của nó còn cao hơn cả cái sai số của layer số, của cái mô hình mà có layer số 20 lớp. Vì vậy chúng ta thấy là cái tác dụng của cái nối tắt rất là hiệu quả. Đặc biệt là chúng ta vẫn có thể tiếp tục cải tiến được trên những cái mạng mà có số lớp lên đến hàng trăm. Và không phải ngẫu nhiên mà cái bài này được đánh giá là một trong những thành tựu lớn trong Deep Learning. Vì đến tính từ thời điểm 2015 cho đến bây giờ là 10 năm.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 20,
      "start_timestamp": "0:13:42",
      "end_timestamp": "0:14:39"
    }
  },
  {
    "page_content": "tính từ thời điểm 2015 cho đến bây giờ là 10 năm. Và đã có là hơn 200.000 và gần xấp xỉ 300.000 citation, là 300.000 cái trích dẫn. Thì cách đây là hơn một năm thì mới chỉ khoảng là 210.000 nhưng mà sau một năm là nó nhảy lên 90.000. Thì thế thì chúng ta thấy đó là cái tốc độ tăng citation rất là nhanh và chưa thấy có một cái dấu hiệu gì là dừng lại. Thì điều đó chứng tỏ là cái kỹ thuật mà Skip Connection này rất là hiệu quả và được rất nhiều những cái nghiên cứu họ sử dụng gần đây. Và với cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 21,
      "start_timestamp": "0:14:33",
      "end_timestamp": "0:15:12"
    }
  },
  {
    "page_content": "cái nghiên cứu họ sử dụng gần đây. Và với cái kết nối tắt này thì không chỉ ResNet mà những cái kiến trúc khác ví dụ như là DenseNet cũng sẽ có các cái kết nối tắt. Đây là các kết nối tắt. Rồi Transformer cũng vậy. Chúng ta thấy là Transformer là Attention Is All You Need. Tức là là tất cả những gì bạn cần. Nhưng mà các bạn nhìn vô đây thì chúng ta thấy cái kết nối tắt mới chính là những cái thao tác mà nhiều nhất. Đây là một cái nối tắt. Một kết nối tắt. Rồi lại tiếp tục kết nối. Kết nối tắt.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 22,
      "start_timestamp": "0:15:07",
      "end_timestamp": "0:15:48"
    }
  },
  {
    "page_content": "nối tắt. Rồi lại tiếp tục kết nối. Kết nối tắt. Đó thì không biết là Attention Is All You Need hay là Skip Connection Is All You Need. Cái này là một cái nói vui. Và tương tự như vậy thì cũng sẽ có Deep Supervision là một cái kiến trúc mạng mà có các cái kết nối tắt. Thì cái kết nối tắt này nó không có theo kiểu của DenseNet mà là nó sẽ tắt ra thành từng nhánh. Và với mỗi nhánh thì chúng ta thấy nếu đi theo đúng cái đường ban đầu là cái đường kiến trúc ở giữa thì sẽ biến đổi rất là nhiều. Nhưng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 23,
      "start_timestamp": "0:15:35",
      "end_timestamp": "0:16:22"
    }
  },
  {
    "page_content": "trúc ở giữa thì sẽ biến đổi rất là nhiều. Nhưng mà nhờ có cái nhánh nó tắt ra, tắt ra, tắt ra, tắt ra ở đây. Thì chúng ta sẽ tính các cái loss ở những cái lớp mà có ít biến đổi hơn. Thì những cái loss ở các lớp ít biến đổi này thì khi chúng ta lan truyền về thì chúng ta sẽ giúp cập nhật được trọng số của những lớp đầu tiên dễ dàng hơn. Tại vì khoảng cách từ lớp đầu tiên này cho đến những cái... ví dụ như đến đây đi. Đến cái chỗ loss này. Chúng ta thấy là chỉ có 1, 2, 3, 4, 5, 6, 7 bước. Trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ta thấy là chỉ có 1, 2, 3, 4, 5, 6, 7 bước. Trong khi đó nếu chúng ta đi hết nguyên 1 cái trục này thì có thể lên đến gấp 2, thậm chí là gấp 2,5 lần là có thể lên đến là 16, 17 bước. Thì nhờ các cái kết nối đầu ra như thế này, nó sẽ giúp cho chúng ta lan truyền đến cái trọng... cái độ lỗi đến những cái lớp đầu tiên và ít bị hiện tượng vanishing gradient hơn. Cảm ơn các bạn đã xem video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=iQqNUKgIZpc",
      "filename": "iQqNUKgIZpc",
      "title": "[CS315 - Chương 2] Vanishing Gradient (Phần 3)",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Tiếp theo chúng ta sẽ cùng tìm hiểu về một số biến thể của thuật toán Gradient Descent Đầu tiên đó là batch Gradient Descent và viết tắt của chữ BGD Đó là chúng ta sẽ truyền toàn bộ dữ liệu huấn luyện vào mô hình của mình Theta là bằng theta trừ alpha nhân cho đạo hàm của... ở đây chúng ta sẽ có chữ kỳ vọng tức là chúng ta đang tính trên toàn bộ dữ liệu của mình kỳ vọng của hàm loss, hàm lỗi Và ví dụ như ở đây chúng ta có một hình ảnh minh họa là một đoạn dữ liệu thì expectation tức là E sẽ được",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:10"
    }
  },
  {
    "page_content": "một đoạn dữ liệu thì expectation tức là E sẽ được tính trên full toàn bộ dữ liệu của mình Và trong đoạn code mã giả chúng ta thấy là chúng ta sẽ lặp Y chạy trên số lượng Epoch Mỗi một Epoch là một lượng chúng ta huấn luyện trên toàn bộ dữ liệu của mình Chúng ta sẽ duyệt qua Y với toàn bộ số Epoch Và với mỗi Epoch chúng ta sẽ tính Gradient trên full toàn bộ dữ liệu Vậy là chúng ta đưa toàn bộ data của chúng ta vào Và chúng ta sẽ có được Gradient cho từng tham số Và ở đây thì tham số sẽ là bằng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 1,
      "start_timestamp": "0:00:59",
      "end_timestamp": "0:01:54"
    }
  },
  {
    "page_content": "cho từng tham số Và ở đây thì tham số sẽ là bằng tham số trừ cho Learning Rate Alpha Nhân cho Vector Gradient của mình Thì ở đây chính là cái mã giả của Batch Gradient Descent Phiên bản thứ hai, biến thể thứ hai đó là Stochastic Gradient Descent Viết tắt của chữ SGD Thì ở đây chúng ta sẽ truyền trên từng mẫu 1 Chúng ta sẽ truyền từng mẫu 1 để huấn luyện cho cái mô hình của mình Thì công thức của chúng ta sẽ là theta là bằng theta trừ cho Alpha Nhân cho nabla của theta Và ở đây chúng ta sẽ tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 2,
      "start_timestamp": "0:01:51",
      "end_timestamp": "0:02:43"
    }
  },
  {
    "page_content": "cho nabla của theta Và ở đây chúng ta sẽ tính trên 1 mẫu dữ liệu Y Và 1 cái mẫu dữ liệu Y này thì sẽ được lấy ngẫu nhiên Thế thì nếu chúng ta minh họa nguyên 1 cái đoạn dữ liệu của chúng ta như thế này Thì phương pháp Stochastic Gradient Descent là chúng ta bốc ra ngẫu nhiên 1 cái mẫu dữ liệu Để chúng ta đưa vào và chúng ta huấn luyện Thì cái mẫu dữ liệu này là một cặp XE và EA Và trong cái mã giả này thì chúng ta sẽ Có là Y cũng sẽ lặp qua tất cả số epoch của mình Với mỗi epoch thì chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 3,
      "start_timestamp": "0:02:38",
      "end_timestamp": "0:03:29"
    }
  },
  {
    "page_content": "số epoch của mình Với mỗi epoch thì chúng ta sẽ shuffle Cái data này sẽ xáo Tức là nó sẽ được sắp xếp một cách ngẫu nhiên Thay đổi cái thứ tự ngẫu nhiên Và với mỗi 1 cái example in data Thì cái example của chúng ta chính là mẫu dữ liệu này Chính là cái mẫu dữ liệu này Thì khi đó chúng ta sẽ đưa cái mẫu dữ liệu này Vào bên trong cái hàm EVALUATE GRADIENT để tính đạo hàm Như vậy thì params rad là cái gradient Chỉ được tính trên 1 mẫu dữ liệu ngẫu nhiên ở đây Và công thức cập nhật thì cũng tương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 4,
      "start_timestamp": "0:03:24",
      "end_timestamp": "0:04:07"
    }
  },
  {
    "page_content": "nhiên ở đây Và công thức cập nhật thì cũng tương tự như là Thuật toán gradient descent nguyên bản Đó là params bằng params trừ cho alpha Nhân cho cái thành phần nabla này Và đến với biến thể Có cái sự lai ghép Nó có sự ngẫu nhiên Của cái stochastic gradient descent Nhưng đồng thời là nó sẽ không có tính trên full toàn bộ dữ liệu Thì đó chính là mini-batch Gradient Descent viết tắt của chữ MGD Thì chúng ta sẽ truyền vào 1 khối Chúng ta sẽ truyền vào 1 khối dữ liệu Để huấn luyện Và ở đây chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 5,
      "start_timestamp": "0:04:04",
      "end_timestamp": "0:04:42"
    }
  },
  {
    "page_content": "1 khối dữ liệu Để huấn luyện Và ở đây chúng ta sẽ có cái khái niệm Nó gọi là batch size tức là kích thước của 1 khối Thì kích thước của 1 khối Thì thường là lũy thừa của 2 Ví dụ như là 1, 2, 4, 8 Thì tại sao người ta hay chọn cái lũy thừa của 2 Là vì trong máy tính của chúng ta Kiến trúc của mình là kiến trúc nhị phân Nên thường là các cái bộ chẳng của số 2 Thì nó sẽ vừa fit với lại cái dữ liệu của mình Nên tính toán nó sẽ nhanh hơn Thế thì cái công thức của mini-batch gradient descent Theta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 6,
      "start_timestamp": "0:04:40",
      "end_timestamp": "0:05:20"
    }
  },
  {
    "page_content": "thức của mini-batch gradient descent Theta sẽ là bằng theta trừ cho alpha nhân cho nabla Thế thì ở đây chúng ta thấy là nó sẽ đi lấy trên mẫu dữ liệu Từ y cho đến y cộng n Thì đây là 1 batch Tương tự như vậy cho y chúng ta sẽ lấy trên 1 batch Để chúng ta huấn luyện Thế thì nếu chúng ta vẽ cái khối này là toàn bộ dữ liệu Thì chúng ta sẽ chia cái dữ liệu của mình ra Thành từng batch mỗi cái này là 1 batch Rồi thì cái mã giả của chúng ta là như sau Với mỗi y chạy từ nằm trong cái range của số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 7,
      "start_timestamp": "0:05:17",
      "end_timestamp": "0:05:56"
    }
  },
  {
    "page_content": "sau Với mỗi y chạy từ nằm trong cái range của số lượng epoch Tức là chúng ta cũng duyệt qua tất cả các cái số epoch của mình Và tại 1 cái thời điểm này thì chúng ta sẽ xáo ngẫu nhiên Tức là chúng ta sẽ shuffle cái mẫu dữ liệu của chúng ta Để cho nó có cái tính ngẫu nhiên trong đó Và tại 1 thời điểm thì chúng ta sẽ lấy ra 1 batch Ví dụ như ở đây là 1 batch Chúng ta sẽ duyệt qua tất cả cái batch của data của mình Và chúng ta sẽ truyền nó vào cái hàm evaluate gradient Thì ở đây chúng ta sẽ tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 8,
      "start_timestamp": "0:05:51",
      "end_timestamp": "0:06:39"
    }
  },
  {
    "page_content": "hàm evaluate gradient Thì ở đây chúng ta sẽ tính được cái gradient Chúng ta cũng sẽ cập nhật tương tự như thuật toán stochastic gradient descent Như vậy thì chúng ta sẽ có 1 cái bảng so sánh về các cái biến thể này Đầu tiên đó là cái batch gradient descent Thì chúng ta thấy là vì nó được tính trên full toàn bộ cái dữ liệu Nên rõ ràng là cái chi phí tính toán lớn Và đồng thời là cái bộ nhớ của chúng ta có thể sẽ là sẽ phải cần rất là nhiều Trong khi đó stochastic gradient descent thì ngược lại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 9,
      "start_timestamp": "0:06:32",
      "end_timestamp": "0:07:20"
    }
  },
  {
    "page_content": "khi đó stochastic gradient descent thì ngược lại Là tại 1 thời điểm chúng ta chỉ tính trong duy nhất 1 mẫu dữ liệu thôi Do đó thì cái bộ nhớ, cái chi phí về bộ nhớ của chúng ta Thì sẽ tiết giảm rất là đáng kể Nhưng mà bù lại thì có thể cái thời gian tính toán của chúng ta sẽ lâu Ở trên là cái chi phí tính toán bao gồm là cái tài nguyên tính toán là CPU Rồi RAM là tốn Nhưng ở phía dưới thì chúng ta lại liên quan điểm tối tính toán Thay vì chúng ta tính hết 1 khối lớn thì chúng ta lại tính từng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 10,
      "start_timestamp": "0:07:14",
      "end_timestamp": "0:07:57"
    }
  },
  {
    "page_content": "ta tính hết 1 khối lớn thì chúng ta lại tính từng mẫu từng mẫu Do đó cái thời gian của chúng ta sẽ lâu hơn Và mini-batch thì đâu đó nó sẽ là nằm ở giữa Tức là chúng ta sẽ tính trên 1 khối lớn là n mẫu dữ liệu mà thôi Thì ở đây nó sẽ là cân bằng hơn giữa 2 phương pháp ở trên Và cái landscape tức là cái đồ họa của hàm lỗi của chúng ta cho từng biến thể này Đối với Batch Gradient Descent thì chúng ta sẽ thấy cái đường đi của nó rất là mượt Nó rất là mượt Là vì nó được tính trên tổng thể toàn bộ dữ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 11,
      "start_timestamp": "0:07:55",
      "end_timestamp": "0:08:36"
    }
  },
  {
    "page_content": "mượt Là vì nó được tính trên tổng thể toàn bộ dữ liệu của mình Nên cái đường đi của nó sẽ mượt Còn Stochastic Gradient Descent thì chúng ta sẽ thấy nó rất là zíc zắc, rất là nhấp nhô Thì cái này đó là do có cái yếu tố ngẫu nhiên Sẽ có lúc chúng ta gặp những mẫu dễ thì cái loss của mình nó thấp Nhưng gặp những mẫu cao thì loss nó cao Nhưng mà nhìn chung sau 1 số lần lặp nhiều đủ lớn Thì nó sẽ hội tụ và tiến về cái giá trị hàm lỗi của mình nó sẽ càng lúc càng thấp Và trong nhiều lý thuyết người",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 12,
      "start_timestamp": "0:08:32",
      "end_timestamp": "0:09:12"
    }
  },
  {
    "page_content": "càng lúc càng thấp Và trong nhiều lý thuyết người ta đã chứng minh đó là Stochastic Gradient Descent Nó sẽ giúp cho cái mô hình của mình học bền vững và ổn định hơn Nhờ có những cái bước nhảy như thế này Những cái bước nhảy dập lên dập xuống như thế này Nó sẽ giúp cho mô hình của chúng ta thoát ra những cái điểm cực tiểu cục bộ Để hy vọng nó có thể tiến đến được những cái điểm tối ưu, những điểm cực tiểu toàn cục hoặc là những điểm cực tiểu tối ưu hơn Thì nhờ có những cái dập như thế này Và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 13,
      "start_timestamp": "0:09:10",
      "end_timestamp": "0:09:23"
    }
  },
  {
    "page_content": "ưu hơn Thì nhờ có những cái dập như thế này Và Mini-batch Gradient Descent thì nó sẽ ở mức lưng chừng ở giữa nó cũng tương đối smooth nhưng mà nó cũng sẽ có những cái zíc zắc nhất định Thì đây là Mini-batch Gradient Descent Và thông thường thì người ta hay sử dụng Mini-batch Gradient Descent vì nó cân bằng được yếu tố về thời gian và chi phí tính toán",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=JSVPNZhpf2g",
      "filename": "JSVPNZhpf2g",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 3 (New)",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với kiến trúc mạng rất là nổi tiếng là AlexNet. Và đây có thể nói là một cái cột mốc quan trọng trong lĩnh vực học sâu. Vì vào năm 2012, khi mà các mô hình máy học đều dựa trên những đặc trưng handcrafted features, tức là các đặc trưng mà được tạo bởi các tri thức chuyên gia để giúp chúng ta giải quyết các vấn đề, thì vào thời điểm năm 2012, kiến trúc mạng AlexNet là một trong những kiến trúc mạng CNN, một trong những kiến trúc mạng học sâu mà có kết quả vượt trội so với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:00"
    }
  },
  {
    "page_content": "trúc mạng học sâu mà có kết quả vượt trội so với những mô hình sử dụng handcrafted features, đánh dấu cho giai đoạn đó là mô hình của mình có khả năng tự học được những đặc trưng cấp cao mà không cần có sự can thiệp của chuyên gia. Thì đây chính là một cái cột mốc quan trọng của deep learning. Nếu nói về lịch sử thì không phải CNN tại thời điểm này mới ra, mà nó có từ trước những năm 2000, trước những năm 1998, nhưng đến năm 2012 thì thành tựu của CNN vượt trội so với các mô hình truyền thống",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:43"
    }
  },
  {
    "page_content": "của CNN vượt trội so với các mô hình truyền thống nên nó là một cái cột mốc đáng chú ý. Thế thì cái vấn đề của những CNN đời đầu đó là gì? Để mà mãi đến năm 2022 thì nó mới có sự đột phá. Cái vấn đề đầu tiên đó là cái hàm kích hoạt của những CNN đời đầu là dùng hàm sigmoid. Sigmoid z là bằng một, chia cho một cộng e mũ trừ z. Thì cái hàm này, đạo hàm của hàm này là nó bé hơn hoặc bằng 0.5, 0.25. Và nếu như cái mạng CNN của chúng ta càng dài, càng nhiều lớp thì cái việc chúng ta tính đạo hàm này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:34",
      "end_timestamp": "0:02:21"
    }
  },
  {
    "page_content": "nhiều lớp thì cái việc chúng ta tính đạo hàm này chúng ta sẽ phải nhân nhiều lần khi thực hiện cái chain rule hay là cái quy tắc chuỗi trong cái việc mà tính đạo hàm. Thì cái việc này nó sẽ hội tụ, khiến cho cái đạo hàm của hàm loss theo cái theta, theta y là nó sẽ tiến về 0. Đối với những cái theta mà ở những cái lớp đầu tiên. Đó, thì dẫn đến là cái việc hội tụ nó chậm. Và chúng ta sẽ xem lại cái vấn đề này trong cái mục gọi là vấn đề của vanishing gradient. Và ngoài ra thì khi tăng cái số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:16",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "gradient. Và ngoài ra thì khi tăng cái số lượng layer của mô hình lên, thì cái độ chính xác của mình, người ta quan sát thấy là có tăng lên. Có tăng lên khi cái số layer tăng lên. Tại vì nó tạo ra những cái đặc trưng, nhiều mức độ khác nhau để có thể giải được nhiều cái loại bài toán và nhiều loại đối tượng. Nhưng khi đó lại xảy ra cái vấn đề, đó là vấn đề về overfitting. Khi tăng cái số lượng layer lên, thì đồng nghĩa chúng ta cũng sẽ tăng cái số lượng tham số làm cho cái mô hình nó phức tạp.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:59",
      "end_timestamp": "0:03:36"
    }
  },
  {
    "page_content": "số lượng tham số làm cho cái mô hình nó phức tạp. Thì nó sẽ gây ra cái hiện tượng là overfitting. Và để chống cái hiện tượng overfitting này, thì cũng đã có một số cái nghiên cứu là họ tìm cách tăng cường dữ liệu. Họ tìm cách tăng cường dữ liệu. Nhưng mà cái việc tăng cường dữ liệu thì đúng là có làm giảm overfitting. Nhưng mà nó lại khiến cho cái tốc độ tính toán rất là chậm. Thì đó là những cái yếu tố tác động đến cái mạng CNN đầu đời, mà khiến cho nó không có thể phát triển được. Thì cũng vì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:34",
      "end_timestamp": "0:04:14"
    }
  },
  {
    "page_content": "cho nó không có thể phát triển được. Thì cũng vì cái giai đoạn mà đầu đời, tức là trước những năm 2000, CPU là một cái tài nguyên không quá phổ biến và người ta cũng chưa có sử dụng nó, cũng như là chưa có nhiều thư viện để hỗ trợ lập trình với GPU. Nên giai đoạn này thì GPU chỉ dùng để chơi game chứ không có dùng để nghiên cứu. Thì đó chính là cái bối cảnh lịch sử trước khi mà AlexNet ra đời. Thế thì AlexNet nó đã có một số cái cải tiến chính. Đầu tiên, đó là thay vì dùng Sigmoid, thì chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:09",
      "end_timestamp": "0:04:51"
    }
  },
  {
    "page_content": "tiên, đó là thay vì dùng Sigmoid, thì chúng ta sẽ dùng ReLU. Và cái điều này thì nó sẽ giúp chúng ta giải quyết vấn đề về vanishing gradient. Rồi, khi cái mô hình sâu hơn thì chúng ta sẽ tìm cách tăng cường cái dữ liệu nhiều hơn thông qua các phép biến đổi, các phép transformation. Ví dụ như là xoay tỷ lệ tịnh tiến, thêm nhiễu hoặc là random crop. Và cái việc này thì nó sẽ giúp chúng ta giải quyết vấn đề. Ở trên là giảm vấn đề vanishing, thì ở dưới sẽ giảm vấn đề về overfitting. Nhưng khi tăng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:04:47",
      "end_timestamp": "0:05:38"
    }
  },
  {
    "page_content": "sẽ giảm vấn đề về overfitting. Nhưng khi tăng cái dữ liệu lên thì tốc độ tính toán chậm. Do đó thì đây là cái nhóm mà có sử dụng GPU để tăng tốc độ. Và tốc độ ở đây là tăng đến 50 lần. Thì ở đây nó sẽ giúp chúng ta giảm được latency. Tức là giảm cái thời gian tính toán. Và cuối cùng, đó là kỹ thuật dropout. Khai thác kỹ thuật dropout để chống hiện tượng overfitting. Thì cái hiện tượng mà overfitting, thì nó sẽ giảm vấn đề vấn đề. Và cái giải pháp sử dụng dropout thì chúng ta đã được đề cập",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:33",
      "end_timestamp": "0:06:21"
    }
  },
  {
    "page_content": "pháp sử dụng dropout thì chúng ta đã được đề cập trong những phần trước. Thì dưới đây chính là cái sơ đồ kiến trúc của AlexNet. Thì nó cũng sẽ có các cái layer. Ví dụ như đây là 1 layer, 2 layer, 5. Nếu tính luôn cả các cái layer cuối thì nó có khoảng là 7 layer. Rồi. Và tiếp theo thì chúng ta sẽ tìm cách trực quan hóa cái mạng CNN. Tức là sau khi cái thành tựu của AlexNet đã vượt trội so với các cái phương pháp mà truyền thống trước đó. Thì người ta mới tìm cách trực quan hóa cái mạng CNN này.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:12",
      "end_timestamp": "0:07:12"
    }
  },
  {
    "page_content": "ta mới tìm cách trực quan hóa cái mạng CNN này. Bằng cách đó là người ta sẽ lấy ra 1 cái lát cắt. Thì nguyên cái này người ta gọi là feature map. Còn 1 cái lát cắt này thì nó gọi là 1 feature. Nó là 1 feature. Rồi. Và cái cách trực quan cũng cực kỳ đơn giản. Đó là chúng ta sẽ lấy cái lát cắt này. Rồi sau đó chúng ta vẽ lên trên 1 cái ma trận. Thì cứ mỗi 1 cái ô trong cái ma trận này nó chính là 1 cái lát cắt. Dạ như cái này sẽ là 1 cái lát cắt gần hạng. Rồi. Thì đây chính là cái cách mà trực",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:07:09",
      "end_timestamp": "0:07:53"
    }
  },
  {
    "page_content": "gần hạng. Rồi. Thì đây chính là cái cách mà trực quan hóa. Và với cái cách trực quan hóa này thì người ta mới phát hiện ra đó là 1 số cái tính chất quan trọng của feature map thứ nhất. Đó là feature map. Nó bảo tồn được yếu tố không gian. Rồi. Tức là nếu như cái đối tượng của mình nó nằm bên tay trái. Nếu như đối tượng nằm ở bên tay trái. Thì cái feature map tương ứng với cái đối tượng đó cũng sẽ nằm phía bên tay trái. Và nó bảo tồn được cái yếu tố về thời gian không gian. Xin lỗi, nó bảo tồn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:07:50",
      "end_timestamp": "0:08:36"
    }
  },
  {
    "page_content": "tố về thời gian không gian. Xin lỗi, nó bảo tồn được cái yếu tố về không gian. Thì những cái đối tượng nào mà nằm ở phía trên. Thì khi lên feature map nếu như nó có respond tức là có thể hiện cái đặc trưng thì nó cũng sẽ nằm phía trên. Đó chính là cái đặc điểm quan trọng của cái feature map. Và nó được sử dụng để phục vụ cho các cái bài toán nâng cao về sau ví dụ như là phát hiện đối tượng. Hoặc thậm chí là phân tích ngữ nghĩa là semantic. Segmentation. Thì các cái mô hình hiện đại là đều sử",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:08:29",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "Thì các cái mô hình hiện đại là đều sử dụng cái feature map của mạng CNN để giải quyết các cái bài toán này. Thế thì cái vấn đề của AlexNet là gì? Đầu tiên đó là với cùng một cái Receptive Field. Thì chúng ta sẽ có cái khái niệm là Receptive Field. Tức là cái trường cảm nhận thông tin. Thì nó sẽ là cái vùng đặc trưng đầu vào để tạo ra một cái đặc trưng mới. Ví dụ, chúng ta có một cái feature map như thế này. Rồi, thì ở đây là trục không gian. Là HW. Thì trường tiếp nhận đó là gì? HW là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:09:20",
      "end_timestamp": "0:10:01"
    }
  },
  {
    "page_content": "Là HW. Thì trường tiếp nhận đó là gì? HW là cái trường cảm nhận thông tin. Rồi, thì ở đây là trường cảm nhận thông tin. Rồi, khi chúng ta thực hiện với cái phép biến đổi convolution, thì chúng ta sẽ có một cái kernel, một cái filter có kích thước như thế này. Và nó sẽ tạo ra một cái điểm. Tức là với một cái kernel này, một cái filter này, khi áp lên trên cái trường tiếp nhận, đây chỉ là Receptive Field, tức là RF, thì nó sẽ tạo ra một cái điểm đặc trưng ở đây. Và chúng ta lấy cái filter này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "00:09:58",
      "end_timestamp": "0:10:39"
    }
  },
  {
    "page_content": "đặc trưng ở đây. Và chúng ta lấy cái filter này chúng ta trượt trên toàn bộ tấm hình, thì chúng ta sẽ tạo ra được một cái feature. Nó là một cái dạng ma trận. Và đối với cái Receptive Field này, thì có thể nếu chúng ta dùng cái phép biến đổi bình thường, convolution bình thường, thì ở đây nó sẽ có cái độ sâu. Ví dụ ở đây độ sâu là D, thì ở đây độ sâu cũng là D. Rồi, thì cái Receptive Field chính là cái vùng này. Là cái vùng đầu vào. Đây là cái vùng đầu vào. Được sử dụng để tạo ra một cái đặc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:10:37",
      "end_timestamp": "0:11:32"
    }
  },
  {
    "page_content": "vùng đầu vào. Được sử dụng để tạo ra một cái đặc trưng mới. Vậy thì khi cái mạng của mình nó có nhiều layer, thì các cái feature map sau, nó sẽ có cái Receptive Field càng lớn. Do đó thì tại sao chúng ta lại phải cần có cái 5x5 và 7x7, thì cái điều này có nghĩa là sao? Ví dụ chúng ta có một cái feature map như thế này. Chúng ta nhân với lại một cái kernel có kích thước là 3x3. Rồi thì nó sẽ tạo ra một cái feature map mới. Rồi, sau đó lại tiếp tục nhân với lại một cái kernel là 3x3. Rồi, nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:11:31",
      "end_timestamp": "0:12:20"
    }
  },
  {
    "page_content": "nhân với lại một cái kernel là 3x3. Rồi, nó sẽ tạo ra một cái feature map mới. Thế thì ở những cái feature map sau, đây là cái feature map sau này. Một cái điểm đặc trưng ở đây, nó được tạo bởi một cái vùng có kích thước là 3x3 ở phía trước. Sau đó, và lưu ý là đây lại là một cái feature. Đây là một cái feature. Với mỗi điểm ở đây, nó lại tạo ra bởi một cái vùng 3x3 phía trước. Rồi cái điểm tiếp theo, nó lại là một cái vùng có kích thước là 3x3, nhưng nó sẽ có overlap với lại cái vùng receptive",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": "0:12:15",
      "end_timestamp": "0:13:14"
    }
  },
  {
    "page_content": "nhưng nó sẽ có overlap với lại cái vùng receptive field của cái điểm bên trái một chút. Do đó thì nó sẽ nới ra thêm một pixel nữa. Rồi, thêm cái điểm nữa thì nó lại tiếp tục nó nới ra. Thì chúng ta thấy là với cái vùng 3x3 bên đây, thì nó sẽ tạo ra cái bề ngang của mình là 1, 2, 3, 4, 5. Tức là cái vùng nếu mà chúng ta đi xuống các cái điểm ở phía dưới nữa, thì nó sẽ tạo ra một cái vùng đó là 5x5. Như vậy thì, hai cái feature map phía sau, đúng không? Nó đã tổng hợp được đầy đủ thông tin đối",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": "0:13:11",
      "end_timestamp": "0:13:57"
    }
  },
  {
    "page_content": "không? Nó đã tổng hợp được đầy đủ thông tin đối với cái kernel nhỏ, đó là 3x3. Còn cái feature map phía sau, nó lại là một cái vùng, xin lỗi, nó lại là tạo ra một cái vùng là kích thước là 5x5. Rõ ràng là với cùng một cái receptive field là 5x5, thì thay vì chúng ta sử dụng cái filter kích thước là 5x5, thì chúng ta sẽ sử dụng hai cái phép biến đổi, hai cái phép convolution 3x3 liên tiếp nhau, thì nó sẽ tương đương hai cái layer mà 3x3, thì nó sẽ tương đương với một cái layer bằng 5x5. Về mặt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 19,
      "start_timestamp": "0:13:53",
      "end_timestamp": "0:14:11"
    }
  },
  {
    "page_content": "sẽ tương đương với một cái layer bằng 5x5. Về mặt tính lượng thì cái giải pháp nào nó sẽ có lợi hơn? Nếu như chúng ta dùng hai cái layer 3x3, thì ở đây cái số tham số của mình sẽ là 2x3, 3 là bằng 18, trong khi đó một cái 5x5 thì nó lên đến là 25 tham số, thì rõ ràng là 18 tham số nó sẽ ít hơn 25 tham số, thì việc này nó có thể giúp chúng ta, nếu như mà cùng một cái độ sâu, thì nó sẽ giúp chúng ta giải quyết được hiện tượng convolution. Cảm ơn các bạn đã xem video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Kih2WcksxyM",
      "filename": "Kih2WcksxyM",
      "title": "[CS315 - Chương 2] Các biến thể của CNN (Phần 1)",
      "chunk_id": 20,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Trước khi đến với những mô hình học sâu, thì chúng ta sẽ có một trong những nền tảng đầu tiên của Deep Learning, đó chính là mạng Neural Network. Đây có thể nói là một trong những mạng học sâu đời đầu. Và ý tưởng của mạng Neural Network là một biến thể cho rất nhiều kiến trúc về sau, cụ thể là CNN, RNN và thậm chí là Transformer. Bài báo là Attention Ion Unit Nhưng thực tế thì trong kiến trúc này vai trò của mạng Neural Network hay là thành phần MLP trong bài báo đó họ dùng là MLP thì vai trò",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 0,
      "start_timestamp": "0:00:15",
      "end_timestamp": "0:01:07"
    }
  },
  {
    "page_content": "MLP trong bài báo đó họ dùng là MLP thì vai trò này cực kỳ quan trọng trong việc phi tuyến hóa bài toán của mình để giúp giải quyết được bài toán phức tạp Nó là một mô hình bước đầu để đánh dấu vào việc giải quyết các bài toán phi tuyến tính. Trong các mô hình như CNN và ANN, chúng ta cũng có thể thấy có chữ NN ở đây. Nó chính là chữ Neural Network. Vậy thì chúng ta có thể thấy là vai trò của mạng Neural Network rất là quan trọng. Sự khác biệt của mạng Neural Network so với những kiến trúc mạng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 1,
      "start_timestamp": "0:01:05",
      "end_timestamp": "0:01:54"
    }
  },
  {
    "page_content": "mạng Neural Network so với những kiến trúc mạng thuộc nhóm tuyến tính Nếu chúng ta bỏ 2 lớp ẩn này đi và bỏ dấu 3 chấm này đi thì nó chính là Softmax Regression Đây chính là một mô hình hồi quy Softmax Nhưng khi chúng ta chèn thêm các lớp ẩn, ở đây nó gọi là lớp ẩn Hoặc thuật ngữ tiếng Anh gọi là hidden layer khi chúng ta thêm các hidden layer này vào thì nó sẽ giúp chúng ta giải quyết được các bài toán phi tuyến tính và chúng ta cũng có một quy tắc đó là ngay sau lớp biến đổi tuyến tính là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 2,
      "start_timestamp": "0:01:46",
      "end_timestamp": "0:02:35"
    }
  },
  {
    "page_content": "quy tắc đó là ngay sau lớp biến đổi tuyến tính là sigma thì chúng ta phải có một cái hàm kích hoạt hàm này bắt buộc phải là một cái hàm phi tuyến tại vì nếu không thì hai lớp biến đổi tuyến tính liên tiếp thì nó sẽ tạo ra thành một tổ hợp tuyến tính các bài toán phi tuyến do đó chúng ta phải có những thành phần phi tuyến tính như thế này Và tham số của mô hình của chúng ta sẽ được đánh số từ theta1, theta2, cho đến thetaL tức là ở đây chúng ta có L layer Và ở cái module cuối cùng đó là hàm Loss",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 3,
      "start_timestamp": "0:02:32",
      "end_timestamp": "0:03:20"
    }
  },
  {
    "page_content": "L layer Và ở cái module cuối cùng đó là hàm Loss Function, hàm độ lỗi thì chúng ta cũng sẽ sử dụng công thức Cross entropy chúng ta không thay đổi cái chỗ này và ở đây thì chúng ta sẽ minh họa xem ý nghĩa hình học của mạng Neural Network như thế nào thì ở bên trái chúng ta có 1 cái ví dụ là 2 tập điểm hình tròn và tam giác là có mối quan hệ phi tuyến tính tại vì chúng ta không thể nào dùng 1 cái đường thẳng để chia 2 tập điểm này ra làm 2 phần và dùng đường cong như thế này, thì mới có thể chia",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 4,
      "start_timestamp": "0:03:18",
      "end_timestamp": "0:04:09"
    }
  },
  {
    "page_content": "dùng đường cong như thế này, thì mới có thể chia được. Vậy thì làm sao mạng Neural Network này có thể phân chia 2 tập tròn và tam giác này ra làm 2 phần? Thì chúng ta đã biết trong mạng Logistic Regression thì mỗi một cái node này tương ứng là một đường phân lớp tuyến tính. Và cụ thể là các trọng số mà nối đến Neural Network này pham tham số của trường thẳng của mình. Như vậy, cái Neural đầu tiên nó sẽ giúp cho chúng ta tạo ra được 1 cái đường phân lớp, tách ra làm 2 phần và đây là 1 cái bộ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 5,
      "start_timestamp": "0:04:02",
      "end_timestamp": "0:04:42"
    }
  },
  {
    "page_content": "phân lớp, tách ra làm 2 phần và đây là 1 cái bộ phân loại yếu. Nhưng nhiều cái bộ phân loại yếu ráp lại với nhau. Chúng ta có nhiều cái bộ phân loại yếu và ở những cái nodes tiếp theo, nó đã tổng hợp có trọng số các cái nodes ở đằng trước. Như vậy là nó đang tạo ra các cái đặc trưng cấp cao các đặc trưng cấp cao tổng hợp từ những đặc trưng trước đó Mỗi đặc trưng ở phía trước sẽ là đường thẳng như thế này Và khi chúng ta tính tổng trọng số lại thì nó đã giúp chúng ta dần dần phân tách tập hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 6,
      "start_timestamp": "0:04:41",
      "end_timestamp": "0:05:28"
    }
  },
  {
    "page_content": "nó đã giúp chúng ta dần dần phân tách tập hình tròn và hình tam giác ra làm hai phần tách biệt như thế này Đó chính là ý nghĩa hình học của mạng Neural Network Các layer đầu tiên sẽ tạo ra các đặc trưng cấp thấp phân tách ra thành 2 phần như thế này nhưng ở những đặc trưng phía sau sẽ tạo ra những đặc trưng cấp cao hơn, phi tuyến tính hơn và phức tạp hơn để giải quyết các bài toán phức tạp của chúng ta Đó chính là sơ lược về kiến trúc mạng Neural Network Hãy subscribe cho kênh Ghiền Mì Gõ Để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 7,
      "start_timestamp": "0:05:18",
      "end_timestamp": "0:05:47"
    }
  },
  {
    "page_content": "Network Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=lO0rvNo-49s",
      "filename": "lO0rvNo-49s",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 4 (New)",
      "chunk_id": 8,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến một mô hình, cơ bản tiếp theo là mô hình Softmax. Cái đường đi của mô hình này là nó nằm trong nhóm tuyến tính và thuộc bài toán là phân loại. Nhưng trong trường hợp này, số lớp phân loại của chúng ta là nhiều hơn 2, tức là ca lớn hơn 2. Mô hình dưới dạng đồ thị của Softmax Regression là như sau. Input đầu vào của chúng ta cũng có các đặc trưng, đó là Input Feature và đồng thời chúng ta cũng có thành phần Bias. Nếu như trong mô hình Logistic Regression, mỗi một đặc trưng,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:06"
    }
  },
  {
    "page_content": "mô hình Logistic Regression, mỗi một đặc trưng, mỗi một Neuron chúng ta đưa vào để xử lý, thì nó đều có một phần tổng và một hàm kích hoạt, tức là một phép biến đổi tuyến tính. Ngay sau phép biến đổi tuyến tính, chúng ta sẽ có một hàm kích hoạt phi tuyến. Và để giải quyết được bài toán phân lớp đa lớp, chúng ta có thể sử dụng nhiều hơn một Neuron này. Tuy nhiên, việc chúng ta sử dụng nhiều Neuron như vậy, nó có khả năng gây ra hiện tượng gọi là nhập nhằng. Cụ thể là trong mô hình của chúng ta,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:01:54"
    }
  },
  {
    "page_content": "nhập nhằng. Cụ thể là trong mô hình của chúng ta, nếu như chúng ta có các tập điểm dạy như thế này, thì nếu chúng ta dùng ba cái node này độc lập nhau, thì nó sẽ tách ra làm ba cái phần mặt phẳng mỗi một node tương ứng với lại một cái đường thẳng. Thì nó sẽ có những cái khu vực mà chúng ta sẽ không biết là nó sẽ xếp về lớp nào. Ví dụ nếu theo cái đường thẳng số 1 này, thì chúng ta sẽ nói cái điểm chấm hỏi này là hình tròn. Nhưng nếu chiếu theo cái đường phân lớp số 2 này, thì chúng ta nói đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 2,
      "start_timestamp": "0:01:46",
      "end_timestamp": "0:02:36"
    }
  },
  {
    "page_content": "đường phân lớp số 2 này, thì chúng ta nói đó là hình cộng. Thì do đó nó tạo ra sự nhập nhằng. Và mô hình Softmax Regression là sẽ loại bỏ đi cái thành phần sigmoid độc lập này để đưa chung vào một cái hàm Softmax. Thì qua cái hàm Softmax này chúng ta sẽ tính ra các cái giá trị y ngã 1, y ngã 2 và y ngã k. Y ngã 1 nếu mà bình thường nó tính thì nó chỉ dựa trên một giá trị z1 thôi. Nhưng qua cái hàm Softmax thì nó sẽ phải có cái sự tổng hợp của tất cả những cái giá trị z1, z2 cho đến zk. Thì cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 3,
      "start_timestamp": "0:02:27",
      "end_timestamp": "0:03:19"
    }
  },
  {
    "page_content": "cả những cái giá trị z1, z2 cho đến zk. Thì cái công thức Softmax của mình cụ thể nó sẽ là Softmax của z. Ví dụ như ở đây là zi. Nhưng nó sẽ có sự tham gia của các cái z còn lại là từ z1 cho đến zk. Và nó sẽ là bằng e-mũ của zi chia cho tổng của e-mũ zk với k là chạy từ 1 cho đến k lớn. k lớn là tổng số lớp của mình. Thì cái công thức Softmax này nó sẽ có rất nhiều những cái điểm lợi. Thứ nhất đó là tính đạo hàm của nó cũng dễ. Nhưng đồng thời là nó sẽ đưa về một cái không gian xác suất trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 4,
      "start_timestamp": "0:03:12",
      "end_timestamp": "0:04:09"
    }
  },
  {
    "page_content": "là nó sẽ đưa về một cái không gian xác suất trong đó các cái thành phần y này, y ngã y này của chúng ta thì đều là lớn hơn 0 và bé hơn 1. Các cái giá phân bố xác suất của mình thì nó là từ 0 cho đến 1. Và đồng thời tổng của các cái y ngã y này thì đều là bằng 1 với y chạy từ 1 cho đến k. Thì đây chính là đưa về một cái không gian xác suất khá là đẹp. Và chúng ta sẽ dựa trên cái y ngã nào mà cho cái xác suất cao nhất thì chúng ta sẽ kết luận nó thuộc về cái phần lớp đó. Còn đối với cái hàm lỗi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 5,
      "start_timestamp": "0:04:00",
      "end_timestamp": "0:04:59"
    }
  },
  {
    "page_content": "thuộc về cái phần lớp đó. Còn đối với cái hàm lỗi thì chúng ta sẽ sử dụng cái hàm Cross entropy. Thế thì Cross entropy nếu như cái thành phần Softmax này chúng ta ký hiệu là y ngã. Thì khi đó hàm lỗi J theta của Xi thì sẽ được ghi là bằng Cross entropy của y ngã y. Thì cái công thức của mình nó sẽ là bằng log y, log y ngã trừ và tổng với y chạy từ 1 cho đến k. Và ở đây là chỉ số y. Thì đây là công thức của Cross entropy. Tương tự như là binary Cross entropy thì Cross entropy nó sẽ tạo ra cái sự",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 6,
      "start_timestamp": "0:04:45",
      "end_timestamp": "0:05:40"
    }
  },
  {
    "page_content": "entropy thì Cross entropy nó sẽ tạo ra cái sự mô hình trừng phạt nặng hơn khi chúng ta dự đoán sai. Và sẽ giúp cho cái mô hình của mình huấn luyện nhanh hơn. Thì sau đây chúng ta sẽ xem cái ý nghĩa về mặt hình học của các cái tham số của mình. Đầu tiên đó là chúng ta sẽ thấy cái mô hình của mình nó sẽ có một cái tham số là theta. Và qua cái tham số cái mô hình của mình nó sẽ chia cái không gian của mình ra làm nhiều phần. Nếu như trong cái phần trước chúng ta thấy là chúng ta dùng mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 7,
      "start_timestamp": "0:05:32",
      "end_timestamp": "0:06:11"
    }
  },
  {
    "page_content": "phần trước chúng ta thấy là chúng ta dùng mô hình logistic theo kiểu là màu vàng và không phải màu vàng. Một xanh lá và không phải xanh lá thì nó sẽ chia ra thành các cái không gian như thế này. Và nó sẽ có những cái khu vực là bị nhập nhằng như thế này. Mình sẽ không biết được là nó thuộc về lớp nào. Nhưng qua cái mô hình softmax regression Mô hình hồi quy softmax thì cái đầu ra của mình là nó sẽ cho một cái phân bố xác suất. Và với cái phân bố xác suất này thì chúng ta chỉ có thể từ một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 8,
      "start_timestamp": "0:06:05",
      "end_timestamp": "0:06:48"
    }
  },
  {
    "page_content": "xác suất này thì chúng ta chỉ có thể từ một cái điểm chúng ta chỉ có thể kết luận nó thuộc về một lớp duy nhất mà thôi. Nhờ cái cách mà chuẩn hóa theo kiểu softmax này nếu ở đây thì chúng ta sẽ gán nó về lớp màu vàng. Nếu ở đây thì có thể gán về lớp màu đỏ. Do đó nó sẽ chia cái không gian của mình ra. Chia cái không gian của mình ra. Ví dụ vậy thành 4 phần và với mỗi một cái điểm thì nó sẽ thuộc vào một phần chứ nó không có thuộc vào hai cái phần. Gây ra cái sự nhập nhằng giống như trong cái mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 9,
      "start_timestamp": "0:06:41",
      "end_timestamp": "0:06:52"
    }
  },
  {
    "page_content": "Gây ra cái sự nhập nhằng giống như trong cái mô hình logistic regression.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=m19884tczqs",
      "filename": "m19884tczqs",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)",
      "chunk_id": 10,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với một mô hình tạo sinh đầu tiên, đó là mô hình Autoencoder hay còn gọi là bộ tự mã hóa. Nền tảng của mô hình này là dựa trên hướng tiếp cận là học, không giám sát. Mục tiêu đó là làm sao chúng ta sẽ biểu diễn được đặc trưng của dữ liệu gốc ban đầu. Ví dụ như đầu vào của chúng ta là ảnh của một con số viết tay. Chúng ta sẽ tìm cách biểu diễn ảnh này thành một vector đặc trưng, trong đó nó có chiều thấp hơn. Giả sử như ảnh của chữ số viết tay có kích thước 28 x 28, đây là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:04"
    }
  },
  {
    "page_content": "của chữ số viết tay có kích thước 28 x 28, đây là kích thước chuẩn trong tập dữ liệu MNIST. 28 x 28 mà khi chúng ta flatten, tạo thành một vector, nó sẽ có kích thước 784 chiều. Như vậy thì autoencoder là bước đầu tiên là làm sao để học ra được một cách biểu diễn vector x có số chiều lớn này, và một vector z có số chiều nhỏ hơn, tức là z này phải có số chiều nhỏ hơn 784 chiều này. Và cái dữ liệu mà chúng ta học là dữ liệu không có gán nhãn, tức là chúng ta chỉ có con số này thôi, chứ chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 1,
      "start_timestamp": "0:00:55",
      "end_timestamp": "0:01:42"
    }
  },
  {
    "page_content": "là chúng ta chỉ có con số này thôi, chứ chúng ta không có cái nhãn, đây là số 3. Thì dữ liệu huấn luyện của chúng ta là dữ liệu không có gán nhãn, vì chúng ta đang tiếp cận theo cái hướng là học không giám sát. Thì cái encoder này nó sẽ học một ánh xạ từ cái dữ liệu gốc ban đầu là nhiều chiều sang một cái dữ liệu z là trong một cái không gian ẩn, thấp chiều hơn. Thì nếu như chúng ta vẽ trực quan hóa thì giả sử như đây là cái không gian flatten, tức là một cái không gian tiềm ẩn của mình. Và đầu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 2,
      "start_timestamp": "0:01:36",
      "end_timestamp": "0:02:18"
    }
  },
  {
    "page_content": "là một cái không gian tiềm ẩn của mình. Và đầu vào của mình sẽ có một cái hình là x, cái dữ liệu này là dữ liệu x, có số chiều lớn, chúng ta sẽ map nó vào một cái không gian z. Và z này có số chiều nhỏ hơn, số chiều của x. Thì đây là cái bước đầu tiên là encode. Nhưng mà làm sao để có thể học được cái không gian ẩn này? Tại vì nếu như chúng ta chỉ đơn giản đó là làm giảm cái số chiều xuống thì chúng ta có thể dùng một cái trực quan rất là ngây thơ. Đó chính là chúng ta sẽ random chọn một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 3,
      "start_timestamp": "0:02:09",
      "end_timestamp": "0:02:51"
    }
  },
  {
    "page_content": "thơ. Đó chính là chúng ta sẽ random chọn một cái vector z có số chiều nhỏ hơn số chiều của x. Là sao? Thế thì nó thiếu một cái sợi dây để liên kết về mặt ý nghĩa giữa z và x. Nó thiếu một cái sợi dây liên kết đó. Do đó thì chúng ta sẽ tìm cách để huấn luyện mô hình, sao cho nó có thể sử dụng được cái đặc trưng z này. Sử dụng được cái đặc trưng z để từ đó nó có thể tái tạo ngược trở lại được cái x. Chứ còn nếu không thì chúng ta random một cái vector là sao? Thì như vậy, cái mục tiêu là tái tạo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 4,
      "start_timestamp": "0:02:42",
      "end_timestamp": "0:03:23"
    }
  },
  {
    "page_content": "là sao? Thì như vậy, cái mục tiêu là tái tạo lại được cái dữ liệu gốc x. Nó sẽ là cái sợi dây vô hình để liên kết cái đặc trưng z, cái đặc trưng biểu diễn z với lại cái ảnh gốc ban đầu. Và để làm được việc này thì chúng ta sẽ cần có một cái mô hình, đó là một cái decoder. Với cái decoder này nó sẽ giúp cho chúng ta tái tạo ra được một cái x mũ. Và cái x mũ này thì mình muốn là nó phải có cái nội dung giống với lại cái ảnh đầu vào x. X và x mũ phải có nội dung giống với lại cái ảnh đầu vào x.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 5,
      "start_timestamp": "0:03:16",
      "end_timestamp": "0:04:12"
    }
  },
  {
    "page_content": "phải có nội dung giống với lại cái ảnh đầu vào x. Như vậy thì decoder nó sẽ tìm cách để học một cái ánh xạ, học một cái ánh xạ từ cái không gian ẩn z về để xây dựng lại cái x mũ này. Thế thì nếu chúng ta trực quan hóa trong cái không gian tiềm ẩn, latent, latent space, từ cái ảnh ban đầu là x, đây là x, thì chúng ta qua cái encoder chúng ta sẽ ánh xạ nó sang một cái không gian latent, để tạo ra thành một cái vector có số chiều ít hơn là z. Và để mà có cái sợi dây liên kết giữa z với lại x thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 6,
      "start_timestamp": "0:03:59",
      "end_timestamp": "0:04:42"
    }
  },
  {
    "page_content": "mà có cái sợi dây liên kết giữa z với lại x thì chúng ta phải tái tạo ngược trở lại được. Thì để cho cái việc này tạo ra được mối quan hệ về mặt ý nghĩa giữa vector biểu diễn z và x thì chúng ta phải có thêm cái thành phần tái tạo. Về mặt công thức, làm sao chúng ta có thể tái tạo lại được? Thì đó chúng ta sẽ phải có một cái hàm đó gọi là hàm loss. Và cái hàm loss này là một cái hàm mean squared error, là lấy sai số giữa cái x và x mũ. Chúng ta lấy x trừ x mũ rồi bình phương lên, thì cái hàm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 7,
      "start_timestamp": "0:04:36",
      "end_timestamp": "0:05:22"
    }
  },
  {
    "page_content": "lấy x trừ x mũ rồi bình phương lên, thì cái hàm lỗi này là nó không cần nhãn. Tại vì sao? Nhãn của nó thật ra cũng chính là cái x. Nhãn của nó cũng chính là x. Chúng ta lấy x trừ cho x mũ rồi bình phương. Thì đây là mean squared error. Và với cái biểu diễn gọn gàng hơn, tức là thay vì chúng ta sẽ phải có nhiều lớp biến đổi như thế này, rồi nhiều lớp biến đổi như thế này. Thì từ nay về sau chúng ta chỉ cần dùng một cái ký hiệu hình thang. Hai ký hiệu hình thang đó là từ x chúng ta đưa về z và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 8,
      "start_timestamp": "0:05:17",
      "end_timestamp": "0:05:58"
    }
  },
  {
    "page_content": "hiệu hình thang đó là từ x chúng ta đưa về z và chúng ta dùng cái hình thang là phía bên trái là lớn, và phía bên phải đó là cái cạnh nhỏ, tức là ám chỉ từ một không gian nhiều chiều về không gian ít chiều. Sau đó decoder, đây là encoder. Còn decoder là chúng ta sẽ làm một cái hình thang ngược lại, là từ không gian ít chiều hơn về không gian nhiều chiều hơn. Nó sẽ tạo ra cái thằng x mũ. Và sai số cái hàm loss của mình lúc này vẫn dùng là một cái hàm, không gán nhãn. Đó là chúng ta dùng chính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 9,
      "start_timestamp": "0:05:53",
      "end_timestamp": "0:06:32"
    }
  },
  {
    "page_content": "hàm, không gán nhãn. Đó là chúng ta dùng chính cái x sẽ là cái nhãn luôn. Thì từ nay về sau chúng ta sẽ ký hiệu như thế này cho nó gọn. Và số chiều trong không gian ẩn thì nó sẽ tương ứng với lại cái chất lượng của cái việc tái tạo. Nếu như chúng ta dùng cái vector biểu diễn z mà chỉ có hai chiều, thì khi chúng ta tái tạo lại thì cái chất lượng nó không có được tốt, nó sẽ bị như thế này, nó mờ, rồi không rõ nét. Nhưng nếu mà chúng ta tăng cái số chiều lên là 5 chiều, thì chúng ta thấy nó đã rõ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 10,
      "start_timestamp": "0:06:27",
      "end_timestamp": "0:07:00"
    }
  },
  {
    "page_content": "chiều lên là 5 chiều, thì chúng ta thấy nó đã rõ ràng hơn. Còn cái round trip thì chúng ta thấy nó là rất là rõ. Rõ, thì khi chúng ta tăng cái số chiều lên, nó sẽ giúp cho chúng ta tạo ra cái dữ liệu mà gần với lại cái round trip hơn. Thì không gian ẩn nhỏ hơn, cái không gian ẩn nhỏ hơn, nó sẽ là một cái nút thắt, là một cái bottleneck cho huấn luyện rất là lớn. Tại vì từ một không gian nhiều chiều, giảm xuống một không gian ít chiều hơn, nó đã mất thông tin rồi. Nhưng mà nếu mà mất những thông",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 11,
      "start_timestamp": "0:06:57",
      "end_timestamp": "0:07:38"
    }
  },
  {
    "page_content": "thông tin rồi. Nhưng mà nếu mà mất những thông tin mà không quan trọng thì không sao. Nhưng mà đoạn này nếu nó quá nhỏ, nó quá nhỏ, ví dụ như 2 chiều, thì nó sẽ không đủ thông tin để có thể tái tạo được về cái ảnh gốc ban đầu. Nó sẽ tạo ra cái bottleneck. Vậy thì cái autoencoder là nó sẽ cho chúng ta học cái biểu diễn đặc trưng, là để buộc cái mạng, nó phải học được cái cách biểu diễn trong cái không gian ẩn thấp chiều hơn. Đó là cái bottleneck hidden layer, là từ một cái vector x về một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 12,
      "start_timestamp": "0:07:34",
      "end_timestamp": "0:08:20"
    }
  },
  {
    "page_content": "hidden layer, là từ một cái vector x về một cái vector z. Là nó buộc cái mạng, nó sẽ phải học về cái không gian ít chiều hơn. Đồng thời với cái reconstruction loss, từ cái này, chúng ta tái tạo ngược trở lại để tạo ra cái x-mũ, thì nó sẽ buộc không gian ẩn phải lưu giữ lại cái đặc trưng. Tức là cái z này nó không phải là một cái vector ngẫu nhiên nữa, mà nó phải lưu giữ được. Nó phải lưu giữ được, hoặc là mã hóa được, càng nhiều thông tin về cái dữ liệu gốc ban đầu, càng tốt. Thì cái này là từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 13,
      "start_timestamp": "0:08:14",
      "end_timestamp": "0:08:28"
    }
  },
  {
    "page_content": "dữ liệu gốc ban đầu, càng tốt. Thì cái này là từ x-mũ mà chúng ta tái tạo ngược trở lại về x, thì nó gọi là tự mã hóa là autoencoding. Và autoencoding thì viết tắt của chữ là automatically encoding data, hay còn gọi là self encoding. Rồi thì đây chính là cái kiến trúc của autoencoder.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=mrI-KCWTr2I",
      "filename": "mrI-KCWTr2I",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 2",
      "chunk_id": 14,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Tiếp theo, chúng ta sẽ cùng tìm hiểu cách thức mà một mạng tạo sinh đối kháng, mạng GAN được huấn luyện như thế nào. Đầu tiên, chúng ta sẽ nhắc lại, trong một kiến trúc của mạng GAN, sẽ bao gồm hai mô đun. Mô hình G mục tiêu là tạo ra dữ liệu giả để cố đánh lừa mô hình phân loại D. Còn ngược lại, D là mô hình phân loại cố gắng thực hiện xác định xem dữ liệu nào là thật và dữ liệu nào giả do G tạo ra. Khi huấn luyện, với mục tiêu đối nghịch cho D và G, chúng ta sẽ tạo ra một hàm loss đặc biệt.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:56"
    }
  },
  {
    "page_content": "D và G, chúng ta sẽ tạo ra một hàm loss đặc biệt. Đối với điểm tối ưu toàn cục, G có khả năng tạo ra một phân phối là dữ liệu thật. Tức là khi mô hình này huấn luyện thành công, G sẽ càng lúc cho cái độ chính xác, ảnh thực càng lúc càng giống thật. Và hàm lỗi trong việc huấn luyện một mạng GAN sẽ được tính như thế nào? Thế thì trước mắt chúng ta sẽ xét đối với mô hình phân loại D. Đối với mô hình phân loại D, chúng ta sẽ tìm cách cực đại hóa kỳ vọng này. Trong đó, đối với dữ liệu thật, chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:47",
      "end_timestamp": "0:01:53"
    }
  },
  {
    "page_content": "này. Trong đó, đối với dữ liệu thật, chúng ta luôn mong muốn đó là xác suất để dự đoán điểm dữ liệu thật là cao nhất. Tức là nó sẽ tiến về 1. Ngược lại, đối với những điểm dữ liệu FAKE, tức là dữ liệu giả, thì người ta sẽ luôn mong muốn là cái giá trị này tiến về 0. Tức là nó thấp. Khi thằng này tiến về 0, tức là nó cho biết đó là dữ liệu giả, thì 1 trừ 0, nguyên cả cái vế này, nó sẽ càng cao, càng tốt. Và nó sẽ tiến về 1. Nó cũng hoàn toàn tương tự như cái vế bên đây. Như vậy thì tổng hợp lại,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:42",
      "end_timestamp": "0:02:41"
    }
  },
  {
    "page_content": "tự như cái vế bên đây. Như vậy thì tổng hợp lại, đó là cả dữ liệu thật và dữ liệu giả, thì log của DX cộng cho log của 1 trừ D của GX, thì nó đều phải được hướng đến sao cho đạt giá trị nhỏ nhất. Và chúng ta chú ý là tại thời điểm này, chúng ta sẽ đi tìm cái discriminator, tức là cái bộ phân loại. Còn G trong trường hợp này, đó là cố định. G trong trường hợp này là cố định. Rồi, và G của G chính là cái dữ liệu fake này nè. Đây chính là G của G. Thì qua cái D, nó sẽ cố gắng làm sao cho cái D của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:36",
      "end_timestamp": "0:03:30"
    }
  },
  {
    "page_content": "qua cái D, nó sẽ cố gắng làm sao cho cái D của G, tức là cái xác suất thuộc về cái lớp dữ liệu thật là thấp nhất có thể, tức là tiến về 0. Rồi, thì đây là cái phần hàm lỗi cho discriminator, tức là cái mô hình phân loại. Chúng ta sẽ đến một cái hàm lỗi tiếp theo liên quan đến cái bộ tạo sinh, tức là cái mô hình tạo sinh G. Thì nhắc lại, G mục tiêu đó là làm sao cho cái dữ liệu giả của mình, nó có thể đánh lừa được cái mô hình phân loại D. Thế thì ở khía cạnh ngược lại, chúng ta thấy là đối",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:03:22",
      "end_timestamp": "0:04:07"
    }
  },
  {
    "page_content": "thì ở khía cạnh ngược lại, chúng ta thấy là đối chiếu với cái công thức loss của discriminator, chúng ta sẽ thấy nó có cái dạng thức giông giống nhau. Nó sẽ có dạng thức giống nhau. Cái khác ở đây đó là thay vì chúng ta tìm max, thì ở đây chúng ta lại tìm min. Tức là chúng ta đang đi làm một cái công việc ngược lại. Và tương tự như trong cái công thức hàm loss của discriminator, thì cái công thức của logDx, thì dx của mình, đó là cái xác suất thuộc về cái lớp dữ liệu giả. Dữ liệu thật. Thì nếu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:04:01",
      "end_timestamp": "0:05:10"
    }
  },
  {
    "page_content": "về cái lớp dữ liệu giả. Dữ liệu thật. Thì nếu như thật sự đó là dữ liệu thật, thì chúng ta luôn đối với generator, chúng ta muốn kéo cái xác suất đó xuống thấp. Càng thấp càng tốt. Còn đối với cái dữ liệu giả thì sao? Đối với dữ liệu giả thì đây là cái ảnh tạo bởi dữ liệu giả. Và dữ liệu dx, tức là cái xác suất mà để phân biệt đó là dữ liệu thật hay không, thì mình lại luôn mong muốn đó là càng cao càng tốt. Tại vì đó là dữ liệu giả, thì mình muốn đánh lừa mà. Mình muốn đánh lừa nên mình phải",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:05:00",
      "end_timestamp": "0:05:44"
    }
  },
  {
    "page_content": "đánh lừa mà. Mình muốn đánh lừa nên mình phải đưa cái xác suất này nó lên cao. Và nó càng tiến về 1 thì càng tốt. Do đó thì 1-D của dx thì nó sẽ tiến về 0, tức là càng thấp càng tốt. Nguyên cái vế này sẽ là càng thấp càng tốt. Rồi như vậy tóm lại cả 2 số hạng đó là logD và log của 1-D của G(z) thì đều là càng thấp càng tốt. Do đó thì chúng ta sẽ đi tìm D sao cho cái kỳ vọng này là nhỏ nhất. Lưu ý là cái công thức kỳ vọng ở đây là được tính trên những cái mẫu dữ liệu mà mình đã lấy mẫu. Rồi và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:05:35",
      "end_timestamp": "0:06:37"
    }
  },
  {
    "page_content": "những cái mẫu dữ liệu mà mình đã lấy mẫu. Rồi và trong công thức này chúng ta đi tìm D để cho tối ưu do đó, D của mình sẽ là 1 cái hàm cố định. Vậy thì khi chúng ta kết hợp cả huấn luyện cả D và G thì sao? Khi chúng ta huấn luyện cả D và G thì chúng ta sẽ có 1 cái hàm, nó gọi là hàm minimax. Vì đây là 1 cái bài toán gọi là minimax. Trong đó cái vế bên trong là chúng ta sẽ phải đi tìm D sao cho cái kỳ vọng này là lớn nhất trước. Tức là chúng ta sẽ đi huấn luyện D trước. Sau khi chúng ta huấn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:06:23",
      "end_timestamp": "0:07:19"
    }
  },
  {
    "page_content": "sẽ đi huấn luyện D trước. Sau khi chúng ta huấn luyện D cho tốt xong thì chúng ta sẽ đi tiếp tục huấn luyện G. Chúng ta sẽ tìm G sao cho nguyên cái vế này là nhỏ nhất. Thì khi đó là D của mình sẽ là cố định. Tức là khi chúng ta đi tìm G để cho cái giá trị của mình nhỏ nhất thì D lúc này nó đã được cố định rồi. Và cứ như vậy thì chúng ta sẽ, cái quá trình này chúng ta sẽ cập nhật sao cho đến khi nào mà nó hội tụ. Thì khi mà nó hội tụ, tức là D nó trở nên là càng lúc càng tốt và G cũng càng lúc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:10",
      "end_timestamp": "0:07:54"
    }
  },
  {
    "page_content": "trở nên là càng lúc càng tốt và G cũng càng lúc trở nên càng tốt. Thì khi đó là cái mô hình của mình, cả 2 thằng giống như là 2 đôi bạn cùng tiến. G thì sẽ càng lúc càng tạo ra những cái tấm ảnh chất lượng hơn, chân thật hơn. Còn D thì cái khả năng phân biệt, cái ảnh thật và ảnh giả ngày càng cao. Do là cái khả năng giả hình của G càng cao thì D của mình cũng sẽ càng có tính phân biệt cao hơn. Do đó thì G và D giống như là 2 đôi bạn cùng tiến là sẽ là càng lúc cái khả năng của nó sẽ, cái hiệu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:07:44",
      "end_timestamp": "0:08:27"
    }
  },
  {
    "page_content": "sẽ là càng lúc cái khả năng của nó sẽ, cái hiệu năng của nó sẽ ngày càng cao. Vậy thì khi mà cái mô hình, sau khi cái mô hình của mình đã được huấn luyện, thì chúng ta sẽ sử dụng G như là một cái hàm tạo sinh để tạo ra cái dữ liệu mới mà mình chưa từng bắt gặp trước đó. Cái cách tạo sinh của chúng ta cũng rất là dễ. Cái thành phần D thì chúng ta sẽ bỏ qua và không sử dụng. Và chúng ta chỉ cần random một cái noise G, rồi sau đó từ cái noise G này chúng ta qua cái hàm G thì chúng ta sẽ tạo ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "0:08:16",
      "end_timestamp": "0:09:03"
    }
  },
  {
    "page_content": "này chúng ta qua cái hàm G thì chúng ta sẽ tạo ra được một cái tấm ảnh mới. Và cái việc biến đổi cái phân phối đối với G nó cũng khá là có tính là liên tục. Ví dụ như ở đây chúng ta có một cái vector G tuân theo phân bố 0,1 nó nằm ở phía trên. Thì khi chúng ta qua cái hàm generator nó sẽ tạo ra cái hình, cái con ngỗng màu đen như thế này. Và tương đối với trong cái không gian của cái ảnh thật, nó nằm ở đây. Đây là phân phối dữ liệu mục tiêu. Và khi chúng ta sampling một cái điểm khác ở phía",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:08:54",
      "end_timestamp": "0:09:42"
    }
  },
  {
    "page_content": "Và khi chúng ta sampling một cái điểm khác ở phía dưới đây, thì qua cái hàm G chúng ta có hình một cái con chim như thế này. Và nó nằm ở đây. Thế thì khi chúng ta di chuyển từ cái điểm ở trên xuống dưới cái điểm ở dưới, cứ lần lượt với mỗi điểm chúng ta lấy mẫu, thì chúng ta qua cái hàm G thì chúng ta cũng sẽ được các cái mẫu dữ liệu. Và khi chúng ta vẽ các cái mẫu dữ liệu này lên thì chúng ta thấy là có một cái sự dịch chuyển mượt mà từ cái ảnh con ngỗng màu đen sang cái con chim màu cam này.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:09:31",
      "end_timestamp": "0:10:20"
    }
  },
  {
    "page_content": "con ngỗng màu đen sang cái con chim màu cam này. Thì chúng ta từ trái sang phải thì cũng giống như là chúng ta lấy mẫu từ trên xuống dưới với mỗi điểm trong cái không gian latent, chúng ta qua generator, chúng ta tạo ra một tấm ảnh. Thì chúng ta thấy là dần dần cái con ngỗng màu đen này, cái đầu của mình nó hướng về phía bên đây, thì nó dần dần là cái đầu nó sẽ không rõ hướng, rồi sau đó qua đây sẽ là hướng về bên tay trái. Về màu sắc thì chúng ta thấy là nó đang màu đen, đến đây thì nó bắt đầu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "0:10:16",
      "end_timestamp": "0:10:35"
    }
  },
  {
    "page_content": "thấy là nó đang màu đen, đến đây thì nó bắt đầu dần dần ngã màu chuyển sang cái cánh, và sau đó là cái phần bụng chuyển sang màu cam, thì từ trái sang phải chúng ta thấy có cái sự thay đổi một cách mượt mà, thì là biến đổi cái phân phối với cái mô hình gan. Hãy subscribe cho kênh Ghiền Mì Gõ để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=N6F7elExenE",
      "filename": "N6F7elExenE",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta đã cùng tìm hiểu về mô hình dựa trên gradient tổng quát và chúng ta có 3 công việc cần phải làm. Công việc đầu tiên là xác định hàm dự đoán y ngã là bằng f x theta, sau đó xác định hàm lỗi là g của theta, trong đó nhận dữ kiện xi, chính là dữ liệu huấn luyện. Công việc cuối cùng là tìm theta sao cho hàm j là nhỏ nhất. Công việc số 3 này đã có 1 công cụ là gradient descent và thuật toán backpropagation. Công việc 2 này đã được tích hợp trong deep learning framework. Từ nay về sau, chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:28"
    }
  },
  {
    "page_content": "deep learning framework. Từ nay về sau, chúng ta chỉ tập trung vào 2 công việc đầu, đó là thiết kế và xác định hàm lỗi. Một số hàm dựa trên gradient cơ bản chúng ta có thể liệt kê ở đây. Đầu tiên là mô hình dữ liệu đầu ra, nó có mối quan hệ phụ thuộc một cách tuyến tính x, nó chia ra làm 2 loại bài toán. Bài toán đầu tiên là hồi quy. Hồi quy thì nếu như một số tài liệu hoặc là một số bạn có thể phát biểu đó là giá trị đầu ra của mình là giá trị liên tục, còn bài toán phân loại thì giá trị đầu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 1,
      "start_timestamp": "0:01:18",
      "end_timestamp": "0:02:14"
    }
  },
  {
    "page_content": "liên tục, còn bài toán phân loại thì giá trị đầu ra y của mình sẽ là giá trị rời rạc. Tuy nhiên cách định nghĩa như vậy sẽ không toàn diện và khó cho chúng ta trong một số tình huống. Ví dụ như bài toán đoán tuổi, chúng ta sẽ không biết đó là bài toán hồi quy hay đó là bài toán phân loại. Tại vì tuổi của mình có thể là một số thuộc một tập hợp từ 0 cho đến 200. Ví dụ vậy. Thế thì chúng ta sẽ có một cách định nghĩa khác, nó sẽ tổng quát hơn. Đó là bài toán hồi quy là bài toán đầu ra của mình là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 2,
      "start_timestamp": "0:02:07",
      "end_timestamp": "0:02:45"
    }
  },
  {
    "page_content": "bài toán hồi quy là bài toán đầu ra của mình là y. Nếu như chúng ta có hai giá trị y1 và y2 mà chúng ta thấy nó có tính thứ tự thì đó là bài toán hồi quy. Thế nào có tính thứ tự? Chúng ta có thể đặt được các dấu bé, dấu lớn và dấu bằng. Ví dụ bài toán đoán tuổi thì chúng ta có thể đặt các dấu đó là 6 tuổi thì là bé hơn 12 tuổi. 6 tuổi thì lớn hơn 3 tuổi, ví dụ vậy. Đó là giá trị output của mình có tính thứ tự. Thì đó là bài toán hồi quy. Còn nếu cái output của mình, nếu hai giá trị y1 và y2 mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 3,
      "start_timestamp": "0:02:37",
      "end_timestamp": "0:03:27"
    }
  },
  {
    "page_content": "cái output của mình, nếu hai giá trị y1 và y2 mà nó chỉ có thể đặt được dấu bằng hoặc dấu khác thì lúc đó là không có tính thứ tự. Ví dụ như bài toán dự đoán đồ vật là chó, mèo, gà, vịt thì mèo thì là bằng mèo. Mèo sẽ khác chó chứ không thể nào mà mèo nhỏ hơn chó hoặc là mèo lớn hơn chó. Thì đó là cái cách để chúng ta có thể biết đó là bài toán hồi quy hay bài toán tuyến tính. Thì đối với cái bài toán hồi quy thì chúng ta sẽ có cái mô hình là hồi quy tuyến tính hay còn gọi là linear regression.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 4,
      "start_timestamp": "0:03:19",
      "end_timestamp": "0:03:59"
    }
  },
  {
    "page_content": "quy tuyến tính hay còn gọi là linear regression. Và đối với cái bài toán phân loại thì chúng ta sẽ có hai tình huống. Tình huống đầu tiên đó là phân loại nhị phân, tức là cái số phân lớp ca của mình là có hai phân lớp. Và chúng ta sẽ có cái mô hình đó là hồi quy logistic hay là logistic regression. Đối với trường hợp mà ca lớn hơn 2 thì đó sẽ là chúng ta sẽ có cái mô hình đó là hồi quy softmax hay còn gọi là softmax regression. Còn trong cái trường hợp mà cái mô hình của mình phi tuyến tính thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 5,
      "start_timestamp": "0:03:53",
      "end_timestamp": "0:04:31"
    }
  },
  {
    "page_content": "hợp mà cái mô hình của mình phi tuyến tính thì chúng ta sẽ có rất nhiều những cái mô hình hiện đại tập trung vào giải quyết cái bài toán mà y của mình phụ thuộc một cách phi tuyến tính với là x đầu vào. Và một trong những cái mô hình đầu tiên mà giải quyết cái bài toán mà có tính chất phi tuyến tính đó là mô hình Neural Network. Neural Network hay còn gọi là mạng Neural Nhân tạo, ANN. Thì đây có thể nói là một trong những cái mô hình đầu tiên để đặt nền móng cho học sâu. Và các cái mô hình về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 6,
      "start_timestamp": "0:04:22",
      "end_timestamp": "0:05:14"
    }
  },
  {
    "page_content": "đặt nền móng cho học sâu. Và các cái mô hình về sau thì chúng ta thấy nó có cái chữ A, có cái chữ NN, ví dụ như là CNN. Thì cái chữ NN ở đây nó cũng chính là Neural Network. Và còn ANN thì nó cũng có cái chữ NN là Neural Network. Và thậm chí là Transformer thì rất nhiều những cái, kể cả Transformer thì rất nhiều những cái module ở trong Transformer nó cũng dựa trên cái kiến trúc của Neural Network. Do đó thì chúng ta mới gọi Neural Network là một trong những cái mô hình nền tảng đầu tiên về học",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 7,
      "start_timestamp": "0:05:05",
      "end_timestamp": "0:05:57"
    }
  },
  {
    "page_content": "trong những cái mô hình nền tảng đầu tiên về học sâu. Và chúng ta sẽ đến với cái mô hình đầu tiên. Đó là mô hình tuyến tính và giải quyết cho bài toán hồi quy. Cụ thể đó là mô hình hồi quy tuyến tính. Thì đây là cái dạng đồ thị của cái mạng, đây là cái dạng đồ thị của cái mô hình Linear Regression hồi quy tuyến tính. Trong đó dữ kiện đầu vào sẽ là các cái đặc trưng. Thì đặc biệt ở đây chúng ta sẽ thấy có một cái số 1, nó là tượng trưng cho cái bias, cái giá trị bias. Còn x1, x2, xm đó là các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 8,
      "start_timestamp": "0:05:51",
      "end_timestamp": "0:06:34"
    }
  },
  {
    "page_content": "bias, cái giá trị bias. Còn x1, x2, xm đó là các cái đặc trưng đầu vào, các cái đặc trưng đầu vào để giúp cho chúng ta dự đoán cái giá trị đầu ra. Thế thì câu hỏi là tại sao chúng ta phải có bias? Bias sẽ đại diện cho toàn bộ những cái đặc trưng mà chúng ta không biết và không thống kê được trong m đặc trưng ở đây. Tức là ngoài m đặc trưng này, nó sẽ có những cái đặc trưng nào đó nữa mà chúng ta không biết. Thế thì tất cả những cái đặc trưng mà góp phần đưa ra cái giá trị dự đoán, nó sẽ gom vào",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 9,
      "start_timestamp": "0:06:30",
      "end_timestamp": "0:07:09"
    }
  },
  {
    "page_content": "phần đưa ra cái giá trị dự đoán, nó sẽ gom vào một cái đại lượng gọi là bias. Ngoài ra với bias thì nó sẽ giúp cho mình chúng ta có khả năng biểu diễn linh hoạt hơn với rất nhiều những cái dạng giá trị khác nhau, rất nhiều những cái dạng đường thẳng khác nhau. Và cái hàm mô hình của mình là y ngã sẽ là bằng fθx, là nó sẽ có cái công thức đó là bằng theta chuyển vị nhân với x. Thì đây chính là cái công thức mà dạng tuyến tính. Trong đó thì cái đầu ra nó sẽ được nhân trọng số với các cái giá trị,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 10,
      "start_timestamp": "0:07:01",
      "end_timestamp": "0:07:55"
    }
  },
  {
    "page_content": "ra nó sẽ được nhân trọng số với các cái giá trị, với các cái đặc trưng đầu vào. Thì ở đây chúng ta thấy là theta chính là cái tham số của cái mô hình là đặc trưng, là trọng số tương ứng với các cái đặc trưng. Ví dụ theta ở đây nó sẽ là một cái vector. Và vector này thì nó sẽ bao gồm là m cộng 1 chiều là theta 0 theta 1 cho đến theta m. Thì theta 0 tương ứng là cái trọng số với bias, theta 1 là trọng số với đặc trưng x1, theta 2 tương ứng với trọng số x2, và theta m là cái trọng số với đặc trưng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 11,
      "start_timestamp": "0:07:49",
      "end_timestamp": "0:08:32"
    }
  },
  {
    "page_content": "số x2, và theta m là cái trọng số với đặc trưng xm. Thì đây chính là cái công thức tổng, tổng có trọng số, chúng ta dùng cái ký hiệu tổng ở đây. Và với cái giá trị đầu dự đoán y ngã thì chúng ta sẽ đi so sánh nó với lại cái y. Chúng ta sẽ đi so sánh và chúng ta luôn mong muốn cái giá trị dự đoán này xấp xỉ y. Thì cái công thức thể hiện cái dự đoán, cái sai số giữa cái dự đoán và cái thực tế thì chúng ta sẽ dùng cái công thức đó là tổng bình phương. Với cái hàm lỗi này, chúng ta sẽ sử dụng cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 12,
      "start_timestamp": "0:08:27",
      "end_timestamp": "0:09:07"
    }
  },
  {
    "page_content": "Với cái hàm lỗi này, chúng ta sẽ sử dụng cái thuật toán Backpropagation để đi huấn luyện. Chúng ta sẽ có cái lỗi, từ hai cái này chúng ta sẽ tính ra được cái lỗi là G. Từ G chúng ta sẽ lan truyền ngược đến đây, đến các cái trọng số này, để từ đó chúng ta sẽ cập nhật các cái trọng số. Thế thì để làm việc chuyện đó chúng ta sẽ dùng công cụ đạo hàm và việc thiết kế cái mô hình của mình nó cũng phải đảm bảo nó có khả năng tính đạo hàm được. Thì ở đây chúng ta thấy các thao tác là theta chuyển vị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 13,
      "start_timestamp": "0:09:03",
      "end_timestamp": "0:09:38"
    }
  },
  {
    "page_content": "đây chúng ta thấy các thao tác là theta chuyển vị nhân với x, rồi theta x trừ y, đây đều là những cái hàm mà khả vi và có thể tính đạo hàm được. Dẫn đến là thuật toán Backpropagation nó sẽ chạy được. Rồi bây giờ chúng ta sẽ đến một cái tình huống trực quan, đó là giả sử như cái dữ liệu đầu vào của chúng ta chỉ có một đặc trưng là x thôi. Và y của mình thì nó sẽ phụ thuộc một cách tuyến tính, đó là một cái hàm đồng biến. Thì qua cái hàm này chúng ta sẽ tìm, nếu mà sau khi chúng ta huấn luyện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 14,
      "start_timestamp": "0:09:33",
      "end_timestamp": "0:10:28"
    }
  },
  {
    "page_content": "ta sẽ tìm, nếu mà sau khi chúng ta huấn luyện xong và chúng ta tìm được thì chúng ta sẽ có được một cái đường đi xuyên qua các cái điểm dữ liệu này. Và để đại diện cho cái đường này thì nó sẽ cần có cái tham số theta ở đây. Tức là cái phương trình đường thẳng, cái phương trình đường thẳng này sẽ là cái phương trình dựa trên cái tham số ở bên đây. Cụ thể đó là theta 0 cộng cho theta 1 x 1 cộng cho theta 2 x 2 v.v. là bằng 0. Trong trường hợp này chúng ta chỉ có duy nhất một biến số, do đó thì nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 15,
      "start_timestamp": "0:10:18",
      "end_timestamp": "0:11:15"
    }
  },
  {
    "page_content": "ta chỉ có duy nhất một biến số, do đó thì nó sẽ là theta 0 cộng cho theta 1 x x bằng 0. Thì đây chính là cái phương trình đường thẳng của cái đường mô hình đi qua các cái điểm khi mà đã được huấn luyện xong. Thì trọng số, các cái trọng số này sẽ là cái trọng số, là cái tham số của cái phương trình đường thẳng này. Rồi, chúng ta sẽ đến với cái mô hình thứ hai, đó là mô hình Logistic Regression. Đây là một cái dạng mô hình tuyến tính dùng cho cái bài toán đó là phân loại, nhưng mà phân loại nhị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 16,
      "start_timestamp": "0:11:07",
      "end_timestamp": "0:11:59"
    }
  },
  {
    "page_content": "bài toán đó là phân loại, nhưng mà phân loại nhị phân. Tức là số dạng đầu ra sẽ là 2. Và mô hình này thì nó có dạng đồ thị như sau. Và đây là cái đồ thị tính toán. Rồi, thì cái y ngã, tức là cái giá trị dự đoán, nó sẽ là bằng sigmoid của theta x. Thì chúng ta chú ý là trong cái Linear Regression, thì nó sẽ dừng ở đây. Nhưng đối với mô hình Logistic Regression, nó sẽ có thêm một cái hàm sigmoid ở đây. Thì nhờ có cái hàm sigmoid này, nó sẽ đưa cái giá trị output của mình về cái giải giá trị từ 0",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 17,
      "start_timestamp": "0:11:50",
      "end_timestamp": "0:12:49"
    }
  },
  {
    "page_content": "giá trị output của mình về cái giải giá trị từ 0 cho đến 1. Thì nếu như cái giá trị y ngã này thuộc về lớp 0, gần tiến gần về 0, thì nó sẽ thuộc về một lớp số 0. Và nếu y ngã này lớn hơn 0.5, tiến về 1, thì cái nhãn của mình sẽ là 1. Thì nhờ cái hàm sigmoid này, nó sẽ đưa về hai cái thái cực đó là 0 và 1 để giúp cho chúng ta phân loại đối tượng với đặc trưng đầu vào. Thì cũng tương tự như là Linear Regression, chúng ta sẽ có bias và chúng ta sẽ có các đặc trưng input. Và khi chúng ta đã tính ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 18,
      "start_timestamp": "0:12:38",
      "end_timestamp": "0:13:42"
    }
  },
  {
    "page_content": "các đặc trưng input. Và khi chúng ta đã tính ra được cái y ngã này rồi, thì chúng ta sẽ dùng cái công thức đó là hàm loss, hàm lỗi là bằng binary cross entropy. Cái này là viết tắt của chữ binary cross entropy. Giữa cái giá trị dự đoán, thì sigmoid của theta chuyển vị nhân x chính là giá trị dự đoán và cái giá trị thực tế. Thế thì cái công thức binary cross entropy của mình, nếu như ở đây chúng ta ký hiệu gọn lại là y ngã, thì bce của y ngã và y, thì nó sẽ có công thức đó là bằng trừ của y, log",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 19,
      "start_timestamp": "0:13:30",
      "end_timestamp": "0:14:13"
    }
  },
  {
    "page_content": "thì nó sẽ có công thức đó là bằng trừ của y, log y ngã, cộng cho 1 trừ y nhân cho log của 1 trừ y ngã. Và thì đây chính là cái công thức binary cross entropy, cái hàm loss, hàm lỗi của binary cross entropy. Và khi chúng ta sử dụng cái mô hình logistic, hồi quy logistic thì các trọng số theta 0, theta 1, theta 2, theta m, nó chính là trọng số để tạo ra phương trình đường thẳng này. Và cụ thể luôn, cái phương trình đường thẳng này nó sẽ có cái dạng thức đó là theta 0, cộng cho theta 1, x1, cộng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 20,
      "start_timestamp": "0:14:06",
      "end_timestamp": "0:14:49"
    }
  },
  {
    "page_content": "thức đó là theta 0, cộng cho theta 1, x1, cộng cho theta 2, x2. Thì ở đây chúng ta có 2 cái đặc trưng thôi, nên chúng ta sẽ ghi công thức với 2 đặc trưng, nhưng mà một cách tổng quát thì nó có thể kéo đến theta m, xm là x bằng 0. Và tất cả những cái điểm nào thuộc về một phía này thì khi chúng ta thế vào cái phương trình này, thế các cái đặc trưng x1 và x2 v.v. vào thì nó sẽ cùng dấu. Ví dụ như ở đây sẽ là cùng dấu lớn hơn 0 và các cái điểm màu cam khi thế vào cái phương trình này thì nó sẽ là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 21,
      "start_timestamp": "0:14:41",
      "end_timestamp": "0:15:31"
    }
  },
  {
    "page_content": "cam khi thế vào cái phương trình này thì nó sẽ là v.v.v. Và những cái điểm nào nằm trên cái đường phân biên, phân cách này nè, cái đường phân loại 2 tập điểm này nè, thì nó sẽ là bằng 0. Vì đó chính là cái ý nghĩa của mô hình Logistic Regression, ý nghĩa của các tham số liên quan đến cái đường boundary, cái đường phân biên giữa 2 tập điểm. Và mô hình thứ 3, đó là cái mô hình tuyến tính và cho phân loại nhiều hơn 2 lớp, k lớn 2, thì chúng ta sẽ có mô hình softmax regression. Và thay vì chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 22,
      "start_timestamp": "0:15:27",
      "end_timestamp": "0:16:12"
    }
  },
  {
    "page_content": "mô hình softmax regression. Và thay vì chúng ta có k phân lớp thì chúng ta sẽ có k giá trị, k giá trị là từ z1 cho đến zk. Và ở đây sẽ có các lớp biến đổi tuyến tính làm tổng trọng số. Tuy nhiên sau đó thì chúng ta sẽ qua 1 cái hàm softmax, k cái giá trị đầu vào qua cái hàm softmax, nó sẽ tạo ra k cái giá trị đầu ra là y ngã 1 cho đến y ngã k. Và y ngã 1 cho đến y ngã k qua cái hàm softmax thì nó sẽ thỏa mãn tính chất đó là y ngã, y ngã k nhỏ thì lớn hơn 0 và bé hơn 1. Và tổng của y ngã k thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 23,
      "start_timestamp": "0:16:04",
      "end_timestamp": "0:16:52"
    }
  },
  {
    "page_content": "lớn hơn 0 và bé hơn 1. Và tổng của y ngã k thì là bằng 1 với k chạy từ 1 cho đến k lớn, k lớn là số phân lớp của mình. Thì đây chính là một cái biểu diễn cho cái không gian xác suất. Trong cái không gian xác suất thì các cái giá trị của mình nó sẽ nhận giá trị từ 0 cho đến 1 và tổng là bằng 1. Thế thì nếu giá trị nào lớn nhất thì đó sẽ thuộc về cái lớp tương ứng. Và cái hàm lỗi ở đây chúng ta sẽ đi so sánh. Chúng ta sẽ mong muốn là k cái giá trị này nó sẽ xấp xỉ với lại y1, y2 và yk. Thế thì để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 24,
      "start_timestamp": "0:16:42",
      "end_timestamp": "0:17:20"
    }
  },
  {
    "page_content": "này nó sẽ xấp xỉ với lại y1, y2 và yk. Thế thì để cho k cái giá trị này nó xấp xỉ nhau thì chúng ta sẽ sử dụng hàm cross entropy. Thế thì giả sử như cái softmax của cái theta chuyển vị, theta chuyển vị nhân x thì chúng ta ký hiệu là y ngã. Thì khi đó chúng ta sẽ có công thức đó là cross entropy của y ngã và y thì nó sẽ là bằng trừ của tổng với k chạy từ 1 cho đến k lớn. K lớn chính là số lớp và y log y ngã k. Thì đây chính là cái công thức cross entropy với y ngã là cái công thức mà viết gọn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "entropy với y ngã là cái công thức mà viết gọn lại của softmax theta chuyển vị k. Thế thì về mặt trực quan thì trong trường hợp mà chúng ta có nhiều cái phân lớp thì cái đường boundary mà giúp cho chúng ta phân biệt 4 cái lớp này. Cái đường như thế này nó sẽ tách ra làm 4 phần thì nó sẽ không có tình trạng 1 điểm thì nó sẽ không thuộc về cái phần nào. Ví dụ như với 1 điểm ở đây thì chúng ta dựa trên cái đường phân biên này chúng ta sẽ biết nó sẽ thuộc về cái lớp xanh lá. Rồi cái điểm ở đây thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "thuộc về cái lớp xanh lá. Rồi cái điểm ở đây thì nó sẽ thuộc về cái lớp màu vàng. Thì đó chính là hồi quy softmax.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NEK5lIyST0M",
      "filename": "NEK5lIyST0M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Rồi trong những phần trước thì chúng ta đã cùng tìm hiểu về sự khác nhau giữa VAE, Variational Autoencoder và Diffusion Cả hai mô hình VAE và Diffusion đều dựa trên lý thuyết đó là chúng ta sẽ cực đại hóa log của PX này, tức là làm sao cho kỳ ảnh X của mình giống thật nhất. Thay vì chúng ta cực đại hóa log PX này, chúng ta sẽ cực đại hóa chặn dưới, tức là evidence lower bound ELBO của kỳ vọng này. Nếu như trong công thức của VAE, thì cái Z này là một vector ẩn, thì ở đây chúng ta sẽ có nhiều",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:57"
    }
  },
  {
    "page_content": "là một vector ẩn, thì ở đây chúng ta sẽ có nhiều vector ẩn, tại vì mô hình Diffusion của mình sẽ thực hiện nhiều bước để encoding. Nguyên lý của nó đó là chia thành những bước nhỏ, thì nó sẽ giúp chúng ta đơn giản hóa bài toán của mình. Thay vì chúng ta làm một bước lớn thì nó sẽ khó để huấn luyện và bài toán của chúng ta phức tạp hơn. Thay vì chúng ta có một biến Z thì bây giờ nó sẽ là T biến là X1 cho đến XT, và do đó thì thành phần Z này sẽ biến thành từ X1 cho đến XT. Còn đối với biến X này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:00:46",
      "end_timestamp": "0:01:34"
    }
  },
  {
    "page_content": "thành từ X1 cho đến XT. Còn đối với biến X này của mình thì nó sẽ là X0, tức là cái giá trị ký hiệu ở đây. X0 sẽ là ảnh đầu vào được sampling theo phân bố của data X. Vậy thì công thức ở trên sẽ được đưa về và bài toán mô hình Diffusion model sẽ đưa về việc cực đại hóa kỳ vọng của x1 cho đến XT cho trước X0. Thì đây chính là latent của mình. Và xT sẽ là gồm x0 cho đến XT, nó mở, trộn lại với nhau. Còn công thức ở đây thì nó đem qua từ đây. Như vậy thì đây chính là mô hình của Diffusion model.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:01:28",
      "end_timestamp": "0:02:21"
    }
  },
  {
    "page_content": "vậy thì đây chính là mô hình của Diffusion model. Vậy thì bây giờ chúng ta sẽ đến với bước đầu tiên, đó là quá trình khuếch tán thuận hay còn gọi là encoding. Ở bước encoding này, công thức của phân bố xác suất x1, tức là phân bố xác suất của các vector ẩn khi cho trước ảnh gốc đầu vào lấy mẫu x0, thì nó sẽ được biểu diễn bằng sơ đồ ở đây. Và công thức phân bố xác suất của các biến ẩn cho trước x0, thì nó sẽ là bằng tích của t từ 1 cho đến T lớn của q X1, XT cho trước XT từ 1. Thế thì các q",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:02:15",
      "end_timestamp": "0:03:10"
    }
  },
  {
    "page_content": "lớn của q X1, XT cho trước XT từ 1. Thế thì các q phân bố của XT cho trước XT từ 1, nó chính là các dấu mũi tên này. Tức là từ x0, chúng ta sẽ ra được phân bố xác suất của x1. Từ XT cho trước x1, chúng ta sẽ ra được phân bố xác suất của XT. Từ XT, chúng ta sẽ ra được phân bố xác suất của XT cộng 1. Từ XT lớn cho trước x1, chúng ta sẽ ra được phân bố xác suất của XT lớn. Thì đây là một quá trình các bước để encoding. Và phân bố xác suất của x1 cho đến xT sẽ là bằng tích phân bố xác suất này.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:03:06",
      "end_timestamp": "0:03:53"
    }
  },
  {
    "page_content": "cho đến xT sẽ là bằng tích phân bố xác suất này. Tiếp theo, chúng ta sẽ tham số hóa hàm phân bố xác suất. Thế thì ở đây chúng ta sẽ tham số hóa dùng công thức thêm nhiễu. Để đại diện cho thêm nhiễu, chúng ta sẽ dùng một phân bố Gauss. Trong đó, mean là bằng căn của alphaT nhân xT cho 1. Và variance là bằng 1 trừ alphaT nhân với I. I là cái ma trận đơn vị. Thế thì alphaT của mình sẽ là một con số lớn hơn 0 và nhỏ hơn 1. Nếu alphaT mà càng tiến về 0, tức là cái thao tác mà căn của alphaT nhân với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:03:48",
      "end_timestamp": "0:04:34"
    }
  },
  {
    "page_content": "0, tức là cái thao tác mà căn của alphaT nhân với xT cho 1 là chúng ta đang làm yếu. Làm yếu cái tín hiệu của xT đi. Làm yếu cái tín hiệu của xT cho 1. Sau đó chúng ta thêm nhiễu đã làm yếu cái thằng xT cho 1. Và cái thành phần mà độ lệch nó tương ứng sẽ là cái nhiễu mà chúng ta muốn thêm vào. Thế thì nếu alphaT mà càng nhỏ, thì cái xT cho 1 càng yếu và 1 trừ alphaT càng lớn, tức là cái nhiễu của mình càng mạnh. Thì cái quá trình khuếch tán này nó sẽ càng nhanh. Còn khi alphaT của mình mà càng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:04:28",
      "end_timestamp": "0:05:10"
    }
  },
  {
    "page_content": "nó sẽ càng nhanh. Còn khi alphaT của mình mà càng tiến về 1, tức là xT này chỉ bị, xT cho 1 này chỉ bị làm yếu một ít. Còn cái phần, phần nhiễu này thì chúng ta cũng thêm vô một ít. Như vậy thì kỳ ảnh của mình nó sẽ ít bị thêm nhiễu. Thế thì cũng là tham số nhưng mà ở đây, cái quá trình encoding này, thì cái tham số alphaT này của mình là cố định. Và cố định theo từng bước T. Tức là với mỗi cái bước T chúng ta sẽ có một cái alpha riêng. Và nó sẽ khác so với lại VAE. Đó là cái quá trình encoding",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:05:06",
      "end_timestamp": "0:05:49"
    }
  },
  {
    "page_content": "khác so với lại VAE. Đó là cái quá trình encoding này không có tham số huấn luyện phi. Tức là chúng ta không có huấn luyện cái tham số alphaT này. Mà alphaT này là một con số cố định. Vậy thì chúng ta sẽ ghi lại cái công thức ở đây. Đó là q xT cho trước xT. q của xT cho trước xT cho 1. Thì đây chính là một cái phân bố xác suất trong cái không gian mà chúng ta mã hóa. Phân bố gauss với mean là bằng căn của alphaT xT cho 1. Chúng ta đang làm yếu thông tin của cái ảnh trước đó đi. Rồi thêm vô một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:05:45",
      "end_timestamp": "0:06:23"
    }
  },
  {
    "page_content": "tin của cái ảnh trước đó đi. Rồi thêm vô một cái thành phần nhiễu là 1 trừ alphaT. Thì đây chính là cái công thức của khuếch tán thuận. Thế thì chúng ta sẽ đến với một cái kỹ thuật. Đó là kỹ thuật Reparameterization hay gọi là tái tham số hóa. Thì cái này cũng tương tương tương tự như là cái VAE. Nếu như cái thao tác x mà chúng ta sampling, cái ký hiệu này là sampling. Thì cái thao tác sampling này là một cái thao tác không tính đạo hàm được. Đây là một cái thao tác không tính đạo hàm được. Dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:06:19",
      "end_timestamp": "0:06:58"
    }
  },
  {
    "page_content": "là một cái thao tác không tính đạo hàm được. Dẫn đến là khi chúng ta sử dụng cái kỹ thuật tính Gradient Ascent, chúng ta sẽ không thể huấn luyện được cái mô hình Diffusion Model này. Do đó chúng ta sẽ viết lại x dưới dạng là một cái hàm số khác. Và thay vì chúng ta lấy mẫu trên x, thì chúng ta sẽ lấy mẫu trên cái biến epsilon. Ví dụ epsilon này sẽ tuân theo cái phân bố chuẩn. Ví dụ như epsilon là nằm ở đây. Thì khi chúng ta lấy epsilon nhân với sigma, rồi cộng cho mu, thì nó sẽ ra cái x nằm ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:06:51",
      "end_timestamp": "0:07:39"
    }
  },
  {
    "page_content": "sigma, rồi cộng cho mu, thì nó sẽ ra cái x nằm ở đây. Nếu chúng ta lấy epsilon nằm ở đây, thì khi chúng ta nhân sigma và cộng mu, thì nó sẽ ra cái biến x nằm ở đây. Thế thì đây là một cái thao tác hoàn toàn tương đương. Thay vì chúng ta lấy mẫu trong cái không gian phân bố là gauss, với mean là bằng mu và sigma. Bằng mu và sigma, variance là bằng sigma. Thì chúng ta sẽ lấy trong cái không gian gauss là phân bố chuẩn không một. Thì khi chúng ta huấn luyện, thì chuyển đến cái tham số epsilon này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:07:31",
      "end_timestamp": "0:08:21"
    }
  },
  {
    "page_content": "luyện, thì chuyển đến cái tham số epsilon này rồi, thì nó sẽ không có chuyển đi đâu nữa. Nên cho dù epsilon này là một cái thao tác, là một cái sampling variable từ phân bố chuẩn, nhưng mà chúng ta sẽ không có cập nhật tham số ở đây. Mà chúng ta chỉ đi cập nhật các cái tham số nếu có ở các cái bước mu và sigma này thôi. Vậy thì tại sao chúng ta lại dùng cái công thức này và cái quá trình khuếch tán thuận, chúng ta không có dùng các cái tham số huấn luyện được, mà chỉ dùng cái alpha và một trừ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:08:13",
      "end_timestamp": "0:08:56"
    }
  },
  {
    "page_content": "huấn luyện được, mà chỉ dùng cái alpha và một trừ alpha là những cái tham số mà cố định. Đó là vì cái quá trình encoding, thì chúng ta đơn giản hóa cái mô hình của mình. Nó không có tham số để huấn luyện nên nó sẽ đỡ bị hiện tượng overfitting hơn. Và cái mô hình của mình, decoding về sau, nó bám theo cái công thức này để mà nó cố gắng khôi phục lại cái phân bố xác suất này. Sao cho nó decode giống với cái giá trị này nhất. Thế thì nó giảm được, thứ nhất là nó giảm được cái lỗi. Vì cái này nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 13,
      "start_timestamp": "0:08:49",
      "end_timestamp": "0:09:26"
    }
  },
  {
    "page_content": "thứ nhất là nó giảm được cái lỗi. Vì cái này nó không có tham số, tức là cái độ cố định của nó sẽ cao. Mặc dù nó là một cái phân bố xác suất nhưng mà nó sẽ cố định. Còn nếu như cái này mà có tham số vào thì cái việc huấn luyện của mình nó sẽ vừa phụ thuộc cả encoding mà vừa phụ thuộc cả decoding. Nên cái size số của mình nó sẽ rất là lớn và nó khó hội tụ. Vậy thì chúng ta sẽ free tham số cái bước mà khuếch tán thuận, nó có nhiều cái lợi chống overfitting và cái việc huấn luyện về sau nó sẽ dễ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 14,
      "start_timestamp": "0:09:10",
      "end_timestamp": "0:10:13"
    }
  },
  {
    "page_content": "và cái việc huấn luyện về sau nó sẽ dễ hơn. Và đồng thời nó có một cái lợi thứ ba đó là với cái cách mà chúng ta sampling như thế này thì xt với t bất kỳ chúng ta có thể tính được theo x0, tức là cái ảnh ban đầu mà công thức nó rất là đơn giản. Bây giờ chúng ta sẽ thử với những cái x1 và x2 trước. Thì với x1 thì nó sẽ là bằng căn của alpha 1 nhân với x0 cộng cho căn của alpha 1 nhân với epsilon. Với epsilon đó là một cái biến theo cái phân bố chuẩn. Sau đó chúng ta thay cái công thức x2 thì sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 15,
      "start_timestamp": "0:09:56",
      "end_timestamp": "0:00:00"
    }
  },
  {
    "page_content": "Sau đó chúng ta thay cái công thức x2 thì sẽ là bằng căn của alpha 2 nhân x1 cộng cho căn của 1 nhân alpha 2 nhân epsilon 1. epsilon 1 cũng là một cái biến theo phân bố chuẩn luôn. Thì chúng ta thay cái công thức x1 ở trên đem xuống đây thì lúc này nó sẽ là bằng căn của alpha 2 nhân cho căn của alpha 1 x0 cộng cho căn của 1 trừ alpha 1 epsilon 0. Tất cả cộng cho căn của 1 trừ alpha 2 epsilon 1. Rồi thì chúng ta thay vào đây thì nó sẽ là bằng căn của alpha 1, alpha 2, x0 cộng cho căn của... Thay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 16,
      "start_timestamp": "0:00:00",
      "end_timestamp": "0:11:44"
    }
  },
  {
    "page_content": "của alpha 1, alpha 2, x0 cộng cho căn của... Thay vào đây thì nó sẽ là alpha 2 1 trừ alpha 1 epsilon 0 cộng cho căn của 1 trừ alpha 2 tất cả nhân cho epsilon 1. Thế thì cái công thức này nó sẽ đưa về đây. Những cái biến đổi của chúng ta hồi nãy nó chính là ở đây. Và ở đây chúng ta sẽ có một chú ý 2 cái biến epsilon 0 và epsilon 1 là 2 cái biến lấy mẫu với cùng một phân bố. Thì khi đó chúng ta cộng lại nó cũng sẽ ra cùng một cái phân bố Gaussian. 2 cái phân bố Gaussian mà có cùng một cái mean là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 17,
      "start_timestamp": "0:11:39",
      "end_timestamp": "0:12:28"
    }
  },
  {
    "page_content": "2 cái phân bố Gaussian mà có cùng một cái mean là bằng 0 thì khi chúng ta cộng lại nó sẽ ra một phân bố Gaussian. Và khi đó cái công thức của cái sigma của mình nó sẽ là bằng 1 trừ alpha 1 nhân alpha 2. Hay chúng ta biết gọi là triển khai. Đó là bằng epsilon của căn của cái vế bên tay trái là alpha 2 trừ cho alpha 1 alpha 2. Rồi cộng cho 1 trừ cho alpha 2. Thì đây là một cái công thức mà khá là kinh điển của cái việc mà chúng ta cộng 2 cái biến ngẫu nhiên theo phân bố chuẩn. Thế thì trừ alpha 2",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 18,
      "start_timestamp": "0:12:21",
      "end_timestamp": "0:12:57"
    }
  },
  {
    "page_content": "nhiên theo phân bố chuẩn. Thế thì trừ alpha 2 cộng alpha 2 là mất do đó thì chúng ta sẽ còn là 1 trừ alpha 1 alpha 2 epsilon. Và một cách tương tự thì cái xt bất kỳ nó sẽ được tính dưới từ cái x0 và một cái biến epsilon theo phân bố chuẩn. Và công thức của nó sẽ là như đây. Thế thì alpha ở đây sẽ là alpha gạch ngang trên đầu. Đó công thức của cái alpha t gạch ngang trên đầu. Nếu mà viết triển khai ra thì alpha gạch ngang t sẽ bằng alpha 1 alpha 2... cho đến alpha t. Và epsilon ở đây thì vẫn là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 19,
      "start_timestamp": "0:12:55",
      "end_timestamp": "0:13:40"
    }
  },
  {
    "page_content": "2... cho đến alpha t. Và epsilon ở đây thì vẫn là một cái biến ngẫu nhiên theo phân bố chuẩn. Thì cái công thức này chúng ta thấy khá là gọn. Và như vậy thì chúng ta đã tìm hiểu xong cái quá trình khuếch tán thuận. Bây giờ chúng ta sẽ sang cái quá trình khuếch tán nghịch. Với cái thao tác encoding là chúng ta đang phun thêm nhiễu vào. Vậy thì cái thao tác encoding là chúng ta sẽ tìm cách để đi khử nhiễu. Chúng ta sẽ tìm cách để đi khử nhiễu. Và cái hàm khử nhiễu này nó sẽ là có tham số theta.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 20,
      "start_timestamp": "0:13:33",
      "end_timestamp": "0:14:21"
    }
  },
  {
    "page_content": "cái hàm khử nhiễu này nó sẽ là có tham số theta. Hay nói cách khác, encoding theta là một cái hàm số truyền vào cái xt để ra xt trừ một. Sao cho nó bớt đi một cái lượng nhiễu nào đó. Như vậy thì làm sao chúng ta có thể khử nhiễu được? Vì dựa trên cái công thức của cái ELBO mà chúng ta đã có ở những slide trước. Qua một số cái phép biến đổi, thì ở đây là do số lượng phép biến đổi quá nhiều. Nên chúng ta chỉ ghi cái kết quả cuối cùng ở đây thôi. Thì nó sẽ có ba cái thành phần số hạng. Số hạng đầu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 21,
      "start_timestamp": "0:14:16",
      "end_timestamp": "0:15:00"
    }
  },
  {
    "page_content": "nó sẽ có ba cái thành phần số hạng. Số hạng đầu tiên đó là cái kỳ vọng của phân bố xác suất của x1 cho trước x0. X0 của mình chính là cái ảnh gốc ban đầu. Nó sau đó thêm một ít nhiễu để tạo ra thành x1. Thì chúng ta sẽ lấy kỳ vọng trên toàn bộ cái phân bố của x1. Và log của Ptheta x0 cho trước x1. Thì cái ý nghĩa của cái công thức này đó là gì? Ý nghĩa của cái công thức này đó là từ x1 cho trước x1. Chúng ta khôi phục được trở lại x0. Và phân bố xác suất của Ptheta x0 này là phải cực đại. Tại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 22,
      "start_timestamp": "0:14:54",
      "end_timestamp": "0:15:41"
    }
  },
  {
    "page_content": "xác suất của Ptheta x0 này là phải cực đại. Tại vì trong công thức của diffusion model là chúng ta cực đại cái kỳ vọng này. Tương đương chúng ta cực đại hóa cái kỳ vọng này. Ở đây vì có dấu trừ nên chúng ta sẽ là minimize, tức là chúng ta tối thiểu hóa cái công thức này. Ở đây có dấu trừ nên chúng ta sẽ minimize cái công thức này. Đối với số hạng đầu tiên đó là reconstruction. Tức là làm sao chúng ta có thể tái tạo lại được cái x0 ban đầu. Sao cho cái xác suất này là cao nhất. Tức là chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 23,
      "start_timestamp": "0:15:38",
      "end_timestamp": "0:16:30"
    }
  },
  {
    "page_content": "cho cái xác suất này là cao nhất. Tức là chúng ta tái tạo lại được cái x0 ban đầu từ cái x1. Tái tạo lại được. Rồi trong cái công thức prior matching, thì ở đây là chúng ta cũng... Nếu như mà các công thức trước thì chúng ta nhớ lại cái công thức của VAE thì cái công thức reconstruction này cũng tương tự như VAE. Prior matching này cũng tương tự như VAE. Đó là chúng ta làm sao để chính quy hóa với một cái prior distribution. Tức là chúng ta mong muốn cái phân bố PXT này của mình, đó là một phân",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 24,
      "start_timestamp": "0:16:25",
      "end_timestamp": "0:17:06"
    }
  },
  {
    "page_content": "muốn cái phân bố PXT này của mình, đó là một phân bố chuẩn. Vậy thì làm sao để cho cái q của XT, cho trước XT từ 1 là nó tuân theo một cái phân bố chuẩn. Giống như cái PXT này. Thì đây chính là cái thành phần regularization. Rồi, và thành phần cuối cùng, đó chính là cái kỳ vọng này. Rồi, chạy t chạy từ 1 cho đến T lớn. Thì cái ý nghĩa của cái tổng kỳ vọng này đó là cái sự consistency. Là cái consistency, tức là cái sự nhất quán giữa cái kỳ vọng của cái hàm chúng ta denoise, giải mã, chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 25,
      "start_timestamp": "0:17:02",
      "end_timestamp": "0:17:53"
    }
  },
  {
    "page_content": "của cái hàm chúng ta denoise, giải mã, chúng ta khử nhiễu. Với lại cái phân bố của q XT, XT từ 1. Tức là cái phân bố của cái quá trình encode. Decode nó sẽ giống với cái phân bố mà chúng ta đã từng encode. Thì trong cái slide tiếp theo, chúng ta sẽ có cái minh họa rõ hơn cái chỗ này. Các cái thành phần như là reconstruction và prior matching nó tương tự như VAE. Và cái sự khác biệt ở đây chính là cái consistency, chúng ta đã nhắc như hồi nãy. Đây chính là cái sự đặc thù riêng của cái diffusion",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 26,
      "start_timestamp": "0:17:44",
      "end_timestamp": "0:18:37"
    }
  },
  {
    "page_content": "chính là cái sự đặc thù riêng của cái diffusion model. Như vậy thì làm sao để có thể huấn luyện được cái hàm P này. Sao cho nó khớp với lại cái q. Thì ở trong cái hình này, nó minh họa một cái trực quan. Đó là cái quá trình, cái màu tím ở đây, tương ứng là cái màu hồng ở đây. Là cái phân bố của cái XT. Phân bố của XT khi chúng ta được encode từ XT-1, được encode từ XT-1. Tức là chúng ta phun nhiễu và thêm nhiễu từ XT-1. Thì cái phân bố này nó phải khớp với lại cái phân bố của cái Pθ, tức là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 27,
      "start_timestamp": "0:18:32",
      "end_timestamp": "0:19:26"
    }
  },
  {
    "page_content": "khớp với lại cái phân bố của cái Pθ, tức là cái màu xanh của XT, cho trước XT-1. Tức là chúng ta khử nhiễu từ XT-1 để về cái XT. Thì cái kết quả của cái việc thêm nhiễu, nó phải khớp với kết quả của chúng ta khử nhiễu từ cái ảnh phía sau. Thì đây chính là cái ConsistencyLoss. Và chúng ta sẽ biến đổi một chút xíu để chuyển từ cái công thức ở bên Slide này về cái dạng. Đó là chúng ta sẽ tính cái phân bố của cái q XT. Khi chúng ta biết cả XT và X0, thì tại sao lại như vậy? Trong cái quá trình mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 28,
      "start_timestamp": "0:19:19",
      "end_timestamp": "0:19:55"
    }
  },
  {
    "page_content": "thì tại sao lại như vậy? Trong cái quá trình mà chúng ta add-denoit và denoit, thì nhờ có cái X0, nó sẽ giúp cho chúng ta định hướng được cái quá trình denoit. Và đảm bảo được cái XT của mình, đó là một cái phân bố đúng. Thì khi chúng ta sửa cái công thức bên tay trái lại, viết theo một cái cách khác thì nó sẽ ra như thế này. Và chúng ta chú ý có một số cái sự khác biệt được highlight bởi cái màu tím. Nếu như trong công thức trước, là chúng ta làm sao từ XT-1, chúng ta thêm nhiễu vào, chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "sao từ XT-1, chúng ta thêm nhiễu vào, chúng ta thêm nhiễu vào XT. Thì bây giờ, cái công thức của mình là từ X0, chúng ta thêm nhiễu vào để tạo ra cái XT. Và cái XT này nó vẫn theo cái phân bố Gaussian, ờ, tuân theo cái phân bố chuẩn. Rồi ở cái công thức bên dưới, cái thành phần consistency nó sẽ chuyển thành là cái phân bố của cái hàm denoit. Chúng ta denoit cái XT về cái XT-1. Ờ, denoit. Từ XT về XT-1, thì cái phân bố này, nó phải giống với lại cái phân bố ground truth. Ground truth là q của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "cái phân bố ground truth. Ground truth là q của XT-1 cho trước XT và X0. Thì khi chúng ta biết được cái X0 và chúng ta biết được cái XT, thì chúng ta có thể dễ dàng chúng ta nội suy và tính được cái XT-1. Còn nếu mà chúng ta không có cái X0 này, thì chúng ta có thể bị lạc hướng và chúng ta sẽ không biết được là cái XT-1 nó nằm ở đâu. Do đó nhờ có cái thành phần X0 này, nó sẽ giúp chúng ta xác định được cái XT-1.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NJVpvCzceRk",
      "filename": "NJVpvCzceRk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 4",
      "chunk_id": 31,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Thế thì nãy giờ chúng ta đã nói về những mô hình tuyến tính, tức là cái giá trị đầu ra y nó sẽ phụ thuộc một cách tuyến tính với lại x. Thế thì nếu trong trường hợp mà y nó phụ thuộc một cách không có tuyến tính, tức là y nó sẽ phụ thuộc phi tuyến với lại x, thì cái giá trị này của mình, cái hàm của mô hình của mình nó sẽ như thế nào? Thì chúng ta sẽ sử dụng một cái mạng đó là mạng Neural Network. Cái sự khác biệt lớn nhất giữa mạng Neural Network so với lại cái mạng Softmax Regression, đó chính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:53"
    }
  },
  {
    "page_content": "so với lại cái mạng Softmax Regression, đó chính là nó có rất nhiều cái lớp hidden layer ở giữa. Đây là các lớp hidden layer. Và đến cái lớp cuối cùng thì nó sẽ tương đương với một cái hàm, tương đương với một cái mô hình đó là mô hình Softmax của mình. Như vậy sự khác biệt của Neural Network và Softmax đó là chúng ta sẽ chèn thêm rất nhiều những cái lớp biến đổi trung gian ở giữa. Với cái việc chèn nhiều lớp biến đổi trung gian ở giữa, nó sẽ giúp cho chúng ta tạo ra được các đặc trưng ở nhiều",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 1,
      "start_timestamp": "0:00:38",
      "end_timestamp": "0:01:35"
    }
  },
  {
    "page_content": "cho chúng ta tạo ra được các đặc trưng ở nhiều cấp độ khác nhau. Ở những cái đặc trưng ở lớp đầu tiên thì đây là những cái đặc trưng cấp thấp. Còn đối với những cái lớp tiếp theo thì nó sẽ tạo ra những cái đặc trưng và đặc trưng cấp giữa, tức là midlevel feature. Còn những cái đặc trưng ở lớp cuối cùng, đó sẽ là highlevel feature, tức là những cái đặc trưng cấp cao. Và với những cái đặc trưng cấp cao này thì nó sẽ giúp cho chúng ta phân biệt các mẫu dữ liệu đầu vào một cách rất là dễ dàng, do",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 2,
      "start_timestamp": "0:01:28",
      "end_timestamp": "0:02:11"
    }
  },
  {
    "page_content": "mẫu dữ liệu đầu vào một cách rất là dễ dàng, do có tính trừu tượng của nó. Với đây chúng ta sẽ có một cái mô hình trực quan để ví dụ cho dữ liệu của mình, đó là phụ thuộc một cách phi tuyến tính. Với 2 tập điểm trong và ngoài vòng tròn này, chúng ta thấy rằng là không thể nào chúng ta dùng một đường thẳng để chia ra làm 2 phần được. Không có cách nào để chia ra 2 tập mô hình tròn và hình tam giác bằng một đường thẳng. Do đó để chia ra được thì chúng ta chỉ có thể dùng một cái đường phân lớp mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 3,
      "start_timestamp": "0:02:04",
      "end_timestamp": "0:02:53"
    }
  },
  {
    "page_content": "ta chỉ có thể dùng một cái đường phân lớp mà dạng phi tuyến tính như thế này. Nó sẽ đi zigzag như thế này. Và làm sao có thể làm được cái chuyện này? Ý tưởng rất là đơn giản, với mỗi một cái node trong cái mạng Neural Network ở đây, tương ứng đó chính là một cái Logistic Regression. Nó chính là một cái node tổng và sigmoid, tức là một cái lớp hồi quy tuyến tính. Thì đặc trưng cái trọng số của mình đó, nó chính là cái hệ số của cái phương trình đường thẳng để phân tách ra làm 2. Cái trọng số của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 4,
      "start_timestamp": "0:02:40",
      "end_timestamp": "0:03:35"
    }
  },
  {
    "page_content": "thẳng để phân tách ra làm 2. Cái trọng số của một cái node Logistic, tức là một cái node hình tròn bao gồm tổng và sigmoid ở đây, thì nó sẽ là một cái trọng số của một cái phương trình đường thẳng để phân tách ra làm 2. Vậy thì chúng ta mượn cái ý tưởng đó để giải thích tại sao một cái mạng Neural Network có thể phân tách được ra khi mà cái mô hình của mình không có thể dùng được một đường thẳng. Với cái node mà chúng ta đang tô đỏ ở đây, thì nó sẽ tạo ra được một cái đường biên. Thì đây nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 5,
      "start_timestamp": "0:03:23",
      "end_timestamp": "0:04:05"
    }
  },
  {
    "page_content": "nó sẽ tạo ra được một cái đường biên. Thì đây nó được gọi là một cái bộ phân lớp yếu. Và một cái bộ phân lớp yếu này, nhiều cái bộ phân lớp yếu này, ví dụ như cái đường màu đen ở đây, thì chúng ta sẽ có một cái đường khác, rồi cái đường màu xanh lá ở đây, thì chúng ta sẽ có một cái đường khác tương tự như vậy. Và tổ hợp, ở cái lớp biến đổi Hidden layer tiếp theo, nó sẽ tổ hợp lại các cái đường phân lớp màu đỏ, màu đen, màu xanh lá và màu nâu để tạo ra thành một cái đường bao khép kín. Và với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 6,
      "start_timestamp": "0:03:55",
      "end_timestamp": "0:04:48"
    }
  },
  {
    "page_content": "tạo ra thành một cái đường bao khép kín. Và với cái đường bao khép kín này, thì nó đã giúp cho chúng ta phân tách ra được. Làm 2 phần. Đó là cái vùng màu tam giác và hình tròn. Thì đây chính là cái ý tưởng tại sao một cái mạng Neural Network có thể giải quyết được một cái bài toán phi tuyến tính. Là nhờ các cái đặc trưng, các cái bộ phân lớp yếu ở các lớp đầu tiên tổ hợp lại với nhau để tạo ra các cái đặc trưng cấp giữa, tức là đặc trưng cấp vừa. Các cái đặc trưng cấp vừa, nó sẽ tổ hợp lại để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 7,
      "start_timestamp": "0:04:38",
      "end_timestamp": "0:05:23"
    }
  },
  {
    "page_content": "Các cái đặc trưng cấp vừa, nó sẽ tổ hợp lại để tạo ra các cái đặc trưng ở các lớp tiếp theo, đó là đặc trưng cấp cao. Các cái đặc trưng cấp cao này, nó sẽ giúp cho chúng ta khoanh vùng được một cách chính xác và khi độ phức tạp của chúng ta sẽ ngày càng cao khi chúng ta tích hợp càng nhiều lớp phía dưới. Thì đó chính là sơ lược qua những cái kiến trúc mạng dựa trên dạng đồ thị tính toán, chúng ta có thể tạo ra được các cái mô hình giải quyết được các cái bài toán phi tuyến tính và phi tuyến. Và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 8,
      "start_timestamp": "0:05:11",
      "end_timestamp": "0:05:52"
    }
  },
  {
    "page_content": "các cái bài toán phi tuyến tính và phi tuyến. Và đây là những cái mô hình rất là cơ bản, thì đối với cái mạng Neural Network thì nó đã bắt đầu cho cái kỷ nguyên của Deep Learning, các cái mô hình học sâu. Thì người ta đã có rất nhiều những cái cải tiến, CNN, ANN, Transformer đã có rất nhiều cái cải tiến từ cái mạng Neural Network này để cho mô hình chúng ta có thể huấn luyện một cách dễ dàng hơn và có thể học được trên những cái dữ liệu phức tạp hơn và bài toán phức tạp hơn cũng như là tổng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 9,
      "start_timestamp": "0:05:45",
      "end_timestamp": "0:06:15"
    }
  },
  {
    "page_content": "tạp hơn và bài toán phức tạp hơn cũng như là tổng quát hơn. Thì trên đây đó là giới thiệu về mạng Neural Network, chúng ta sẽ kết thúc cái phần đầu đó là lý thuyết về gradient, các cái mô hình dựa trên gradient. Trong những phần tiếp theo thì chúng ta sẽ tìm hiểu về các cái mô hình hiện đại hơn, bao gồm các cái mạng học sâu như là CNN, ANN, Transformer, cũng như là các cái mô hình cho AI tạo sinh.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=NqnUZDkYvM0",
      "filename": "NqnUZDkYvM0",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)",
      "chunk_id": 10,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chương 2. Quá trình tiến hóa của mô hình học sâu Trong chương này thì chúng ta sẽ cùng tìm hiểu về quá trình tiến hóa của các mô hình học sâu. Và đây là một trong những chương rất quan trọng của mô học này. Vì nó vừa mang tính chất nền tảng. Tại vì nó bao gồm hai câu hỏi lớn nhất khi chúng ta xây dựng các mô hình học sâu. Đó là vấn đề về Overfitting và vấn đề về Vanishing Gradient. Khi chúng ta nghiên cứu về học sâu thì chắc chắn chúng ta sẽ phải nhắc đến hai cái vấn đề này. Và kết thúc cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nutq54Y8sH4",
      "filename": "nutq54Y8sH4",
      "title": "[CS315 - Chương 2] Giới thiệu chương",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:49"
    }
  },
  {
    "page_content": "phải nhắc đến hai cái vấn đề này. Và kết thúc cái chương này thì chúng ta sẽ trả lời được các câu hỏi như sau. Đầu tiên đó là những cái vấn đề cốt lõi mà các nhà khoa học máy tính nói chung cũng như là các nhà khoa học về các mô hình học sâu nói riêng đang giải quyết những vấn đề gì. Rồi các giải pháp mà các mô hình học sâu đã đề xuất ra để giải quyết các vấn đề cốt lõi này là gì? Và với những thành tựu đã có thì chúng ta thấy liệu có còn nhiều dư địa để phát triển các mô hình học sâu hay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nutq54Y8sH4",
      "filename": "nutq54Y8sH4",
      "title": "[CS315 - Chương 2] Giới thiệu chương",
      "chunk_id": 1,
      "start_timestamp": "0:00:42",
      "end_timestamp": "0:01:29"
    }
  },
  {
    "page_content": "dư địa để phát triển các mô hình học sâu hay không? Nếu như trả lời được câu hỏi này thì sẽ giúp chúng ta có thể tự tin để mà có thể đề xuất ra những cái mô hình mới có thể giải quyết được các cái vấn đề cho từng cái tình huống mà chúng ta đang quan tâm.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nutq54Y8sH4",
      "filename": "nutq54Y8sH4",
      "title": "[CS315 - Chương 2] Giới thiệu chương",
      "chunk_id": 2,
      "start_timestamp": "0:01:20",
      "end_timestamp": "0:01:34"
    }
  },
  {
    "page_content": "Tiếp theo chúng ta sẽ bàn về tốc độ của mô hình Diffusion Đối với mô hình Diffusion thì vấn đề lớn nhất là nó phải sampling rất nhiều bước trung gian để có thể encode và decode Như vậy thì làm sao để có thể sinh ra ảnh với tốc độ nhanh hơn Nguyên nhân là trong quá trình thêm nhiễu vào, nhiễu sau sẽ phụ thuộc vào nhiễu trước Tức là để denoise được xt-2 thì phải có xt-1 Mà muốn tính được xt-1 thì phải có xt Chính sự tuần tự này sẽ khiến chúng ta chậm Nguyên nhân của tuần tự này là nó giả định theo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:59"
    }
  },
  {
    "page_content": "Nguyên nhân của tuần tự này là nó giả định theo chuỗi Markov, tức là phải có x thứ t trừ 1 xong chúng ta mới có thể tính được xt. Đó chính là nguyên nhân. Và ngược lại khi chúng ta denoise cũng như thế. Như vậy thì thời gian chạy của diffusion sẽ là bằng t nhân cho thời gian chạy của GAN và VAE. Vậy thì chúng ta sẽ nhắc lại công thức tạo sinh của mô hình của mình. Trong mô hình tạo sinh của mình thì công thức sử dụng theo cách thức số 2 của chúng ta đó là đoán xem cái nhiễu tại một thời điểm t",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 1,
      "start_timestamp": "0:00:54",
      "end_timestamp": "0:01:42"
    }
  },
  {
    "page_content": "ta đó là đoán xem cái nhiễu tại một thời điểm t so với lại cái nhiễu đúng là bao nhiêu thì chúng ta sẽ có mi của qi xt phải x0 là bằng công thức này và mi của theta xt t thì nó sẽ là bằng công thức này trong công thức này thì chúng ta thấy nó có tính chất gọi là Markov tức là phải tính xt cũ trước rồi mới tính xt tuy nhiên có một bài báo khác đó là DDIM tức là denoising diffusion implicit model thì đã bỏ đi cái yếu tố gọi là chuỗi Markov tức là chúng ta sẽ không có yêu cầu quý xt, xt trừ 1 phải",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 2,
      "start_timestamp": "0:01:34",
      "end_timestamp": "0:02:27"
    }
  },
  {
    "page_content": "ta sẽ không có yêu cầu quý xt, xt trừ 1 phải là một chuỗi Markov, tức là phải tính được xt trừ 1 xong rồi chúng ta mới tính được cái xt này thì ở đây chúng ta sẽ dùng cái sơ đồ này để dễ hình dung đó là từ xt chúng ta có thể tính trực tiếp lên x1 xin lỗi từ x0 chúng ta có thể tính trực tiếp lên x1 từ x0 chúng ta có thể tính trực tiếp đến x2 mà không cần thông qua không cần thông qua cái bước tính x1 này thì công thức của mình sẽ là qi của xt khi chúng ta biết trước xt trừ 1 x0 thì lúc này chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 3,
      "start_timestamp": "0:02:25",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "chúng ta biết trước xt trừ 1 x0 thì lúc này chúng ta sẽ tính trực tiếp từ x0 mà không cần qua xt trừ 1 vậy thì ở trên công thức này chúng ta thấy bản chất của các công thức nó chỉ là một sự tính toán với các hệ số a, b và b a và b hàm mi của quý xt, xt0, xt0 là bằng a, b, axt, bε tư tưởng như vậy mi theta của xt, t là bằng axt, bε, theta xt Thế thì chúng ta chỉ cần tìm a và b sao cho miễn là cái xt nó thỏa mãn xt là bằng căn của alpha t x0 cộng cho 1 trừ căn alpha 1 trừ... cộng cho căn của 1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 4,
      "start_timestamp": "0:03:01",
      "end_timestamp": "0:03:54"
    }
  },
  {
    "page_content": "cho 1 trừ căn alpha 1 trừ... cộng cho căn của 1 trừ alpha epsilon thì như vậy là đã đúng được Thì cái mô hình DDIM ý tưởng của nó đó là thay vì chúng ta đi từng bước phụ thuộc bước thứ t chúng ta tính xong thì chúng ta mới đến được bước thứ T cộng 1 thì nó sẽ dùng một cái công thức trực tiếp từ x0 cho đến cái vị trí thứ T luôn và ngược lại cũng vậy thế thì nó sẽ nhảy cóc, nói một cách nôm na đó là nó sẽ tính toán nhảy cóc cái bước mà encoding và decoding và như vậy thì cái tốc độ của DDIM có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 5,
      "start_timestamp": "0:03:51",
      "end_timestamp": "0:04:36"
    }
  },
  {
    "page_content": "và decoding và như vậy thì cái tốc độ của DDIM có thể nhanh hơn gấp 10 hoặc thậm chí là gấp 100 lần so với lại DDPM DDPM Đây là mô hình probabilistic tức là mô hình có xác suất Còn ở đây là implicit Tức là một mô hình mà nó có thể tính một cách đơn định không có kiểu yếu tố nhiễu trong đó không có yếu tố nhiễu Thế thì xét về tốc độ thì DDPM nó hơn Còn xét về độ chính xác thì nó gần như tương đương và thậm chí là tốt hơn ở một số tình huống ví dụ với số Step 10, FID là 10, DDPM là 13, DDPM là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 6,
      "start_timestamp": "0:04:34",
      "end_timestamp": "0:05:40"
    }
  },
  {
    "page_content": "dụ với số Step 10, FID là 10, DDPM là 13, DDPM là 300 khi thực hiện với 1000 step, DDPM cho độ chính xác cho FID là tốt nhất DDPM cũng gần như tương đương, 4.0 nhưng từ 100 trở về trước, ở đây là 4,0, còn ở đây là gần 10,4,0, rất tốt hơn 10 nhiều Với DDIM, số step của mình mà nhỏ hơn 100, độ chính xác FID của mình tốt hơn hẳn so với DDPM. Tương tự như vậy cho bộ CelebA-64, kết quả cũng hoàn toàn tương tự như vậy. DDIM có thể nói là một trong những cải tiến đột phá trong việc đó là cải tiến về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 7,
      "start_timestamp": "0:05:28",
      "end_timestamp": "0:06:27"
    }
  },
  {
    "page_content": "cải tiến đột phá trong việc đó là cải tiến về tốc độ của một mô hình diffusion chuyển từ dạng probabilistic sang dạng deterministic để mà mình có thể lấy mẫu nhanh. Và một kỹ thuật khác đó là progressive distillation khi nói đến mô hình học máy thì chúng ta sẽ có kỹ thuật tức là huấn luyện một mô hình teacher có một số tham số rất là lớn và mô hình student có số lượng tham số ít hơn trong trường hợp này thì chúng ta sẽ huấn luyện mô hình teacher và student phối hợp với nhau để sao cho chúng ta,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 8,
      "start_timestamp": "0:06:23",
      "end_timestamp": "0:07:10"
    }
  },
  {
    "page_content": "và student phối hợp với nhau để sao cho chúng ta, thay vì chúng ta phải đi từng bước như thế này thì chúng ta có thể đi những cái đường tắt mà vẫn có thể đến được đích progressive distillation ở đây chúng ta sẽ huấn luyện teacher trước và sau đó chúng ta sẽ distill vào knowledge của student theo đường màu vàng này thì student của mình là đi theo các đường tắt, tức là nó bỏ qua các bước trung gian ở đây sau đó, nếu là progressive có nghĩa là gì? nó lấy chính cái đường tắt này, tức là cái mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 9,
      "start_timestamp": "0:07:05",
      "end_timestamp": "0:07:57"
    }
  },
  {
    "page_content": "lấy chính cái đường tắt này, tức là cái mô hình mà đi denoise theo cái kiểu đường tắt này để làm teacher để làm teacher, là cái đường màu vàng này là teacher thì chúng ta sẽ đi một cái đường tắt hơn nữa, đó là student chúng ta sẽ bỏ qua cái node này bỏ qua cái node của teacher cũ để tạo ra một student mới có bước nhảy cóc nhanh hơn thì đây chính là Progressive Length Distillation chúng ta từng bước giảm số bước của mình xuống để tăng tốc độ denoise Mô hình Guided Distillation ý tưởng cũng là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 10,
      "start_timestamp": "0:07:48",
      "end_timestamp": "0:08:36"
    }
  },
  {
    "page_content": "Mô hình Guided Distillation ý tưởng cũng là dùng Distillation nhưng mà kết hợp với Latent Diffusion Đây là một mô hình cho chúng ta vừa đạt được tốc độ huấn luyện và tốc độ inference của mình. Đây là mô hình có Condition là Y, cho phép chúng ta điều hướng mô hình của mình. Vì vậy, ở đây là một mô hình Guided Distillation là giao thoa hoặc là kết hợp của Progressive tức là chúng ta sẽ đi các đường đi tắt thay vì chúng ta đi từng bước, từng bước, từng bước thì chúng ta sẽ đi tắt hoặc thậm chí là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 11,
      "start_timestamp": "0:08:32",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "từng bước thì chúng ta sẽ đi tắt hoặc thậm chí là tắt hơn, tức là chúng ta có thể đi trực tiếp từ đây sang đây thông qua cái việc là chưng cất tuần tự sau đó chúng ta kết hợp với mô hình Latent Diffusion, tức là chúng ta chỉ làm bước encode và decode ở trên không gian latent thôi, tức là chúng ta không làm trong không gian ảnh mà làm trên không gian latent và kết quả của Guided Distillation thì chúng ta thấy là rất là đẹp và Các bước từ 2 bước, 4 bước và 8 bước thì kết quả gần như tương đương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 12,
      "start_timestamp": "0:09:18",
      "end_timestamp": "0:10:03"
    }
  },
  {
    "page_content": "4 bước và 8 bước thì kết quả gần như tương đương nhau, không có sự phân biệt gì nhiều Với chỉ 2 bước mà kết quả của chúng ta rất là tốt So với đương nhiên là 8 bước nhiều bước hơn thì nó sẽ đẹp hơn, chi tiết hơn nhưng mà 2 bước thì kết quả cũng rất là tốt và khi chúng ta denoise mà chỉ có hai bước thì rõ ràng tốc độ mình nhanh hơn rất là nhiều so với lại denoise cả t bước thì đây là cái kết quả vào năm 2023 và chúng ta sẽ có cái mô hình consistency model tức là chúng ta sẽ kết hợp các cái loss",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 13,
      "start_timestamp": "0:09:59",
      "end_timestamp": "0:10:45"
    }
  },
  {
    "page_content": "model tức là chúng ta sẽ kết hợp các cái loss lại với nhau là bằng min của EMA của XT và T Rồi F của theta x t phải thì đây là một cái target network hay còn gọi là mô hình của teacher Còn online network sẽ là mô hình student Tóm lại là đối với những cái giải pháp mà giảm cái tốc độ thì chúng ta sẽ dùng cái mô hình đó là teacher và student Kết hợp hai cái network này lại để chúng ta có thể tạo ra cái mô hình mà tốt hơn, đi tắt hơn và multi-step hơn ví dụ như ở đây chúng ta thấy là cái đường này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 14,
      "start_timestamp": "0:10:40",
      "end_timestamp": "0:11:42"
    }
  },
  {
    "page_content": "ví dụ như ở đây chúng ta thấy là cái đường này nè là đi 1 phát 1 đến đích thì nó đã tiết giảm cho chúng ta rất là nhiều các bước denoise như vậy thì chúng ta có thể là single step generation là một bước nhảy từ xt lớn về x0 Và kết quả của Latent Consistency Model thì cũng hoàn toàn tương tự như các mô hình trước Với 4 Step Inference, 4 Step Denoise thì kết quả của mình vẫn cho chất lượng rất tốt Ngoài ra thì chúng ta sẽ có các kỹ thuật liên quan đến vấn đề về Fine-tune lại mô hình Fine-tune mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 15,
      "start_timestamp": "0:11:37",
      "end_timestamp": "0:12:20"
    }
  },
  {
    "page_content": "đến vấn đề về Fine-tune lại mô hình Fine-tune mô hình diffusion Khi nói về mô hình diffusion thì tham số thường rất lớn Lý do đó là nó phải encode cả văn bản Cộng với lại encode cả thông tin về mặt hình ảnh Do đó số lượng tham số của mình của các mô hình diffusion thường rất là lớn có những mô hình lên đến gần 1 tỷ tham số có những mô hình hiện đại hơn thì có thể lên đến 3 tỷ, 4 tỷ tham số để tạo được những kỹ ảnh chất lượng tốt và hiểu được văn bản, hiểu được yêu cầu đầu vào của mình thì số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 16,
      "start_timestamp": "0:12:16",
      "end_timestamp": "0:13:09"
    }
  },
  {
    "page_content": "bản, hiểu được yêu cầu đầu vào của mình thì số tham số là lớn và chúng ta muốn fine-tune mô hình diffusion này với data set của mình Thì khi đó nó rất dễ bị hiện tượng overfitting. Tại vì trong các cái bài trước chúng ta đã nói rồi, hiện tượng overfitting xảy ra khi số lượng tham số lớn và khi dữ liệu của mình ít. Và thông thường mình không phải là một cái doanh nghiệp lớn, thì số data của mình sẽ ít hơn rất là nhiều. Do đó thì nó sẽ bị hai yếu tố này, tham số lớn và dữ liệu thì ít. Thì hiện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 17,
      "start_timestamp": "0:12:55",
      "end_timestamp": "0:14:03"
    }
  },
  {
    "page_content": "tố này, tham số lớn và dữ liệu thì ít. Thì hiện tượng overfitting. Như vậy thì để có thể fine-tune được thì chúng ta có thể sẽ sử dụng một kỹ thuật nó gọi là low-rank adaptation Ý tưởng của mình rất là đơn giản đó là trong các thao tác tính toán của các mạng transformer thì thao tác attention là một trong những thao tác mà được tính nhiều nhất trong attention thì tham số wkv là những cái ma trận xin lỗi chính xác là wkwv đây chính là những cái tham số để ánh xạ từ x về wkv Đây là tham số mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 18,
      "start_timestamp": "0:13:57",
      "end_timestamp": "0:14:49"
    }
  },
  {
    "page_content": "tham số để ánh xạ từ x về wkv Đây là tham số mà chiếm nhiều dung lượng tham số nhất Và giả sử chúng ta lấy 1 ma trận WQ ra, thì ma trận này có kích thước là N nhân M Nếu chúng ta fine-tune trên toàn bộ cái ma trận này, thì số lượng tham số chúng ta là lớn Do đó ý tưởng của Low-Rank Adaptation đó là chúng ta sẽ cộng cái ma trận WQ mà đã train trước đó thì chúng ta sẽ đóng băng nó lại, hiểu đóng băng là chúng ta sẽ để cái dấu chấm này hoặc là dấu gạch này đi, là đóng băng lại sau đó chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 19,
      "start_timestamp": "0:14:43",
      "end_timestamp": "0:15:34"
    }
  },
  {
    "page_content": "gạch này đi, là đóng băng lại sau đó chúng ta sẽ cộng nó với 1 cái low-rank ma trận 1 cái ma trận có cái hạng thấp thì ví dụ như đây là 1 cái ma trận A A thấp thế thì 1 cái ma trận low-rank là 1 cái ma trận mà có thể A của chúng ta có thể phân rã ra được bằng 2 cái ma trận có cái rank thấp ví dụ ở đây là n nhân m ở đây sẽ là n và m nhưng mà phần ma trận bên trái thì kích thước của mình sẽ là d thì a của mình là bằng tích của hai ma trận low rank trong đó d sẽ rất bé so với n, d rất bé so với m",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 20,
      "start_timestamp": "0:15:30",
      "end_timestamp": "0:16:21"
    }
  },
  {
    "page_content": "trong đó d sẽ rất bé so với n, d rất bé so với m khi đó số lượng tham số của ma trận a sẽ rất ít so với n và m Như vậy thì chúng ta đã giảm số lượng tham số của mô hình xuống Thông qua việc kết hợp ma trận WQ đã được train trước đó Với một ma trận low-rank là A Nếu chúng ta fine-tune từ đầu thì nó sẽ là n nhân m tham số Trong khi đó nếu chúng ta fine-tune mà kết hợp WQ đóng băng Cộng với lại A Cộng với ma trận A này thì số tham số của mình là không tính, tại vì đã đóng băng rồi nên không tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 21,
      "start_timestamp": "0:16:13",
      "end_timestamp": "0:17:09"
    }
  },
  {
    "page_content": "tính, tại vì đã đóng băng rồi nên không tính mà bên đây sẽ là n cộng m, tất cả nhân d vì d rất bé hơn so với nm nên tỷ số này chắc chắn là số tham số nm lớn hơn số tham số 3 rất là nhiều thì đây là một kỹ thuật rất phổ biến và cho độ chính xác, cho tính hiệu quả rất là cao Rồi, thì đây là những cái mô hình thay vì chúng ta fine-tune trên toàn bộ cái ma trận W Giống như hồi nãy chúng ta nói thay vì chúng ta fine-tune trên toàn bộ cái ma trận W Kích thước là D nhân K Thì bây giờ chúng ta sẽ lấy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 22,
      "start_timestamp": "0:17:07",
      "end_timestamp": "0:17:23"
    }
  },
  {
    "page_content": "thước là D nhân K Thì bây giờ chúng ta sẽ lấy cái ma trận này cộng với một cái ma trận kích thước là D nhân R, R nhân cho K R là rank của ma trận mới R này sẽ rất bé, chúng ta thấy nó rất nhỏ so với D Đây chính là ý tưởng của Low-Rank Low-Rank LoRA đã kết hợp với rất nhiều phương pháp ví dụ như Latent Consistency Model kết hợp với các mô hình Distillation để cho những ảnh có kết quả rất đẹp và chất lượng cao như đây là Latent Consistency Model thì LCM LoRA cho kết quả ở hàng trên rồi với cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "thì LCM LoRA cho kết quả ở hàng trên rồi với cái Backbone SD là 1.5 Backbone tốt hơn là SD XL rồi SD 1 tỷ tham số thì với cái mô hình số tham số càng nhiều đương nhiên là cái chất lượng sẽ càng cao nhưng mà cho dù gì đi chăng nữa thì khi dùng LCM với lại LoRA thì vừa đạt được tốc độ tốt mà vừa cái dữ liệu của mình không có bị hiện tượng overfitting.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=nZc5vWo2Rrg",
      "filename": "nZc5vWo2Rrg",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 8",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Như vậy, trong phần này chúng ta đã cùng nghiên cứu về vấn đề Overfitting. Đây là một vấn đề kinh điển trong lĩnh vực học máy và có hai lý do. Một là do mô hình quá phức tạp, tham số quá nhiều, trong khi đó dữ liệu của mình quá ít. Và để giải quyết vấn đề Overfitting, chúng ta sẽ có một trong hai cách. Đó là 1 là tăng data length và 2 là chúng ta giảm tham số của mô hình xuống. Nhưng mà đương nhiên các công ty công nghệ muốn mô hình của mình có tính chất tổng quát cao và có khả năng nhớ được dữ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=oLsDzI7yn0E",
      "filename": "oLsDzI7yn0E",
      "title": "[CS315 - Chương 2] Kết luận",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:01"
    }
  },
  {
    "page_content": "chất tổng quát cao và có khả năng nhớ được dữ liệu, thì họ làm điều ngược lại ở khía cạnh số lượng tham số. Các công ty công nghệ lớn tăng số lượng param lên, nhưng đồng thời data của họ tăng lên cũng rất nhiều để cho tương ứng. Tại vì họ không có thiếu tài nguyên tính toán và dữ liệu nên cái việc này là khả thi đến với họ. Rồi, vấn đề thứ 2 là chính là cái vấn đề về Vanishing Gradient. Đây là một trong những vấn đề rất là đau đầu khi chúng ta làm với các thuật toán, các mô hình học sâu. Tại vì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=oLsDzI7yn0E",
      "filename": "oLsDzI7yn0E",
      "title": "[CS315 - Chương 2] Kết luận",
      "chunk_id": 1,
      "start_timestamp": "0:00:51",
      "end_timestamp": "0:01:46"
    }
  },
  {
    "page_content": "với các thuật toán, các mô hình học sâu. Tại vì với những mô hình học sâu thì chúng ta sẽ phải nhân đạo hàm rất là nhiều lần. Và xu hướng khi mà cần tiến đến cái giá trị cực tiểu thì đạo hàm của mình sẽ càng giảm, dẫn đến đó là cái gradient của mình sẽ giảm, dẫn đến là cái mô hình của mình không hội tụ. Sau đó thì đối với 2 cái vấn đề này, chúng ta đã có những cái cải tiến của các biến thể liên quan đến mạng CNN và các mô hình dựa trên chuỗi, ví dụ như là RNN và Transformer. Trong đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=oLsDzI7yn0E",
      "filename": "oLsDzI7yn0E",
      "title": "[CS315 - Chương 2] Kết luận",
      "chunk_id": 2,
      "start_timestamp": "0:01:40",
      "end_timestamp": "0:02:27"
    }
  },
  {
    "page_content": "chuỗi, ví dụ như là RNN và Transformer. Trong đó Transformer là mô hình sinh sau đẻ muộn. Nó đã tận dụng được rất nhiều thành tựu của các kiến trúc trước đó. Ví dụ như là Skip Connection, Ví dụ như là LayerNorm, Ví dụ như là cái optimizer là AdamW, Ví dụ như là StackLayer. Ví dụ như là Ví dụ như là TransGPT, Ví dụ như là Transformer. Và việc huấn luyện các mô hình mà Transformer hiện nay thì đã có rất nhiều những doanh nghiệp công ty, hoặc là tổ chức nghiên cứu lớn mà thường là tổ chức nghiên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=oLsDzI7yn0E",
      "filename": "oLsDzI7yn0E",
      "title": "[CS315 - Chương 2] Kết luận",
      "chunk_id": 3,
      "start_timestamp": "0:02:14",
      "end_timestamp": "0:03:45"
    }
  },
  {
    "page_content": "chức nghiên cứu lớn mà thường là tổ chức nghiên cứu ở bên trong doanh nghiệp lớn để tạo ra các mô hình cho cộng đồng có thể sử dụng, ví dụ như là DeepSix, Ví dụ như là Llama, v.v. Các mô hình này đã góp phần cho việc nghiên cứu các mô hình học sâu hiện đại ngày càng trở nên thuận tiện hơn. Trên đây là bài giảng về quá trình tiến hóa của các mô hình học sâu.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=oLsDzI7yn0E",
      "filename": "oLsDzI7yn0E",
      "title": "[CS315 - Chương 2] Kết luận",
      "chunk_id": 4,
      "start_timestamp": "0:03:37",
      "end_timestamp": "0:03:51"
    }
  },
  {
    "page_content": "Các môn trước đây, nếu chúng ta tìm cách để liên kết giữa hình ảnh và văn bản, thì Visual Programming đi theo một phương cách hoàn toàn khác. Vì Visual Programming là gì? Chúng ta sẽ cùng tìm hiểu trong phần tiếp theo. Đầu tiên là phát triển bài toán. Mục tiêu của chúng ta là hướng đến để phát triển một mô hình có khả năng thực hiện được nhiều task khác nhau, hay gọi là General Purpose AI. Cách tiếp cận thông thường của chúng ta là 1. Chúng ta có thể học không giám sát trên tập dữ liệu rất lớn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:49"
    }
  },
  {
    "page_content": "thể học không giám sát trên tập dữ liệu rất lớn hay gọi là pre-training. Và cái pre-training này sẽ giúp chúng ta tạo ra những cái pre-trained model để có thể tổng quát hóa được các task, thì nó có thể tạo ra được các embeddings và dùng các embeddings đó để giải quyết các tác vụ của các bài toán khác nhau. Cách tiếp cận thứ 2 đó là học giám sát. Thì chúng ta sẽ fine-tune mô hình cho từng task cụ thể. Thế thì sẽ có bước pre-training trước và sau đó sẽ là fine-tuning sau. Tuy nhiên cái thách thức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 1,
      "start_timestamp": "0:00:40",
      "end_timestamp": "0:01:28"
    }
  },
  {
    "page_content": "sẽ là fine-tuning sau. Tuy nhiên cái thách thức của mình đó chính là nó sẽ có rất nhiều bài toán khác nhau và cái cách tiếp cận cũng rất là khác nhau nên rất khó để có thể nhân rộng được cái mô hình này. Do đó thì cái visual programming viết tắt là VisPro thì đầu vào nó sẽ nhận vào hình ảnh và một cái yêu cầu từ người dùng như vậy là ngôn ngữ hay còn gọi là instruction. Và cái output của mình thì nó sẽ tạo ra hình ảnh để được biến đổi theo cái hướng dẫn theo cái yêu cầu đầu vào. Vậy thì VisPro",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 2,
      "start_timestamp": "0:01:16",
      "end_timestamp": "0:02:10"
    }
  },
  {
    "page_content": "dẫn theo cái yêu cầu đầu vào. Vậy thì VisPro đã thực hiện tương tự như một cái ngôn ngữ lập trình bậc cao. Tức là nếu như một cái ngôn ngữ lập trình của chúng ta đã biến từ dòng lệnh thành một cái mã nguồn, một cái dòng lệnh thành một cái chương trình. Thì ở đây VisPro sẽ biến từ một cái prompt hay còn gọi là instruction của mình thành một cái chương trình. Vì vậy thì nếu chúng ta dùng code thì nó sẽ rất là không tự nhiên và nó sẽ đi theo những cái quy tắc rất là cứng nhắc. Vì vậy thì tương tác",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 3,
      "start_timestamp": "0:01:58",
      "end_timestamp": "0:02:50"
    }
  },
  {
    "page_content": "quy tắc rất là cứng nhắc. Vì vậy thì tương tác prompt hay còn instruction thì nó sẽ linh động hơn, nó sẽ có tính linh động cao hơn. Và người dùng khi này họ có thể sáng tạo với rất nhiều những cái yêu cầu khác nhau nhưng không cần phải cài đặt lại chương trình của mình hoặc là biên dịch lại chương trình của mình. Vì vậy đó chính là cái ý nghĩa của visual programming và nó sẽ hỗ trợ các cái hàm cơ bản trong xử lý ảnh từ thư viện OpenCV hoặc là các cái module ngôn ngữ thị giác. Vì vậy ở dưới đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 4,
      "start_timestamp": "0:02:39",
      "end_timestamp": "0:03:32"
    }
  },
  {
    "page_content": "cái module ngôn ngữ thị giác. Vì vậy ở dưới đây là một cái ví dụ minh họa cho visual programming. Đầu vào chúng ta sẽ có một cái instruction đó là Replace the ground with white snow and the bear with the white polar bear. Thì chúng ta sẽ thấy tấm hình này sẽ được chỉnh sửa lại theo mong muốn là thay con gấu này bằng con gấu polar bear, tức là con gấu Bắc Cực. Và cái nền ở đây sẽ là white snow, tức là nền tuyết trắng. Thì để làm được cái việc này thì cái visual programming nó sẽ tạo ra một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 5,
      "start_timestamp": "0:03:19",
      "end_timestamp": "0:04:04"
    }
  },
  {
    "page_content": "thì cái visual programming nó sẽ tạo ra một cái chương trình, nó sẽ tạo ra một cái chương trình ở dạng là bậc cao, đó là 1, nó sẽ tạo ra cái image. Sau đó nó sẽ tạo ra cái object, nó sẽ tạo ra cái câu lệnh đó là Set, và image bằng image, tức là nó sẽ lấy cái biến số ở phía trên đem xuống. Rồi sau đó nó sẽ trả ra cái object 0. Rồi sau đó tiếp tục nó sẽ viết một cái chương trình đó là Select, select cái gì thì nó cũng sẽ truyền vào cái image ở phía trên đem xuống. Nhưng mà cái object ở đây mình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 6,
      "start_timestamp": "0:03:54",
      "end_timestamp": "0:04:53"
    }
  },
  {
    "page_content": "trên đem xuống. Nhưng mà cái object ở đây mình lấy nó sẽ là object 0 ở trên đem xuống. Tức như vậy thì toàn bộ cái chương trình này là được do một cái mô hình nó gọi là GPT, GPT-3, nó tạo ra. Và từ cái mô hình, từ cái đoạn code ở đây nó sẽ biến nó thành một cái đoạn code, ví dụ như là code Python. Kèm theo các cái lời gọi đến các cái thư viện và nó sẽ chuyển đổi cái mã này nó giống giống như mã giả, nó gần giống như mã giả, nhưng mà nó gần hơn mã giả. Nó sẽ chuyển đổi cái đoạn code ở bên tay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 7,
      "start_timestamp": "0:04:41",
      "end_timestamp": "0:05:19"
    }
  },
  {
    "page_content": "mã giả. Nó sẽ chuyển đổi cái đoạn code ở bên tay trái này thành các cái mã thật để mà thực hiện. Thì đây chính là cái ý tưởng của visual programming và các cái module mà được visual programming hỗ trợ đó là module image understanding, rồi thao tác trên trên ảnh, đầu tiên là hiểu ảnh, sau đó sẽ là thao tác trên ảnh, thì bao gồm các cái thao tác như là thay thế một cái đối tượng nào đó, rồi lấy ra một cái màu sắc color pop, tức là lấy cái màu sắc của nó ra, thay bằng cái màu xám, rồi làm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 8,
      "start_timestamp": "0:05:08",
      "end_timestamp": "0:06:03"
    }
  },
  {
    "page_content": "màu sắc của nó ra, thay bằng cái màu xám, rồi làm background, rồi gán nhãn, rồi thay thế emoji v.v. Đây là những cái thao tác mà có thể hỗ trợ bởi visual programming và đương nhiên không phải là tất cả, và sau này chúng ta có thể nâng cấp lên các cái thao tác xử lý ảnh khác. Đồng thời là có các cái thao tác nâng cao hơn, ví dụ như là knowledge retrieval, thì ở đây chúng ta sẽ dùng cái list các cái đối tượng, rồi đánh giá, rồi đếm, rồi nhận xét kết quả v.v. Và màu đỏ đó là các cái module sử dụng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 9,
      "start_timestamp": "0:05:57",
      "end_timestamp": "0:06:44"
    }
  },
  {
    "page_content": "quả v.v. Và màu đỏ đó là các cái module sử dụng mạng Neural, còn màu xanh chính là những cái module mà xử lý đơn giản và có trong cái ngôn ngữ Python. Và các cái module này sẽ được kích hoạt dựa trên các cái chương trình được tạo ra bằng cái chỉ dẫn ngôn ngữ tự nhiên, hay còn gọi là Language Instruction, hay còn gọi là Prompt. Đây là cái Prompt. Và chi tiết các bước thực hiện của Visual Programming đó là nó sẽ sử dụng cái In-context Learning, In-context Instruction Program Pair, tức là chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 10,
      "start_timestamp": "0:06:26",
      "end_timestamp": "0:07:30"
    }
  },
  {
    "page_content": "Instruction Program Pair, tức là chúng ta sẽ cho cái mô hình GPT-3 của mình học các cái, nó sẽ là In-context Learning với dữ liệu đó nằm một cái cặp, là các cái cặp Instruction và Program. Thì những cái Instruction program này, Instruction và cái đoạn Code chương trình đó, thì nó có thể là bao gồm các cái tác vụ mà chúng ta đã đề cập ở những bước trước, bao gồm đó là Image Understanding, Image Manipulation và Knowledge Retrieval. Thì sau khi chúng ta có cái In-context Learning, chúng ta sẽ đưa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 11,
      "start_timestamp": "0:07:17",
      "end_timestamp": "0:08:14"
    }
  },
  {
    "page_content": "ta có cái In-context Learning, chúng ta sẽ đưa vào cái chương trình Visual Programming kèm theo cái Natural Language Instruction, thì đây chính là cái yêu cầu đầu vào của mình. Đây chính là yêu cầu và kèm theo cái tấm ảnh của mình. Thì nói một cách nôm na, đó là một cái cặp ảnh và prompt là do người dùng đưa vào, còn cái In-context với các Instruction Program nó giống như là một cái database, là những cái mẫu chương trình mà chúng ta đã tạo trước đó, bao gồm các cái thao tác, ví dụ như là thay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 12,
      "start_timestamp": "0:07:55",
      "end_timestamp": "0:08:44"
    }
  },
  {
    "page_content": "đó, bao gồm các cái thao tác, ví dụ như là thay emoji, ví dụ như là thao tác chỉnh sửa hình ảnh, ví dụ như là color pop, ở đây chúng ta thấy là loại bỏ cái background đi, thay nó bằng Grayscale, ảnh Grayscale, còn cái chủ thể, cái foreground của mình sẽ là giữ nguyên. Thì tất cả những cái thao tác này, nó sẽ là những cái loại thao tác đã được định nghĩa trước với các cái Instruction Program, ví dụ, nó học qua ví dụ, gọi là example, hoặc là few shot, đây là những cái từ khóa khác nhau để nói về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 13,
      "start_timestamp": "0:08:37",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "đây là những cái từ khóa khác nhau để nói về cùng một cái cách học, few shot prompting, hoặc là In-context learning. Thì khi chúng ta đưa vào cái Visual Program, nó sẽ tạo ra cái High Level Program, thì High Level Program là gì? Đó chính là các cái đoạn code mã giả như thế này, nó gọi là High Level Program, không nó chưa có đến cái bước gọi là thực thi ở đây ha. Đây chính là cái High Level Program. Rồi sau đó là cái High Level Program này sẽ đưa qua một cái module, nó gọi là Program",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 14,
      "start_timestamp": "0:09:13",
      "end_timestamp": "0:09:59"
    }
  },
  {
    "page_content": "này sẽ đưa qua một cái module, nó gọi là Program Interpreter, nó sẽ biến những cái đoạn code dưới dạng gần như, dưới dạng mã giả này thành cái đoạn code thật. Và sau đó thì chúng ta sẽ thực thi nó để tạo ra cái code trả lời, có thể là một cái dự đoán, prediction hoặc là Visual Reasoning. Thì trong cái ví dụ ở bên trên, đó là cái Composition Visual Question Answering, tức là một cái câu hỏi phức hợp giữa hình ảnh và một cái câu hỏi. Đó là câu hỏi với tấm ảnh này, đó là Are there both tie and",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 15,
      "start_timestamp": "0:09:44",
      "end_timestamp": "0:10:40"
    }
  },
  {
    "page_content": "hỏi với tấm ảnh này, đó là Are there both tie and glasses in the picture? Thì cái câu hỏi này là một cái câu hỏi dạng Reasoning, do đó nó sẽ phải thực hiện từng bước. Bước số đầu tiên đó là Locate, là phát hiện, phát hiện đối tượng, nó tương ứng là object detection. Đầu vào sẽ là tấm ảnh và object chúng ta cần tìm đó là tie, là có cái cà vạt hay không. Và cái thứ hai, đó là nó sẽ gọi cái hàm đếm với cái Bounding Box, tức là đếm cái số lượng Bounding Box của mình. Tiếp theo thì nó sẽ là phát",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 16,
      "start_timestamp": "0:10:24",
      "end_timestamp": "0:11:26"
    }
  },
  {
    "page_content": "Box của mình. Tiếp theo thì nó sẽ là phát hiện đối tượng và với cái đối tượng là Glass, là cái kính, rồi sau đó nó sẽ là thực hiện đếm. Và sau đó nó sẽ có một cái bước Reasoning, đó là If then, đó là Yes. Nếu số lượng của cái câu hỏi đầu tiên, cái loại đối tượng đầu tiên là answer 0, là cái cà vạt lớn hơn 0, và cái số lượng của cái đối tượng thứ hai là mắt kính, là thể hiện trong cái biến answer 1, lớn hơn 0, thì cả hai cái vế này mà cũng đúng thì nó sẽ trả về là Yes, ngược lại thì nó sẽ trả về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 17,
      "start_timestamp": "0:11:11",
      "end_timestamp": "0:12:01"
    }
  },
  {
    "page_content": "nó sẽ trả về là Yes, ngược lại thì nó sẽ trả về là No. Thì đây là một cái đoạn code mang tính chất gọi là Logic và Reasoning. Nó sẽ Reasoning từ cái câu hỏi về cái đoạn code Logic này. Và khi chúng ta thực thi cái đoạn code này thông qua cái Program Interpreter thì nó sẽ trả về cái kết quả Result là bằng No. Như vậy thì cái Visual Programming nó đã tiến hành là lập luận dựa trên những cái database chúng ta đã có, đó là Instruction và Program đã có, để mà nó tạo ra một cái đoạn chương trình mới.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 18,
      "start_timestamp": "0:11:42",
      "end_timestamp": "0:12:35"
    }
  },
  {
    "page_content": "để mà nó tạo ra một cái đoạn chương trình mới. Nó có thể nó sẽ thay đổi những cái tham số, ví dụ như trong cái chương trình này chúng ta thấy có những cái tham số mang tính chất động, đó chính là những cái mang tính chất động, đó là cái đối tượng mà chúng ta cần tìm, đó là Tie và Glasses. Đây là những cái mang tính chất là động. Nhưng nó sẽ có những cái tĩnh, nó sẽ cần cái Instruction Program hỗ trợ, đó chính là cái câu hỏi, đó là Are there both, có cái từ both, Tie and Glasses in the Picture.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 19,
      "start_timestamp": "0:12:21",
      "end_timestamp": "0:13:23"
    }
  },
  {
    "page_content": "có cái từ both, Tie and Glasses in the Picture. Thì cái câu hỏi là có cái hai đối tượng này hay không? Thì đó là một cái bài toán cố định và nó biết là nó sẽ phải gọi hai hàm, đó là hàm định vị và hàm đếm. Và sau đó dựa trên cái logic thì nó sẽ tổng hợp lại cái kết quả để trả lời là có hay không? Tương tự như vậy cho cái task, đó là chúng ta sẽ có hai ảnh trái và phải và Statement đó là Left and Right Image Content Total of 6 people on 2 boards. Thế thì đây là một cái dạng câu hỏi mang tính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 20,
      "start_timestamp": "0:13:13",
      "end_timestamp": "0:14:01"
    }
  },
  {
    "page_content": "Thế thì đây là một cái dạng câu hỏi mang tính chất gọi là logic, trong đó có cái sự gọi là sử dụng nội dung của cả hai hình ảnh. Ở đây cũng tương tự như vậy, nó sẽ gọi cái module là VQA, VQA, VQA là bao nhiêu người trong tấm ảnh, sau đó nó sẽ tính tổng lại hai đáp số. VQA này là một cái module đã có sẵn, nó đã có sẵn. Tương tự như vậy là cái Locate này là một module đã có sẵn. Thì nhiệm vụ của Visual Programming đó là nó biết phối hợp kết hợp các cái module với nhau để làm sao cho tạo thành một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 21,
      "start_timestamp": "0:13:44",
      "end_timestamp": "0:14:35"
    }
  },
  {
    "page_content": "cái module với nhau để làm sao cho tạo thành một chương trình hoàn thiện, hoàn chỉnh. Thì đó chính là cái ý tưởng của thuật toán Visual Programming. Và kỹ thuật chính mà nó sử dụng ở đây chính là Prompt Engineering và In-context Learning, để cung cấp ngữ cảnh, cộng với cái ví dụ minh họa. Và cái mô hình sử dụng ở đây là GPT-3. Một cách tổng quát thì chúng ta có thể sử dụng các cái mô hình mà dạng decoder, các cái mô hình dạng decoder, bất kỳ, chứ không phải là GPT-3. Rồi, thì cái In-context",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 22,
      "start_timestamp": "0:14:26",
      "end_timestamp": "0:15:15"
    }
  },
  {
    "page_content": "chứ không phải là GPT-3. Rồi, thì cái In-context Example, In-context Example nó sẽ là một cái ví dụ như đây, là chúng ta sẽ truyền vào một cái cặp Instruction Program. Thì đây giống như là những cái mẫu ví dụ để cho máy tính nó sẽ tự biết được là các cái thao tác cần phải thực hiện. Với một vài ví dụ nhỏ, sau này nó có thể tổng hợp thành các cái thao tác phức tạp hơn, hoặc là các cái thao tác tương tự, kết nối lại các cái thao tác đơn giản để tạo thành cái thao tác phức tạp hơn, hoặc là cũng là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 23,
      "start_timestamp": "0:15:03",
      "end_timestamp": "0:16:02"
    }
  },
  {
    "page_content": "thành cái thao tác phức tạp hơn, hoặc là cũng là cái thao tác đó, nhưng mà với những cái tham số khác. Ví dụ như ở đây nó dùng cái từ là nhân vật là Nicole Kidman, sau này có thể thay là David Beckham, hoặc là thay bằng nhân vật khác. Thì đó chính là tính vừa kết hợp giữa động và tĩnh. Tĩnh tức là cái thể loại bài toán, còn động, đó chính là những cái tham số của các cái instruction này. Ví dụ như đây là emoji, đây là tên của một nhân vật. Và một số cái ví dụ khác, ví dụ như là hỏi đáp, câu hỏi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 24,
      "start_timestamp": "0:15:48",
      "end_timestamp": "0:16:32"
    }
  },
  {
    "page_content": "số cái ví dụ khác, ví dụ như là hỏi đáp, câu hỏi kết hợp trên hình ảnh là Is there helmet in the photo? That is not blue. Thì câu trả lời đó là no. Đó và bên phải đó là những cái instruction, nó là những cái program mà cái chương trình nó sẽ khuyến nghị chúng ta sẽ ngay chạy. Trong đó nó sẽ gọi đến những cái module. Thì những cái module này sẽ có một số module là phức tạp và nó sẽ gọi từ một cái module khác, ví dụ như là object detection. Rồi, hoặc cũng có thể những cái module đơn giản thì cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 25,
      "start_timestamp": "0:16:15",
      "end_timestamp": "0:17:08"
    }
  },
  {
    "page_content": "cũng có thể những cái module đơn giản thì cái này có thể là sử dụng các cái hàm, các cái hàm của OpenCV là chúng ta có thể thực hiện được cái thao tác đơn giản này rồi. Thì đây là một cái module phức tạp mà chúng ta gọi đến một cái module Deep Learning khác. Thế thì cái bài này, bài Visual Programming này là một cái best paper của CVPR 2023. Và cái hay của nó đó chính là nó khai thác được sức mạnh của mô hình ngôn ngữ GPT để có thể tự động lên các cái bước mà chúng ta cần phải thực hiện trên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 26,
      "start_timestamp": "0:16:59",
      "end_timestamp": "0:17:49"
    }
  },
  {
    "page_content": "các cái bước mà chúng ta cần phải thực hiện trên cái tấm ảnh của mình. Thay vì là chúng ta phải train những cái mô hình đặc thù, riêng biệt. Và nếu mà chúng ta tạo ra một cái mô hình mà có thể làm được tất cả những cái task mà chúng ta nói, thì mô hình cực kỳ phức tạp. Do đó thì rất khó để có thể train được cái mô hình như vậy. Vì vậy thì GPT sử dụng cái mô hình ngôn ngữ và cộng với lại cái Visual Programming này, nó giống như là một cái proxy hoặc là một cái người trung gian để mà có thể gọi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 27,
      "start_timestamp": "0:17:21",
      "end_timestamp": "0:18:25"
    }
  },
  {
    "page_content": "hoặc là một cái người trung gian để mà có thể gọi các cái module khác để mà có thể sử dụng được. Và giải quyết được các bài toán phức tạp như là đánh dấu vật thể dựa trên cái kiến thức tổng quát, đánh dấu định danh của một cái người nổi tiếng nào đó hoặc một cái thương hiệu logo. Vì vậy thì các cái large pre-trained module bây giờ là nó đều có thể định danh được những cái đối tượng nổi tiếng, những cái thương hiệu, logo, những cái vật thể. Và kiến thức đó thì nó được thu thập dựa trên sự hiểu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 28,
      "start_timestamp": "0:18:05",
      "end_timestamp": "0:19:03"
    }
  },
  {
    "page_content": "thức đó thì nó được thu thập dựa trên sự hiểu biết của mô hình GPT. GPT là một cái large language model, nó được train trên cái dữ liệu internet scale, internet scale dataset. Nên các cái kiến thức của nó thì rất là đa dạng phong phú và những cái nào mà thuộc về kinh điển, ví dụ như Apple, Microsoft, Dell v.v. thì các cái large language model như là GPT-3 và nó hoàn toàn có thể nhận diện ra được và chuyển đổi nó thành cái chương trình trung gian cho mình được. Đây là bài toán chỉnh sửa ảnh, một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 29,
      "start_timestamp": "0:18:38",
      "end_timestamp": "0:19:27"
    }
  },
  {
    "page_content": "cho mình được. Đây là bài toán chỉnh sửa ảnh, một trong những cái bài toán cũng rất là hot gần đây. Ví dụ như chúng ta xóa định danh người thay đổi phong cách, khuôn mặt, vật thể thì đầu tiên nó sẽ là thực hiện cái thuật toán và segmentation để có các cái đối tượng ở đây. Sau đó sẽ lựa chọn các cái đối tượng mà cần phải giữ lại, object 1, rồi sau đó là chúng ta sẽ thực hiện loại bỏ đi màu sắc colorpop trên cái phần còn lại của đối tượng, đó là object, không phải là đối tượng chính mà là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 30,
      "start_timestamp": "0:19:03",
      "end_timestamp": "0:19:38"
    }
  },
  {
    "page_content": "đó là object, không phải là đối tượng chính mà là background. object 1 là background này và nó sẽ truyền vào trong này để thực hiện colorpop, colorpop cũng sẽ là một cái hàm được định sẵn trước, chúng ta chỉ việc gọi cái hàm đó thôi. Như vậy thì các cái ưu điểm chính của Visual Programming đó chính là nó dễ hiểu, dễ giải thích, tại vì các logic của mình đã được quy định trước đó rồi và chúng ta chỉ việc bắt chước lại các logic đó thôi và người dùng có thể kiểm tra được logic của chương trình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 31,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "dùng có thể kiểm tra được logic của chương trình cũng như các code trung gian và nếu cần thì chúng ta cũng có thể thay đổi và can thiệp vào chương trình nếu cần để cho nó thực hiện đúng hơn. Và ứng dụng của Visual Programming trong rất nhiều những loại bài toán khác nhau bao gồm là hỏi đáp, câu hỏi kết hợp với hình ảnh, compositional visual question answering, suy luận trên từng tập hình ảnh, reasoning with images, đánh dấu vật thể, chỉnh sửa hình ảnh với ngôn ngữ tự nhiên thì đây là một trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 32,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ảnh với ngôn ngữ tự nhiên thì đây là một trong những bài toán mà được cộng đồng quan tâm rất nhiều trong thời gian vừa qua. Hãy đăng ký kênh để xem những video mới nhất.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p71NOY7qzCc",
      "filename": "p71NOY7qzCc",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 5",
      "chunk_id": 33,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta đã tìm hiểu qua về quá trình encode và decode của mô hình của mình Đó là mô hình tổng quát, chúng ta sẽ huấn luyện mô hình này như thế nào Chúng ta sẽ xem dựa trên công thức của mình, đó là công thức này Hai thành phần reconstruction và prior matching là hoàn toàn tương tự như VAR Nhưng sự khác biệt nằm ở bước denoising matching, tức là quá trình denoising chính xác với phân bố ban đầu Thì quá trình denoising được biểu hiện bởi công thức này là P của XT trừ một Cho trước XT, với tham số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:08"
    }
  },
  {
    "page_content": "này là P của XT trừ một Cho trước XT, với tham số Theta, thì đây là một hàm, hiểu một cách nôm na, đó là một hàm từ XT khử nhiễu để ra XT trừ một Chúng ta luôn mong muốn phân bố xác suất này gần với lại phân bố xác suất của Q Q là phân bố xác suất trong quá trình encoding Ý nghĩa của công thức Q là chúng ta thấy trước điểm x0, tức là ảnh gốc ban đầu không có nhiễu Chúng ta có được ảnh nhiễu ở đây là tại XT và chúng ta sẽ biết được, chúng ta sẽ có được phân bố xác suất của XT trừ một Mức độ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 1,
      "start_timestamp": "0:00:59",
      "end_timestamp": "0:01:47"
    }
  },
  {
    "page_content": "sẽ có được phân bố xác suất của XT trừ một Mức độ nhiễu ít hơn so với XT, thì đây là cái route mà chúng ta mong muốn để mô hình P Theta bắt chước theo phân bố này Thì có một cái meme vui đó là, đây là cái anh chàng Mr. Bean, tương ứng là cái hàm denoise Và ở đây chúng ta denoise khi chúng ta không biết trước cái đáp án, chúng ta chỉ có ảnh, trước đó là XT thôi Và chúng ta sẽ phải đi xác định XT trừ một Trong khi đó cái anh chàng này thì anh có cái đáp án là x0 nên anh có thể xác định được cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 2,
      "start_timestamp": "0:01:37",
      "end_timestamp": "0:02:26"
    }
  },
  {
    "page_content": "cái đáp án là x0 nên anh có thể xác định được cái phân bố nhiễu của này một cách chính xác Thì anh này sẽ tìm cách để bắt chước cái anh này Và cái quá trình huấn luyện thì chúng ta sẽ tính toán trên cái Q của XT trừ một Và dựa trên cái công thức xác suất có điều kiện và Bayes Và cái kết quả thu được, cuối cùng thu được đó là một cái phân bố Gauss Q XT cho trước XT trừ một của mình, đó là một cái phân bố Gauss như thế này Đó là phân bố màu xanh lá như thế này Và đây là Routroot Và cái phân bố",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 3,
      "start_timestamp": "0:02:21",
      "end_timestamp": "0:03:06"
    }
  },
  {
    "page_content": "lá như thế này Và đây là Routroot Và cái phân bố này thì nó sẽ được tham số hóa bởi cái công thức đó là Mu của Q, XT, X0 và Sigma của Q T Thế thì hai cái Mu và Sigma này đó là Mean và Variance được tạo ra từ cái X0, XT và T Trong đó cái thành phần variance ở đây là chỉ phụ thuộc vào T thôi Nó không phụ thuộc vào các cái X0 và XT Lý do đó là vì các cái bán kính này là giống nhau, không thay đổi Nó là những cái hình tròn giống nhau cùng một cái bán kính Bán kính của nó sẽ thay đổi theo T Nhưng mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 4,
      "start_timestamp": "0:02:55",
      "end_timestamp": "0:03:41"
    }
  },
  {
    "page_content": "kính Bán kính của nó sẽ thay đổi theo T Nhưng mà nó sẽ là chỉ phụ thuộc vào biến T thôi, không phụ thuộc vào các cái biến X của mình Và công thức này thì nó có một cái ý nghĩa khác, đó là chúng ta sẽ tìm cách để tối thiểu hóa cái Mean của hai phân phối Lý do đó là vì hai cái phân phối này có độ lệch giống nhau Hai cái phân bố này nó có độ lệch giống nhau Tại vì nó chỉ phụ thuộc vào T Nó chỉ là một cái biến phụ thuộc vào T hoặc chính xác hơn là phụ thuộc vào các cái alpha T Do đó thì hai cái này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 5,
      "start_timestamp": "0:03:32",
      "end_timestamp": "0:04:19"
    }
  },
  {
    "page_content": "thuộc vào các cái alpha T Do đó thì hai cái này là khớp rồi Cái độ rộng của cái phân bố này là khớp rồi Giờ chỉ là làm sao để cái tâm của hai cái hình cầu, tâm của hai cái phân bố này là về khớp lại với nhau thôi Do đó thì cái việc này nó tương đương với việc chúng ta tối thiểu hóa Mean của hai phân phối Một xanh là công thức này và một nâu là công thức này Trong đó, cái Mean của cái phân phối P theta thì đó là một cái hàm tham số hóa bởi Phi Tức là nói cách khác, chúng ta sẽ xây dựng một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 6,
      "start_timestamp": "0:04:11",
      "end_timestamp": "0:05:04"
    }
  },
  {
    "page_content": "là nói cách khác, chúng ta sẽ xây dựng một cái hàm để ước lượng cái mu này Ước lượng cái mu này từ XT trước đó và cái giá trị T Vậy thì cái mô hình này thì chúng ta sẽ có hai cách, xin lỗi, có ba cách tính và diễn giải khác nhau Cái công thức trước đó nó sẽ được đưa về cái công thức này, tức là nó sẽ tương đương với việc chúng ta đi minimize hai cái phân bố Đây chính là hai cái Mean của hai phân phối Mean của cái phân phối Và chúng ta mong muốn hai cái phân phối này khớp với nhau, giống như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 7,
      "start_timestamp": "0:04:55",
      "end_timestamp": "0:05:39"
    }
  },
  {
    "page_content": "hai cái phân phối này khớp với nhau, giống như trong cái nhận xét trước Vậy thì cái công thức của Mu-Q là nó sẽ có công thức như thế này Chúng ta hoàn toàn có thể tính được, chứng minh được cái công thức này nhưng mà nó sẽ hơi mất thời gian Chúng ta chỉ ghi cái kết quả cuối cùng thôi ha Thì cái Mu-Q nó sẽ có cái công thức như trên Và chúng ta sẽ có ba cách để chúng ta thực hiện cái việc mà tối ưu cái công thức này Cách thứ nhất đó là chúng ta sẽ đưa về cái Mu-Q Mu của theta x t là bằng cái công",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 8,
      "start_timestamp": "0:05:33",
      "end_timestamp": "0:06:23"
    }
  },
  {
    "page_content": "đưa về cái Mu-Q Mu của theta x t là bằng cái công thức này Và khi đó chúng ta lấy cái Mu-Q trừ cho Mu theta, hai cái công thức này trừ cho nhau Thì chúng ta thấy là cái thành phần này loại bỏ Và cái thành phần này ở trên thì chúng ta sẽ xem như là hằng số Do đó thì chúng ta chỉ việc tối ưu sao cho cái x theta mũ x t t xấp xỉ với x0 Thế thì cái công thức này nói một cách khác Đó là chúng ta đang làm sao mà cái mô hình của mình có khả năng khôi phục được ảnh gốc từ mỗi step Lưu ý là trong cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 9,
      "start_timestamp": "0:06:15",
      "end_timestamp": "0:07:08"
    }
  },
  {
    "page_content": "phục được ảnh gốc từ mỗi step Lưu ý là trong cái công thức này chúng ta được tính tổng trên nhiều step chứ không phải chỉ tại một thời điểm T sẽ chạy từ 2 cho đến t lớn Và ở đây chính là cái ảnh mà mình khôi phục được Ảnh gốc, ảnh ban đầu khôi phục được Tức là chúng ta luôn mong muốn khôi phục lại cái ảnh ban đầu Và cái x mũ theta này nó phải xấp xỉ với x0 Đây là route root nè Đây là route root để mà chúng ta phải huấn luyện để mà bắt chước cái x0 này Thì đây là cái cách số 1 và cái cách số 1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 10,
      "start_timestamp": "0:07:03",
      "end_timestamp": "0:07:41"
    }
  },
  {
    "page_content": "x0 này Thì đây là cái cách số 1 và cái cách số 1 cũng tương đương với lại cái cách số 2 Tức là nó chỉ là cái cách cách để mà biểu diễn khác nhau thôi Thì cái công thức mu của Q nó cũng có thể biểu diễn dưới dạng là một phần alpha t x t Nhân cho cái công thức này Với cái đại lượng epsilon này là tuân theo cái phân bố Gaussian 0 1 Và xt thì trong những slide trước chúng ta đã có cái công thức tính xt từ x0 và epsilon rồi Do đó chúng ta sẽ tính từ cái công thức này chúng ta sẽ suy ra được công",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 11,
      "start_timestamp": "0:07:37",
      "end_timestamp": "0:08:18"
    }
  },
  {
    "page_content": "từ cái công thức này chúng ta sẽ suy ra được công thức của epsilon Thì epsilon là bằng cái công thức này Thì từ đó chúng ta sẽ ra được mu của theta xtt là bằng cái công thức này Và khi chúng ta lấy 2 cái hiệu số này chúng ta trừ cho nhau thì nó khử Và cái thành phần này là hằng số do đó thì nó sẽ tương đương với cái việc epsilon theta xt t trừ cho epsilon Hay nói cách khác đó là cái mô hình này là chúng ta dự đoán cái nhiễu của từng step Chúng ta đi dự đoán nhiễu của từng step Với step chạy từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 12,
      "start_timestamp": "0:08:16",
      "end_timestamp": "0:09:08"
    }
  },
  {
    "page_content": "đi dự đoán nhiễu của từng step Với step chạy từ 2 cho đến t thì làm sao cho cái nhiễu này là nhỏ nhất Với step chạy từ 2 cho đến t thì làm sao cho cái nhiễu này là nhỏ nhất Và công thức cách thức làm số 3 đó là chúng ta đi dự đoán cái vector gradient của logpt Vector gradient của logpt này hình ảnh nói hiểu một cách nôm na đó chính là cái hướng Vector hướng gradient là thể hiện hướng mà Thì cái hướng để mà hướng đến cái phân bố của cái ảnh xt Hướng đến cái phân bố của cái xt của mình Rồi thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 13,
      "start_timestamp": "0:09:04",
      "end_timestamp": "0:09:54"
    }
  },
  {
    "page_content": "Hướng đến cái phân bố của cái xt của mình Rồi thì cái s theta t xt này nó sẽ tìm cách là cực tiểu hóa hay nói cách khác là dự đoán được cái hướng này Thì tương tự như vậy chúng ta có 2 cái công thức này và khi chúng ta trừ cho nhau Thì nó sẽ 2 cái thành phần này là hằng số thì nó sẽ đưa về cái công thức này Thì đây là cái cách làm số 3 và cái công thức này nó gọi là score function Rồi, vậy thì bản chất của 3 cái cách này đó là giống nhau và chúng ta thực hiện theo cái cách số 1 Hay là chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 14,
      "start_timestamp": "0:09:47",
      "end_timestamp": "0:10:40"
    }
  },
  {
    "page_content": "ta thực hiện theo cái cách số 1 Hay là chúng ta làm theo cái cách số 2 thì cũng giống nhau Cách số 1 đó là chúng ta tìm cách để tính cái L2 Tức là cái sai số giữa cái hàm dự đoán cái ảnh so với lại cái x0 ban đầu Còn đối với cái công thức của, xin lỗi trong cái công thức này thì nó để nhầm Nó không phải là mu theta xt mà nó sẽ là x mũ theta xt 1 Rồi, thì chúng ta mong muốn là cái x mũ theta này là khớp với lại cái x0 ban đầu Còn trong cái công thức của cái cách số 2 đó là qua cái hàm, qua cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 15,
      "start_timestamp": "0:10:33",
      "end_timestamp": "0:11:19"
    }
  },
  {
    "page_content": "thức của cái cách số 2 đó là qua cái hàm, qua cái mô hình có cái theta ở đây Vậy thì các bạn có thể nhận ra cái nhiễu này, thì chúng ta sẽ dự đoán được cái nhiễu Và cái nhiễu này thì chúng ta tính cái sai số với lại cái nhiễu ban đầu này của mình Tức là yêu cầu cái mô hình dự đoán được cái nhiễu mà chúng ta đã thêm vào trước đó Và cách làm số 3 đó là chúng ta đi dự đoán cái hướng để cho cái mô hình của mình dịch chuyển vào Vậy để khái quát hóa các cái cách làm của khác nhau thì chúng ta sẽ dùng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 16,
      "start_timestamp": "0:11:13",
      "end_timestamp": "0:11:56"
    }
  },
  {
    "page_content": "cái cách làm của khác nhau thì chúng ta sẽ dùng cái không gian latent như sau Một cái không gian này chính là cái phân bố Pdata của mình Và x0 đây chính là cái ảnh mà chúng ta đã lấy mẫu được Sau đó thì chúng ta nhân với lại căn của alpha t x0 thì đây chính là cái mean của cái xt Nhưng mà chưa có cái xt tại vì chúng ta sẽ phải xác định dựa trên cái variance nữa Và cái variance giả sử như cái epsilon của mình là sampling là ở đây theo phân bố Gauss Thế thì chúng ta sẽ nhân với lại căn của 1 trừ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 17,
      "start_timestamp": "0:11:52",
      "end_timestamp": "0:12:46"
    }
  },
  {
    "page_content": "Thế thì chúng ta sẽ nhân với lại căn của 1 trừ alpha t thì nó sẽ ra cái vector màu đỏ này Và sau đó chúng ta lấy cái vector màu đỏ này đem qua đây Thì chúng ta sẽ ra được cái xt của mình Đem ra, tính ra được cái xt của mình Như vậy thì cái xt nó sẽ là bằng căn của alpha t x0 cộng cho căn của 1 trừ alpha t epsilon thì nó là nằm ở đây Và bây giờ nhiệm vụ của chúng ta ở đây là cái quá trình encode Bây giờ chúng ta decode để làm sao cho từ cái xt này có thể đi được trở về cái xt x0 Vậy thì trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 18,
      "start_timestamp": "0:12:38",
      "end_timestamp": "0:13:27"
    }
  },
  {
    "page_content": "này có thể đi được trở về cái xt x0 Vậy thì trong cái quá trình huấn luyện thì chúng ta sử dụng cái cách số 1 Cách số 1 của mình đó là gì? Là chúng ta sẽ đi ước lượng cái xtt hay cái khác đó là đang đi dự đoán ảnh gốc ban đầu x0 Và chúng ta thấy là cái điểm này nó mong muốn là làm sao cho 2 cái này là khoảng cách nhỏ nhất Với cái cách làm số 1 thì cái mu theta xtt nó sẽ có cái công thức này Trong đó cái thành phần x0 xtheta mũ này tức là cái giá trị mà chúng ta dự đoán Và khi chúng ta có được",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 19,
      "start_timestamp": "0:13:17",
      "end_timestamp": "0:14:08"
    }
  },
  {
    "page_content": "trị mà chúng ta dự đoán Và khi chúng ta có được cái xt theta 0 này rồi thì chúng ta sẽ dịch chuyển Chúng ta sẽ dịch chuyển cái xt đi theo cái hướng này thì đây sẽ là cái xt trừ 1 Đi về cái phân bố của xt trừ 1 Đối với cái cách làm số 2 thì chúng ta sẽ đi dự đoán nhiễu dựa trên cái công thức này Thì chúng ta sẽ có cái nhiễu dự đoán và chúng ta kỳ vọng là cái nhiễu dự đoán của mình khớp với cái nhiễu thực tế Thì khi mà chúng ta xác định được cái nhiễu đó thì chúng ta cũng sẽ xác định được cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 20,
      "start_timestamp": "0:14:05",
      "end_timestamp": "0:14:55"
    }
  },
  {
    "page_content": "nhiễu đó thì chúng ta cũng sẽ xác định được cái phân bố của mình là P của xt trừ 1 Và cái cách làm số 3 đó là chúng ta sẽ xác định dựa trên cái gradient Thế thì cái gradient của mình nó sẽ được ước lượng bởi cái công thức của xt theta Và chúng ta mong muốn là cái này nó sẽ xấp xỉ Cái xt theta này nó sẽ xấp xỉ với lại cái nabla của cái log của mình, p theta Mong muốn nó xấp xỉ Thế thì khi chúng ta tính ra được cái xt theta rồi thì xt của mình sẽ được dịch chuyển về hướng này Dịch chuyển đi về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 21,
      "start_timestamp": "0:14:45",
      "end_timestamp": "0:15:32"
    }
  },
  {
    "page_content": "được dịch chuyển về hướng này Dịch chuyển đi về cái hướng này dựa trên cái công thức này Vậy thì tóm lại cho dù chúng ta làm theo cách nào đi chăng nữa thì nó cũng hoàn toàn tương đương nhau Đó là chúng ta đang dịch chuyển từ cái xt về cái xt trừ 1, sau đó từ xt trừ 1 về cái xt trừ 2 Cứ như vậy, kéo cho đến khi nào mà tiến về cái x0, sao cho nó khớp với lại cái x0 nhất Thì đó chính là cái cách thức mà cái mô hình của mình huấn luyện De-noise và mục tiêu của mình đó là làm sao tìm các cái tham",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 22,
      "start_timestamp": "0:15:21",
      "end_timestamp": "0:16:19"
    }
  },
  {
    "page_content": "mục tiêu của mình đó là làm sao tìm các cái tham số theta để cho 3 cái mục tiêu trên, đó là thỏa mãn Một đó là cái gradient để hướng đến cái phân bố là khớp nhất hoặc là dự đoán được cái nhiễu là chính xác nhất hoặc là chúng ta khôi phục lại được cái ảnh gốc giống với lại cái x0 nhất, thì đó là 3 cái cách khác nhau Thì trên đây chúng ta đã cùng tìm hiểu qua 3 cái cách thức tương đương để mà có thể huấn luyện được cái mô hình diffusion Hy vọng là các bạn có thể hình dung được cái cách thức mà mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 23,
      "start_timestamp": "0:16:05",
      "end_timestamp": "0:16:19"
    }
  },
  {
    "page_content": "các bạn có thể hình dung được cái cách thức mà mô hình nó vận hành qua cái bước gọi là encoding Và encoding thì chúng ta sẽ không có tham số nhưng mà decode, khi chúng ta decode ngược lại thì chúng ta sẽ đi tìm cái theta này Sao cho cái việc xấp xỉ, đó có 3 cái cách để xấp xỉ, cái cách đầu tiên đó là xấp xỉ nhân noise Cách thứ 2 đó là xấp xỉ theo cái x0 Cách đầu tiên là xấp xỉ theo nhân noise Cách thứ 2 đó là xấp xỉ theo x0 Cách thứ 3 đó là xấp xỉ theo cái log của cái p Theta, tức là cái hướng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "xỉ theo cái log của cái p Theta, tức là cái hướng đi của mình, nó xấp xỉ Trong những phần tiếp theo thì chúng ta sẽ cùng tìm hiểu về những cái chủ đề mở rộng của cái mô hình diffusion liên quan đến cái việc là điều hướng liên quan đến việc tăng độ phân giải, tốc độ huấn luyện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=p7P_K5NzZo4",
      "filename": "p7P_K5NzZo4",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 5",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng tìm hiểu về thuật toán Gradient Descent Đây có thể nói là một trong những thuật toán rất là hiệu quả trong việc tối ưu hóa Một cái hàm khả vi Và các mô hình máy học mà dựa trên Gradient hiện đại Ví dụ như là học sâu, các mô hình ngôn ngữ lớn Đều dựa trên ý tưởng của thuật toán Gradient Descent Như vậy, vai trò của thuật toán Gradient Descent là gì? Và các bước thực hiện ra sao? Chúng ta sẽ cùng tìm hiểu trong những phần tiếp theo Chúng ta sẽ nhắc lại một chút xíu về mô hình dựa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:53"
    }
  },
  {
    "page_content": "Chúng ta sẽ nhắc lại một chút xíu về mô hình dựa trên Gradient Descent Đó là chúng ta sẽ dựa trên dữ liệu x để đưa ra giá trị dự đoán Và dựa trên giá trị thực tế chúng ta sẽ có đạo hàm Mục tiêu của mình là chúng ta sẽ đi tìm tham số theta sao là một tham số tối ưu Sao cho giá trị hàm lỗi này là nhỏ nhất Tức là sai số giữa y ngã và dự đoán y ngã và thực tế y là thấp nhất Vậy thì đây có lẽ là một trong những công việc chúng ta phải thực hiện thường xuyên Khi chúng ta huấn luyện một mô hình máy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:49",
      "end_timestamp": "0:01:33"
    }
  },
  {
    "page_content": "xuyên Khi chúng ta huấn luyện một mô hình máy học Do đó chúng ta sẽ bắt đầu tại công việc này Đó là làm sao chúng ta có thể tìm được giá trị nhỏ nhất của một hàm số Thế thì ở đây là một hình tượng là giả sử chúng ta đang đứng trên một đỉnh núi Và chúng ta đang muốn tìm đường để đến giá trị nhỏ nhất, tức là chân núi Ý tưởng đó là mình sẽ tìm cách để cập nhật và giảm độ cao Chúng ta sẽ tiếp tục giảm độ cao Rồi đến một những ngọn núi thấp hơn, chúng ta lại tiếp tục giảm độ cao Đến những ngọn núi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:30",
      "end_timestamp": "0:02:13"
    }
  },
  {
    "page_content": "ta lại tiếp tục giảm độ cao Đến những ngọn núi thấp hơn nữa Và giảm cho đến khi nào chúng ta không thể giảm được nữa thì đó là nơi mà chúng ta cần đến Đây là một hình minh họa vui để cho thấy chúng ta phải cập nhật liên tục Đây là một quá trình lặp để tìm được giá trị cực tiểu Vậy thì Gradient Descent là gì? Gradient Descent là một thuật toán nằm trong nhóm tối ưu hóa để tìm giá trị cực tiểu của hàm khả vi Hàm khả vi là một hàm có khả năng tính đạo hàm được Như vậy thì thuật toán này chỉ có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:07",
      "end_timestamp": "0:03:19"
    }
  },
  {
    "page_content": "hàm được Như vậy thì thuật toán này chỉ có thể chạy được với những hàm có thể tính đạo hàm được Và ở đây chúng ta sẽ có hai dạng hàm cơ bản Đó là dạng hàm lõm và hàm lồi Cả hai dạng hàm này đều là hai dạng cơ bản trong giải tích Ngoài ra chúng ta có những dạng hàm phối hợp Tức là một hàm sẽ vừa có lõm và vừa có phần lồi Đối với phần lồi thì chúng ta sẽ tìm được giá trị cực đại Còn đối với hàm lõm thì chúng ta sẽ tìm được giá trị cực tiểu Còn hàm lõm thì chúng ta sẽ tìm được giá trị cực đại Nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:03:11",
      "end_timestamp": "0:04:19"
    }
  },
  {
    "page_content": "lõm thì chúng ta sẽ tìm được giá trị cực đại Nó gọi là localMaximum Còn đây là localMinimum Sự khác biệt ở đây là đối với hàm lồi và hàm lõm Tại một vị trí này chúng ta thấy là hướng của mình đang hướng đi lên Thì đạo hàm của mình sẽ hướng cho chúng ta để tìm được cái điểm cực tiểu Cái điểm cực đại của bộ Trong khi đó ngược lại, đối với giá trị localMinimum Thì đạo hàm của mình sẽ hướng ngược lại Hướng ngược lại, lẽ ra chúng ta sẽ phải đi xuống Thì đạo hàm lại hướng chúng ta đi lên Đạo hàm lại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:04:11",
      "end_timestamp": "0:05:07"
    }
  },
  {
    "page_content": "Thì đạo hàm lại hướng chúng ta đi lên Đạo hàm lại hướng chúng ta đi lên, giống như tình huống bên này Vậy thì để tìm giá trị nhỏ nhất thì chúng ta sẽ phải Cập nhật theo hướng ngược với hướng của đạo hàm Sau đây là chi tiết cho các bước thực hiện trong thuật toán Gradient Descent Đầu tiên là chúng ta sẽ khởi tạo tham số Xác suất để giá trị theta mà chúng ta khởi tạo được mà trùng Theta này là theta mà chúng ta khởi tạo Theta old, nó trùng với theta sao này Xác suất của chúng ta là cực kỳ thấp Do",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:05:03",
      "end_timestamp": "0:05:49"
    }
  },
  {
    "page_content": "sao này Xác suất của chúng ta là cực kỳ thấp Do đó chúng ta sẽ phải tìm cách dựa trên đạo hàm Dựa trên đạo hàm giống như là một chỉ báo để cho chúng ta biết Đi về hướng nào là sẽ tìm được đến điểm cực tiểu Khi có tính đạo hàm thì chúng ta sẽ update và cập nhật từ từ Theta old này bằng một theta new Và cứ như vậy là update update Và ở bên dưới sẽ là cái minh họa cho cái mô hình Đây chính là cái mô hình của mình Khi ban đầu khởi tạo tham số của mình thì mô hình của mình đoán rất tệ Do đó nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:05:46",
      "end_timestamp": "0:06:34"
    }
  },
  {
    "page_content": "mình thì mô hình của mình đoán rất tệ Do đó nó sẽ không khớp với lại tập điểm này Nhưng khi chúng ta bắt đầu tính đạo hàm Chúng ta sẽ bắt đầu tính đạo hàm Thì đạo hàm có định nghĩa Đạo hàm của một hàm z theo biến theta Thì nó sẽ có định nghĩa là bằng f của theta cộng h Trừ cho f theta khi h tiến đến 0 Thì đây là đạo hàm một phía Nhưng mà chúng ta làm như vậy để cho nó đơn giản Đạo hàm một phía Rồi chúng ta thấy là tại vị trí này Đạo hàm của mình sẽ là dương Tức là nó hướng lên Hướng này là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:06:32",
      "end_timestamp": "0:07:11"
    }
  },
  {
    "page_content": "mình sẽ là dương Tức là nó hướng lên Hướng này là hướng dương hay là hướng đi lên Tại sao nó có cái dấu mũi tên đi lên này Là vì đạo hàm nó còn có một ý nghĩa là tiếp tuyến tại vị trí của mình Tại cái biến số của mình Tiếp tuyến tại đây Nhưng mà nó sẽ có hướng Thì hướng này sẽ là hướng đồng biến tức là hướng đi lên Trong khi đó lẽ ra cái điểm cực tiểu của mình Thì nó nằm ở phía ngược lại Lẽ ra chúng ta phải đi về cái hướng ngược lại Thì đó là lý do tại sao ở đây chúng ta thấy là nó có cái dấu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:09",
      "end_timestamp": "0:07:57"
    }
  },
  {
    "page_content": "do tại sao ở đây chúng ta thấy là nó có cái dấu trừ Có cái dấu trừ để đi ngược Với lại cái hướng của đạo hàm Đi ngược hướng Rồi sau khi chúng ta đã tính được cái đạo hàm là cái Thể hiện bởi cái mũi tên màu xanh là hướng lên như thế này Còn nếu mà xét về cái việc mà cập nhật đi tới hay đi lui Thì chúng ta dùng cái dấu mũi tên này Tức là dấu cộng là dương Thì chúng ta sẽ tiến hành cái bước số 3 Đó là chúng ta sẽ cập nhật lại cái tham số của mình Cập nhật lại cái tham số Và chúng ta sẽ đi ngược",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:07:52",
      "end_timestamp": "0:08:36"
    }
  },
  {
    "page_content": "Cập nhật lại cái tham số Và chúng ta sẽ đi ngược hướng Chúng ta sẽ đi ngược hướng với cái hướng của đạo hàm Tức là chúng ta sẽ đi xuống Và ngược hướng thể hiện ở cái dấu dấu trừ Ở đây là dùng cái ký hiệu nabla cho nó tổng quát Do đó là tại sao chúng ta dùng nabla Là vì đây là cái... Một cách tổng quát thì theta của chúng ta Có thể là một vector Nó sẽ là một vector gồm nhiều cái đĩa thành phần Rồi, và ở đây nó sẽ có một cái siêu tham số đó là alpha Thì tên của cái siêu tham số này á Nó gọi là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "0:08:32",
      "end_timestamp": "0:09:12"
    }
  },
  {
    "page_content": "Thì tên của cái siêu tham số này á Nó gọi là learning rate Nếu mà dịch xác nghĩa sang tiếng Việt đó là hệ số học Tuy nhiên mình có suy nghĩ và đặt cho nó một cái tên Mà mình nghĩ là phù hợp Nó sẽ không xác nghĩa với cái từ learning rate Nhưng mà nó thể hiện được cái bản chất của cái mô hình của mình Đó chính là hệ số dò dẫm Hay viết gọn lại đó là hệ số dò Tại sao được gọi là hệ số dò? Khi chúng ta tính đạo hàm Thì đạo hàm là một hệ số dò dẫm Đạo hàm nhìn chung là nó chỉ giúp cho chúng ta biết",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:09:08",
      "end_timestamp": "0:09:49"
    }
  },
  {
    "page_content": "hàm nhìn chung là nó chỉ giúp cho chúng ta biết cái hướng đi thôi Hướng đi tại cái vị trí này Thì đối với cái vị trí này đạo hàm của mình là hướng đi lên Tức là nó đang hướng dương Nhưng chúng ta sẽ phải đi cái hướng ngược lại với nó để tìm được cái Cái giá trị nhỏ nhất của mình để tìm được đến cái điểm cực tiểu của mình Chúng ta sẽ phải đi theo cái hướng ngược lại là hướng âm Nhưng cái độ lớn của đạo hàm thì không có lý thuyết nào chứng minh được rằng là Khi chúng ta đi đúng một cái đại lượng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:09:44",
      "end_timestamp": "0:10:21"
    }
  },
  {
    "page_content": "rằng là Khi chúng ta đi đúng một cái đại lượng bằng độ lớn của đạo hàm Thì nó sẽ giúp cho chúng ta đến được ngay cái điểm theta sao ở đây Tức là không có lý thuyết nào nói cái độ dài này đúng bằng đạo hàm Do đó thì nó cũng có khả năng đạo hàm của mình Nó sẽ kéo chúng ta đi lố qua cái theta sao này Chúng ta biết là phải đi hướng ngược lại Nhưng mà nếu đi đúng theo cái giá trị đạo hàm này Thì có thể chúng ta sẽ đi lố qua bên này Do đó thì chúng ta sẽ đi một cách từ tốn, đi một cách từ từ Theta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "0:10:17",
      "end_timestamp": "0:11:03"
    }
  },
  {
    "page_content": "ta sẽ đi một cách từ tốn, đi một cách từ từ Theta old ở đây sẽ được cập nhật một cách từ từ Cho đến lúc nào mà chạm được đến cái theta sao Thế thì để mà đi từ từ ở đây thì chúng ta sẽ phải nhân với một cái đại lượng Một cái siêu tham số alpha và alpha này thường là một con số rất là bé Thì nếu chúng ta không biết alpha là bao nhiêu thì mặc định trong các cái mẹo Đó là chúng ta sẽ chọn alpha đâu đó là khoảng 10 mũ trừ 4 Tại sao nó lại là cái con số rất là bé như thế này Lý do đó là vì trong các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": "0:10:59",
      "end_timestamp": "0:11:37"
    }
  },
  {
    "page_content": "số rất là bé như thế này Lý do đó là vì trong các cái mô hình mà phức tạp Thì cái độ dốc của cái hàm của mình nó rất là cao Độ dốc này rất là cao Do đó cái giá trị đạo hàm của mình nó rất là lớn Nó có thể là kéo đến đây dẫn đến là chúng ta sẽ đi lố Khi chúng ta đi hướng ngược lại chúng ta sẽ đi lố qua cái điểm cực tiểu Thì theta với alpha mà nhỏ thì nó sẽ có thể có một cái điểm yếu đó là nó sẽ đi rất là chậm Nhưng bù lại đó là nó sẽ đi chắc chắn Chúng ta cứ đi một chút rồi chúng ta cập nhật Đi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 16,
      "start_timestamp": "0:11:33",
      "end_timestamp": "0:12:17"
    }
  },
  {
    "page_content": "Chúng ta cứ đi một chút rồi chúng ta cập nhật Đi một chút rồi chúng ta sẽ cập nhật Rồi và ở cái hướng ngược lại Nếu như chúng ta ở bên tay trái thì đạo hàm của mình nó sẽ là hướng âm Tức là nó đang đi xuống đúng không là đạo hàm của mình sẽ là hướng âm Thì mình sẽ đi theo cái hướng ngược với nó đó là hướng dương Thì cho dù là nằm bên trái hay bên phải cái điểm cực tiểu của bộ Thì đạo hàm đều có chung một quyết nguyên tắc đó là chỉ ngược hướng với cái điểm cực tiểu của bộ của mình Do đó thì dù",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 17,
      "start_timestamp": "0:12:13",
      "end_timestamp": "0:13:07"
    }
  },
  {
    "page_content": "cái điểm cực tiểu của bộ của mình Do đó thì dù bên trái hay bên phải chúng ta vẫn luôn để cái dấu ở đây là dấu trừ Tức là đi ngược hướng với đạo hàm Và khi chúng ta cập nhật cái tham số Thì ở bước tiếp theo là cái điểm của chúng ta nó đã rớt xuống Và khi đó cái mô hình của mình nó cũng tiến gần hơn Nó sẽ có xu hướng tiến gần hơn về các điểm dữ liệu của mình Xấp xỉ với điểm dữ liệu của mình Thì chúng ta sẽ quay ngược trở lại để tính đạo hàm Và khi chúng ta tính đạo hàm thì một lần nữa đạo hàm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 18,
      "start_timestamp": "0:12:59",
      "end_timestamp": "0:14:03"
    }
  },
  {
    "page_content": "khi chúng ta tính đạo hàm thì một lần nữa đạo hàm lại thể hiện cái hướng ngược với lại cái hướng có cái điểm cực tiểu Chúng ta lại tiếp tục cập nhật tham số để đi cái hướng ngược lại Và khi chúng ta cập nhật cái tham số mới Thì cái hàm, cái đường quyết định, cái decision boundary Đường biên quyết định nó sẽ càng tiệm cận và nó sẽ xấp xỉ vào bên trong cái điểm dữ liệu của mình Thì đây chính là mô phỏng cho thuật toán Gradient Descent thực hiện từng bước lặp đi lặp lại Và cái việc này chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 19,
      "start_timestamp": "0:14:00",
      "end_timestamp": "0:14:47"
    }
  },
  {
    "page_content": "bước lặp đi lặp lại Và cái việc này chúng ta sẽ dừng khi nào Thì chúng ta sẽ có hai cách Một, đó là dừng khi cái F' theta là bằng 0 Hoặc là đây là trường hợp là hàm đơn biến Hoặc là trị tuyệt đối của NABLA của J Theo biến theta là bằng 0 Hoặc là bé hơn một cái ngưỡng nào đó Thông thường cái khả năng mà bằng 0 rất là thấp Và chúng ta chỉ xét một cái ngưỡng nào đó thôi Nhưng cái cách này thì rất là khó Tại vì khi chúng ta theta mà bằng 0 Hoặc là rất là bé mà chúng ta dừng Thì có khả năng là nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 20,
      "start_timestamp": "0:14:43",
      "end_timestamp": "0:15:28"
    }
  },
  {
    "page_content": "là bé mà chúng ta dừng Thì có khả năng là nó sẽ mắc kẹt ở những điểm cục bộ Do đó nó có một kiểu dừng thứ hai Đó là khi chúng ta lặp đủ nhiều Khi chúng ta lặp đủ nhiều thì chúng ta sẽ dừng Thì đây là cái giải pháp phổ biến hơn Mà thường các mô hình máy học hay sử dụng Ở đây chúng ta có một cái lưu ý là F ở đây là hàm G Tức là hàm lỗi của mình Rồi Thì ở trong cái sơ đồ này Đó là chúng ta sẽ có các cái khái niệm Khái niệm đầu tiên, đây chính là khái niệm gradient Tức là cái đạo hàm theo một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 21,
      "start_timestamp": "0:15:26",
      "end_timestamp": "0:16:14"
    }
  },
  {
    "page_content": "niệm gradient Tức là cái đạo hàm theo một cái vector tham số theta của mình Đạo hàm của hàm lỗi theo cái tham số theta Cái thứ hai, đó là cái initial weight Tức là cái điểm khởi tạo Tham số mầm khởi tạo mặc định ban đầu Rồi cái incremental step Tức là cái bước nhảy của mình Đó là một cái bước nhảy từng bước như thế này Thì đây là một cái bước nhảy nhỏ Và cái minimal cost Tức là cái vị trí mà cái hàm lỗi của mình Nó đạt được cái giá trị cực tiểu Và trong cái này thì chúng ta sẽ thấy có hai cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 22,
      "start_timestamp": "0:16:09",
      "end_timestamp": "0:16:57"
    }
  },
  {
    "page_content": "Và trong cái này thì chúng ta sẽ thấy có hai cái trục Một trục là trục về trọng số Là cái tham số theta Cái trọng số của mô hình Tức là cái tham số theta F của cái hàm mô hình Và một cái trục là chiều cao Và cái trục tung của mình chính là cái cost Là biểu diễn cho J của theta Là cái sai số của mô hình khi tại một cái vị trí theta Thì đây chính là những cái khái niệm mà chúng ta cần phải nắm vững Khi chúng ta làm việc với thuật toán gradient descent Và nó sẽ có một cái tình huống đó là Khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 23,
      "start_timestamp": "0:16:54",
      "end_timestamp": "0:17:12"
    }
  },
  {
    "page_content": "descent Và nó sẽ có một cái tình huống đó là Khi chúng ta cập nhật theta là bằng theta Trừ cho alpha nhân đạo hàm của hàm J Thì cái hệ số learning rate này là alpha Mà quá thấp, low learning rate Thì chúng ta sẽ thấy các cái bước đi của mình nó rất là chậm Nó rất là ngắn Mà ngắn tức là nó sẽ đi rất là nhiều lần Nhiều lần, tức là rất là lâu Trong khi đó, nếu như mà cái learning rate của mình nó quá cao Thì có khả năng là nó sẽ đi và nó lố qua Cái điểm cực tiểu ở đây Nó sẽ đi lố qua luôn Thế thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "điểm cực tiểu ở đây Nó sẽ đi lố qua luôn Thế thì một cái learning rate mà phù hợp Đó là một cái learning rate mà nó sẽ đi đủ nhanh Nhưng mà sẽ không đi lố qua được cái điểm cực tiểu Nhưng mà để mà có được cái learning rate đó Thì chúng ta cũng sẽ có rất nhiều những cái phiên bản Có những cái chiến thuật Có những cái chiến thuật để chọn learning rate Thì chúng ta sẽ tìm hiểu trong những cái phần tiếp theo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=pCeNKsO8prM",
      "filename": "pCeNKsO8prM",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 2)",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chắc hồi trước thì chúng ta đã cùng tìm hiểu về kiến trúc autoencoder Bây giờ thì chúng ta sẽ cùng tìm hiểu về một biến thể rất là quan trọng, đó chính là Variational Autoencoder Trước hết thì chúng ta sẽ nhắc lại autoencoder là gì và chúng ta sẽ xem có những điểm gì cần phải cải tiến trong kiến trúc này Đầu tiên đó là autoencoder thì sẽ bao gồm hai thành phần, đó là một encoder và một decoder Trong đó, encoder, nhiệm vụ của nó là chúng ta sẽ nén dữ liệu và biểu diễn dữ liệu ở số chiều cao về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:59"
    }
  },
  {
    "page_content": "dữ liệu và biểu diễn dữ liệu ở số chiều cao về một vector biểu diễn thấp chiều hơn Nếu chỉ như vậy thì không được, chúng ta sẽ phải tái tạo lại được so với dữ liệu gốc ban đầu là x, chúng ta sẽ phải có một decoder Với decoder này thì nó sẽ giúp chúng ta liên kết về mặt ý nghĩa giữa vector z và dữ liệu gốc ban đầu x Chúng ta tưởng tượng là trong một không gian latent, giống như ở đây thì ảnh của mình sẽ được map vào một không gian và ở đây sẽ là vector z Vector z này qua decoder sẽ khôi phục",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:46",
      "end_timestamp": "0:01:46"
    }
  },
  {
    "page_content": "là vector z Vector z này qua decoder sẽ khôi phục ngược lại về ảnh gốc ban đầu Câu hỏi đặt ra đó là bây giờ chúng ta sẽ dùng autoencoder này để làm gì? Rõ ràng các mô hình tạo sinh được sử dụng để sinh hình ảnh, do đó chúng ta sẽ tiến hành sinh hình ảnh Ví dụ chúng ta có một vector ở đây và chúng ta sẽ qua hàm decoder, viết tắt chữ D, thì nó sẽ tạo ra thành một tấm hình Với kiến trúc encoder thì nó không có gì đảm bảo rằng ảnh sau khi chúng ta tái tạo lại có thể là một ảnh có ý nghĩa Đó là ý",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:40",
      "end_timestamp": "0:02:35"
    }
  },
  {
    "page_content": "tái tạo lại có thể là một ảnh có ý nghĩa Đó là ý thứ nhất. Ý thứ hai là một điều rất quan trọng, một vector z phải nằm ở gần z trong không gian latent space Khi chúng ta decoder ra thì liệu có gì đảm bảo rằng ảnh mà chúng ta qua decoder phải có tính chất gì đó giống với vector z ở đây không? Tại vì hai vector biểu diễn z và z phải ở trong không gian của mình nằm gần nhau, chúng ta kỳ vọng cái số giải mã ra được là giống như số 3 Chứ không thể nào nếu vector z phải gần z, nhưng nếu chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:23",
      "end_timestamp": "0:03:27"
    }
  },
  {
    "page_content": "nào nếu vector z phải gần z, nhưng nếu chúng ta decode mà nó ra số 7 chẳng hạn Thì đây là điều mà chúng ta không mong muốn. Chúng ta mong muốn là z phải gần z, thì khi decode nó phải ra con số giống với con số z này Thì đó mới đúng là một cái không gian latent. Với autoencoder nó không có đảm bảo được cái chuyện đó Nếu như vector z sau khi tôi đã encode, thì khi tôi decode nó sẽ ra lại đúng ảnh ban đầu Nó thiếu đi một tính chất chắn và tính liên quan trong không gian của mình. Đó là những điểm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:03:18",
      "end_timestamp": "0:04:14"
    }
  },
  {
    "page_content": "quan trong không gian của mình. Đó là những điểm gần nhau sẽ có cùng một ý nghĩa giống nhau Và đó chính là điểm yếu của autoencoder và variational autoencoder sẽ tìm cách giải quyết cái vấn đề này Đó là thay vì với mỗi một cái ảnh khi chúng ta encode thì cũng có một cái module là encode Đó là trong không gian latent. Tuy nhiên thay vì chúng ta ánh xạ sang một điểm cố định giống như trong autoencoder Thì ở đây cái mà chúng ta sẽ ánh xạ sang đó chính là một distribution, một cái phân bố Thế thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:04:04",
      "end_timestamp": "0:05:10"
    }
  },
  {
    "page_content": "là một distribution, một cái phân bố Thế thì tại sao lại là phân bố mà không phải là một điểm cố định? Tại vì nếu chúng ta ánh xạ sang một điểm cố định Thì nó sẽ dễ khiến cái mô hình của mình là học thuộc cái vị trí, tức là cứ ảnh đó thì vị trí đó, ảnh đó thì vị trí đó Mà nó không có cái tính chất tổng quát. Thế thì dẫn đến là khi chúng ta có một cái điểm nào đó gần gần với điểm gì Thì khi chúng ta tạo sinh ra nó không ra cái con số giống con số 3 này. Trong khi đó nếu chúng ta ánh xạ sang một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:58",
      "end_timestamp": "0:05:40"
    }
  },
  {
    "page_content": "3 này. Trong khi đó nếu chúng ta ánh xạ sang một cái phân bố Vì nó là một cái phân bố nên khi chúng ta lấy mẫu ngẫu nhiên một cái vector z nào đó để chúng ta thực hiện cái việc tái tạo lại Thì cái z này nó có thể nằm ở đây, nó có thể nằm ở đây, nó có thể nằm ở đây, nó có thể nằm ở đây Nói chung là xung quanh cái giá trị min này, thì cái vector z này khi chúng ta decode ra nó cũng đều có khả năng là tạo ra được cái số 3 như bạn đọc Thì chính nhờ cái yếu tố ngẫu nhiên nó sẽ khiến cho cái mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:05:30",
      "end_timestamp": "0:06:23"
    }
  },
  {
    "page_content": "cái yếu tố ngẫu nhiên nó sẽ khiến cho cái mô hình của mình không có học thuộc Và từ đó là nó sẽ tổng quát hơn và nó thỏa mãn được tính chất mà chúng ta mong muốn đó là hai vector gần nhau Thì khi chúng ta decode nó sẽ giống nhau Thì khi ra một cái phân bố như thế này thì chúng ta random, chúng ta bốc ngẫu nhiên một cái vector z Theo cái phân bố mà chúng ta đã encode được là bao gồm hai tham số là mi và sigma Thì cái đường màu vàng này, ý nghĩa của nó đó chính là cái phép sampling là lấy mẫu Và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:06:17",
      "end_timestamp": "0:07:09"
    }
  },
  {
    "page_content": "nó đó chính là cái phép sampling là lấy mẫu Và lấy mẫu với cái phân bố được đại diện bởi hai tham số của cái phân bố đó là mi và sigma Thì đây chính là cái sự khác biệt lớn nhất của autoencoder và decoder Đó là thay vì chúng ta encode về một cái vector z cố định thì chúng ta sẽ đưa về một cái phân bố Và từ cái phân bố này chúng ta mới bắt đầu đi lấy mẫu nó Rồi sau đó cái vector z ở đây chúng ta decode Và cái mục tiêu của nó cũng hoàn toàn tương tự như autoencoder Thì cái module này là hoàn toàn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:07:03",
      "end_timestamp": "0:08:01"
    }
  },
  {
    "page_content": "như autoencoder Thì cái module này là hoàn toàn tương tự Hoàn toàn tương tự cái autoencoder Rồi thì đây chính là cái ý tưởng của VAE Thế thì chi tiết chúng ta sẽ đi đến những cái khái niệm Thì mi ở đây là cái min vector Thì chúng ta biết là trong một cái phân bố chuẩn hoặc là phân bố gauss Thì nó sẽ có hai cái tham số để biểu diễn cho cái phân bố gauss này Một đó là mi là min vector Và hai đó là standard deviation vector là sigma Với mi và sigma thì chúng ta có thể tạo ra được cái phân bố gauss",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:07:55",
      "end_timestamp": "0:08:36"
    }
  },
  {
    "page_content": "thì chúng ta có thể tạo ra được cái phân bố gauss của mình Cái variational autoencoder nó chính là một cái biến thể Và biến thể này là mang tính xác suất Đây là một cái biến thể mang tính xác suất của autoencoder Sự khác biệt nó nằm ở chỗ này Thay vì chúng ta đưa đến một cái vector z cố định thì chúng ta sẽ đến một cái cặp giá trị đại diện cho một phân bố, đó là mi và sigma rồi sau đó chúng ta sẽ đi lấy mẫu ngẫu nhiên và xoay xung quanh cái tham số mi và sigma này rồi, và cái việc lấy mẫu này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:08:32",
      "end_timestamp": "0:09:16"
    }
  },
  {
    "page_content": "số mi và sigma này rồi, và cái việc lấy mẫu này thì từ giá trị trung bình và độ lệch chuẩn để chúng ta lấy cái mẫu tìm ẩn z thì vector z này sẽ là cái vector tìm ẩn trong cái không gian latent của mình thế thì cái giai đoạn tiếp theo của autoencoder đó chính là chúng ta sẽ tối ưu hóa cái VAR này như thế nào tức là chúng ta huấn luyện cái VAR này như thế nào thì ở đây, đối với cái giai quá trình mã hóa thì chúng ta sẽ ký hiệu bởi cái phân bố xác suất đó là Q tức là cho trước x, x là cái ảnh đầu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:09:10",
      "end_timestamp": "0:10:10"
    }
  },
  {
    "page_content": "suất đó là Q tức là cho trước x, x là cái ảnh đầu vào thì cái phân bố của z khi cho trước x thì nó được tham số hóa bởi phi thì nhờ có cái tham số phi này nè chúng ta mới có thể tính toán từ x chúng ta sẽ tính toán ra được qua các cái bước mà encode chúng ta sẽ tính toán ra được cái mi và sigma thì đây là chính là tham số của nguồn ở cái quá trình giải mã thì chúng ta sẽ có cái phân bố là p theta khi cho trước x thì chúng ta sẽ có được cái phân bố của z rồi và cái hàm loss cuối cùng của VAR đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:10:06",
      "end_timestamp": "0:10:56"
    }
  },
  {
    "page_content": "bố của z rồi và cái hàm loss cuối cùng của VAR đó là l phi theta và là x thì phi theta và x thì phi chính là cái tham số của encoder và theta chính là cái tham số của decoder và cái hàm loss này, cái hàm lỗi này sẽ bao gồm 2 thành phần đó là sai số tái tạo và thành phần chính quy cái thành phần chính quy này nè cái thành phần để giúp cho chúng ta đưa cái phân bố của mi và sigma về đúng như cái phân bố mà chúng ta mong muốn đó gọi là phân bố tiềm ẩn Tiếp theo thì chúng ta sẽ tính cái sai số tái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:10:48",
      "end_timestamp": "0:11:58"
    }
  },
  {
    "page_content": "ẩn Tiếp theo thì chúng ta sẽ tính cái sai số tái tạo này đó là cái sai số được tính từ bằng cách đó là so sánh cái x ban đầu với lại cái x mũ sau khi chúng ta đã decode thì chúng ta có thể tính bằng cách là dùng log likelihood hoặc là dùng hàm độ lỗi bình phương chúng ta sẽ lấy x trừ cho x mũ tức là cái x sau khi chúng ta đã decode trừ cho cái giá trị ban đầu rồi tất cả là lấy tổng bình phương các cái sai số thì đây là tổng bình phương Tiếp theo thì liên quan đến cái thành phần chính quy thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:11:54",
      "end_timestamp": "0:12:10"
    }
  },
  {
    "page_content": "thì liên quan đến cái thành phần chính quy thì chúng ta sẽ đảm bảo rằng là cái phân bố của Q với cho trước x thì cái phân bố của vector z cho trước x là cái phân bố Q và cái phân bố Q này thì được tạo bởi cái tham số đó là phi thì cái phân bố Q này nè tức là đại diện cho được đợt đại diện bởi hai cái tham số mi và sigma nè thì chúng ta mong muốn nó xấp xỉ với lại một cái phân bố ẩn tiềm ẩn một cái phân bố ẩn tiềm ẩn là px thì chúng ta sẽ chính quy hóa thì px nó là cái gì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=peYaH97QeEw",
      "filename": "peYaH97QeEw",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Cho đến thời điểm này, mạng RNN, cho dù với các biến thể như Deep Stack, hay Bi-directional thì nó vẫn còn bị một cái điểm yếu rất là lớn đó chính là vấn đề về điểm nghẽn thông tin, hay còn gọi là Bottleneck Thì đây là cái hiện tượng gì? Chúng ta sẽ cùng xem một vài cái ví dụ để minh họa Trên đây, đó là một cái kiến trúc ANN được sử dụng để encode một cái câu văn bản nguồn Và decode ANN thì dùng để dịch sang một cái văn bản đích Ví dụ như đây là chúng ta dịch từ tiếng Anh sang tiếng Pháp Thế thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:59"
    }
  },
  {
    "page_content": "ta dịch từ tiếng Anh sang tiếng Pháp Thế thì cái điểm nghẽn thông tin nó sẽ thể hiện ở cái bottleneck này Tại vị trí cuối cùng mà chúng ta encode câu văn bản nguồn thì mọi thông tin của văn bản nguồn đều được chứa trong duy nhất một vector này. Và đây chính là cái điểm nghẽn của mình, khiến cho mô hình của mình không đủ thông tin toàn cục và thông tin cần thiết tại một thời điểm để chúng ta dịch ra ví dụ tại cái vector này, chúng ta muốn dịch ra cái từ rơ thì có thể cái thông tin của cái từ i",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:54",
      "end_timestamp": "0:01:40"
    }
  },
  {
    "page_content": "cái từ rơ thì có thể cái thông tin của cái từ i là cái từ quan trọng nhất để giúp chúng ta dịch cái từ rơ này nè thì cái hàm lượng thông tin của nó đã bị mai một rất là nhiều rồi vì từ i khi đến được cái điểm nghẽn này nè thì nó đã bị biến đổi một lần, hai lần, ba lần, bốn lần và năm lần và đây là một cái ví dụ rất là bé trong những cái bài toán phức tạp hơn ví dụ như là bài toán tóm tắt văn bản thì để kể từ lúc chúng ta đọc hết cái văn bản cho đến lúc chúng ta bắt đầu tóm tắt nó có thể lên đến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:33",
      "end_timestamp": "0:02:15"
    }
  },
  {
    "page_content": "lúc chúng ta bắt đầu tóm tắt nó có thể lên đến hàng trăm hoặc thậm chí là hàng ngàn chữ hàng ngàn cái token thì dẫn đến là cái từ ở đầu tiên nó đến cái chỗ điểm nghẽn này nè nó đã bị quên từ ai đã bị quên nhiều mình nói nó quên hết thì cũng không đúng, tại vì có thể chúng ta sử dụng một số biến thể như LSTM để giúp chúng ta lưu được những thông tin quan trọng nhưng mà đâu đó nó vẫn sẽ bị quên quên đi, một phần, quên nhiều khi từ ai này bị quên nhiều, đến lúc chúng ta cần dịch ra từ r, chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:12",
      "end_timestamp": "0:03:05"
    }
  },
  {
    "page_content": "đến lúc chúng ta cần dịch ra từ r, chúng ta bắt đầu từ start là bắt đầu quá trình decode thì khả năng chúng ta ra từ r này là thấp trong khi đó nếu chúng ta bắt đầu dịch, mà sau khi chúng ta vừa đọc xong từ ai thì xác suất chúng ta dịch ra được từ r, từ r trong tiếng Pháp là từ ai của mình, thì nó sẽ cao hơn đó chính là mô tả cho hiện tượng là điểm nghẽn thông tin khi chúng ta dự đoán đến từ xua thì rõ ràng là thông tin của từ xua ban đầu ở đây khi chúng ta lan truyền đến từ xua này cũng hoàn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:02:58",
      "end_timestamp": "0:03:59"
    }
  },
  {
    "page_content": "khi chúng ta lan truyền đến từ xua này cũng hoàn toàn tương tự, nó đã bị mất thông tin rất nhiều rồi Do đó, điểm nghẽn thông tin này cần phải giải quyết. Cơ chế để giải quyết là cơ chế Attention. Chốc nữa chúng ta sẽ cùng lý giải tại sao Attention có thể giúp chúng ta giải quyết được vấn đề điểm nghẽn về mất thông tin. Còn đầu tiên chúng ta sẽ tìm hiểu thế nào là Attention và cách thức thực hiện của nó là gì. Đầu tiên là chúng ta sẽ có các vector hidden là s Khi quá trình decode bắt đầu thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:03:50",
      "end_timestamp": "0:04:47"
    }
  },
  {
    "page_content": "hidden là s Khi quá trình decode bắt đầu thì chúng ta nạp vào từ start Đây là một từ token để đánh dấu quá trình decode thì chúng ta sẽ tiến hành lấy cái h t1 này nè tức là cái vector đánh dấu cái quá trình dịch lấy cái h này đi so sánh với lại các cái vector ẩn của encoder để xem, để tính cái attention score để cho biết là tại cái thời điểm này nè là t bằng 1 chúng ta sẽ attend, chúng ta sẽ quan tâm đến cái từ nào, cái token nào thì để tính cái attention score thì chúng ta dùng cái phép biến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:04:41",
      "end_timestamp": "0:05:40"
    }
  },
  {
    "page_content": "attention score thì chúng ta dùng cái phép biến đổi đó là tích vô hướng, lấy cái ht này, nhân tích vô hướng với lại cái s ví dụ như tại đây là ht với s1, tại đây là ht với s2 thì mỗi cái giá trị vô hướng này nó sẽ là một giá trị, một cái tích vô hướng này là một cái scalar Rt là 1 vector, kích thước của nó là n kích thước của nó là đúng bằng n Rt là 1 vector n chiều Tiếp theo, vì tích vô hướng này có giá trị rất lớn từ trừ vô cùng cho đến cộng vô cùng Do đó chúng ta phải chuẩn hóa bằng hàm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:05:36",
      "end_timestamp": "0:06:40"
    }
  },
  {
    "page_content": "vô cùng Do đó chúng ta phải chuẩn hóa bằng hàm Softmax Qua việc chuẩn hóa chúng ta sẽ ra được xác suất là Từ ht này đang attend 90% 90% đến từ ai Còn các từ còn lại đều là dưới 10% Vì vậy nó đang tập trung nhiều vào từ i Và alpha t sẽ là trọng số của các từ này Thế qua hàm Softmax chúng ta biết rằng là nó không thay đổi kích thước của vector đầu vào Do đó nếu rt là vector n chiều thì alpha t cũng là vector n chiều sau khi chúng ta biết là chúng ta phải attend vào từ i nhiều rồi thì chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:06:33",
      "end_timestamp": "0:07:27"
    }
  },
  {
    "page_content": "ta phải attend vào từ i nhiều rồi thì chúng ta sẽ tính attention output bằng cách là nhân các trọng số ở attention distribution ở đây với chính các vector có chứa thông tin đầy đủ nhất của các từ này, đó là s1, s2 cho đến sn Như vậy thì bước tiếp theo là chúng ta sẽ tính tổng trọng số alpha với các cái vector ẩn chứa thông tin của các từ ở đây thì chúng ta sẽ ra được context vector Và context vector này ứng với ví dụ này thì nó đang chứa 90% thông tin của từ quan trọng nhất của mình tại thời",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:21",
      "end_timestamp": "0:08:18"
    }
  },
  {
    "page_content": "tin của từ quan trọng nhất của mình tại thời điểm hiện tại đó là từ ai thì khi đó vector C này nó sẽ giúp chúng ta đi decode chính xác hơn để xác suất để mà nó ra được từ R, sẽ là cao hơn do đó chúng ta sẽ lấy vectorCT này, con cat với lại ht ở trước đó thì thật sự mà nói, cái thông tin chính để giúp chúng ta decode, nó nằm ở đây còn cái ht này, như đã nói, khi đã bị biến đổi rất nhiều rồi thì hàm lượng thông tin của từ i trong ht này rất là ít Trong khi thông tin của từ i tại vector CT này sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "00:08:10",
      "end_timestamp": "0:09:08"
    }
  },
  {
    "page_content": "Trong khi thông tin của từ i tại vector CT này sẽ nhiều hơn Tại vì 90% của s1 là tỷ trọng cực kỳ cao Tại vì s1 chứa thông tin của từ i là nhiều nhất Sau khi đã concat được vector này Chúng ta sẽ bắt đầu decode để đi tính ra cái output dự đoán Chúng ta sẽ tính hoàn toàn tương tự như không có attention, có nghĩa là gì? Hai cái vector này chúng ta ghép lại với nhau, đúng không? Thì sau đó chúng ta sẽ nhân với lại một cái vector V V nhân với lại CT và HT Rồi, sau đó qua cái hàm Softmax để chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "00:09:01",
      "end_timestamp": "0:09:59"
    }
  },
  {
    "page_content": "và HT Rồi, sau đó qua cái hàm Softmax để chúng ta tính xác suất của từ nào trong từ tiếng Pháp tương ứng thì tương tự như là attention, không có attention và ở đây chúng ta có một chú ý đó là ct nó có kích thước là bao nhiêu? thì ct nó sẽ có kích thước giống với kích thước của S mà S chúng ta biết rồi đó là một vector d chiều tất cả S và H đều là vector d chiều do đó ở đây sẽ là vector d sau khi chúng ta concat lại CT với ht thì ở đây nó sẽ ra vector đó là 2d tại vì CT là vector d chiều còn H",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "00:09:52",
      "end_timestamp": "0:10:52"
    }
  },
  {
    "page_content": "vector đó là 2d tại vì CT là vector d chiều còn H cũng là vector d chiều cộng lại thì sẽ là vector 2d Như vậy thì chúng ta đã cùng tìm hiểu qua kiến trúc ANN Kết hợp với Attention Thì ANN Kết hợp với Attention nếu mà chúng ta biểu diễn gọn lại bằng sơ đồ ở đây thì chúng ta thấy kể cả khi cái văn bản này của chúng ta rất là dài Ví dụ là có 1000, mình có 1000 cái token đầu vào 1.000 từ khi bắt đầu quá trình dịch là tại đây không, khi bắt đầu quá trình là encode, ví dụ như tại vị trí thứ T tại đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:10:44",
      "end_timestamp": "0:11:37"
    }
  },
  {
    "page_content": "là encode, ví dụ như tại vị trí thứ T tại đây chúng ta đến đây và đi truy vấn trong 1.000 từ này xem từ nào là từ được quan tâm tại thời điểm hiện tại sau đó chúng ta sẽ tổng hợp để ra một vector như thế này như vậy nếu đi theo đường như cũ thì từ thứ 2, giả sử như từ đang cần decode là từ thứ 2 thì sẽ phải đi lần lượt qua rất nhiều chúng ta sẽ phải đi qua ít nhất là 1000 từ tức là chúng ta sẽ phải biến đổi 1000 lần trong khi đó nếu chúng ta đi theo con đường 1 xanh lá ở đây Từ đây lên đây,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "00:00:00",
      "end_timestamp": "0:12:22"
    }
  },
  {
    "page_content": "đi theo con đường 1 xanh lá ở đây Từ đây lên đây, xong từ đây, chúng ta đi dự đoán cái giá trị tiếp theo thì nó chỉ mất có 2 lần biến đổi như vậy là 2 so với 10.000 lần thì rõ ràng là cái 2 nó sẽ có chứa thông tin và nó sẽ ít bị mất thông tin hơn Vì vậy, có thể thấy là ANN với Attention là biến thể rất quan trọng để giúp cho chúng ta ít bị mất mát thông tin Nhờ các kết nối tắt này, khi chúng ta huấn luyện, chúng ta có y ngã ở đây Nhờ các kết nối tắt, chúng ta đi ngược lại, chúng ta đi ngược lại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": "0:12:17",
      "end_timestamp": "0:13:00"
    }
  },
  {
    "page_content": "tắt, chúng ta đi ngược lại, chúng ta đi ngược lại và chúng ta lại đi ngược lại Vì việc chúng ta cập nhật tham số ở những cái tình huống là cái chữ đầu tiên nó sẽ không bị hiện tượng là vanishing gradient Tuy nhiên, với attention thì nó vẫn sẽ có những cái điểm yếu Vậy thì vấn đề của nó là gì? Thứ nhất, đó là chúng ta tính tuần tự từ trái sang phải Vì tính tuần tự, hoặc là chúng ta đi theo chiều ngược lại cũng như vậy thì tính tuần tự đến từ bên trái trước rồi mới đến bên phải sau nó sẽ không",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 16,
      "start_timestamp": "00:00:00",
      "end_timestamp": "0:13:52"
    }
  },
  {
    "page_content": "trái trước rồi mới đến bên phải sau nó sẽ không thể song song hóa được tính toán Và chính cái việc này sẽ gây ra việc lãng phí về JBL Tại vì đến thời điểm mà Attention ra thì các mạng học sâu của CNN đã khai thác sức mạnh GPU để tính toán song song và tăng tốc độ huấn luyện lên rất là nhiều lần rồi Nhưng mà nếu vẫn còn encoder theo kiểu như thế này thì chúng ta sẽ rất khó khai thác sức mạnh của GPU Các vector biểu diễn từ encoder chưa thực sự tương tác với nhau Ví dụ chúng ta thấy, cái sự tương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 17,
      "start_timestamp": "0:13:47",
      "end_timestamp": "0:14:31"
    }
  },
  {
    "page_content": "tác với nhau Ví dụ chúng ta thấy, cái sự tương tác ở đây nếu có chỉ là giữa hai cái từ, ví dụ như là hai từ xt và xt cộng một Thì chúng ta thấy là nó chỉ có sự tương tác giữa hai cái từ liên tiếp, ví dụ như là xt và xt cộng một, nó có tương tác qua lại Còn nó sẽ không có tương tác một cách trực tiếp với những từ ở xa hơn Thì nó sẽ thiếu tính tương tác giữa các từ để tạo ra những đặc trưng mới Chưa tận dụng được các mẹo của các mô hình học sâu hiện đại Rõ ràng trong tiến trình phát triển của các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 18,
      "start_timestamp": "0:14:29",
      "end_timestamp": "0:15:36"
    }
  },
  {
    "page_content": "đại Rõ ràng trong tiến trình phát triển của các mô hình học sâu có rất nhiều mẹo đã được tìm ra để nhằm giải quyết vấn đề Overfitting và Vanishing Gradient nhưng mà biến thể này chưa khai thác được nhiều thì chúng ta sẽ cùng đến với một trong những biến thể rất là nổi tiếng đó là Transformer thì Transformer nó kế thừa được rất nhiều mẹo trong mô hình học sâu đầu tiên, chúng ta sẽ xem đến yếu tố từ trái sang phải nếu như trong ANN chúng ta encode tính thứ tự này để nhằm đảm bảo phân biệt được từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 19,
      "start_timestamp": "0:15:33",
      "end_timestamp": "0:16:24"
    }
  },
  {
    "page_content": "tính thứ tự này để nhằm đảm bảo phân biệt được từ do you understand với lại từ you do understand là hai câu khác nhau nó sẽ xử lý từ Do trước xong rồi đến từ U dẫn đến là thông tin của từ Do sẽ nhiều hơn so với thông tin của từ Do việc chúng ta có dấu mũi tay này là để phục vụ cho thể loại dữ liệu có tính thứ tự của văn bản bây giờ Transformer đã giải quyết vấn đề này như thế nào? đó là dùng cái Positional Embedding. tức là ví dụ như khi chúng ta có một cái từ ở đây một cái nó ra đây rồi sau đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 20,
      "start_timestamp": "0:16:19",
      "end_timestamp": "0:17:02"
    }
  },
  {
    "page_content": "có một cái từ ở đây một cái nó ra đây rồi sau đó thì chúng ta sẽ đưa vào một cái tính toán và nếu như chúng ta để cái dấu mũi tay này thì nó sẽ tạo ra sự phụ thuộc lẫn nhau giữa từ trước với từ sau và chúng ta sẽ gắn thêm vào một position ví dụ như ở đây là từ Do chúng ta sẽ gắn thêm cái thông tin về mặt vị trí đó là vị trí số 1 rồi, tiếp theo đó là từ u chúng ta sẽ gắn thêm cái vị trí là số 2 Vì việc gắn này sẽ nhờ module positional embedding. Từ Do sẽ được biến thành một vector biểu diễn. Từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 21,
      "start_timestamp": "0:16:59",
      "end_timestamp": "0:17:41"
    }
  },
  {
    "page_content": "Từ Do sẽ được biến thành một vector biểu diễn. Từ Do sẽ là v của do. Còn số 1 sẽ là positional embedding của số 1. Đây là một vector. và hai cái vector này cộng lại với nhau để nó vừa có chứa được thông tin của từ Do mà vừa có chứa được thông tin của số 1 thì cái Positional Embedding này chúng ta có thể sử dụng một công thức cố định hoặc là chúng ta sẽ huấn luyện luôn cái phần này để cho khi chúng ta gặp cái vị trí số 1 thì chúng ta sẽ dùng một vector khi chúng ta đến cái vị trí số 2 chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 22,
      "start_timestamp": "0:17:35",
      "end_timestamp": "0:18:39"
    }
  },
  {
    "page_content": "vector khi chúng ta đến cái vị trí số 2 chúng ta sẽ dùng một cái vector khác và hai cái vector đó sẽ đại diện cho hai cái thứ tự khác nhau thì đó chính là hai cái Positional Embedding Và đây chính là cái module mà mình nghĩ là rất là quan trọng để giúp chúng ta đoạn tuyệt với kiến trúc ANN trước đây. Các kiến trúc ANN trước đây bị một cái rào cản đó chính là cái tính thứ tự đó. Nó sẽ khiến chúng ta không khai thác được cái GPU. Và nếu bỏ được cái này thì cái việc tính toán Do cộng 1 và U cộng 1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 23,
      "start_timestamp": "0:18:32",
      "end_timestamp": "0:19:35"
    }
  },
  {
    "page_content": "này thì cái việc tính toán Do cộng 1 và U cộng 1 hay là vector biểu diễn của Do cộng vector biểu diễn của 1 và nó sẽ độc lập với nhau thì khi đó chúng ta sẽ xử lý song song được. Ngoài ra thì Transformer còn rất nhiều những cái khai thác đến những cái mẹo của các mô hình trước đây. Ví dụ cái Add này, đây là một cái Skip Connection. Skip Connection sẽ giúp chúng ta giải quyết vấn đề Vanishing Gradient Còn cái norm giúp chúng ta chống hiện tượng Overfitting Multihead Attention sẽ giải quyết vấn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 24,
      "start_timestamp": "0:19:31",
      "end_timestamp": "0:20:18"
    }
  },
  {
    "page_content": "Overfitting Multihead Attention sẽ giải quyết vấn đề trước đây, đó chính là các từ không có tính tương tác nhau các vector biểu diễn của từ ở encoder này, nó thiếu tính tương tác nhau MultiHeadAttention sẽ giúp chúng ta tương tác đặc trưng giữa các từ đầu vào Chúng ta dùng từ là token, giữa token đầu vào Nhằm giúp tạo ra các đặc trưng có tính gọi là phân loại cao hơn, các đặc trưng cấp cao hơn Nếu như chúng ta thực hiện cái Multihead Attention này thì bản chất chỉ là cộng trọng số nó chỉ là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 25,
      "start_timestamp": "0:20:12",
      "end_timestamp": "0:21:12"
    }
  },
  {
    "page_content": "này thì bản chất chỉ là cộng trọng số nó chỉ là cộng trọng số, do đó nó sẽ không giải quyết được các bài toán phi tuyến tính để phi tuyến tính hóa thì chúng ta sẽ phải có lớp FeedForward này thì đây là giúp cho chúng ta nonlinear giải quyết các bài toán nonlinear Add & Norm cũng tương tự như ở dưới Rồi, ở đây chúng ta sẽ thấy là nó sẽ có biến thể của Stack ở đây Stack layer Mục đích của stack layer này, ví dụ là lặp lại 6 lần này để giúp chúng ta tạo ra các đặc trưng học sâu, giúp chúng ta giải",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 26,
      "start_timestamp": "0:21:03",
      "end_timestamp": "0:22:13"
    }
  },
  {
    "page_content": "tạo ra các đặc trưng học sâu, giúp chúng ta giải quyết được các bài toán phức tạp. Ở nhánh decoder cũng hoàn toàn có các kỹ thuật tương tự nhưng nó có duy nhất một cái module khác biệt đó chính là cross attention. Tại sao chúng ta dùng từ Cross? Là vì có sự băng qua từ encoder sang decoder Nhờ có sự tổng hợp thông tin từ encoder chúng ta sẽ đưa vào decoder để giúp chúng ta dự đoán các từ trong chuỗi của mình Chúng ta có 3 dấu mũi tên tương ứng là Query, Key và Value. Trong đó, chúng ta sẽ tương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 27,
      "start_timestamp": "0:22:08",
      "end_timestamp": "0:22:48"
    }
  },
  {
    "page_content": "Query, Key và Value. Trong đó, chúng ta sẽ tương tác giữa Query, query của mình, nó sẽ đến từ decoder này. Còn Key và Value là 2 dấu mũi tên đến từ decoder. Rồi, và cuối cùng là qua cái lớp linear và softmax thì hoàn toàn tương tự như cho cái biến thể ANN đó là V của cái output này, output tại thời điểm này là Decoded, tại thời điểm T, sau đó là softmax thì nó sẽ ra được cái output xác suất. Như vậy thì chúng ta đã cùng lướt qua những cái biến thể của mô hình dữ liệu dạng có thứ tự. Chúng ta đã",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 28,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "của mô hình dữ liệu dạng có thứ tự. Chúng ta đã thấy là Transformer là một mô hình sinh sau đẻ muộn và nó đã tận dụng được rất nhiều thành tựu của các mô hình trước đó. Bên cạnh những về mặt kiến trúc, Transformer còn sử dụng optimizer Optimizer là sử dụng AdamW, đây là một optimizer mới cho việc hội tụ tốt hơn, sử dụng hàm kích hoạt, norm cũng hiện đại hơn, sẽ giúp cho mạng transformer được huấn luyện tốt hơn và tận dụng hơn. Đó chính là sơ lược các mô hình học sâu trong dữ liệu là chuỗi. Hi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "các mô hình học sâu trong dữ liệu là chuỗi. Hi vọng là chúng ta sẽ nắm bắt được việc áp dụng trong giải quyết các vấn đề vanishing gradient, vấn đề giải quyết vấn đề về overfitting để tiếp tục phát triển các mô hình học sâu này. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=PFMQfuOaEWA",
      "filename": "PFMQfuOaEWA",
      "title": "[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 2)",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng tìm hiểu về mô hình khuếch tán diffusion model và sự khác biệt giữa diffusion model so với mô hình variational autoencoder ra sao, quá trình khuếch tán được thực hiện như thế nào. Chúng ta sẽ nhắc lại công thức của mô hình xác suất đằng trước, đó là log P của x sẽ là bằng tổng của hai kỳ vọng này. Thì thành phần số 2, bản chất của nó chính là công thức của KL divergence của phân bố V, z cho trước x và P của z cho trước x. Đây là kỳ vọng của một con số lớn hơn bằng 0, do đó chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:07"
    }
  },
  {
    "page_content": "vọng của một con số lớn hơn bằng 0, do đó chúng ta sẽ có cái chặn dưới của mình, đó chính là số hạng bên tay trái. Cái số hạng bên tay trái, kỳ vọng này gọi là evidence lower bound, tức là cái chặn dưới của log Px. Khi chúng ta huấn luyện, chúng ta sẽ tìm cách để vì chúng ta muốn cực đại hóa log Px, chúng ta sẽ đem cái chặn dưới, chúng ta cũng cực đại hóa nó luôn. Khi chúng ta nâng cái chặn dưới lên thì đồng thời nó cũng sẽ nâng cái Px lên. Và công thức này sau khi chúng ta biến đổi thì nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:59"
    }
  },
  {
    "page_content": "công thức này sau khi chúng ta biến đổi thì nó sẽ ra cái biểu thức bên tay phải. Thì ở đây cụ thể là gì? Kỳ vọng của Qz cho trước x, log P của x và z sẽ là bằng P của x cho trước z, nhân với lại P của z. Chia cho Qz của x. Thì chúng ta sẽ tách cái thành phần này ra. Chúng ta sẽ tách ra thì nó sẽ là bằng kỳ vọng của Qz cho trước x và log của Px cho trước z. Sau đó chúng ta sẽ cộng cho cái log của tích của thành phần này và cái thành phần bên tay phải. Thì chúng ta tách nó ra, log của tích sẽ là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:42",
      "end_timestamp": "0:02:52"
    }
  },
  {
    "page_content": "phải. Thì chúng ta tách nó ra, log của tích sẽ là bằng tổng của 2 log. Do đó nó sẽ là bằng cộng cho Qz cho trước x và log của Pz chia cho Qz cho trước x. X sẽ là bằng log của Pz. Sau đó là trừ cho kỳ vọng của Qz. Rồi, kỳ vọng của log của Qz cho trước x. Rồi, thế thì ở đây chúng ta có thể đảo thứ tự của nó lại. Chúng ta đảo thứ tự lại bằng cách đó là cái vế này thì tương đương với lại cái biểu thức ở bên tay trái. Còn cái vế này thì chúng ta sẽ đảo thứ tự lại. Nó sẽ là bằng trừ của kỳ vọng của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:02:39",
      "end_timestamp": "0:04:28"
    }
  },
  {
    "page_content": "đảo thứ tự lại. Nó sẽ là bằng trừ của kỳ vọng của Qz cho trước x, trừ cho kỳ vọng của Qz cho trước x, nhân cho Pz. Rồi, thì cái công thức này thì nó sẽ là bằng trừ của kỳ vọng của Qz cho trước x, nhân cho log của Qz cho trước x, chia cho Pz. Thì bản chất của cái công thức này, Q của x, log của Q của z cho trước x, chia cho x, thì đây chính là KL divergence này. Là KL divergence của Qz cho trước x. Rồi, với cái Pz, vế bên trái là giống và vế bên phải cũng giống luôn. Chúng ta có cái dấu trừ ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:04:18",
      "end_timestamp": "0:05:20"
    }
  },
  {
    "page_content": "phải cũng giống luôn. Chúng ta có cái dấu trừ ở đằng trước. Như vậy thì chúng ta đã chứng minh được cái công thức của cái elbow này. Thế thì bây giờ, cái ý nghĩa của cái công thức này đó là gì? Thì chúng ta sẽ cùng tìm hiểu trong cái phần tiếp theo. Rồi, thì ở đây chính là chúng ta sẽ có cái mô hình đầu tiên, đó là mô hình Variational Autoencoder. Với cái công thức này, thì chúng ta sẽ thấy là 2 vế và ý nghĩa của 2 vế đó là gì? Rồi, thì đối với cái vế bên trái, ý nghĩa của nó đó là khi chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:05:16",
      "end_timestamp": "0:06:25"
    }
  },
  {
    "page_content": "vế bên trái, ý nghĩa của nó đó là khi chúng ta từ cái z, tức là cho trước z nè. Z là một cái vector trong không gian ẩn của mình. Nó là một cái random variable. Nhưng nó sẽ được tính ra cái P. Thì bản chất của cái này đó chính là cái xác suất của x. Là xác suất của x cho trước z. Thì cái ý nghĩa của nó đó là cái giá trị mà mình tạo ra x từ z. Cái giá trị của x tạo ra từ z. Nó sẽ giống với lại cái ảnh ban đầu, giống với lại cái ảnh góc. Thì cái mô hình Variational Autoencoder, nó đã đưa cái việc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:06:18",
      "end_timestamp": "0:07:09"
    }
  },
  {
    "page_content": "hình Variational Autoencoder, nó đã đưa cái việc đó là chúng ta cực đại hóa cái công thức này. Thì khi cực đại hóa, thì tức là cái thành phần này sẽ là giá trị lớn nhất. Mà cái xác suất để cho cái x lớn nhất khi cho trước z, nó chính là chúng ta tạo ra một cái tấm hình giống với ảnh ban đầu. Từ z, chúng ta tạo ra x. Thì làm sao cho cái x này nó giống với lại ảnh ban đầu nhất. Thì đó chính là cái ý nghĩa của cái công thức log của Px cho trước z. Ở đây chúng ta đừng quan tâm cái log nữa, tại vì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:07:05",
      "end_timestamp": "0:07:47"
    }
  },
  {
    "page_content": "Ở đây chúng ta đừng quan tâm cái log nữa, tại vì khi chúng ta cực đại hóa cái hiệu này, thì chúng ta sẽ cực đại hóa cái thành phần này và cực tiểu hóa cái thành phần KL Divergence này. Tại vì ở đây có dấu trừ nên chúng ta sẽ đi cực tiểu hóa. Còn cực tiểu hóa của một cái hàm log thì nó sẽ tương đương với việc là mình đi cực tiểu hóa cái Px. Tại vì log là một cái hàm đồng biến, nên chúng ta đi tìm giá trị log của một cái biểu thức fx. Thì nó sẽ tương đương, chúng ta đi tìm cái việc chúng ta tìm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:07:38",
      "end_timestamp": "0:08:29"
    }
  },
  {
    "page_content": "đương, chúng ta đi tìm cái việc chúng ta tìm max của cái log của fx, thì nó sẽ tương đương với việc chúng ta đi tìm max của fx. Do đó thì cái việc mà đi cực đại hóa cái này tương đương với cái việc là chúng ta đi cực đại hóa P của x cho trước z. Và chúng ta cho trước cái z của mình là đi nằm trong cái phân bố của Qzx. Qzx của mình chính là cái kết quả của quá trình encode. Tức là chúng ta biến từ cái ảnh góc ban đầu về cái vector z trong không gian latent. Và cái z này thì nó sẽ tuân theo cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:08:23",
      "end_timestamp": "0:09:17"
    }
  },
  {
    "page_content": "gian latent. Và cái z này thì nó sẽ tuân theo cái phân bố này. Cái z này nó sẽ là phân bố Q. Thế thì khi chúng ta lấy mẫu hết tất cả các z, lấy mẫu hết z theo cái phân bố Q này, chúng ta đi decode để tạo ra cái x mũ này. Thì cái x mũ này nó phải giống, nó giống thật nhất. Vâng, thì cái Px cho trước z chính là làm sao cho cái x mũ này là giống thật nhất, giống ảnh góc. Còn cái thành phần thứ hai thì thay vì chúng ta đi cực đại hóa cái dấu trừ này, thay vì chúng ta đi cực đại hóa cái vế bên tay",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 10,
      "start_timestamp": "0:09:07",
      "end_timestamp": "0:10:10"
    }
  },
  {
    "page_content": "thay vì chúng ta đi cực đại hóa cái vế bên tay phải thì tương đương với việc là chúng ta sẽ đi cực tiểu hóa cái thành phần KL divergence thôi. Thì đây chính là cái thành phần chính quy trong cái mô hình Variational Autoencoder. Và cái Pz này, cái Pz này là một cái phân bố tiên nghiệm. Và chúng ta mong muốn cái phân bố tiên nghiệm này, nó sẽ là một cái normal Gaussian. Thì là một cái phân bố chuẩn Gaussian N01. Rồi, thì đây chính là cái mô hình Variational Autoencoder. Và ý nghĩa của nó đó là từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 11,
      "start_timestamp": "0:09:58",
      "end_timestamp": "0:10:46"
    }
  },
  {
    "page_content": "Autoencoder. Và ý nghĩa của nó đó là từ x, chúng ta sẽ qua cái encode, chúng ta sẽ tạo ra được một cái phân bố, ra một cái phân bố xác suất là qi, phi, zx. Thì phi ở đây là cái tham số của encoder. Và từ cái qi này chúng ta sẽ sample, chúng ta sẽ sample, thì khi chúng ta sample thì chúng ta sẽ có được hết cái kỳ vọng này, tính được cái kỳ vọng này. Chúng ta sample một cái z và chúng ta decode để tạo ra cái x mũ. Thì chúng ta luôn mong muốn là cái x mũ này giống thật, nó thể hiện qua cái việc là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 12,
      "start_timestamp": "0:10:34",
      "end_timestamp": "0:11:23"
    }
  },
  {
    "page_content": "x mũ này giống thật, nó thể hiện qua cái việc là cực đại hóa cái P của x cho trước z. Rồi, thì so sánh cái mô hình Variational Autoencoder với mô hình diffusion, thì Variational Autoencoder là một pha, là từ cái ảnh góc x, nó encode thành một cái vector z, một cái không gian nhiễu, một cái phân bố nhiễu. Và cái phân bố nhiễu này chúng ta sẽ sample ra để có được cái vector z này. Thì đây là cái hình ảnh minh họa của cái vector z. Đó là một cái nhiễu. Qua cái hàm decode thì chúng ta sẽ tạo ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 13,
      "start_timestamp": "0:11:17",
      "end_timestamp": "0:12:03"
    }
  },
  {
    "page_content": "nhiễu. Qua cái hàm decode thì chúng ta sẽ tạo ra được một cái phân bố xác suất là P theta x cho trước z. Và chúng ta lấy mẫu để có được cái x mũ này. Thì trong cái mô hình Variational Autoencoder là decode nó sẽ tạo ra cái x mũ. Và chúng ta sẽ mong muốn cho cái x mũ này xấp xỉ với lại cái ảnh góc ban đầu, đó là cái vế thứ nhất. Cái vế thứ hai đó là cái thành phần chính quy hóa là cái nhiễu này, thì nó sẽ tuân theo cái phân bố 0.1. Còn đối với cái mô hình diffusion ở dưới đây thì thay vì một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 14,
      "start_timestamp": "0:11:55",
      "end_timestamp": "0:12:45"
    }
  },
  {
    "page_content": "cái mô hình diffusion ở dưới đây thì thay vì một bước, Thứ nhất, cái sự khác biệt thứ nhất đó là thay vì một bước thì ở đây chúng ta sẽ có nhiều bước encoding, nhiều bước nhỏ encoding. Và cuối cùng chúng ta cũng đến được cái random noise như thế này theo cái phân bố normal distribution. Nhưng cái sự khác biệt thứ hai đó là trong mô hình VAE thì nó sẽ có tham số, có cái tham số phi. Còn ở đây là không có tham số, các encoding này là không có tham số. Thì đó chính là cái sự khác biệt lớn nhất mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 15,
      "start_timestamp": "0:12:37",
      "end_timestamp": "0:13:16"
    }
  },
  {
    "page_content": "số. Thì đó chính là cái sự khác biệt lớn nhất mà chúng ta thấy được giữa hai cái mô hình VAE và AE. VAE thì sẽ có tham số và chỉ có một bước, một bước nhảy là đến được cái random noise. Thế thì chúng ta thấy là cái việc mà chúng ta ánh xạ trực tiếp từ ảnh thế giới thực sang cái random noise này mà chỉ qua một bước, thì đây là một cái bài toán khó. Và chưa kể khi chúng ta decode ngược trở lại từ cái random noise này thì đây cũng là một cái bài toán khó. Tuy nhiên khi thay vì chúng ta giải một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 16,
      "start_timestamp": "0:13:09",
      "end_timestamp": "0:13:57"
    }
  },
  {
    "page_content": "toán khó. Tuy nhiên khi thay vì chúng ta giải một cái bài toán khó với một cái encoder thì chúng ta sẽ chia nhỏ nó ra thành nhiều bước. Thì những cái bước encoding này nó sẽ là một cái mô hình dễ hơn, dễ hơn rất là nhiều. Chúng ta phun một ít nhiễu lên trên cái X0 để được cái X1, rồi sau đó phun một ít nhiễu lên để thành X2. Và cái ảnh của mình dần dần nó đã bị mất hết cái đối tượng góc ban đầu. Và khi chúng ta phun đến cái bước thứ T thì ở đây là nó xấp xỉ với một cái normal distribution. Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 17,
      "start_timestamp": "0:13:52",
      "end_timestamp": "0:14:27"
    }
  },
  {
    "page_content": "là nó xấp xỉ với một cái normal distribution. Thì chút nữa chúng ta cũng sẽ có cái phần chứng minh cái ảnh này nó sẽ tiến về cái normal distribution. Sau đó chúng ta giải mã thì cái việc chúng ta giải mã decoding từ những cái bước nhỏ này, thì cái mô hình của mình nó sẽ dễ học hơn, dễ học để tìm ra được cái theta. Tức là thay vì chúng ta giải quyết một bài toán khó, mô hình phức tạp để có thể giải mã được, thì những cái bài toán dễ như thế này thì chúng ta sẽ cần cái số lượng tham số nó ít hơn,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chúng ta sẽ cần cái số lượng tham số nó ít hơn, cái tính khả thi của nó nó cao hơn và chất lượng hình ảnh của nó cũng sẽ cao hơn. Thì đó chính là cái sự khác biệt giữa VAE và AE. Hãy subscribe cho kênh Ghiền Mì Gõ để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qCEs0PIGwek",
      "filename": "qCEs0PIGwek",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 3",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với vấn đề đầu tiên mà chúng ta cần phải giải quyết, đó chính là vấn đề về overfitting. Thì overfitting không phải là một vấn đề riêng của lĩnh vực học sâu mà đó là một vấn đề chung của mọi mô hình máy học. Thế thì overfitting là gì, nguyên lý của nó ra sao, nguyên nhân là gì và giải pháp là gì thì chúng ta sẽ cùng tìm hiểu trong phần này. Đầu tiên khi nói về hiện tượng overfitting thì chúng ta sẽ phải nhắc đến cái vấn đề đó là cái mô hình của mình. Nó dự đoán rất là tốt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:54"
    }
  },
  {
    "page_content": "đó là cái mô hình của mình. Nó dự đoán rất là tốt trên tập Train nhưng nó lại rất là tệ trên tập Test. Thì cái này có một số biểu hiện mang tính chất định lượng, ví dụ như là trên tập Train chúng ta huấn luyện xong chúng ta dùng chính tập Train để chúng ta đánh giá, thì cái độ chính xác của mình nó có thể lên đến 80% ví dụ vậy. Nhưng khi chúng ta Test trên tập Dữ liệu Test thì độ chính xác của mình nó rớt xuống rất là đáng kể. Ví dụ nếu mà nó khoảng 75% thì ok là cái mô hình của mình tương đối",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:46",
      "end_timestamp": "0:01:28"
    }
  },
  {
    "page_content": "75% thì ok là cái mô hình của mình tương đối tốt và nó sẽ không có quá bị hiện tượng Overfitting. Tuy nhiên nếu cái độ chính xác trên tập Test của mình mà chỉ còn có khoảng 60% thì nó đã có một sự giảm đáng kể từ 80% xuống 60%. Vì vậy cái tình huống này đó là hiện tượng Overfitting. Thì đây là một cái ví dụ mang tính chất định lượng để giúp chúng ta hình dung về cái hiện tượng này. Thế thì nếu xét về giải thích thì chúng ta có rất nhiều những cái cách thức để giải thích cho cái hiện tượng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:16",
      "end_timestamp": "0:02:16"
    }
  },
  {
    "page_content": "cái cách thức để giải thích cho cái hiện tượng Overfitting. Thì đây là một cái mô hình nó rất là phức tạp và dữ liệu không đủ nhiều. Thì đây là một cái cách giải thích cho cái nguyên nhân của hiện tượng Overfitting mà các bạn thấy phổ biến nhất khi chúng ta đọc các tài liệu trên các bài báo khoa học hoặc là trên nguồn internet. Hoặc là một cái cách giải thích khác đó là hiện tượng Overfitting là cái hiện tượng mà mô hình của mình nó sẽ tìm cách để mà học thuộc các mẫu dữ liệu Train thay vì là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:04",
      "end_timestamp": "0:02:40"
    }
  },
  {
    "page_content": "để mà học thuộc các mẫu dữ liệu Train thay vì là chúng ta tổng quát hóa lên. Để sao cho sau này khi có một cái dữ liệu mới thì nhờ có tính chất tổng quát hóa này nó có thể dễ dàng xử lý được trên những cái dữ liệu mới. Thì hình ở dưới đây là minh họa hai cái tình huống. Cái tình huống đầu tiên đó là Appropriate Fitting. Thì đây là một cái mô hình được gọi là tốt. Thì cái mô hình này là mô hình tốt tại vì sao? Mặc dù ở cái đường phân loại, cái đường màu đỏ này là cái đường phân lớp giữa hai tập",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:30",
      "end_timestamp": "0:03:26"
    }
  },
  {
    "page_content": "màu đỏ này là cái đường phân lớp giữa hai tập X và O thì chúng ta thấy là nó vẫn còn hai cái điểm X mà nằm trộn chung với lại cái điểm O. Tức là nó đang đặt sai vị trí. Thì cái hai cái sai này thì nó có thể có nhiều nguyên nhân. Cái nguyên nhân đầu tiên đó là do cái dữ liệu này thực sự là Outlier và do chúng ta gán nhãn sai. Thế thì nếu như cái mô hình của mình mà cứ tìm cách để mà học thuộc những cái tình huống mà gán nhãn sai thì vô hình chung nó đã làm mất đi tính tổng quát của cái mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:16",
      "end_timestamp": "0:03:52"
    }
  },
  {
    "page_content": "nó đã làm mất đi tính tổng quát của cái mô hình của mình. Do đó nếu mà mô hình của chúng ta biết gạn lọc ra và loại bỏ những cái Outlier một cách hợp lý thì cái mô hình của mình nó sẽ có tính tổng quát quá cao. Cái tình huống thứ hai đó là cái dữ liệu này thực sự là dữ liệu được gán nhãn đúng. Tuy nhiên cái hai cái điểm này thì nó sẽ nằm ở cái đường biên. Nó sẽ nằm ở gần đường biên và có cái sự giao thoa giữa hai cái loại điểm với nhau. Thì thông thường những cái điểm này là những cái điểm mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:03:46",
      "end_timestamp": "0:04:29"
    }
  },
  {
    "page_content": "thường những cái điểm này là những cái điểm mà có cái khả năng xảy ra trong thực tế rất là thấp. Nên nếu mà chúng ta cứ chăm chăm học vô những cái điểm này thì vô hình chung chúng ta lại bỏ qua những cái tình huống tổng quát. Còn bên tay phải đó là một cái tình huống để minh họa cho cái hiện tượng Overfitting. Đó là cái mô hình của chúng ta khi mà nó đi theo cái biên giới giữa hai cái điểm X và O. Thì nó sẽ tìm cách kéo các cái điểm X mà Outlier ở đây về cùng phía với các cái điểm X thông",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:04:17",
      "end_timestamp": "0:05:05"
    }
  },
  {
    "page_content": "ở đây về cùng phía với các cái điểm X thông thường. Thế thì các cái đường cong mà nó đi khúc khuỷu như thế này nó sẽ là cố gắng để đi học thuộc. Đây là những cái tình huống mà nó học thuộc. Và vì cái yếu tố học thuộc này nó sẽ khiến cho cái mô hình của mình không có tổng quát hóa. Thế thì đây là một vài cái cách để chúng ta giải thích cho hiện tượng Overfitting. Tuy nhiên tất cả những cái cách này thì nó đều không có cái tính thuyết phục. Tại vì nó mang tính chất gọi là trừu tượng hoặc là cảm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:04:54",
      "end_timestamp": "0:05:42"
    }
  },
  {
    "page_content": "nó mang tính chất gọi là trừu tượng hoặc là cảm nhận. Thì bây giờ làm sao có một cái cách giải thích nào đó mang tính chất định lượng hơn, thuyết phục hơn. Và đương nhiên nếu mà chúng ta bám vào những cái lý thuyết cơ bản mà chúng ta đã học ở bậc phổ thông thì đó là một cái cách giải thích tốt. Thế thì ở đây chúng ta sẽ lý giải cái hiện tượng Overfitting bằng kiến thức toán cấp 3. Và chúng ta sẽ nhắc lại cái mô hình huấn luyện của mình. Đầu tiên đó là chúng ta sẽ có cái dữ liệu X qua cái hàm mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:05:33",
      "end_timestamp": "0:06:13"
    }
  },
  {
    "page_content": "đó là chúng ta sẽ có cái dữ liệu X qua cái hàm mô hình là một cái hàm F theta X. Vì vậy thì chúng ta sẽ ra được cái giá trị dự đoán Y ngã. Y ngã trong trường hợp này chính là bằng F của theta, theta X. Và chúng ta mong muốn cái giá trị này nó sẽ xấp xỉ với lại giá trị thực tế Y. Thế thì mục tiêu cuối cùng của cái việc huấn luyện một cái mô hình máy học đó là làm sao cho cái F theta X là khớp với lại cái giá trị dự đoán, cái giá trị thực tế. Trong đó thì X và Y của mình đó là một cái mẫu dữ liệu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:06:05",
      "end_timestamp": "0:07:03"
    }
  },
  {
    "page_content": "đó thì X và Y của mình đó là một cái mẫu dữ liệu để huấn luyện. Đây là một cái mẫu dữ liệu để Train. Và chúng ta sẽ đưa về cái bài toán, đưa cái công thức này về cái dạng là giải hệ phương trình, giải hệ phương trình trong toán cấp 3. Và sử dụng một số cái kiến thức mà chúng ta đã biết để lý giải cho cái hiện tượng overfitting. Đầu tiên đó là chúng ta giả sử hàm F là một cái hàm tuyến tính. Còn trong trường hợp hàm F là một cái hàm phi tuyến thì chúng ta hoàn toàn có thể lập luận một cách tương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:06:46",
      "end_timestamp": "0:07:38"
    }
  },
  {
    "page_content": "chúng ta hoàn toàn có thể lập luận một cách tương tự. Tuy nhiên ở đây chúng ta sử dụng cái hàm tuyến tính để chúng ta đơn giản hóa công thức, cho chúng ta có thể cảm nhận được cái sự khác biệt và cái sự cần thiết trong cái việc cân bằng giữa cái số mẫu dữ liệu huấn luyện và cái tham số của mô hình. Do đó hàm tuyến tính là một cái hàm đủ đơn giản để giải thích, để minh họa. Rồi, thì bây giờ với một mẫu dữ liệu huấn luyện, với một mẫu dữ liệu huấn luyện XA và EA thì cái E này chính là cái chỉ số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:07:24",
      "end_timestamp": "0:08:17"
    }
  },
  {
    "page_content": "luyện XA và EA thì cái E này chính là cái chỉ số của mẫu. Và ta sẽ có một phương trình, như vậy với một mẫu dữ liệu XA thì chúng ta sẽ có một phương trình tuyến tính, đó là FθXA là bằng EA. Chúng ta luôn mong muốn cái hàm dự đoán của mình đối với mẫu dữ liệu thứ Y này sẽ là khớp với cái kết quả Ground Truth. Và nếu như đây là một cái hàm tuyến tính thì chúng ta sẽ viết lại cái hàm F ở dạng như sau. Đó là theta0 cộng cho theta1 XI. Thứ nhất, lưu ý là cái XI ở đây đó là một cái vector. Vector này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:08:06",
      "end_timestamp": "0:09:11"
    }
  },
  {
    "page_content": "là cái XI ở đây đó là một cái vector. Vector này thì bao gồm là m chiều. Rồi, thì chúng ta sẽ có thành phần số thứ 1, thứ 2, cho đến thứ M, từ 1 đến M. Và kèm theo cái thành phần nữa đó là bias. Thì đây là một cái mô hình tuyến tính chuẩn. Thì phương trình này, nguyên cái biểu thức này sẽ bằng với cái giá trị dự đoán là EA. Thì đây là một cái phương trình tuyến tính. Đây là một cái phương trình tuyến tính. Và dựa trên cái kiến thức cũ mà chúng ta đã học trước đây, đó là một cái chúng ta muốn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:09:00",
      "end_timestamp": "0:09:52"
    }
  },
  {
    "page_content": "ta đã học trước đây, đó là một cái chúng ta muốn giải được các cái ẩn số của cái phương trình này. Cụ thể ở đây, ẩn số của mình chính là theta0, theta1, theta2 và thetaM. Thì ở đây có tất cả là m cộng 1 ẩn. Chúng ta có tất cả m cộng 1 ẩn. Tương ứng với lại theta0, theta1, theta2 và thetaM. Thì đây chính là cái ẩn số mà chúng ta cần giải. Và để mà tìm được m cộng 1 cái ẩn số này, thì chúng ta và lưu ý là tìm với một nghiệm duy nhất. Tại vì khi chúng ta huấn luyện một cái mô hình máy học, thì khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:09:36",
      "end_timestamp": "0:10:30"
    }
  },
  {
    "page_content": "ta huấn luyện một cái mô hình máy học, thì khi huấn luyện xong một cái mô hình máy học, thì chúng ta sẽ có duy nhất một mô hình. Mà một mô hình thì đó sẽ là một bộ tham số và thôi. Như vậy thì giả sử như cái mô hình mà có độ chính xác cao nhất của chúng ta, đó là theta0 là nó đúng trong các tình huống khi chúng ta triển khai trong thực tế. Mô hình mà tối ưu là chúng ta ký hiệu là bởi theta0. Thì để mà tìm ra được cái theta sao này, với một nghiệm duy nhất thì chúng ta phải có đủ ít nhất là m",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:10:22",
      "end_timestamp": "0:11:06"
    }
  },
  {
    "page_content": "duy nhất thì chúng ta phải có đủ ít nhất là m cộng 1 phương trình. Giải một cái m cộng 1 ẩn thì chúng ta cần có đủ m cộng 1 phương trình. Ở đây là chúng ta lưu ý là đang giả sử hàm của mình là một cái hàm tuyến tính. Vậy thì gọi n là số mẫu dữ liệu huấn luyện. Khi đó thì chúng ta sẽ có một hệ các phương trình. Đây là mẫu dữ liệu thứ nhất, mẫu dữ liệu thứ nhất, rồi mẫu dữ liệu thứ n. Và ở đây chúng ta lưu ý là có cái dấu 3 chấm, tức là có bao gồm mẫu thứ 2, thứ 3, thứ 4, cho đến mẫu thứ n. Thế",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": "0:10:57",
      "end_timestamp": "0:11:38"
    }
  },
  {
    "page_content": "mẫu thứ 2, thứ 3, thứ 4, cho đến mẫu thứ n. Thế thì nếu như cái phương trình mà ít hơn về số ẩn, tức là n, nếu mà số phương trình ít hơn số ẩn, tức là n, phương trình bé hơn m cộng 1, thì cũng dựa trên kiến thức toán cấp 3 là cái hệ phương trình này là vô số nghiệm. Mà cái hệ phương trình vô số nghiệm thì nó sẽ xảy ra cái vấn đề đó là cái xác suất để khi chúng ta kết thúc quá trình huấn luyện, mà chúng ta tìm ra được cái bộ tham số tối ưu nhất, tức là cái bộ tham số theta sao mà có thể đúng cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": "0:11:28",
      "end_timestamp": "0:12:18"
    }
  },
  {
    "page_content": "là cái bộ tham số theta sao mà có thể đúng cho cả tập Train và tập Test mà tốt nhất, hoặc là tổng quát nhất, hoặc là đáng chính xác trên tập Test nhất, thì đây là 3 cái cách nói khác nhau hả, bộ tham số tối ưu nhất, hoặc là tổng quát nhất, hoặc là đáng chính xác trên tập Test nhất. Thì xác suất để mà cái p của theta bằng theta sao, tức là chúng ta huấn luyện ra được tìm được cái này sẽ là bằng 1 phần vô cùng. Tại sao? Tại vì theta sao thì chỉ có 1 nhưng mà với n bé hơn m cộng 1, tức là số ẩn bé",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "1 nhưng mà với n bé hơn m cộng 1, tức là số ẩn bé hơn số, xin lỗi số phương trình bé hơn số ẩn, thì nó là có vô số nghiệm, thì nó sẽ là 1 trên vô cùng, tức là gần như bằng 0. Xác suất cực kỳ thấp. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Qj6HkeNtIuI",
      "filename": "Qj6HkeNtIuI",
      "title": "[CS315 - Chương 2] Overfitting (Phần 1)",
      "chunk_id": 20,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với mô hình tiếp theo đó là clip Routed Language Image Retraining Routed Language Image Retraining là clip phát triển từ clip, clip cho thấy tiềm năng trong việc khai thác thông tin dựa trên một cặp dữ liệu huấn luyện, đó là hình ảnh và văn bản và khai thác dữ liệu này để cho bài toán, đó là Image Classification Tuy nhiên, điều gì xảy ra nếu chúng ta khai thác nó cho những bài toán, ví dụ như là phân đoạn ngữ nghĩa, bài toán Pose Estimation xác định tư thế của người, dáng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:03"
    }
  },
  {
    "page_content": "Pose Estimation xác định tư thế của người, dáng người, bài toán phát hiện đối tượng Chúng ta thấy trong thị giác máy tính có rất nhiều bài toán khác nhau và clip đã thể hiện được tiềm năng trong bài toán đầu tiên, đó là bài toán Classification Vậy thì, làm sao chúng ta có thể khai thác nó cho các bài toán khác? Đó chính là câu hỏi chúng ta đặt ra là làm sao áp dụng được ý tưởng tương tự với clip, nhưng mà cho bài toán phân biệt, phát hiện đối tượng, phân đoạn ngữ nghĩa đối tượng và xác định tư",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 1,
      "start_timestamp": "0:00:39",
      "end_timestamp": "0:01:50"
    }
  },
  {
    "page_content": "phân đoạn ngữ nghĩa đối tượng và xác định tư thế Pose Estimation Như vậy thì, nó đòi hỏi chúng ta phải nắm bắt được thông tin thị giác, nhưng mà nó không phải ở mức độ toàn cục, tại vì trong mô hình clip, chúng ta truyền vào nguyên một tấm ảnh và chúng ta sẽ ra được vector biểu diễn thông qua image encoder, tắc chứ ic Rồi câu mô tả của chúng ta, thì qua text image encoder là ic, text encoder là te, nó sẽ tạo ra một cái văn bản, sau đó chúng ta sẽ so hai cái này lại với nhau, thế thì nó chưa có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 2,
      "start_timestamp": "0:01:33",
      "end_timestamp": "0:02:26"
    }
  },
  {
    "page_content": "so hai cái này lại với nhau, thế thì nó chưa có cơ chế để mà chúng ta khai thác trên từng vùng của đối tượng Vậy thì làm sao chúng ta có thể nắm bắt được thông tin thị giác ở mức độ chi tiết hơn và vùng cục bộ, thay vì là vùng toàn bộ, tấm ảnh Thì cái kết quả chính mà clip đã đạt được đó là clip G-clip có thể học những cái không cần dữ liệu, tức là Zero-Shot Transfer cho bài toán phát hiện đối tượng Trên hình đây chúng ta thấy là khi chúng ta đưa vào một cái code prompt là raccoon, thì nó đã",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 3,
      "start_timestamp": "0:02:16",
      "end_timestamp": "0:03:07"
    }
  },
  {
    "page_content": "đưa vào một cái code prompt là raccoon, thì nó đã chỉ ra được cái vị trí của cái đối tượng đó ở đâu, kèm theo cái score tương ứng của mình là bao nhiêu phần trăm Khi chúng ta gõ cái prompt mà đa đối tượng, ở đây là một đối tượng, còn đây là một đối tượng, còn nếu chúng ta đưa vào nhiều hơn một đối tượng, ví dụ như là person, bicycle, car, motorbike, motorcycle Và giữa các đối tượng này thì chúng ta để cách nhau bởi một cái dấu chấm để phân biệt, thì nó cũng khoanh vùng được Apple, rồi prompt là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 4,
      "start_timestamp": "0:02:52",
      "end_timestamp": "0:03:43"
    }
  },
  {
    "page_content": "thì nó cũng khoanh vùng được Apple, rồi prompt là tương tự như vậy cho các ví dụ khác, thì chúng ta thấy là nó có thể khoanh vùng được cái bánh xe, có thể khoanh vùng được nguyên chiếc xe Rồi vân vân, thì đây chính là thế mạnh của clip sau với lệch clip, đó là nó có thể học không cần dữ liệu Zero-Shot Transfer cho cái bài toán phát hiện đối tượng Và clip thì chế tên bài báo của mình đó là Routed Language Image Retraining, thì chúng ta cũng sẽ có bắt gặp những cụm từ mới, thì cái cụm từ mà chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 5,
      "start_timestamp": "0:03:28",
      "end_timestamp": "0:04:12"
    }
  },
  {
    "page_content": "bắt gặp những cụm từ mới, thì cái cụm từ mà chúng ta đang cần quan tâm ở đây đó chính là Routed Language Image Thì cái Routed Language Image đó là chúng ta sẽ tìm cách để liên kết giữa các cái từ hoặc là cụm từ trong câu với một vật thể hoặc là một vùng của tấm ảnh, ví dụ chúng ta có nguyên một cái tấm ảnh như thế này Và chúng ta có một cái code prompt đó là ví dụ như một cái bus.person, thì giả sử như trong hình này thì nó có một chiếc xe bus, nó có một chiếc xe bus Và có một người ở đây thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 6,
      "start_timestamp": "0:03:59",
      "end_timestamp": "0:05:12"
    }
  },
  {
    "page_content": "nó có một chiếc xe bus Và có một người ở đây thì nó sẽ tìm cách liên kết cái từ bus này với lại cái phần, cái khu vực mà tương ứng có cái nội dung hình ảnh đó, rồi nó liên kết cái person với lại cái khu vực mà tương ứng có cái đối tượng trong hình ảnh đó, đó là cái vùng màu đen ở đây Và như vậy thì nó đã liên kết được giữa văn bản và hình ảnh, thì Routed Language Image đó là một cái phương pháp hoặc là một cái bài toán mà giúp cho chúng ta khoanh vùng được cái đối tượng ảnh mà tương đương với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 7,
      "start_timestamp": "0:04:51",
      "end_timestamp": "0:05:44"
    }
  },
  {
    "page_content": "vùng được cái đối tượng ảnh mà tương đương với lại cái nội dung ở bên trong tấm hình của mình Thì cái ý tưởng chính đó là đưa bài toán phát hiện đối tượng Object Detection trở về thành một cái bài toán đó là phân lập hoặc là từ hoặc là cụm từ trong câu hay là phrase, routing Và chúng ta sẽ phát hiện vật thể và phân lập cái cụm từ, hai đối tượng nó có cái sự tương đồng cao Thì ở đây là một cái ví dụ, chúng ta thấy đó là khi chúng ta đưa vô một cái câu mô tả thì trong cái câu mô tả tương ứng với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 8,
      "start_timestamp": "0:05:33",
      "end_timestamp": "0:06:19"
    }
  },
  {
    "page_content": "câu mô tả thì trong cái câu mô tả tương ứng với một tấm ảnh, đây là một cái cặp ảnh và câu mô tả Thì nó sẽ có cái cụm từ là đi kèm với lại cái khu vực mà cái ảnh nó có nội dung đó, small, vial, op, vaccine Thì đây là một cái hình ảnh tương ứng với cái mô tả của cái hình ảnh tương ứng với lại cái câu mô tả đó Thế thì clip, clip có khả năng nhận diện được các đối tượng ít gặp và trừu tượng Tức là bên cạnh những đối tượng rất phổ biến như là car, dog, bus, person, v.v. Thì ở đây chúng ta thấy là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 9,
      "start_timestamp": "0:06:13",
      "end_timestamp": "0:06:56"
    }
  },
  {
    "page_content": "dog, bus, person, v.v. Thì ở đây chúng ta thấy là những cụm từ này là những cái từ ít gặp, ống tiêm, vaccine, v.v. đó là những cái từ ít gặp Thì thậm chí là những cái từ mà có tính trừu tượng cao ví dụ như là the view, là khoanh vùng nguyên cái này là the view Rồi beautiful caribbean, caribe sea, thì ở đây chúng ta thấy là nó biết đây là một cái biển ở caribbean để mà nó khoanh vùng Thì đây chính là những cái khái niệm rất là trừu tượng và ít gặp trong thực tế mà clip nó vẫn có thể phát hiện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 10,
      "start_timestamp": "0:06:46",
      "end_timestamp": "0:07:39"
    }
  },
  {
    "page_content": "gặp trong thực tế mà clip nó vẫn có thể phát hiện bằng định vị được Vậy thì cách thức hoạt động và các cái module chính của clip là thực hiện như thế nào Thì đầu tiên đó là chúng ta sẽ tạo ra một cái code prompt tổng quát là tên của 80 vật thể trong tập dữ liệu coco được phân cách bởi dấu chấm Tức là mỗi một cái vật thể thì sẽ cách nhau với các vật thể khác, ví dụ chữ person, cách chữ bicycle là dấu chấm như thế này Và kèm theo là một cái câu mô tả, một cái cặp câu mô tả giữa hình ảnh và chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 11,
      "start_timestamp": "0:07:26",
      "end_timestamp": "0:08:25"
    }
  },
  {
    "page_content": "tả, một cái cặp câu mô tả giữa hình ảnh và chúng ta sẽ đưa các cái từ này, cái code prompt Và cái câu mô tả này qua textencoder thì chúng ta sẽ tạo ra được là P0, P1, P2 v.v. Và tương tự như vậy thì cái ảnh chúng ta cũng sẽ khoanh vùng các cái đối tượng này và qua cái visualencoder để tạo ra cái O0, O1, O2 Lưu ý đó là trong cái mô hình clip thì chúng ta sẽ kết hợp hai cái loại dữ liệu là hình ảnh và văn bản ở bước trung gian G-clip thì là ở bước trung gian, trong khi đó với clip thì chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 12,
      "start_timestamp": "0:08:22",
      "end_timestamp": "0:09:21"
    }
  },
  {
    "page_content": "trung gian, trong khi đó với clip thì chúng ta chỉ kết hợp nó ở cái bước cuối cùng thôi Còn ở đây chúng ta sẽ thực hiện ở bước trung gian Thì tại sao lại có những cái việc như vậy? Đó là khi chúng ta tổng hợp ra cái đặc trưng thì ở phía trên là chỉ thuần nội dung cái đặc trưng về văn bản Còn ở bên dưới là các cái đặc trưng mà chúng ta thuần về hình ảnh và qua cái Fusion này thì chúng ta sẽ kết hợp được với nhau Đó là lấy cái đặc trưng của hình ảnh để bỏ vào văn bản và lấy nội dung của văn bản",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 13,
      "start_timestamp": "0:09:09",
      "end_timestamp": "0:09:59"
    }
  },
  {
    "page_content": "ảnh để bỏ vào văn bản và lấy nội dung của văn bản đưa vào hình ảnh để cho nó có thể tương tác để giúp cho hình ảnh nó có thể thực sự được thấy ở trong văn bản này Và cái sự khác biệt lớn nhất đó chính là cái module thứ 2, đó là chúng ta sẽ đo cái độ tương đồng giữa mỗi vùng và từ mô tả thay thế cho cái module phân lớp truyền thống Và ở trên đây chúng ta sẽ có m từ khóa là P1, P2, m token là P1, P2 và Pm Thì chúng ta có một cái lưu ý ở đây là có những cái từ mà dài và có hai, gọi là giống như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 14,
      "start_timestamp": "0:09:44",
      "end_timestamp": "0:11:03"
    }
  },
  {
    "page_content": "những cái từ mà dài và có hai, gọi là giống như tiếng Việt của mình là từ F là hair dryer thì nó sẽ tách ra làm hai, làm hai token hoặc có những cái từ hoặc cụm từ nó sẽ đi một cái combo với nhau, ví dụ như là blue dot, nó là một cái cụm từ thì nó sẽ tách ra làm hai token Thì khi đó chúng ta thấy là tính cái độ tương đồng nó sẽ là hai cái phần tử trên cái ma trận mà có cái giá trị lớn, ví dụ như đây là chữ tính từ và đây là danh từ thì chẳng hạn Hoặc trong cái ví dụ trên thì chúng ta thấy là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 15,
      "start_timestamp": "0:10:37",
      "end_timestamp": "0:11:31"
    }
  },
  {
    "page_content": "Hoặc trong cái ví dụ trên thì chúng ta thấy là hair dryer thì đây chính là hair và đây là dryer, hair và dryer này thì nó sẽ đi chung với nhau một cái combo khi chúng ta so sánh cái độ tương đồng với cái feature của cái hình ảnh là của cái máy sấy tóc Thì cái ý tưởng của nó cũng tương tự như clip nhưng mà clip thì sẽ tách nó ra thành các cái khu vực, các cái mảnh hình ảnh nhỏ rồi sau đó nó sẽ đi tính độ tương đồng với những cái từ ở bên trong cái chuỗi prompt của mình Cái token được tạo ra bởi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 16,
      "start_timestamp": "0:11:17",
      "end_timestamp": "0:12:21"
    }
  },
  {
    "page_content": "chuỗi prompt của mình Cái token được tạo ra bởi cái prompt của mình Sau khi chúng ta đã tính được cái ma trận này rồi thì chúng ta sẽ đi tính cái alignment loss giữa cái ground truth, đây là cái ma trận ground truth Và ở trên đó là cái ma trận mà chúng ta được tính từ cái độ tương đồng giữa cái vùng ảnh, cục bộ với lại các cái token ở bên trong cái prompt của mình Và alignment loss này thì mục đích là để xác định xem cái đối tượng đó là gì, bên cạnh đó thì chúng ta sẽ có cái region feature để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 17,
      "start_timestamp": "0:12:03",
      "end_timestamp": "0:13:09"
    }
  },
  {
    "page_content": "cạnh đó thì chúng ta sẽ có cái region feature để tính cái localization loss Mục tiêu đó là để cho chúng ta xác định xem cái vị trí, cái sai số khi dự đoán vị trí Thế thì quá trình huấn luyện của clip thì nó sẽ bao gồm đầu tiên đó là cái phrase routing Với mỗi một cái tấm ảnh ở đây, O1, O2, ON chúng ta sẽ truyền vào, truyền vào đây và chúng ta sẽ ra được O O chính là cái feature hoặc là cái embedding của cái vùng ảnh Và sau đó thì chúng ta sẽ lấy cái prompt, prompt của mình thì nó sẽ được hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 18,
      "start_timestamp": "0:12:57",
      "end_timestamp": "0:13:49"
    }
  },
  {
    "page_content": "cái prompt, prompt của mình thì nó sẽ được hình thành từ cái câu là detect person bicycle car third brush v.v. Rồi, và cái ở đây thêm một cái ý nữa đó là cái feature mà biểu diễn cho cái đặc trưng hình ảnh thì đó là một cái đặc trưng có kích thước đó là D chiều Còn cái ảnh của mình thì nó sẽ có N cái vùng, N vùng Rồi tương tự như vậy thì prompt thì đặc trưng của mỗi từ hoặc là token thì chúng ta sẽ biểu diễn bởi các cái vector và đại diện nó là ma trận p Ma trận p này thì cũng tương tự đó là nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 19,
      "start_timestamp": "0:13:43",
      "end_timestamp": "0:14:41"
    }
  },
  {
    "page_content": "trận p Ma trận p này thì cũng tương tự đó là nó sẽ có chiều của cái đặc trưng văn bản sẽ là D chiều, giống như bên đây để mà sau này chúng ta có thể nhân tích vô hướng được Và số token của chúng ta thì sẽ có m token, và m này thì thường lớn hơn N rất là nhiều Rồi sau khi chúng ta lấy cái O và P chúng ta nhân với nhau thì chúng ta sẽ ra được cái S routing Thì cái S routing này nó sẽ có kích thước đó là N nhân m, trong đó N là số vật thể hoặc số vùng, m là số token Và cuối cùng là chúng ta sẽ dựa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 20,
      "start_timestamp": "0:14:31",
      "end_timestamp": "0:15:32"
    }
  },
  {
    "page_content": "m là số token Và cuối cùng là chúng ta sẽ dựa trên cái S routing này để chúng ta đi tính cái loss của mình, trong đó loss của mình thì nó sẽ có cái T phải là được mở rộng ra từ T bao gồm là N đối tượng Rồi, thế thì clip đó là cho phép chúng ta có thể tạo ra một cái câu prompt thủ công Ở trên ví dụ trên thì chúng ta có thể thấy những cái đối tượng hiếm và lạ thì ta có thể mô tả đối tượng đó bằng một cái nguồn tự nhiên Bình thường thì chúng ta mô tả đó là Car, Bus, Car, Dog, đây là những cái đối",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 21,
      "start_timestamp": "00:15:19",
      "end_timestamp": "0:16:07"
    }
  },
  {
    "page_content": "tả đó là Car, Bus, Car, Dog, đây là những cái đối tượng tương đối là phổ biến Thì chúng ta sẽ không cần phải mô tả nhiều hơn, nhưng đối với cái từ lạ, ví dụ như là cá đuối, là stingray, thì nếu chúng ta đưa vào cái mô hình clip để mà phát hiện đối tượng thì chúng ta thấy là cái khả năng phát hiện của nó khá là thấp, nó chỉ phát hiện được một con và với cái Confidence là khoảng 0.21 Nhưng khi chúng ta mô tả nó dài dòng hơn, nhiều thông tin hơn, ví dụ như là stingray with a flat and round, thì ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 22,
      "start_timestamp": "00:15:51",
      "end_timestamp": "0:16:42"
    }
  },
  {
    "page_content": "dụ như là stingray with a flat and round, thì ở đây chúng ta sẽ, mô hình của mình nó sẽ hiểu và nó sẽ phát hiện ra cái đối tượng nhiều hơn và dày đặc hơn. Thì cái việc mà bổ sung thêm cái câu mô tả này nó gọi là manual prompt tuning và cái việc này thì cũng hoàn toàn có thể làm tự động nếu như chúng ta có cái dữ liệu có gắn nhãn thì có thể tự động làm cái quá trình là prompting này bằng cách đó là chúng ta sẽ huấn luyện một cái module nhỏ là một cái phép biến đổi tuyến tính thôi, là một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "một cái phép biến đổi tuyến tính thôi, là một cái linear mapping thôi để mà trực tiếp học ra cái prompt cái prompt này sẽ được học và tạo tự động. Nếu như chúng ta có cái dữ liệu thì chúng ta có thể cho nó học để mà bổ sung thêm cái câu mô tả này Với cái slide này, với cái bài về G-Clip thì chúng ta thấy là cái tiềm năng của mô hình ngôn ngữ hình thị giác nó có thể cho chúng ta giải quyết được những cái bài toán phức tạp hơn so với cái bài toán phân đoạn so với bài toán phân loại đối tượng đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "phân đoạn so với bài toán phân loại đối tượng đó là các cái bài toán như là phát hiện đối tượng Cảm ơn các bạn đã xem video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=qV3LpPXdXCE",
      "filename": "qV3LpPXdXCE",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 3",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chào các bạn, chúng ta sẽ cùng đến với chủ đề đầu tiên trong mô máy học nâng cao, đó chính là mô hình dựa trên Gradient. Tại sao chúng ta cần phải tìm hiểu mô hình dựa trên Gradient? Thì hiện nay các mô hình hiện đại và có rất nhiều những ứng dụng trong thực tế Ví dụ như các mô hình ngôn ngữ lớn, ChatGPT, các mô hình sinh ảnh như diffusion model Đều được huấn luyện dựa trên một phương pháp dựa trên Gradient, tức là chúng ta tính đạo hàm Và cái phương pháp này là nguyên lý của nó là gì? Và tại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:03"
    }
  },
  {
    "page_content": "phương pháp này là nguyên lý của nó là gì? Và tại sao nó có những ưu điểm để các mô hình hiện đại đều tập trung để sử dụng Gradient làm nền tảng để huấn luyện? Chúng ta sẽ cùng tìm hiểu trong bài học ngày hôm nay Đầu tiên chúng ta sẽ cùng tìm hiểu về ý tưởng của mô hình dựa trên Gradient Ý tưởng của mô hình dựa trên Gradient thì chúng ta sẽ nhận dữ liệu đầu vào là x Thì x này có thể là bất cứ loại dữ liệu nào Ví dụ như nó có thể là dữ liệu dạng vector, nó cũng có thể là dữ liệu dạng ma trận",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:43"
    }
  },
  {
    "page_content": "vector, nó cũng có thể là dữ liệu dạng ma trận hoặc là tensor Với hai loại là vector, ma trận hoặc là tensor, chúng ta có thể biểu diễn rất nhiều những loại dữ liệu khác nhau Ví dụ như có thể biểu diễn dữ liệu văn bản, dữ liệu dạng hình ảnh, video Và khi chúng ta đưa qua mô hình thì mô hình của mình sẽ được ký hiệu bằng một hàm, đó là hàm fx Nhưng chúng ta lưu ý là đối với hàm fx ở đây nó sẽ có một tham số, đó là tham số theta Cũng tương tự như trong toán phổ thông của chúng ta Ví dụ như chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 2,
      "start_timestamp": "0:01:35",
      "end_timestamp": "0:02:46"
    }
  },
  {
    "page_content": "trong toán phổ thông của chúng ta Ví dụ như chúng ta giải tìm m, tìm tham số m sao cho phương trình bậc 2 Ví dụ như x bình trừ m x cộng 3 m bình trừ 1 bằng 0 có 2 nghiệm Ví dụ vậy, đây là bài toán mà hồi phổ thông chúng ta được làm qua Tham số chính là m của mình và dạng thức của hàm của mình là hàm bậc 2 Chúng ta có thể ký hiệu f của m x bằng 0, trong đó fmx là công thức ở vế bên tay trái Chúng ta xác định được dạng thức của hàm f rồi Tuy nhiên trong đó chúng ta sẽ có nhiều tham số để quyết",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 3,
      "start_timestamp": "0:02:25",
      "end_timestamp": "0:03:50"
    }
  },
  {
    "page_content": "trong đó chúng ta sẽ có nhiều tham số để quyết định việc dự đoán m chính xác đến mức độ nào Chúng ta phải tìm tham số sao cho hàm fx, nó thỏa mãn việc đó là dự đoán chính xác Đầu ra của hàm fx là y ngã và đây là giá trị mà chúng ta được dự đoán từ mô hình Đương nhiên là việc dự đoán một giá trị nào đó chúng ta luôn mong muốn là nó sẽ xấp xỉ với giá trị thực tế Giá trị thực tế chúng ta sẽ ký hiệu là bằng y Để cho giá trị dự đoán xấp xỉ được với giá trị thực tế thì chúng ta phải có một hàm gọi là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 4,
      "start_timestamp": "0:03:39",
      "end_timestamp": "0:04:28"
    }
  },
  {
    "page_content": "trị thực tế thì chúng ta phải có một hàm gọi là hàm lỗi Ký hiệu là chữ j Hàm lỗi này sẽ có biến số, lúc này nó không phải là x nữa mà biến số của mình lúc này nó sẽ là theta Biến số của nó sẽ là theta và x,y của mình nó sẽ đóng vai trò giống như là tham số Nó sẽ khác so với lại hồi xưa, khi mà chúng ta đặt cái tên biến mà là x,y thì nó sẽ ngầm hiểu đó là biến số Còn trong trường hợp này thì cái hàm lỗi của mình x,y sẽ là tham số và nó chính là cái dữ liệu huấn luyện Đó chính là cái dữ liệu huấn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 5,
      "start_timestamp": "0:04:22",
      "end_timestamp": "0:05:15"
    }
  },
  {
    "page_content": "dữ liệu huấn luyện Đó chính là cái dữ liệu huấn luyện Và mình sẽ phải tìm cái biến số theta làm sao cho cái việc dự đoán này là chính xác nhất Và cái việc tìm cái giá trị theta cho cái này chính xác nhất thì nó sẽ tương đương với cái việc là chúng ta đi tìm một cái hàm min Tìm theta sao cho hàm lỗi là đạt giá trị nhỏ nhất Thế thì ba cái công việc chúng ta cần phải làm khi xây dựng một cái mô hình dựa trên Gradient Một, đó là chúng ta sẽ xác định xem cái hàm fx của mình nó sẽ có cái dạng thức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 6,
      "start_timestamp": "00:05:10",
      "end_timestamp": "0:05:56"
    }
  },
  {
    "page_content": "xem cái hàm fx của mình nó sẽ có cái dạng thức như thế nào Thứ hai, đó là chúng ta sẽ thiết kế cái hàm lỗi là g theta x sao cho cái việc mà dự đoán càng chính xác thì cái lỗi của mình thấp Nhưng đó chưa phải là một cái tiêu chí để thiết kế một cái hàm lỗi càng chính xác thì càng nhỏ Nhưng cái đó chưa phải là một cái tiêu chí duy nhất mà chúng ta sẽ còn rất nhiều những cái tiêu chí khác Mình có thể kể một vài cái tiêu chí ví dụ như là nó có thể hoạt động tốt khi chúng ta làm việc hoạt động tốt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 7,
      "start_timestamp": "00:05:50",
      "end_timestamp": "0:06:45"
    }
  },
  {
    "page_content": "hoạt động tốt khi chúng ta làm việc hoạt động tốt khi huấn luyện với dữ liệu mà mất cân bằng Tức là cái y này của mình nó sẽ có nhiều class ví dụ vậy và có những class thì xuất hiện rất nhiều nhưng có những cái class rất ít Thì cái hàm lỗi này nó phải làm sao để cho hướng cái mô hình đến cái việc là kể cả những mẫu dữ liệu mà ít thì vẫn có thể được cho cái vai trò ngang bằng với lại những cái mẫu dữ liệu nhiều Rồi ngoài ra thì chúng ta sẽ có những cái tiêu chí nữa ví dụ như hàm lỗi như thế nào",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 8,
      "start_timestamp": "00:06:31",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "cái tiêu chí nữa ví dụ như hàm lỗi như thế nào để cho cái việc huấn luyện nhanh, hội tụ, huấn luyện nhanh Tức là nó sẽ mau chóng để mà tìm ra được cái tham số tốt nhất Rồi cái việc thiết kế hàm mô hình cũng vậy nó cũng sẽ dựa trên cái tính chất của y, cái giá trị thực tế với x để mà chúng ta sẽ thiết kế Ví dụ như nếu y mà phụ thuộc một cách tuyến tính với x thì chúng ta sẽ có các cái hàm tuyến tính Nhưng nếu mà y phụ thuộc một cách phi tuyến với là x thì chúng ta sẽ có các cái hàm là phi tuyến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 9,
      "start_timestamp": "0:07:14",
      "end_timestamp": "0:07:56"
    }
  },
  {
    "page_content": "là x thì chúng ta sẽ có các cái hàm là phi tuyến tính Rồi sau này là tùy thuộc với x của mình, nó là dữ liệu dạng vector, dạng ma trận hay là dữ liệu như thế nào đó mà chúng ta cũng sẽ có những kiểu thiết kế khác nhau Và cái công việc cuối cùng khi chúng ta làm với một cái mô hình mà dựa trên Gradient, đó chính là chúng ta sẽ tìm một cái tham số tối ưu của hàm mô hình Tức là chúng ta sẽ đi tìm cái theta, theta sao? Sao cho cái lỗi ở đây là nhỏ nhất? Thì lỗi mà nhỏ nhất là cái dự đoán càng chính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 10,
      "start_timestamp": "0:07:45",
      "end_timestamp": "0:08:35"
    }
  },
  {
    "page_content": "Thì lỗi mà nhỏ nhất là cái dự đoán càng chính xác Tiếp theo thì chúng ta sẽ cùng so sánh với các cái mô hình khác, thì một số mô hình mà không có dựa trên Gradient, ví dụ như chúng ta có K-Nearest Neighbor Mặc dù đây là một cái thuật toán máy học nhưng mà nó không thực sự là huấn luyện và bản chất của nó chỉ là truy vấn để tìm ra k cái láng giềng gần nhất Và sau đó sẽ dựa trên nhãn của k cái láng giềng đó để từ đó nó dùng cái cơ chế đó gọi là voting để mà lấy ra những cái tập nhãn mà có xuất",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 11,
      "start_timestamp": "0:08:19",
      "end_timestamp": "0:09:07"
    }
  },
  {
    "page_content": "voting để mà lấy ra những cái tập nhãn mà có xuất hiện nhiều nhất để từ đó gắn cái nhãn nhiều nhất đó vào cho cái đặc trưng của mình Thì đây chính là cái ý tưởng của K-Nearest Neighbor. Hướng tiếp cận thứ 2 đó chính là Naive Bayes, thì đây là dựa trên các cái mô hình xác suất mà cụ thể đó là chúng ta dựa trên công thức xác suất có điều kiện như là công thức Bayes Thì ước lượng cái phương pháp này thì nó sẽ ước lượng các cái tham số một cách tường minh Cách tiếp cận thứ 3 đó chính là Decision",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 12,
      "start_timestamp": "0:08:54",
      "end_timestamp": "0:09:50"
    }
  },
  {
    "page_content": "minh Cách tiếp cận thứ 3 đó chính là Decision Tree với các thuật toán ví dụ như là CART, ID3, C4.5 thì nó dựa trên luật để phân chia thành các cái nhánh quyết định Ví dụ như ở đây chúng ta sẽ có một cái node, nó sẽ chia ra làm 2, 2 nhánh ví dụ vậy rồi sau đó chúng ta lại tiếp tục có những cái luật, nó sẽ có những cái luật lại tiếp tục chia xuống Ví dụ như ở trên đây, cái luật của mình sẽ là trời có mây hay không, thì nếu có thì nó sẽ tiếp tục hỏi là cái độ ẩm của mình là cao hay thấp Nếu mà độ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 13,
      "start_timestamp": "00:09:41",
      "end_timestamp": "00:10:19"
    }
  },
  {
    "page_content": "là cái độ ẩm của mình là cao hay thấp Nếu mà độ ẩm cao thì nó sẽ kết luận là mưa, ví dụ vậy, thì đây là một cái mô hình khá là hiệu quả và dễ hiểu Và mở rộng cho cái mô hình Decision Tree đó chính là Random Forest thì như cái tên gọi của mình, Random Forest nó sẽ kết hợp nhiều cái cây thành phần Ví dụ như ở đây chúng ta có một cây thì Random Forest có thể kết hợp thêm nhiều cái cây khác để có thể tạo ra thành một cái khu rừng Và Random Forest là một trong những thuật toán, một cái mô hình mà có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 14,
      "start_timestamp": "00:10:13",
      "end_timestamp": "00:11:02"
    }
  },
  {
    "page_content": "một trong những thuật toán, một cái mô hình mà có thể chống được cái Overfitting và có cái tính tổng quát khá là cao để chúng ta chọn được cái tham số phù hợp Thế thì cả 4 cái mô hình này đều là nằm trong cái nhóm đó là học có giám sát Và thuật toán không giám sát thì chúng ta sẽ có các thuật toán liên quan đến cái Clustering Ví dụ như là có K-Means, DBscan, Hierarchical Clustering, thì ý tưởng của các thuật toán này cũng là những thuật toán lặp việc cập nhật tâm cụm Tức là chúng ta sẽ lặp đi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 15,
      "start_timestamp": "00:10:56",
      "end_timestamp": "0:11:43"
    }
  },
  {
    "page_content": "việc cập nhật tâm cụm Tức là chúng ta sẽ lặp đi lặp lại việc cập nhật tâm cụm Và khác biệt so với các mô hình dựa trên Gradient đó là chúng ta không tính cái Vector đạo hàm, không dựa trên Gradient Và trong cái bảng sau thì chúng ta sẽ so sánh các mô hình trên các khía cạnh khác nhau Khía cạnh đầu tiên đó là cái cơ chế để tối ưu hóa mô hình của mình Thì các thuật toán dựa trên Gradient thì đều dựa trên thuật toán Gradient Ascent Và các biến thể của nó, ví dụ như Stochastic Gradient Ascent,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 16,
      "start_timestamp": "0:11:28",
      "end_timestamp": "0:12:21"
    }
  },
  {
    "page_content": "thể của nó, ví dụ như Stochastic Gradient Ascent, Adam, Root Mean Square Propagation thì đây đều là những cái thuật toán tối ưu hóa Và các mô hình dựa trên Gradient thì đều dựa trên các thuật toán này Trong khi đó các mô hình không dựa trên Gradient, thì cơ chế để tối ưu hóa dựa trên một công thức tường minh hoặc dựa trên các chiến thuật tham lam, heuristic, ví dụ như là Naive Bayes, Decision Tree, K-Nearest Neighbor Xét trên khía cạnh về khả năng diễn giải mô hình thì các mô hình dựa trên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 17,
      "start_timestamp": "0:12:10",
      "end_timestamp": "0:12:55"
    }
  },
  {
    "page_content": "năng diễn giải mô hình thì các mô hình dựa trên Gradient thì thường có tính diễn giải khá là thấp hay một cái cách gọi khác đó là thường có dạng Black Box, hộp đen thì khả năng diễn giải của mình là sẽ thấp Tuy nhiên các nghiên cứu gần đây thì họ cũng đã tìm cách trực quan hóa mô hình dựa trên Gradient nó vận hành như thế nào, rồi giải thích cơ chế của nó để làm sao cho mô hình có thể tối ưu hóa được việc mà dự đoán thì các nghiên cứu đó gần đây cũng được chú tâm rất nhiều Trong khi đó thì mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 18,
      "start_timestamp": "0:12:48",
      "end_timestamp": "0:13:45"
    }
  },
  {
    "page_content": "cũng được chú tâm rất nhiều Trong khi đó thì mô hình không dựa trên Gradient thì nó có tính giải thích dễ dàng hơn và đặc biệt là những mô hình như là Decision Tree, Random Forest chúng ta nhìn vô cái cấu trúc cây thôi là chúng ta có thể hiểu được mô hình vận hành như thế nào Xét trên cái hiệu quả của các tác vụ phức tạp thì thuật toán các mô hình dựa trên Gradient thì nó sẽ cho kết quả rất tốt trên những lĩnh vực như là thị giác máy tính hoặc là xử lý ngôn ngữ tự nhiên trong đó là trên những",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 19,
      "start_timestamp": "0:13:31",
      "end_timestamp": "0:14:26"
    }
  },
  {
    "page_content": "là xử lý ngôn ngữ tự nhiên trong đó là trên những dữ liệu là Unstructured Data ví dụ như là dữ liệu hình ảnh, dữ liệu văn bản, rồi dữ liệu âm thanh và thì đây là những dữ liệu mô hình dựa trên Gradient làm việc rất tốt trong khi đó mô hình không dựa trên Gradient thì thường tốt trên dữ liệu bảng và có quy mô nhỏ ví dụ như là dữ liệu bảng thì nó bao gồm các cột ABC và từng cái cột này thì nó sẽ có kiểu dữ liệu cố định và ý nghĩa của nó là cố định các mô hình không dựa trên Gradient thì làm việc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 20,
      "start_timestamp": "0:14:19",
      "end_timestamp": "0:15:04"
    }
  },
  {
    "page_content": "các mô hình không dựa trên Gradient thì làm việc rất tốt trên dữ liệu này đó là những dữ liệu Structured Data và cuối cùng đó là xét trên khía cạnh chi phí huấn luyện các mô hình dựa trên Gradient thì thường có chi phí huấn luyện rất cao do nó cần rất nhiều tài nguyên tính toán, bộ nhớ, GPU, TPU do các mô hình dựa trên Gradient có số lượng tham số rất lớn ngược lại thì chi phí huấn luyện của các mô hình không dựa trên Gradient thì ít tốn kém hơn như vậy chúng ta đã lượt qua những khía cạnh và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 21,
      "start_timestamp": "0:14:55",
      "end_timestamp": "0:15:38"
    }
  },
  {
    "page_content": "như vậy chúng ta đã lượt qua những khía cạnh và chúng ta thấy mô hình dựa trên Gradient nó có những điểm yếu cố hữu ví dụ như là mô hình của mình khả năng diễn giải sẽ thấp hơn so với những mô hình như là Decision Tree và chi phí huấn luyện của nó sẽ cao hơn tuy nhiên gần đây thì tại sao mô hình dựa trên Gradient lại càng trở nên phổ biến nó có nhiều lý do, lý do đầu tiên đó là dưới sự phát triển của các mạng xã hội thì các dữ liệu của mình sẽ ngày càng phong phú hơn và được lưu trữ công khai",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 22,
      "start_timestamp": "0:15:29",
      "end_timestamp": "0:16:16"
    }
  },
  {
    "page_content": "ngày càng phong phú hơn và được lưu trữ công khai thì ở giai đoạn đầu, ví dụ như là vào những năm 2010, thì cái quy mô dữ liệu của chúng ta đâu đó chỉ khoảng là 1-2 triệu ảnh nhưng mà sau đó đến vào những năm 2020, cụ thể đó là công ty OpenAI được đầu tư thì họ xây dựng những mô hình ví dụ như mô hình clip được huấn luyện trên tập dữ liệu rất lớn lên đến hàng trăm triệu mẫu dữ liệu và gần đây hơn nữa thì vào những năm 2020, thì có tập dữ liệu LAION lên đến 5 tỷ ảnh thì có thể nói là để huấn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 23,
      "start_timestamp": "0:16:10",
      "end_timestamp": "0:16:49"
    }
  },
  {
    "page_content": "LAION lên đến 5 tỷ ảnh thì có thể nói là để huấn luyện được trên những quy mô dữ liệu lên hàng tỷ ảnh thì chỉ có thể có tập đoàn công nghệ lớn họ mới có thể làm được mà thôi và một trong những lý do nữa để khiến mô hình dựa trên Gradient càng trở nên phổ biến đó là tài nguyên của mình tài nguyên cụ thể là tài nguyên tính toán, nó ngày càng mạnh và đồng thời nó sẽ ngày càng rẻ thì nói về phần cứng thì nó sẽ càng càng rẻ và nhờ có tài nguyên tính toán sắp sau này, nó sẽ giúp chúng ta huấn luyện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 24,
      "start_timestamp": "0:16:43",
      "end_timestamp": "0:17:32"
    }
  },
  {
    "page_content": "toán sắp sau này, nó sẽ giúp chúng ta huấn luyện các mô hình nhanh chóng hơn cuối cùng đó là sự hoàn thiện của các mô hình chúng ta thấy đó là trước đây thì chúng ta có cái mạng Neural Network thì nó không có hiệu quả trong việc huấn luyện với các dữ liệu lớn và các bài toán phức tạp nhưng mà gần đây thì chúng ta thấy là có cái kiến trúc như là CNN, RNN, Convolutional Neural Network, Recurrent Neural Network và gần đây nhất chính là Transformer, đó là những cái kiến trúc đã hoàn thiện hơn giúp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "đó là những cái kiến trúc đã hoàn thiện hơn giúp chúng ta có thể hấp thụ được lượng dữ liệu tốt hơn và có thể khai thác được hiệu quả tài nguyên của GPU do đó thì các mô hình dựa trên Gradient đang ngày càng trở nên phổ biến và không chỉ như vậy mà các thành tựu mới nhất của trí tuệ nhân tạo gần đây ví dụ như là ChatGPT, Gemini, chúng ta thấy đó là đều có kiến trúc dựa trên Transformer và cái kiến trúc dựa trên Transformer này, đó là dựa trên, đã đều được huấn luyện dựa trên thuật toán, đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 26,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "đã đều được huấn luyện dựa trên thuật toán, đó là Gradient Descent thì đây chính là một cái ví dụ minh chứng cho cái thành tựu của các mô hình dựa trên Gradient Cảm ơn các bạn đã xem video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=QZrUqMbEY8Q",
      "filename": "QZrUqMbEY8Q",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 1 (New)",
      "chunk_id": 27,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chào mừng các bạn đến với môn học CS3.1.5 Máy học nâng cao. Ngày hôm nay chúng ta sẽ cùng giới thiệu về môn học và ôn lại một số kiến thức cơ bản để làm nền tảng phục vụ cho môn học này. Đầu tiên là giới thiệu môn học. Môn học này sẽ học những nội dung chính là gì? Chúng ta có 15 tuần, sau đây sẽ là những nội dung chi tiết cho từng tuần. Đầu tiên là giới thiệu về môn học và ôn tập những kiến thức toán nền tảng để phục vụ cho các mô hình mà sau chúng ta sử dụng. Và những phần chúng ta sẽ ôn tập",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:00"
    }
  },
  {
    "page_content": "ta sử dụng. Và những phần chúng ta sẽ ôn tập rất là căn bản và rất là cốt lõi trong các mô hình nâng cao. Tuần 2 thì chúng ta sẽ cùng tìm hiểu về mô hình dựa trên Gradient và chúng ta sẽ đến với một thuật toán. Đầu tiên đó chính là thuật toán Gradient Descent. Đây có thể nói là một trong những cái lõi thuật toán để huấn luyện mô hình máy học và đặc biệt là các mô hình học sâu, những mô hình hiện đại đều sử dụng cái lõi là thuật toán Gradient Descent. Sau đó thì chúng ta sẽ cùng tìm hiểu về các",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:51",
      "end_timestamp": "0:01:34"
    }
  },
  {
    "page_content": "Sau đó thì chúng ta sẽ cùng tìm hiểu về các biến thể nâng cao của Gradient Descent, ví dụ như là Momentum, Root Mean Square Propagation, Adam. Và sau đó thì chúng ta sẽ đến với một thuật toán để giúp chúng ta có thể tính đạo hàm và chạy được thuật toán Gradient Descent một cách dễ dàng. Đó chính là thuật toán Lan Truyền Ngược hay còn gọi là Back Propagation và một số mô hình cơ bản dựa trên Gradient. Sau đó thì sang tuần năm thì chúng ta sẽ cùng giới thiệu về quá trình tiến hóa của một vài mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:23",
      "end_timestamp": "0:02:19"
    }
  },
  {
    "page_content": "giới thiệu về quá trình tiến hóa của một vài mô hình kinh điển trong học sâu. Trước khi chúng ta đi qua các mô hình thì chúng ta sẽ nói về hai vấn đề cốt lõi nhất mà các mô hình học sâu hiện nay đều đang gặp phải. Đó chính là vấn đề về Overfitting, tức là quá khớp dữ liệu. Và vấn đề thứ hai đó chính là đặc thù cho lĩnh vực học sâu đó chính là Vanishing Gradient. Đây là một hiện tượng gây ra cho việc huấn luyện chậm và có thể khiến mô hình của chúng ta không học được. Nội dung chính chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:04",
      "end_timestamp": "0:02:56"
    }
  },
  {
    "page_content": "ta không học được. Nội dung chính chúng ta sẽ tìm hiểu trong hôm nay là tuần một, tức là giới thiệu về các kiến thức nền tảng. Sang tuần số 6 thì chúng ta sẽ cùng tìm hiểu về một số mô hình và sự tiến hóa của các mô hình trên dữ liệu ảnh. Sang tuần 7 thì chúng ta sẽ tìm hiểu về các mô hình trên dữ liệu chuỗi và đặc biệt là một dạng dữ liệu mà được nhắc đến là dữ liệu văn bản. Lưu ý đó là dữ liệu chuỗi thì chúng ta không nhất thiết là văn bản có thể là âm thanh, có thể là video và chuỗi thời",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:47",
      "end_timestamp": "0:03:35"
    }
  },
  {
    "page_content": "có thể là âm thanh, có thể là video và chuỗi thời gian. Tuy nhiên thì văn bản sẽ là một dữ liệu chính để chúng ta trình bày cho các mô hình dạng chuỗi này. Và hai mô hình cho dữ liệu ảnh và cho dữ liệu chuỗi thì đều bám theo việc đó là giải quyết hai vấn đề Overfitting và vấn đề về Vanishing Gradient. Tức là khi chúng ta tìm hiểu về các mô hình này thì đều xoay xung quanh vấn đề là các mô hình đó đã giải quyết Overfitting và Vanishing Gradient như thế nào. Sau đó chúng ta sẽ cùng đến với các mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:24",
      "end_timestamp": "0:04:16"
    }
  },
  {
    "page_content": "thế nào. Sau đó chúng ta sẽ cùng đến với các mô hình tạo sinh. Và mô hình tạo sinh nhóm đầu tiên đó chính là các mô hình Autoencoder, Variational Autoencoder và GAN, Generative Adversarial Network. Sau đó chúng ta sẽ cùng tìm hiểu về một trong những mô hình hiện đại hiện nay đang được sử dụng và ứng dụng rộng rãi. Đó chính là mô hình dựa trên xác suất và cụ thể của một mô hình dựa trên xác suất đó chính là mô hình khuếch tán là Diffusion Model. Sau đó sang tuần thứ 11 thì chúng ta sẽ cùng tìm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:07",
      "end_timestamp": "0:04:57"
    }
  },
  {
    "page_content": "Sau đó sang tuần thứ 11 thì chúng ta sẽ cùng tìm hiểu về những mô hình học sâu nhưng mà có sự tham gia của ngôn ngữ và thị giác hay còn gọi là Vision Language Model. Đối với tiếng Anh thì chúng ta để là Vision Language Model nhưng mà khi chúng ta dịch sang tiếng Việt thì nó sẽ đảo lại, đó là ngôn ngữ thị giác. Và 3 mô hình đầu tiên chúng ta sẽ cùng tìm hiểu trong tuần thứ 11 đó chính là mô hình clip, mô hình clip và mô hình clip. Sau đó thì chúng ta sẽ tìm hiểu về những mô hình ngôn ngữ thị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:04:50",
      "end_timestamp": "0:05:36"
    }
  },
  {
    "page_content": "ta sẽ tìm hiểu về những mô hình ngôn ngữ thị giác mà ở cấp độ có sự tương tác về ngữ nghĩa cao hơn, đó là mô hình Visual Programming và GPT for Vision. Rồi cuối cùng trong mô hình ngôn ngữ thị giác thì chúng ta có các mô hình sử dụng mô hình ngôn ngữ thị giác để giải quyết bài toán từ kinh điển cho đến hiện đại của thị giác máy tính. Ví dụ như là Grounding Dino để phục vụ cho bài toán phát hiện vật thể hoặc là phân đoạn ngữ nghĩa giác. Đầu tiên là để phát hiện, sau đó là kết hợp với thuật toán",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:05:30",
      "end_timestamp": "0:06:13"
    }
  },
  {
    "page_content": "là để phát hiện, sau đó là kết hợp với thuật toán SAM để phân đoạn ngữ nghĩa đối tượng. Tức là những mô hình ngôn ngữ thị giác nhưng mà được sử dụng cho những bài toán kinh điển để phát hiện một phân đoạn ngữ nghĩa. Rồi cho các tương tác đa thể thức khác nhau, có rất nhiều loại Prompt mà chúng ta tương tác lên trên tấm hình. Ví dụ như Prompt bình thường thì chúng ta dùng dạng văn bản nhưng mà không chỉ dừng lại ở văn bản. Ví dụ như là tương tác lên trên hình, thông qua dạng Point là điểm, Box",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:07",
      "end_timestamp": "0:07:02"
    }
  },
  {
    "page_content": "lên trên hình, thông qua dạng Point là điểm, Box là Bounding Box, Scribble là đường vạch hoặc. SAM là một trong những mô hình giúp chúng ta tương tác lên trên máy tính thông qua rất nhiều loại Prompt khác nhau. Và cuối cùng là LLaVA, đây có thể nói là một trong những mô hình mã nguồn mở tương đương với GPT-4V để giúp chúng ta giải quyết được các bài toán trong thị giác máy tính nhưng có sử dụng yếu tố ngôn ngữ để tương tác. Ví dụ như chúng ta đặt câu hỏi, chat với hình ảnh, v.v. thì đó chính là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:06:53",
      "end_timestamp": "0:07:46"
    }
  },
  {
    "page_content": "câu hỏi, chat với hình ảnh, v.v. thì đó chính là mô hình LLaVA. Và cuối cùng đó là chúng ta gồm tuần 14 và tuần 15 thì 2 tuần này sẽ được dành cho việc đó là báo cáo đồ án cuối kỳ. Các bạn sẽ trình bày cái đồ án của mình và đồng thời đó là chúng ta sẽ ôn tập để chuẩn bị cho việc thi cuối kỳ. Về hình thức đánh giá môn học này thì sẽ bao gồm là 3 cột điểm chính. Cột điểm đầu tiên đó là bài tập chiếm 30% bao gồm việc chúng ta làm các bài quiz trong quá trình chúng ta xem bài giảng này. Và các bài",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:07:34",
      "end_timestamp": "0:08:20"
    }
  },
  {
    "page_content": "quá trình chúng ta xem bài giảng này. Và các bài tập lập trình, thứ 2 đó là cột đồ án 30%, thì chúng ta sẽ làm theo nhóm và sẽ báo cáo seminar cộng với việc chúng ta sẽ một cuốn report của báo cáo cuối kỳ. Và cuối cùng cột điểm cao nhất đó là 40%, thì đây sẽ là cái cột điểm được sử dụng để thi viết và với đề đóng. Trên đây đó là cách thức mà chúng ta sẽ đánh giá môn học này. Cảm ơn các bạn đã xem video.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RU8d6QAuX0k",
      "filename": "RU8d6QAuX0k",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng tìm hiểu về một số biến thể của mạng GAN và ứng dụng của nó. GAN sẽ bao gồm hai generator và discriminator. Tuy nhiên, khi chúng ta sinh ảnh với độ phân giải rất cao, cụ thể là độ phân giải HD, thì nó sẽ gặp một số vấn đề thách thức, ví dụ như tốc độ huấn luyện, khó hội tụ, hoặc bị overfitting. Thế thì, cái giải pháp của chúng ta đó là thay vì chúng ta sử dụng một cái kiến trúc phức tạp từ độ phân giải thấp lên độ phân giải cao, tức là một cái random noise, từ độ phân giải thấp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:58"
    }
  },
  {
    "page_content": "tức là một cái random noise, từ độ phân giải thấp lên độ phân giải cao, sau đó từ cao xuống thấp, chúng ta chỉ huấn luyện với một cái mạng như thế này, thì chúng ta sẽ huấn luyện từ từ. Thì cái quá trình training process chúng ta thấy là từ trái sang phải, là chúng ta đang đi từ độ phân giải thấp, đi tiến đến cái độ phân giải cao. Với cái độ phân giải thấp, thì chúng ta sẽ học về những cái concept chung của tấm hình. Ví dụ như ở đây chúng ta có cái vector latent, được random sampling theo nhiễu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 1,
      "start_timestamp": "0:00:55",
      "end_timestamp": "0:01:35"
    }
  },
  {
    "page_content": "vector latent, được random sampling theo nhiễu normal 01, thì chúng ta sẽ biến đổi nó thành một cái tấm ảnh có độ phân giải, đó là 4x4. Cái module này thì giúp chúng ta tạo ra tấm ảnh có độ phân giải là 4x4. Và kết hợp với lại cái ảnh thật, thì chúng ta sẽ qua cái discriminator, và dành cho cái ảnh có kích thước là 4x4. Thì chúng ta thấy là với cái mô hình tạo sinh và phân biệt, phân loại, ảnh thật, ảnh giả, mà với độ phân giải thấp, thì cái số lượng tham số nó sẽ rất là ít, do đó cái hội tụ,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 2,
      "start_timestamp": "0:01:31",
      "end_timestamp": "0:02:16"
    }
  },
  {
    "page_content": "lượng tham số nó sẽ rất là ít, do đó cái hội tụ, tốc độ hội tụ nó sẽ nhanh hơn, nó dễ hội tụ hơn. Khi chúng ta lên cái độ phân giải cao hơn, chúng ta sẽ chồng thêm các lớp biến đổi để từ ảnh có độ phân giải 4x4 lên 8x8. Và với ảnh này thì chúng ta thấy nó đã mượt hơn một chút, nó đã mượt hơn, so với lại ảnh ở phía trước là 4x4. Tương tự như vậy, kết hợp với ảnh thật, thì chúng ta sẽ đi qua một bộ phân loại, ảnh thật, ảnh giả, từ 8x8 về lại 4x4. Và cứ như vậy, thì chúng ta nâng dần cái độ phân",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 3,
      "start_timestamp": "0:02:09",
      "end_timestamp": "0:03:02"
    }
  },
  {
    "page_content": "Và cứ như vậy, thì chúng ta nâng dần cái độ phân giải của ảnh lên, từ 4x4 lên 1024 x 1024, thì tạo ra một ảnh có độ phân giải rất là cao. Độ phân giải cao. Và từ cái độ phân giải cao này, chúng ta đưa qua cái mô hình phân loại, thì chúng ta sẽ ra được cái mô hình có khả năng phân biệt được ảnh hay là ảnh thật, hay ảnh giả, thì ở bên tay phải, chúng ta thấy đó là cái kết quả là ảnh có độ phân giải rất là cao. Và khi chúng ta tạo sinh hình ảnh, thì chúng ta sẽ sử dụng cái mô hình G này, chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 4,
      "start_timestamp": "0:02:55",
      "end_timestamp": "0:03:38"
    }
  },
  {
    "page_content": "chúng ta sẽ sử dụng cái mô hình G này, chúng ta sẽ sử dụng cái mô hình G có cái độ phân giải cao này. Và ứng dụng của nó thì chúng ta biết rằng là ở trong cái StyleGAN, StyleGAN 2, thì có công bố một cái trang web đó là This Person Does Not Exist, thì mục tiêu đó là nó tạo ra ngẫu nhiên một cái ảnh người nhưng mà không có thật. Và chúng ta có thể sử dụng cái ảnh này để phục vụ cho cái việc là làm những cái ví dụ nâng cao mà không vi phạm các cái vấn đề về quyền riêng tư. Một cái biến thể khác",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 5,
      "start_timestamp": "0:03:33",
      "end_timestamp": "0:04:13"
    }
  },
  {
    "page_content": "vấn đề về quyền riêng tư. Một cái biến thể khác cũng rất là nổi tiếng của GAN, đó chính là Conditional GAN hay là GAN có điều kiện. Trước đây thì chúng ta từ một cái vector nhiễu Z, chúng ta tạo ra một cái tấm ảnh, nhưng mà cái ảnh này là chúng ta không thể đoán trước được, hoặc là chúng ta không thể kiểm soát được, không thể kiểm soát được cái đầu ra của mình, đó là cái ảnh như thế nào. Thế thì bây giờ chúng ta muốn tăng cái khả năng kiểm soát cái tính chất của ảnh đầu ra, thì chúng ta có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 6,
      "start_timestamp": "0:04:11",
      "end_timestamp": "0:04:56"
    }
  },
  {
    "page_content": "cái tính chất của ảnh đầu ra, thì chúng ta có thể thêm một cái vector điều kiện là vector C. Vector C này có thể hiện, nó có thể là những cái tính chất ví dụ như là độ tuổi của cái người được tạo ra, ví dụ như là trẻ em, hoặc là thanh niên, hoặc là người trung niên. Hoặc cái Conditional này nó cũng có thể là tính chất của mặt, ví dụ như là có đeo khẩu trang hay không, rồi có đeo mắt kính hay không, rồi có râu hay nón hay không, ví dụ vậy. Đó thì đây là những cái, hai cái này sẽ là những cái ví",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 7,
      "start_timestamp": "0:04:48",
      "end_timestamp": "0:05:32"
    }
  },
  {
    "page_content": "đây là những cái, hai cái này sẽ là những cái ví dụ cho cái vector điều kiện. Và cái vector điều kiện này thì chúng ta cũng sẽ đưa vào bên trong cái discriminator để giúp cho phân biệt cái ảnh thật hay giả. Tức là cái này nó sẽ cung cấp thêm thông tin để cho chúng ta phân biệt. Thì biến thể GAN có điều kiện hay Conditional GAN là một trong những biến thể rất là hiệu quả và nổi tiếng. Bên cạnh Conditional GAN thì chúng ta còn có mô hình là Pix2Pix. Pix2Pix thì đây chính là những mô hình mà biến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 8,
      "start_timestamp": "0:05:23",
      "end_timestamp": "0:06:37"
    }
  },
  {
    "page_content": "Pix2Pix thì đây chính là những mô hình mà biến đổi ảnh theo cặp. Có nghĩa là bình thường thì chúng ta chỉ có một tập các cái ảnh. Bình thường là chúng ta chỉ có tập các cái ảnh. Nhưng mà chúng ta sẽ không có cái ảnh đích, cái ảnh mà chúng ta muốn tạo thành. Còn kiến trúc của Pix2Pix tức là nó biến một cái picture thành một cái picture. Vâng, thì nó đòi hỏi chúng ta sẽ phải có một cặp ảnh để huấn luyện. Vì vậy, chúng ta sẽ có một cái cặp ảnh đó là ảnh thật và một cái ảnh mà có cái phân đoạn,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 9,
      "start_timestamp": "0:06:16",
      "end_timestamp": "0:07:09"
    }
  },
  {
    "page_content": "là ảnh thật và một cái ảnh mà có cái phân đoạn, semantic map. Thì đây là một cái cặp ảnh và nó tham gia vào quá trình huấn luyện cũng tương tự như GAN. Nó có generator và discriminator. Thì cái bài toán này đó là gì? Thay vì đầu vào của chúng ta là một cái random noise, thì đầu vào của chúng ta là một cái semantic map. Và từ cái semantic map này, thì chúng ta sẽ tạo ra cái khung ảnh thật. Ví dụ như đây là đường phố, đây là xe cộ, đây là cây cối, đây là bầu trời, thì nó sẽ tạo ra một cái khung",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 10,
      "start_timestamp": "0:07:05",
      "end_timestamp": "0:07:46"
    }
  },
  {
    "page_content": "đây là bầu trời, thì nó sẽ tạo ra một cái khung ảnh có cái concept giống như ở đây. Và ứng dụng của nó đó là dùng cho cái việc biến từ label sang cái street scene, tức là cái khung ảnh đường phố để giúp cho chúng ta có thể tăng cường dữ liệu. Hoặc là trong các ứng dụng liên quan đến bản đồ chẳng hạn, thì từ một cái bản đồ ở bên trái chúng ta có thể tạo ra một cái khung ảnh, nhìn từ trên cao, hoặc ngược lại. Cái này có lẽ là ứng dụng nhiều hơn, đó là chúng ta chụp ảnh từ ảnh vệ tinh, sau đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 11,
      "start_timestamp": "0:07:43",
      "end_timestamp": "0:08:35"
    }
  },
  {
    "page_content": "đó là chúng ta chụp ảnh từ ảnh vệ tinh, sau đó chúng ta sẽ biến thành cái ảnh bản đồ. Và nếu được thì với cái ảnh bản đồ này, thì chúng ta có thể số hóa nó để tạo ra một cái trang tương tự như là Google Maps. Một cái biến thể khác cũng rất là nổi tiếng và có nhiều cái ứng dụng cũng như là phù hợp trong cái việc thực tiễn, đó là CycleGAN. CycleGAN là cho phép chúng ta học các phép biến đổi giữa các miền dữ liệu với nhau. Và ở đây là dữ liệu của mình là không bắt cặp, nghĩa là trong cái mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 12,
      "start_timestamp": "0:08:30",
      "end_timestamp": "0:09:24"
    }
  },
  {
    "page_content": "mình là không bắt cặp, nghĩa là trong cái mô hình Pix2Pix, ví dụ vậy, thì chúng ta đòi hỏi phải có một cặp ảnh. Chúng ta phải có một cái cặp ảnh, x và y là một cặp ảnh. Ví dụ như đây là ảnh x nè. Và cái output của cái generator của mình là x phẩy. Thì đó là một cặp ảnh. Được rồi, còn như cái chi phí để chúng ta tạo ra một cái cặp ảnh này là tốn kém. Hoặc thậm chí, ví dụ như trong cái trường hợp mà từ ảnh vệ tinh sang ảnh bản đồ, chúng ta phải thuê người để mà vẽ cái bản đồ ra. Hoặc thậm chí là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 13,
      "start_timestamp": "0:09:19",
      "end_timestamp": "0:10:10"
    }
  },
  {
    "page_content": "người để mà vẽ cái bản đồ ra. Hoặc thậm chí là có nhiều tình huống chúng ta không có tồn tại cái ảnh đó. Tức là chúng ta không thể tạo ra được cái ảnh x phẩy một cách gọi là chi tiết. Thì chúng ta chỉ có thể là cái dữ liệu không bắt cặp. Tức là đầu vào của mình sẽ là có một tập hợp các cái ảnh nguồn và đầu ra của mình thì nó sẽ có một tập hợp các cái ảnh đích. Ví dụ như chúng ta sẽ có đầu vào sẽ là tập hợp những cái ảnh của những cái con ngựa bình thường. Và đầu ra thì chúng ta sẽ tập hợp những",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 14,
      "start_timestamp": "0:10:05",
      "end_timestamp": "0:10:41"
    }
  },
  {
    "page_content": "thường. Và đầu ra thì chúng ta sẽ tập hợp những cái ảnh có ngựa vằn. Thế thì nếu mà chúng ta đi gán nhãn hết những cái ảnh mà có con ngựa thật và con ngựa vằn như thế, và thực tế là chúng ta không thể có với cùng một cái khung cảnh này mà thay con ngựa vằn, thay con ngựa thật thành ngựa vằn thì chúng ta không có thể làm được cái chuyện đó. Tại vì thực tế nó không thể xảy ra cái hình con ngựa vằn mà đứng ngay cái vị trí này, đứng ngay cái vị trí này, đứng cái bối cảnh này, khung cảnh này. Do đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 15,
      "start_timestamp": "0:10:31",
      "end_timestamp": "0:11:29"
    }
  },
  {
    "page_content": "này, đứng cái bối cảnh này, khung cảnh này. Do đó cái việc tìm ra cái cặp ảnh là không thể, nhưng mà chúng ta vẫn có thể biến đổi cái con ngựa thật này thành ngựa vằn, nhờ cái thuật toán CycleGAN. CycleGAN là nó sẽ đi theo một cái chương trình, biến từ cái domain DX sang cái domain DY, và sau đó chúng ta sẽ có một cái hàm biến đổi ngược lại. Thì lúc này chúng ta sẽ có cái gọi là cycle loss để đảm bảo rằng là cái ảnh tạo ra bởi cái không gian đích là Y, nó phải giống thật nhưng đồng thời ở cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 16,
      "start_timestamp": "0:11:20",
      "end_timestamp": "0:12:14"
    }
  },
  {
    "page_content": "là Y, nó phải giống thật nhưng đồng thời ở cái khía cạnh ngược lại là từ cái không gian Y về lại X, thì cái DX này cũng phải là một cái ảnh giống thật. Thì CycleGAN là một cái biến thể rất là thú vị. Thì nếu như GAN là chúng ta ánh xạ từ một cái random noise sang một cái không gian ảnh, thì CycleGAN là biến đổi từ hai cái miền dữ liệu X và Y cho nhau, biến đổi từ miền dữ liệu X sang miền dữ liệu Y. Ví dụ như trong ví dụ vừa rồi, X của mình chính là ngựa thường. Còn Y ở bên đây đó là ngựa vằn.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 17,
      "start_timestamp": "0:12:08",
      "end_timestamp": "0:12:59"
    }
  },
  {
    "page_content": "là ngựa thường. Còn Y ở bên đây đó là ngựa vằn. Và cái này là không bắt cặp. Nhưng nó vẫn có thể học được các cái phân bố của hai cái domain X và Y này. Như vậy tổng kết lại, trong phần này thì chúng ta đã cùng tìm hiểu về hai cái nhóm mô hình tạo sinh quan trọng, đó chính là autoencoder và biến thể variational autoencoder. Mục đích của variational autoencoder đó là chúng ta sẽ học cái không gian ẩn, chúng ta sẽ học cái không gian tiềm ẩn có số chiều thấp hơn so với dữ liệu đầu vào. Và khi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 18,
      "start_timestamp": "0:12:54",
      "end_timestamp": "0:13:41"
    }
  },
  {
    "page_content": "số chiều thấp hơn so với dữ liệu đầu vào. Và khi chúng ta lấy mẫu Y, thì nó sẽ tái tạo lại qua cái hàm decoder để tái tạo lại cái X mẫu này. Và chúng ta luôn mong muốn cái X mẫu xấp xỉ với lại X. Còn đối với GAN là một cái mạng tạo sinh đối kháng, thì chúng ta không có cái công đoạn nén ảnh này, mà chúng ta từ một cái vector random noise Z, chúng ta sẽ tạo ra một cái ảnh x' (x phẩy). Nhưng mà đương nhiên trong cái quá trình huấn luyện, khi G mà nó càng tốt, thì cái x' (x phẩy) này nó sẽ có xu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 19,
      "start_timestamp": "0:13:31",
      "end_timestamp": "0:14:32"
    }
  },
  {
    "page_content": "nó càng tốt, thì cái x' (x phẩy) này nó sẽ có xu hướng là càng giống với là xReal, tức là x giống thật. Thế thì đối với mạng GAN, mặc dù nó không có cái công đoạn nén, nó không có cái công đoạn là nén, nhưng mà nó có một cái module tương tự như vậy, đó là discriminator. Là một cái module để giúp phân biệt ảnh thật và ảnh giả. Thế thì tưởng là chúng ta có thể tránh cái việc không dùng một cái mạng generator, dùng một cái mạng encoder, nhưng cuối cùng thì cái D này, discriminator này nó sẽ tương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 20,
      "start_timestamp": "0:14:28",
      "end_timestamp": "0:14:32"
    }
  },
  {
    "page_content": "cùng thì cái D này, discriminator này nó sẽ tương đương với lại một cái mạng encoder. Như vậy thì chúng ta đã cùng tìm hiểu qua hai cái kiến trúc rất là kinh điển và vẫn có rất nhiều những cái ứng dụng hiện nay, đó chính là VAE và GAN. Trong phần tiếp theo, phần các cái mô hình tạo sinh học sâu, thứ hai thì chúng ta sẽ được tìm hiểu về mô hình diffusion. Đây cũng là một trong những cái mô hình mà có rất nhiều những cái ứng dụng trong thực tế. Cảm ơn các bạn đã xem video. Hãy đăng ký kênh để xem",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 21,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ơn các bạn đã xem video. Hãy đăng ký kênh để xem video mới nhất.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=RVj2LTBd7IU",
      "filename": "RVj2LTBd7IU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)",
      "chunk_id": 22,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với các mô hình tạo sinh học sau Deep Generated Model phần 2, mô hình Diffusion. Các mô hình tạo sinh hình ảnh đều có gốc gác sử dụng mô hình phát tán, mô hình Diffusion Model. Đây có thể nói là một trong những mô hình có tính ứng dụng rất cao do tạo ra những ảnh có độ phân giải cao, đồng thời có thể cho chúng ta can thiệp và điều hướng nội dung của tấm ảnh. Vậy thì ý tưởng của Diffusion là gì và cách thức huấn luyện ra sao, chúng ta sẽ cùng tìm hiểu trong bài ngày hôm nay.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=SCNZncN1Hvk",
      "filename": "SCNZncN1Hvk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:53"
    }
  },
  {
    "page_content": "chúng ta sẽ cùng tìm hiểu trong bài ngày hôm nay. Các vấn đề chính khi chúng ta tìm hiểu một mô hình Diffusion Model, mô hình phát tán, đó là chúng ta sẽ tìm hiểu về mô hình tạo sinh tổng quát. Mô hình tạo sinh tổng quát này sẽ dựa trên lý thuyết về xác suất thống kê. Sau đó chúng ta sẽ tìm hiểu về cách thức một mô hình được huấn luyện như thế nào. Sau đó chúng ta sẽ nghiên cứu về cách thức để điều hướng ảnh tạo sinh, hay gọi là guidance. Giờ thì chúng ta có thể tạo ra một tấm ảnh mà có nội",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=SCNZncN1Hvk",
      "filename": "SCNZncN1Hvk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:00:45",
      "end_timestamp": "0:01:45"
    }
  },
  {
    "page_content": "thì chúng ta có thể tạo ra một tấm ảnh mà có nội dung giống với điều kiện chúng ta cho trước. Ví dụ như có nội dung giống với chỉ thị lệnh của mình. Trong prompt này nó sẽ có mô tả về nội dung tấm ảnh chúng ta muốn tạo ra. Mô tả nội dung của ảnh. Vấn đề tiếp theo là vấn đề về độ phân giải. Làm sao để chúng ta có thể tạo ra những mô hình sinh ảnh có độ phân giải cao. Vấn đề về tốc độ. Khi nói về mô hình khuếch tán thì chúng ta phải thực hiện rất nhiều bước biến đổi. Vậy thì làm sao để tăng tốc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=SCNZncN1Hvk",
      "filename": "SCNZncN1Hvk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:01:39",
      "end_timestamp": "0:02:21"
    }
  },
  {
    "page_content": "nhiều bước biến đổi. Vậy thì làm sao để tăng tốc độ của quá trình khuếch tán. Và đó chính là những nội dung chính chúng ta sẽ cùng tìm hiểu trong ngày hôm nay. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=SCNZncN1Hvk",
      "filename": "SCNZncN1Hvk",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:02:17",
      "end_timestamp": "0:02:34"
    }
  },
  {
    "page_content": "sau khoảng hơn 2 phút, thuật toán đã được huấn luyện xong và chúng ta sẽ tiến hành trực quan hóa để trực quan hóa không gian latent với các Embedding Vector khái niệm Embedding Vector là những tập dữ liệu chúng ta đã huấn luyện chúng ta biến đổi nó về VectorZ VectorZ là Embedding Vector chúng ta sẽ tìm cách vẽ VectorZ của tập dữ liệu MNIST này lên trên mặt phẳng 2 chiều để xem nó như thế nào chúng ta sẽ có hàm Plot Latent và chúng ta sẽ truyền vào hàm mô hình đã được huấn luyện đó là Autoencoder",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:05"
    }
  },
  {
    "page_content": "hàm mô hình đã được huấn luyện đó là Autoencoder kèm theo Data ở đây chúng ta sẽ tắt gradient và lưu ý ở đây chúng ta có dữ liệu của mình là theo trục X và có dữ liệu đầu vào là X và Y tuy nhiên, trong phần huấn luyện chúng ta sẽ gọi hàm Train không có sử dụng biến Y nhưng ở phần trực quan hóa chúng ta sẽ sử dụng biến Y này để chúng ta có thể vẽ ra những ảnh có cùng một cái nhãn cũng là cùng một cái chữ số xem xem nó có nằm trong chung một khu vực hay không hay là nó nằm ở trải rác ở nhiều nơi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:01:01",
      "end_timestamp": "0:01:54"
    }
  },
  {
    "page_content": "hay không hay là nó nằm ở trải rác ở nhiều nơi chúng ta sẽ dùng encoder và truyền cái X này vào X ở đây là truyền vào cái device sau đó sẽ tính ra Z sau khi chúng ta tính ra cái vector Z của toàn bộ dữ liệu rồi thì chúng ta sẽ rút trích ra CPU sau khi rút trích ra CPU thì chúng ta sẽ lần lượt dùng cái biểu đồ dạng scatter rất là biểu đồ dạng vẽ điểm và truyền cái thành phần đầu tiên và thành phần thứ hai tức là hai tọa độ theo trục X và trục Y về màu sắc là C chúng ta sẽ dùng 10 cái nhãn từ 0",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:46",
      "end_timestamp": "0:02:47"
    }
  },
  {
    "page_content": "về màu sắc là C chúng ta sẽ dùng 10 cái nhãn từ 0 cho đến 9 làm cái nhãn của cái màu và cái color map thì chúng ta sẽ dùng là tab 10 rồi, thế thì ở đây chúng ta sẽ gọi hàm và chúng ta vẽ cái Latent này lên thì nó sẽ ra cái hình ảnh như thế này và chúng ta thấy cái hình này nó sẽ có cái tính chất gì đó là nó sẽ không có dạng một cái phân bố giống như phân bố chuẩn mà nó có thể đi một cái đường dải rất là dài như thế này một cái dải rất là dài đó là ý thứ nhất cái thứ hai đó là có những cái số ví",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:38",
      "end_timestamp": "0:03:25"
    }
  },
  {
    "page_content": "ý thứ nhất cái thứ hai đó là có những cái số ví dụ như số 1 khi những mẫu dữ liệu là cái vector embedding của cái ảnh số 1 thì thấy là nó đã phân tách ra rất tốt so với lại những cái con số khác tại vì cái hình thù của số 1 khá là khác biệt so với những cái con số khác cái số tiếp theo đó là số 7 là màu xám thì cũng khá là khác biệt nhưng mà sẽ có những cái khu vực như thế này là khá là lộn xộn và nó có thể vừa có xanh đỏ tím vàng đầy đủ hết thì cái khu vực này có thể là những cái con chữ mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:03:19",
      "end_timestamp": "0:04:05"
    }
  },
  {
    "page_content": "cái khu vực này có thể là những cái con chữ mà được viết không rõ ràng nên nó sẽ gom lại ở khu vực này rồi, thế thì chúng ta sẽ tiến hành trực quan hóa cái kết quả decode với một cái vector gì bất kỳ thế thì trên cái ảnh của cái không gian Latent Space chúng ta thấy nó có một cái đặc điểm nữa đó là rất nhiều những cái khoảng hở khoảng hở đó là những cái khu vực mà chúng ta thấy có màu trắng là không có được vẽ không có một cái vector embedding nào nằm lên trên đó thì câu hỏi đó là những cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:04:01",
      "end_timestamp": "0:04:52"
    }
  },
  {
    "page_content": "nào nằm lên trên đó thì câu hỏi đó là những cái khoảng hở này khi chúng ta decode thì nó sẽ ra cái tấm ảnh là gì? nó có ý nghĩa hay không? thì cách mà chúng ta sẽ thực nghiệm đó chính là chúng ta sẽ làm cái lưới từ trừ 5 cho đến 10 và từ trừ 10 cho đến 5 rồi, thì chúng ta sẽ thử ha chúng ta sẽ vẽ cái lưới này rồi, trừ 5 là ở đây rồi chúng ta sẽ lấy cái lưới chụp cái màn hình này thì trừ 5 sẽ là ở đây rồi 10 sẽ là ở đây trừ 5 cho đến 10 trừ 5 cho đến 10 thì 10 sẽ là ở đây rồi và trục tung thì là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:04:43",
      "end_timestamp": "0:06:05"
    }
  },
  {
    "page_content": "đến 10 thì 10 sẽ là ở đây rồi và trục tung thì là sẽ từ trừ 10 cho đến 5 trừ 10 cho đến 5 là ở đây trừ 10 cho đến 5 là ở đây rồi, như vậy cái lưới mà dự định chúng ta sẽ vẽ là ở khu vực này trục hoành là từ trừ 5 cho đến 10 và trục tung là từ trừ 10 cho đến 5 như vậy thì chúng ta sẽ có một cái khung vuông rồi, sau đó chiến thuật của chúng ta là gì? chúng ta sẽ chia lưới nó ra ví dụ như trong trường hợp này chúng ta sẽ chia ra làm 12 khoảng cách đều nhau rồi, sau đó chúng ta cũng sẽ chia lưới",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:06:00",
      "end_timestamp": "0:06:55"
    }
  },
  {
    "page_content": "đều nhau rồi, sau đó chúng ta cũng sẽ chia lưới theo chiều dọc như vậy rồi, thì với mỗi một cái điểm trên cái mắt lưới này lấy ví dụ như cái điểm ở đây chúng ta sẽ dùng một điểm đen ví dụ như một cái điểm trên cái mắt lưới này thì nó sẽ là một cái vector z mà chúng ta lấy ra, chấm lên trên cái lưới và chúng ta sẽ qua cái hàm decoder để xem nó ra một cái tấm ảnh gì nó như thế nào sau đó chúng ta lấy cái ảnh này chúng ta sẽ vẽ lên trên thành một cái ma trận với cái ảnh này chúng ta sẽ vẽ ra một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:06:48",
      "end_timestamp": "0:07:35"
    }
  },
  {
    "page_content": "cái ma trận với cái ảnh này chúng ta sẽ vẽ ra một ảnh với một cái điểm z ở đây chúng ta sẽ decode ra và vẽ ảnh lên với cái điểm này, điểm này chúng ta decode ra và vẽ ảnh lên thì chúng ta sẽ ra một cái ma trận các điểm ảnh và chúng ta sẽ quan sát xem nó có cái tính chất gì đặc biệt phải không Rồi, thì đó chính là cái ý tưởng của cái hàm Plot Reconstructed chúng ta sẽ chia ra thành các latent space với n ở đây là bằng 12, chúng ta sẽ chia ra làm 12 khoảng rồi lấy cái x và cái y này chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:31",
      "end_timestamp": "0:08:17"
    }
  },
  {
    "page_content": "12 khoảng rồi lấy cái x và cái y này chúng ta sẽ có được cái latent z là cái điểm màu đen mà chúng ta đã vẽ rồi qua cái hàm decoder chúng ta sẽ ra được x hat tức là cái ảnh được tạo sinh ra và ảnh này sẽ được reset về cái kích thước là 28 x 28 và sau đó vẽ lên cái ma trận ảnh rồi, thì chúng ta sẽ chạy cái đoạn code này đó thì với cái ví dụ này chúng ta có thể thấy đó là ở những cái khu vực phía trên đó sẽ ra một cái hình thù gì đấy và chúng ta không cảm nhận được đó là một cái con số khu vực ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:08:15",
      "end_timestamp": "0:08:57"
    }
  },
  {
    "page_content": "cảm nhận được đó là một cái con số khu vực ở giữa ở đây cũng vậy nó sẽ có lẫn lộn rất nhiều những cái hình ảnh ở trong đó có thể có chứa nhiều con số dẫn đến là mình nhìn mình không cảm nhận được đó là số gì khu vực này cũng vậy thế thì chiếu lên trên cái hình ảnh của cái không gian của mình thì những ảnh ở góc phía trên bên đây là ở khu vực trừ 5 cho đến 5 trừ 5 cho đến 5 tức là nó nằm ở cái khu vực màu trắng và cái khu vực màu trắng này khi chúng ta decode ra thì nó sẽ tạo ra một cái ảnh",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "0:08:54",
      "end_timestamp": "0:09:02"
    }
  },
  {
    "page_content": "chúng ta decode ra thì nó sẽ tạo ra một cái ảnh không có ý nghĩa không giống cái con số nào hết đó thì đây chính là cái điểm yếu của mô hình auto encoder",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=t5t5G61ZtAg",
      "filename": "t5t5G61ZtAg",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ lược qua một số biến thể khác của các mô hình thị giác, ngôn ngữ thị giác Mô hình đầu tiên là Mô hình Clam Ý tưởng của Mô hình này là có chứa một dạng token đặc biệt, đó là set Mô hình này là một trong những chủ đề độc đáo và mới trong thời gian gần đây Mô hình ngôn ngữ sẽ nói thông qua mask, khai thác được mô hình ngôn ngữ cho một bài toán liên quan đến segmentation Thay vì chúng ta cần phải có một mô hình chuyên dụng để segment được hình ảnh của đối tượng Mô hình LM sẽ output ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:27"
    }
  },
  {
    "page_content": "hình ảnh của đối tượng Mô hình LM sẽ output ra prompt và chỉ việc decode là có thể tạo ra mask của đối tượng Tức là kết quả segmentation đến từ large language model, chứ không phải từ một mô hình chuyên dụng cho bài toán segmentation Một ý tưởng cũng tương tự như vậy, đó chính là mô hình route hot Nó có chứa một token đặc biệt, đó là GRD, tức là viết tắt của chữ routing Ý tưởng của nó là sử dụng một multimodal language model để khi chúng ta retrieve mask retrieval head Từ mask retrieval head",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:01:14",
      "end_timestamp": "0:02:16"
    }
  },
  {
    "page_content": "mask retrieval head Từ mask retrieval head này, chúng ta sẽ kết hợp lại với các class có trong đối tượng hình của mình để tạo ra một ảnh mask đẹp Bên cạnh việc trả ra một ngôn ngữ để mô tả tấm hình, chúng ta có thể trả ra một dạng ngôn ngữ nhưng có cấu trúc Ngôn ngữ có cấu trúc là Syntrap, tức là có một ví dụ Girl on chair, man sitting on chair, but... Đây chính là một cấu trúc graph, một cấu trúc có ngữ nghĩa Thay vì chúng ta trả ra một văn bản phi cấu trúc như thế này, chúng ta sẽ trả ra đồng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:02:03",
      "end_timestamp": "0:03:10"
    }
  },
  {
    "page_content": "phi cấu trúc như thế này, chúng ta sẽ trả ra đồng thời thêm Syntrap để cho biết được các đối tượng đã tương tác với nhau như thế nào Và những thông tin đó được lưu trữ như đồ thị Và một bài toán nữa cũng đã được đề cập trong mô hình trước đây, đó là mô hình SIM Thế thì bài báo ở đây là making large multimodal model understand RB3 VisualProm VisualProm ở đây chính là dấu mũi tên, chúng ta dùng dấu mũi tên để làm tương tác và chỉ thị Chỉ dẫn kèm theo text prompt là What is the person marked with",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 3,
      "start_timestamp": "0:03:06",
      "end_timestamp": "0:04:01"
    }
  },
  {
    "page_content": "text prompt là What is the person marked with the red arrow honey? Chúng ta kết hợp cả cái câu prompt dạng text với lại cái VisualProm để mà tăng cái khả năng tương tác cũng như là xử lý cái khả năng dễ hiểu dễ tương tác của người dùng Và một cái mô hình khác nữa đó là chúng ta đã cải tiến cái mô hình thị giác máy tính khác Ở đây chúng ta thấy là chúng ta có sử dụng các cái mô hình của bên mục thị giác máy tính như là mô hình captioning để verbalization Tức là cái tấm ảnh của mình thay vì chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 4,
      "start_timestamp": "0:03:47",
      "end_timestamp": "0:04:43"
    }
  },
  {
    "page_content": "Tức là cái tấm ảnh của mình thay vì chúng ta rút trích nó dưới dạng là VisualFeature Thì ở đây chúng ta sẽ verbalization, tức là chúng ta sẽ mô tả bằng lời nó Vì cái việc tấm ảnh nó sẽ biến thành cái dạng mô tả ngôn ngữ chi tiết thì chúng ta sẽ xử lý nó giống như là với văn bản thôi Thì khi đó chúng ta có thể khai thác được các sức mạnh của các mô hình ngôn ngữ lớn Thì đây chính là cái ý tưởng là biến cái tấm ảnh thành một cái dạng mô tả bằng lời chi tiết Và nó nằm trong cái bài báo đó là MOAI",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:04:32",
      "end_timestamp": "0:05:25"
    }
  },
  {
    "page_content": "chi tiết Và nó nằm trong cái bài báo đó là MOAI Thế thì tổng kết lại chúng ta đã tìm hiểu qua rất nhiều những cái mô hình khác nhau trong phần này Thì đầu tiên đó là cái mô hình RoundingDino thì nó sẽ sử dụng cái ngôn ngữ để query thông tin hình ảnh Và ở cái output của mình nó sẽ là cái dạng segment, segmentation Tức là một cái phân đoạn ảnh Và đầu vào của mình sẽ là một cái prompt dạng ngôn ngữ text Thế thì cái RoundingDino này nó sẽ phải kết hợp với một cái mô hình segmentation rất là tốt Mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 6,
      "start_timestamp": "0:05:18",
      "end_timestamp": "0:06:12"
    }
  },
  {
    "page_content": "với một cái mô hình segmentation rất là tốt Mà dựa trên cái VisualProm hoặc là SpatialProm là chính là mô hình SAM Tại vì cái mô hình RoundingDino này thì nó chỉ tạo ra được cái BoundingBox Chúng ta lấy cái BoundingBox này đưa vào SAM để mà nó segment ra chính xác đối tượng của mình Thế thì có cái cách để mà không cần phải sử dụng SAM mà chúng ta có một cái mô hình end-to-end để mà segment, đó chính là SIM Và SIM nó có một cái điểm thú vị khác đó là nó đa thể thức trong cái VisualProm Nó có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 7,
      "start_timestamp": "0:06:03",
      "end_timestamp": "0:06:54"
    }
  },
  {
    "page_content": "là nó đa thể thức trong cái VisualProm Nó có thể là một điểm, cái VisualProm của mình nó có thể là một điểm Một BoundingBox, một cái Mask hoặc là một cái StripWall, một cái đường nét nguệch ngoạc Và đồng thời là nó có hỗ trợ các cái phương thức là Composite Cũng như là CompositeProm, tức là có sự kết hợp của cả VisualProm, TextProm, vâng Hoặc SIM cũng có thể đưa vào dưới dạng là Referring Prompt Tức là chúng ta sẽ không biết cái đối tượng đó là gì Thì chúng ta sẽ query, đưa vào Key Prompt, dạng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 8,
      "start_timestamp": "0:06:44",
      "end_timestamp": "0:07:36"
    }
  },
  {
    "page_content": "Thì chúng ta sẽ query, đưa vào Key Prompt, dạng là Thumbnail Thì chúng ta sẽ tìm cái đối tượng giống như cái đối tượng trong cái ảnh Thumbnail của mình Thì đây là hai cái mô hình phục vụ cho cái bài toán Segmentation Sau đó thì chúng ta sẽ có những cái mô hình liên quan đến cái việc là khai thác mô hình ngôn ngữ lớn Cho các cái bài toán của ngôn ngữ thị giác, đó là mô hình lava Và mô hình lava nó đã đưa cái đặc trưng ảnh về cùng không gian với lại cái mô hình LLM Thông qua một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 9,
      "start_timestamp": "0:07:31",
      "end_timestamp": "0:08:13"
    }
  },
  {
    "page_content": "gian với lại cái mô hình LLM Thông qua một cái ProjectionLayer Thì nó sẽ đưa về cái không gian của LLM Sau đó thì nó sẽ tận dụng được cái tri thức đã được huấn luyện trước đó của LLM Để mà có thể giải quyết được các cái bài toán phức tạp Và lava đã cải thiện được ba yếu tố đó là Nó có thể được cải thiện thông qua việc tăng cái chất lượng của bộ dữ liệu lên Tăng cái độ phân giải của ảnh Cũng như là tăng cái độ lớn của mô hình lên Thì cái điều này cũng khá là thú vị Đó là nó cho cái kết quả một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 10,
      "start_timestamp": "0:08:09",
      "end_timestamp": "0:09:01"
    }
  },
  {
    "page_content": "cũng khá là thú vị Đó là nó cho cái kết quả một cái mô hình open source Và cho cái kết quả cao hơn các cái mô hình closed source ở một số cái task Và hai cái mô hình open source, hai mô hình closed source được so sánh ở đây chính là GmanEye, Flash, Ultra GmanEye Ultra hoặc là GmanEye Pro Còn cái phiên bản ở đây của GPT, đó là GPT 4V Là 4vision Thì cái lava cho cái kết quả tốt hơn hai cái mô hình này ở một số cái task Nhất định Thế thì cuối cùng đó là chúng ta có thể tùy biến cái đầu vào và đầu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 11,
      "start_timestamp": "0:08:54",
      "end_timestamp": "0:09:37"
    }
  },
  {
    "page_content": "đó là chúng ta có thể tùy biến cái đầu vào và đầu ra của lava Để giải quyết được những cái bài toán khác nhau Tại vì khi chúng ta cấu hình những cái đầu vào và đầu ra Thì sau đó chúng ta sẽ fine-tune lại Còn cái cơ chế chung của lava Nó vẫn là đưa cái đặc trưng ảnh để về cái không gian của cái mô hình ngôn ngữ lớn Và khai thác được cái mô hình ngôn ngữ lớn cho cái việc giải quyết các cái bài toán khác nhau phức tạp Thì trên đây đó là chúng ta đã tổng kết qua những cái mô hình Thị giác ngôn ngữ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 12,
      "start_timestamp": "0:09:34",
      "end_timestamp": "0:09:37"
    }
  },
  {
    "page_content": "tổng kết qua những cái mô hình Thị giác ngôn ngữ Ngôn ngữ thị giác vision language model Mà đã được học trong cái phần số 2 này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=TgONnvdebwU",
      "filename": "TgONnvdebwU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 4",
      "chunk_id": 13,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với mô hình tiếp theo đó là mô hình Blip Blip là viết tắc của chữ Boost Trapping Language Image Retraining Nếu như các mô hình ngôn ngữ thì trước thì thường nó sẽ có hai hạn chế chính Hạn chế đầu tiên xét ở khía cạnh mô hình đó đó là kiến trúc encoder của các mô hình đó thì ít phù hợp cho bài toán tạo sinh văn bản hay là Text Generation Text Generation có thể kể đến một số ngữ cảnh ứng dụng Ví dụ như là VQI tức là Visual Question Answering tức là hỏi đáp về hình ảnh hoặc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:55"
    }
  },
  {
    "page_content": "Answering tức là hỏi đáp về hình ảnh hoặc cũng có thể là image captioning Thế thì các mô hình mà đòi hỏi có sự tạo sinh ra văn bản sau khi chúng ta nhận dữ liệu đầu vào là hình ảnh thì những mô hình trước đó là không có phù hợp Về khía cạnh dữ liệu thì các mô hình trước đây được huấn luyện trên dữ liệu từ web nên nó có rất nhiều dữ liệu bị nhiễu và sai lệch Do đó thì từ những hạn chế này Blip đã đề xuất ra hai ý chính Ý đầu tiên là Blip đã giới thiệu một mô hình multimodal mixture of encoder",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:39"
    }
  },
  {
    "page_content": "thiệu một mô hình multimodal mixture of encoder decoder và với mục tiêu đó là có thể giải quyết được các bài toán liên quan đến loại hình sinh văn bản tức là Text Generation Và một cái Caption, tức là bộ dữ liệu mới được tạo ra từ hai cái module nhỏ Caption là sinh ra cho câu mô tả cho hình ảnh và Module Fill là viết tắc chữ filter thì là loại bỏ những câu mô tả sai hoặc là câu mô tả nhiễu từ cả hai cái câu được mô tả được tạo sinh và câu mô tả được lấy từ web tức là ở đây chúng ta sẽ có hai",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 2,
      "start_timestamp": "0:01:32",
      "end_timestamp": "0:02:22"
    }
  },
  {
    "page_content": "được lấy từ web tức là ở đây chúng ta sẽ có hai câu mô tả với một tấm ảnh Với một tấm ảnh ở đây thì chúng ta sẽ có một câu mô tả lấy từ internet, tức là từ web và một câu mô tả nữa lấy từ module caption, image caption ở đây Thì qua cái module filter thì chúng ta sẽ lọc lại là ví dụ như trong tình huống này là chúng ta sẽ bỏ đi câu blue sky, bakery in sunset path tại vì những thông tin này không liên quan đến nội dung ảnh Trong khi đó chocolate cake with cream frosting liên quan đến nội dung của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 3,
      "start_timestamp": "00:02:17",
      "end_timestamp": "0:03:05"
    }
  },
  {
    "page_content": "with cream frosting liên quan đến nội dung của hình ảnh này và nó sẽ được giữ lại thì đây có lẽ là một trong những đóng góp lớn của clip Vậy thì kiến trúc và mô hình của clip đó là gì? Đóng góp đầu tiên là multi-module mixture of encoder-decoder là một mô hình có khả năng thực hiện cùng lúc 3 chức năng Chức năng đầu tiên là để mã hóa những dữ liệu đơn lẻ tức là chúng ta sẽ tạo ra các đặc trưng biểu diễn các representation vector của ảnh và văn bản một cách độc lập Thì nó thông qua cái module",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 4,
      "start_timestamp": "00:03:02",
      "end_timestamp": "0:04:11"
    }
  },
  {
    "page_content": "bản một cách độc lập Thì nó thông qua cái module ITC Và cái module ITC này thì nó sẽ lấy thông tin caption của hình ảnh Đây chính là cái vector biểu diễn của ảnh Rồi, còn ở đây sẽ là cái vector biểu diễn của văn bản Và ở đây chúng ta thấy trong cái sơ đồ này chúng ta thấy có cái module cross-attention nhưng mà được làm mờ và gạch sọc đi thì hàm ý đó là chúng ta sẽ không có sự tương tác giữa hình ảnh với văn bản là hàm ý đó là để cho hai cái loại đặc trưng này độc lập nhau để sau này khi chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 5,
      "start_timestamp": "0:04:08",
      "end_timestamp": "0:04:48"
    }
  },
  {
    "page_content": "đặc trưng này độc lập nhau để sau này khi chúng ta huấn luyện cái mô hình này xong thì chúng ta có thể sử dụng hai cái module này như là hai cái embedding module cho hình ảnh riêng và cho văn bản riêng tức là chúng ta sẽ cho hình ảnh vào và nó sẽ ra vector biểu diễn nó không cần có sự can thiệp của một cái module văn bản nào khác và ngược lại chúng ta có thể đưa văn bản vào nó sẽ ra cái vector biểu diễn và chúng ta cũng không cần thiết phải đưa ảnh vào để có thể biểu diễn thì cái module này,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 6,
      "start_timestamp": "00:04:43",
      "end_timestamp": "0:05:23"
    }
  },
  {
    "page_content": "ảnh vào để có thể biểu diễn thì cái module này, cái ITC này nó khá là tương đồng với lại cái mô hình clip tức là nó độc lập cái mà nó có sự fusion có chăng nó sẽ là nằm ở cái bước cuối cùng đó là cái ITC mục tiêu của cái ITC này là để mapping để xem coi cái sự tương đồng giữa hình ảnh với văn bản này là có giống nhau hay không thì cái clip này, cái module ITC này nó tương đương với lại cái clip của mình và cái module thứ 2 đó là mã hóa hình ảnh văn bản thì ở đây chúng ta thấy là bên trái là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 7,
      "start_timestamp": "00:05:21",
      "end_timestamp": "0:06:07"
    }
  },
  {
    "page_content": "văn bản thì ở đây chúng ta thấy là bên trái là cross attention là không có được sử dụng nhưng mà trong cái module ITM là image to text encoder thì chúng ta có cái sự đưa cái nội dung của hình ảnh vào để thực hiện cái cross attention thì mục tiêu của cái ITM này là cho cái bài toán đó là captioning là cái bài toán captioning tức là với một tấm ảnh nó sẽ có cái caption mô tả cái tấm ảnh đó và module này thì cũng tương tự như cái ITC tức là nó sẽ nhận cái đầu vào là cái câu mô tả của mình rồi sau",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 8,
      "start_timestamp": "00:06:02",
      "end_timestamp": "0:06:48"
    }
  },
  {
    "page_content": "cái đầu vào là cái câu mô tả của mình rồi sau đó nó có một cái module là B-Self Attention viết tắc của chữ B-Directional Self Attention mục tiêu đó là chúng ta có thể tương tác được cái dữ liệu text theo 2 chiều tức là chúng ta sẽ đọc từ trái sang phải và từ phải sang trái nó cũng giống giống như cái mô hình bird nó cũng giống như cái mô hình bird trong cái việc đó là encode dữ liệu văn bản và module cuối cùng đó chính là cái giải mã hình ảnh văn bản Image-to Text Decoder phục vụ cho các cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 9,
      "start_timestamp": "00:06:42",
      "end_timestamp": "0:07:21"
    }
  },
  {
    "page_content": "văn bản Image-to Text Decoder phục vụ cho các cái bài toán mà có tính chất là tạo sinh ra văn bản thế thì cái sự khác biệt giữa tạo sinh văn bản với lại cái Image-to Text Decoder đó là gì đối với cái module ở giữa tức là ITM mục đích chính của nó đó chỉ là để hiểu cái nội dung hình ảnh ở đây tức là toàn bộ những cái nội dung văn bản chúng ta sử dụng ở đây thì nó sẽ là mô tả cho cái tấm ảnh ở đây nhưng đối với cái bài toán tạo sinh văn bản thì cái mục đích của nó đó là nó hướng đến là chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 10,
      "start_timestamp": "00:07:15",
      "end_timestamp": "0:08:02"
    }
  },
  {
    "page_content": "mục đích của nó đó là nó hướng đến là chúng ta sẽ trả lời câu hỏi chúng ta có thể hỏi đáp trò chuyện với tấm ảnh nói chung là các cái tác vụ nâng cao không có đơn giản chỉ là mô tả tấm ảnh thôi thì đây là cho Text Generation và đây chính là cái giải pháp để giải quyết vấn đề chúng ta nói ở trước đó là ở khía cạnh mô hình thì kiến trúc encoder-decoder nó ít phù hợp cho bài toán sinh văn bản và cái chữ LLM này là viết tắc của Language Model tức là nó sẽ nằm trong cái nhánh là Decode nó tương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 11,
      "start_timestamp": "00:07:59",
      "end_timestamp": "0:08:46"
    }
  },
  {
    "page_content": "là nó sẽ nằm trong cái nhánh là Decode nó tương đương với một cái decoder và ở trong cái hình bên tay phải ở đây nó chính là cái sơ đồ Mask để thể hiện cái việc là chúng ta có được phép thấy cái nội dung ở đằng trước đó hay không Mask tức là không được thấy còn Unmask là được thấy thì đối với cái Image Text Contrastive Learning tức là cái module đầu tiên của mình module đầu tiên là ITC thì nó sẽ tương tự như clip tức là hình ảnh là nó nằm trong cái query hình ảnh và text cái query và cái text",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 12,
      "start_timestamp": "00:08:45",
      "end_timestamp": "0:09:25"
    }
  },
  {
    "page_content": "cái query hình ảnh và text cái query và cái text thì nó sẽ không có được phép thấy nhau nó sẽ không được phép thấy nhau tức là query thì chỉ được thấy query không được thấy text text thì cũng tương tự như vậy text thì chỉ được thấy text chứ không được thấy query rồi và đối với cái module là Image Text Matching tức là tương ứng cái ở giữa thì chúng ta được phép thấy hết tại vì cả hai cái module này nó đều nằm trong cái nhóm là encoder ở đây cũng là encoder từ đây qua đúng không thì đây cũng là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 13,
      "start_timestamp": "00:09:23",
      "end_timestamp": "0:10:06"
    }
  },
  {
    "page_content": "là encoder từ đây qua đúng không thì đây cũng là encoder Image Encoder mà trong encoder thì các cái module của mình là được phép thấy được phép thấy còn cái module ở giữa ờm là Image to Text Generation thì tương ứng là cái module cuối tức là chúng ta sẽ không được phép thấy những cái từ phía sau mà chúng ta chỉ được phép thấy những từ phía trước chỉ được phép thấy những từ phía trước thì đây chính là cái sự khác biệt trong cái cách mà mình nhìn thấy cái thông tin ở trong cái kiến trúc của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 14,
      "start_timestamp": "00:10:03",
      "end_timestamp": "0:10:45"
    }
  },
  {
    "page_content": "nhìn thấy cái thông tin ở trong cái kiến trúc của Transformer rồi các cái token ở đây thì được sử dụng được sử dụng cho các cái mục đích khác nhau đối với cái module về Image Encoder thì ở đây chúng ta sẽ sử dụng là mô hình VIT còn đối với cái Text Encoder thì chúng ta sẽ sử dụng là mô hình BERT thì cái quá trình huấn luyện của mô hình BERT đó là huấn luyện được thực hiện đồng thời với 3 hạng mục tiêu và bộ dữ liệu của mình Bootstrapping thì sẽ sử dụng cho cái việc là tiền huấn luyện rồi module",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 15,
      "start_timestamp": "00:10:43",
      "end_timestamp": "0:11:19"
    }
  },
  {
    "page_content": "dụng cho cái việc là tiền huấn luyện rồi module Captioner và Filter thì được fine-tune trên cái tập dữ liệu gán nhãn thủ công thì cái cách thực hiện đó là chúng ta sẽ có sau khi chúng ta đã huấn luyện cái mô hình multimodal mixture of decoder thì chúng ta sẽ tiến hành sử dụng các cái bộ dữ liệu nhưng mà cái bộ dữ liệu gán nhãn này thì nó rất là hạn chế nó rất là hạn chế so với lại những bộ dữ liệu trên internet là viết tắc của chữ T H H là Human và sau đó thì chúng ta sẽ huấn luyện cho dùng cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 16,
      "start_timestamp": "00:11:17",
      "end_timestamp": "0:11:59"
    }
  },
  {
    "page_content": "và sau đó thì chúng ta sẽ huấn luyện cho dùng cái dữ liệu gán nhãn này thì chúng ta sẽ huấn luyện cho Captioner và Filter sau đó thì chúng ta sẽ từ Captioner chúng ta sẽ tạo ra một cái dữ liệu là Synthesis Synthesis tức là S, viết tắc chữ S thì đây là cái mô tả cho tấm ảnh này nhưng mà được tạo ra bởi module Captioner và cái này thì chúng ta để màu đỏ là có thể sai chúng ta có thể sai do đó thì chúng ta sẽ sử dụng cái module Filter ở đây với cái image chúng ta sẽ đưa cái module Filter bằng cách",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 17,
      "start_timestamp": "00:11:57",
      "end_timestamp": "0:12:31"
    }
  },
  {
    "page_content": "image chúng ta sẽ đưa cái module Filter bằng cách đó là chúng ta sẽ sử dụng cái module Filter bằng cách đó là đưa cái T W và T S T W, tức là W là viết tắc của chữ Web là cái Caption lấy từ mạng internet về và có thể đúng có thể sai cái Synthesis này cái TextSynthesis này thì cũng có thể đúng thể sai chúng ta sẽ đưa vào để Filter để được là TextWeb và TextSynthesis được gán màu xanh tức là những cái nội dung mà đúng những cái nội dung mà đúng với nội dung hình ảnh sau đó thì chúng ta sẽ tổng hợp",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 18,
      "start_timestamp": "00:12:29",
      "end_timestamp": "0:13:07"
    }
  },
  {
    "page_content": "nội dung hình ảnh sau đó thì chúng ta sẽ tổng hợp với lại cái dữ liệu Human Human Annotation dữ liệu Synthesis và dữ liệu trên Web để chúng ta được cái Data Set D thì cái Data Set D này nó sẽ vừa có cái tính, đó là cái Scale tỷ lệ của nó rất là lớn số lượng rất là nhiều, đồng thời là dữ liệu nó sạch hơn và đây cũng là một trong những cái đóng góp chính của bài báo này để cho cái mô hình của mình có thể huấn luyện một cách hiệu quả và cái kết quả của module Captioner-Filter ví dụ như ở trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 19,
      "start_timestamp": "00:13:03",
      "end_timestamp": "0:13:45"
    }
  },
  {
    "page_content": "quả của module Captioner-Filter ví dụ như ở trong hình đây thì chúng ta thấy là cái dữ liệu dữ liệu lấy từ Web về thì là From Bridge Near My House thì ở đây có thể là cái nội dung này nó đúng nó đúng về mặt, là Context là cái này nó sẽ chụp từ trên cầu gần cái nhà của cái người này nhưng mà trong cái tấm hình này nó không có thể hiện cái cây nào, cầu nào và không có thể hiện cái ngôi nhà nào do đó thì ở đây là sai rồi, còn nếu mà Synthesize thì nó sẽ là có màu xanh, tức là Hopper, chúng ta thấy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 20,
      "start_timestamp": "00:13:43",
      "end_timestamp": "0:14:21"
    }
  },
  {
    "page_content": "sẽ là có màu xanh, tức là Hopper, chúng ta thấy có chim Flying Over a Lake at Sunset thì đây là cái nội dung đúng nó sẽ giữ lại tương tự như vậy, ở phía cuối thì chúng ta sẽ thấy cũng có tình huống đó là cái Synthesize Text này là A Large Building of a Lot with a Lot of Windows on it thì ở đây là sai, nó nhầm cái này là cái cửa sổ thì cũng sẽ là được bỏ đi như vậy thì với cái phương pháp Captioner-Filter nó đã giúp chúng ta tạo ra một cái bộ dữ liệu vô cùng lớn và được lọc lại một cách sàng lọc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 21,
      "start_timestamp": "00:14:19",
      "end_timestamp": "0:14:59"
    }
  },
  {
    "page_content": "vô cùng lớn và được lọc lại một cách sàng lọc để phục vụ cho cái việc huấn luyện nó hiệu quả hơn và ứng dụng cho các cái bài toán cụ thể thì Blip được sử dụng rất là nhiều cho các cái bài toán ví dụ như là bài toán VQA là hỏi đáp trên hình ảnh thì cái kiến trúc chung chúng ta có thể sử dụng đó là chúng ta đưa vào một cái tấm ảnh và cái encoder rồi chúng ta lấy cái vector biểu diễn sau đó chúng ta lại tiếp tục encode đưa vào cái module là questionencoder thì chúng ta sẽ ra được cái vector biểu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 22,
      "start_timestamp": "00:14:57",
      "end_timestamp": "0:15:35"
    }
  },
  {
    "page_content": "thì chúng ta sẽ ra được cái vector biểu diễn cho cả hình ảnh và câu hỏi sau đó lấy cái vector biểu diễn của cả hình ảnh câu hỏi này chúng ta sẽ qua cái module decoder đây chính là cái module là LM trong cái slide trước của mình thì nó sẽ tạo ra cái cái câu trả lời và ứng dụng trong cái bài toán là hội thoại hình ảnh thì chúng ta sẽ đưa vào cái imageencoder và độc lập với lại cái caption rồi chúng ta sẽ đưa vào một cái câu hỏi đáp hoặc là một cái hội thoại hoặc là một câu hỏi v.v. và độc lập và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 23,
      "start_timestamp": "00:15:33",
      "end_timestamp": "0:16:15"
    }
  },
  {
    "page_content": "hội thoại hoặc là một câu hỏi v.v. và độc lập và nó sẽ tạo ra một cái vector biểu diễn sau đó đem cả hai cái vector biểu diễn này qua cái module dialogencoder thì cái này có thể là một cái module chúng ta sẽ phải huấn luyện thêm để trả lời cho cái tài là true hay là false tức là cái image và cái caption này là đúng có khớp hay nhau hay không rồi đối với cái bài toán là suy luận trên hình ảnh và ngôn ngữ là natural language visual reasoning thì chúng ta cũng sử dụng cái imageencoder và đã được",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 24,
      "start_timestamp": "00:16:13",
      "end_timestamp": "0:16:47"
    }
  },
  {
    "page_content": "chúng ta cũng sử dụng cái imageencoder và đã được học ở trong cái mô hình clip đã được huấn luyện sẵn trong mô hình clip sau đó chúng ta sẽ đi kết hợp với lại một cái module này để huấn luyện với các cái module cross attention để mà huấn luyện cho cái module cross attention để mà trả lời cho cái câu hỏi đúng sai, cái reasoning này là đúng hay sai và nó có thể kết hợp nhiều loại ảnh với nhau chứ không phải là chỉ cho một hình ảnh như vậy thì chúng ta đã qua cái mô hình clip ở phiên bản đầu tiên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 25,
      "start_timestamp": "00:16:45",
      "end_timestamp": "0:17:21"
    }
  },
  {
    "page_content": "ta đã qua cái mô hình clip ở phiên bản đầu tiên và phiên bản số 2 thì clip nó đã có cái cải tiến chính, đó chính là nó sử dụng các cái pre-trained model rất là mạnh ví dụ như module imageencoder và languagemodel languagemodel thì đây chính là hai cái module mà chúng ta sẽ không có đi fine-tune lại mà chúng ta sẽ đóng băng, nó còn gọi là frozen, chúng ta đóng băng nó đi lý do đó là vì cái hai cái module này nó rất là mạnh và nó được train từ những cái large gọi là data set một cái internet scale",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 26,
      "start_timestamp": "00:17:19",
      "end_timestamp": "0:17:53"
    }
  },
  {
    "page_content": "cái large gọi là data set một cái internet scale data set trước đó nên cái việc huấn luyện lại là không cần thiết và nếu có thì cũng có thể gây ra cái hiện tượng là overfitting do đó chúng ta chỉ tập trung để huấn luyện cái mô hình là WeFormer của mình thôi thì ở đây nó sẽ có hai giai đoạn giai đoạn 1, đó là chúng ta sẽ huấn luyện cái module WeFormer tức là cái module này, thì ở bên đây đó là cái mô hình phóng to thì mục đích của cái module WeFormer này đó là để trích xuất cái thông tin ảnh ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 27,
      "start_timestamp": "00:17:51",
      "end_timestamp": "0:18:33"
    }
  },
  {
    "page_content": "này đó là để trích xuất cái thông tin ảnh ở bên đây nó sẽ trích xuất ra cái thông tin ảnh thì đầu vào của mình chúng ta sẽ phải đưa vào một cái learn query và cái câu caption cái câu caption và sau đó nó sẽ huấn luyện các cái module self-attention, cross-attention feedforward v.v. để mục đích đó là chúng ta làm cái image text matching rồi image text contrastive learning thì đây giống như là cái module clip của mình rồi image grounded text generation và giống như là cái module để mà VQI các cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 28,
      "start_timestamp": "00:18:31",
      "end_timestamp": "0:18:47"
    }
  },
  {
    "page_content": "và giống như là cái module để mà VQI các cái task liên quan đến VQI và cái task này liên quan đến cái captioning nó kế thừa cái ý tưởng của clip 1 và sang giai đoạn 2 thì chúng ta sẽ có một cái phần tập trung để huấn luyện và phần tập trung để huấn luyện và phần tập trung để huấn luyện và sang giai đoạn 2 thì chúng ta sẽ huấn luyện cả WeFormer và một cái projection layer để liên kết cái ảnh vào ngôn ngữ thì cái projection layer nó chính là cái module này thế thì ở giai đoạn 1 là chúng ta chỉ có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 29,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "này thế thì ở giai đoạn 1 là chúng ta chỉ có huấn luyện một cái module WeFormer thôi và sang giai đoạn 2 thì chúng ta sẽ huấn luyện cho cả hai module và cái cách thức chúng ta huấn luyện đó là chúng ta đều có thể tắt cái này ra là 1, đó là chúng ta chỉ huấn luyện một cái LM decoder chúng ta chỉ sử dụng một cái LM decoder một cái cách thứ 2 đó là chúng ta sẽ phải kết hợp thêm cả cái LM encoder và cái module là LM decoder thì đối với cái module LM, cả hai cái cái cách thức này nó sẽ giúp cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "LM, cả hai cái cái cách thức này nó sẽ giúp cho chúng ta giải quyết trên những cái bài toán khác nhau Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=uFYNI0yZYPo",
      "filename": "uFYNI0yZYPo",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 4",
      "chunk_id": 31,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Trong phần trước chúng ta đã được tìm hiểu về momentum Thì đây có thể nói là một trong những lý thuyết rất là quan trọng để làm tiền đề cho tất những cái biến thể biến thể về sau Của các cái Optimizer, các cái thuật toán về tối ưu hóa ý tưởng chính của Momentum đó là nó sẽ tận dụng được động năng của quá khứ để giúp cho chúng ta thoát ra khỏi điểm cực tiểu cục bộ. Tức là tại vị trí này thì thế năng, tức là đạo hàm của mình nó mất, nhưng mà bù lại nó sẽ tận dụng được những thành phần và động năng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:53"
    }
  },
  {
    "page_content": "nó sẽ tận dụng được những thành phần và động năng ở phía trước, nó sẽ giúp cho chúng ta thoát ra và hy vọng là đến được những khu vực có cực tiểu tốt hơn. Và vấn đề của momentum đó là gì? Đối với những khu vực có độ dốc bất thường thì ví dụ như chúng ta thấy trong sơ đồ này Cái phác thảo của HempLoss, chúng ta thấy là cái độ dốc của mình tăng lên, nó dốc xuống rất là cao, sau đó lập tức nó đi ngang, rồi sau đó nó lại lập tức đi lên Tức là nó thay đổi trạng thái, đi xuống, đi ngang và sau đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 1,
      "start_timestamp": "0:00:44",
      "end_timestamp": "0:01:27"
    }
  },
  {
    "page_content": "đổi trạng thái, đi xuống, đi ngang và sau đó là đi lên một cách rất là ngắn như vậy, thì đó chính là cái độ dốc bất thường và nó sẽ khiến cho nó có rất nhiều những cái dao động mà bật qua bật lại, bật qua bật lại giữa hai cái thành dốc này. Cụ thể hơn, đó là chúng ta xét tại một cái điểm ở đây. Thì nếu như cái thành phần mà theo cái theta 1 của mình, mà đạo hàm của mình nó lớn, tức là cái giá trị độ lớn này, nó lớn hơn so với lại cái thành phần theo theta 2, khi chúng ta tổng hợp lại là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 2,
      "start_timestamp": "0:01:17",
      "end_timestamp": "0:02:01"
    }
  },
  {
    "page_content": "theo theta 2, khi chúng ta tổng hợp lại là cái vector tổng hợp thì nó sẽ bị thiên lệch về phía có thành phần radian lớn tức là cụ thể đây là theta 1 khi đó là nó sẽ không có cân bằng mà nó sẽ bật qua bên tay phải sau đó tại vị trí này chúng ta lại tiếp tục tính cái radian và chúng ta lại thấy cái hiện tượng mất cân bằng này lập lại thì khi chúng ta cập nhật thì nó cũng sẽ bị thiên lệch về cái phía mà có cái thành phần lớn hơn, đó chính là thành phần theta 1 tức là một khi cái đạo hàm của mình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 3,
      "start_timestamp": "0:01:59",
      "end_timestamp": "0:02:39"
    }
  },
  {
    "page_content": "phần theta 1 tức là một khi cái đạo hàm của mình theo thành phần, một cái thành phần nào đó mà lớn thì nó sẽ gây ra cái hiện tượng là bật qua bật lại trong khi đó cái đường tối ưu, ideal path thì lẽ ra nó phải là đường đường màu xanh ở đây, nó sẽ phải đi theo cái trục này Nó phải đi theo cái trục này, hay là đi theo cái trục của theo cái hướng của theta, theta2 Thì ở đây nó lại cứ bật qua trái, bật qua phải Thì bây giờ chúng ta sẽ cải tiến cái momentum bằng cách nào Thì muốn cải tiến thì chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 4,
      "start_timestamp": "0:02:30",
      "end_timestamp": "0:03:09"
    }
  },
  {
    "page_content": "bằng cách nào Thì muốn cải tiến thì chúng ta sẽ phải xem cái nguyên nhân của nó là gì Nguyên nhân đó là vì khi chúng ta có hai cái thành phần radian theo theta1 và theta2 Nếu thành phần nào đó lớn thì lẽ ra chúng ta sẽ phải giảm learning rate của nó xuống Nguyên nhân đó là do chúng ta dùng chung learning rate alpha dùng cho g, g là đạo hàm của J theo theta 1 và đạo hàm của J theo theta 2 một cách tổng quát thì nó có thể là có theta 3 theta n thì alpha a đang dùng chung cho radian theo theta 1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 5,
      "start_timestamp": "0:03:02",
      "end_timestamp": "0:04:10"
    }
  },
  {
    "page_content": "alpha a đang dùng chung cho radian theo theta 1 và radian theo theta 2 Bây giờ chúng ta mong muốn mỗi thành phần này sẽ có 1 cái alpha riêng Và nó sẽ giúp chúng ta cân bằng lại, đó chính là ý tưởng của cải tiến adaptive learning rate Giảm dao động dựa trên độ lớn của radian cập nhật gần đây, chúng ta giảm sự dao động đó Ý tưởng chính đó là, giả sử chúng ta có vector g là bằng hai thành phần, là g1 và g2 Nếu như chúng ta lấy alpha nhân với g, thì alpha mà dùng chung Thì không, bây giờ chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 6,
      "start_timestamp": "0:04:03",
      "end_timestamp": "0:04:51"
    }
  },
  {
    "page_content": "alpha mà dùng chung Thì không, bây giờ chúng ta sẽ dùng riêng, mỗi cái thành phần này sẽ có một cái alpha riêng trong đó, ở đây là ý tưởng đầu tiên là tách riêng ha, tách learning rate cho từng tham số và cái ý tưởng tiếp theo, đó là cái radian mà lớn thì learning rate nó sẽ nhỏ tức là nếu cái thành phần theo G1 mà lớn, G2 mà nhỏ, ví dụ vậy thì chúng ta sẽ có cái hệ số alpha 1 cân bằng ngược trở lại nó cân bằng ngược trở lại và thành phần G2 mà nhỏ thì chúng ta sẽ có cái Alpha 2 và khi đó thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 7,
      "start_timestamp": "0:04:45",
      "end_timestamp": "0:05:46"
    }
  },
  {
    "page_content": "nhỏ thì chúng ta sẽ có cái Alpha 2 và khi đó thì cái vector tổng hợp của mình nó sẽ đều hơn thay vì là nó bị thiên lệch như thế này Đường màu đỏ là đường mà nó bị thiên lệch. Nó bị lệch về phía theta, phía theta 1. Rồi, bằng ngược lại thì thành phần theta 2 nhờ có cái alpha 2 lớn, nó sẽ kéo ra để cho nó cân bằng cả hai hướng. Và chi tiết thuật toán Root Mean Square Propagation, đó là chúng ta sẽ khởi tạo với cái alpha là bằng 0.01 và beta thì đây là cái hệ số decay rate tức là cái hệ số mà để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 8,
      "start_timestamp": "0:05:42",
      "end_timestamp": "0:06:43"
    }
  },
  {
    "page_content": "là cái hệ số decay rate tức là cái hệ số mà để cập nhật cho cái momentum thì chúng ta nhìn một cái công thức của cái thuật toán root mean square là V tức là cái vận tốc cập nhật tham số của mình là cái thành phần ở phía trên mà chúng ta khoanh vùng ở đây Cách làm cũ của alpha là theta trừ alpha nhân cho nabla J Alpha là đây và đạo hàm radian là G Cách làm cũ là đạo hàm quá lớn, thành phần radian lớn sẽ lớn hơn những thành phần còn lại R là momentum để phục vụ chuẩn hóa learning rate Chuẩn hóa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 9,
      "start_timestamp": "0:06:32",
      "end_timestamp": "0:07:27"
    }
  },
  {
    "page_content": "để phục vụ chuẩn hóa learning rate Chuẩn hóa Learning Rate, tức là thành phần nào của radian này mà lớn thì cái alpha của nó sẽ nhỏ và thành phần nào mà của radian này mà nhỏ thì cái alpha của mình nó sẽ lớn Đó, thì cái cách làm của chúng ta là như vậy R này nó là một cái vector, chúng ta thấy là R được in đậm, nó là một cái vector thì khi alpha chia cho căn của một vector thì nó sẽ biến thành một vector thì chút nữa chúng ta sẽ ghi rõ hơn cái công thức của nó Đây là hệ số tỷ lệ tùy chỉnh, tức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 10,
      "start_timestamp": "0:07:23",
      "end_timestamp": "0:08:07"
    }
  },
  {
    "page_content": "thức của nó Đây là hệ số tỷ lệ tùy chỉnh, tức là Adaptive Scaling Factor Với mỗi thành phần của G, chúng ta sẽ có một cái alpha riêng Tại sao nó là như vậy? Tại sao alpha chỉ có một cái giá trị scalar là một giá trị? Tại sao khi chia cho căn R nó lại biến thành hệ số tùy chỉnh? Chút nữa chúng ta sẽ chứng minh chi tiết hơn Mỗi tham số sẽ có một cái hệ số tỷ lệ khác nhau và ở đây chúng ta sẽ thấy là nó có một cái thành phần hơi lạ đó là epsilon là bằng một cái con số rất là bé thì ở đây đó là để",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 11,
      "start_timestamp": "0:08:01",
      "end_timestamp": "0:09:02"
    }
  },
  {
    "page_content": "bằng một cái con số rất là bé thì ở đây đó là để chống cho cái việc là có một cái thành phần r nào đó mà bằng 0 có một cái thành phần trong r nào đó mà bằng 0 thì khi đó chúng ta sẽ bị cái lỗi là division by zero chia cho xuống 0 thì chúng ta sẽ cộng thêm epsilon để chống cái hiện tượng đó Và phép toán mà r chia cho căn của epsilon cộng r được thực hiện trên từng phần tử Bây giờ chúng ta sẽ cùng xem xét Giả sử như g là bằng 2 thành phần là g1 và g2 Rồi, khi đó g-r là phép tích Hadamard trên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 12,
      "start_timestamp": "0:08:51",
      "end_timestamp": "0:09:44"
    }
  },
  {
    "page_content": "và g2 Rồi, khi đó g-r là phép tích Hadamard trên từng phần tử d-r-g là g1 bình phương, g2 bình phương sau đó nó sẽ được cộng với thành phần chuẩn hóa ở phía quá khứ đây là beta của quá khứ, tức là 90% thành phần r chuẩn hóa R là thành phần để chúng ta chuẩn hóa learning rate theo kiểu đạo hàm thành phần nào mà càng nhỏ thì learning rate sẽ càng nhỏ Trong công thức thành phần chuẩn hóa này chúng ta sẽ chia cho cái căn, thế thì tại sao nó lại có cái căn Nếu chúng ta lại bỏ đi thành phần epsilon",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 13,
      "start_timestamp": "0:09:40",
      "end_timestamp": "0:10:29"
    }
  },
  {
    "page_content": "cái căn Nếu chúng ta lại bỏ đi thành phần epsilon đây để cho nó dễ hình dung epsilon này chỉ mang tính chất đó là chống cái việc chia cho 0 thôi còn nó sẽ không có nhiều ý nghĩa lắm trong việc chuẩn hóa thì khi chúng ta lấy alpha mà chia cho căn của epsilon cộng cho r thì nó sẽ xấp xỉ tại vì có cái epsilon này nên mình mới để cái dấu xấp xỉ đó là alpha chia cho căn của vector g1 bình g2 bình cộng cho thành phần quá khứ nhưng tại thời điểm ban đầu chúng ta thấy là r bằng 0 nên xem như chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 14,
      "start_timestamp": "0:10:24",
      "end_timestamp": "0:11:14"
    }
  },
  {
    "page_content": "chúng ta thấy là r bằng 0 nên xem như chúng ta tạm bỏ qua thành phần này để chúng ta dễ hình dung khái niệm của việc chuẩn hóa này là gì thì là g1 bình phương và g2 bình phương Thì ở đây là chúng ta thực hiện phép căn là phép căn trên ElementWise do đó nó sẽ là căn của các thành phần bên trong như vậy thì nó sẽ là trị tuyệt đối của G1 và trị tuyệt đối của G2 Rồi, và vì đây là cái phép chia trên phép áp dụng trên từng phần tử do đó thì cái này nó sẽ là bằng một cái vector trong đó alpha chia cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 15,
      "start_timestamp": "0:11:10",
      "end_timestamp": "0:11:57"
    }
  },
  {
    "page_content": "sẽ là bằng một cái vector trong đó alpha chia cho trị tuyệt đối của G1 và α chia cho trị tuyệt đối của G2 như vậy thì chúng ta nhìn lại nếu như G1 của chúng ta mà lớn nếu G1 mà lớn thì khi đó α chia cho G1 đó chính là tương ứng cái α1 của mình đề cập trong slide trước thì α1 là bằng α chia cho trị tuyệt đối G1 G1 lớn thì trị tuyệt đối của G1 sẽ lớn và 1 phần trị tuyệt đối của G1 sẽ nhỏ do đó thằng này sẽ là nhỏ Ngược lại, nếu như G2 mà nhỏ thì khi đó là 1 phần trị tuyệt đối của G2 sẽ lớn do đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 16,
      "start_timestamp": "0:11:51",
      "end_timestamp": "0:12:53"
    }
  },
  {
    "page_content": "đó là 1 phần trị tuyệt đối của G2 sẽ lớn do đó thành phần này sẽ lớn như vậy là nó đáp ứng được yêu cầu mà chúng ta đã thiết kế ban đầu thành phần gradient nào mà lớn thì learning rate sẽ nhỏ và ngược lại Thì khi đó, đây chính là thành phần chấp chơi cho chúng ta chuẩn hóa Thì khi đó cái công thức V này của mình sẽ biến thành là V là bằng alpha 1, tức là alpha chia cho trị tuyệt đối của G1 nhân với lại G1 Thành phần thứ 2 sẽ là alpha chia cho trị tuyệt đối của G2 Ngoài việc chia chuẩn hóa này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 17,
      "start_timestamp": "0:12:45",
      "end_timestamp": "0:13:40"
    }
  },
  {
    "page_content": "tuyệt đối của G2 Ngoài việc chia chuẩn hóa này sẽ khiến cho 2 thành phần gradient cân bằng hơn Đây là ý tưởng để giúp chúng ta thoát ra khỏi vấn đề thiên lệch thì chúng ta xét trong hình ở bên tay phải ở đây chúng ta thấy là tại vị trí A thì nó bị thiên lệch về hướng theta 1 nhưng mà nhờ có cái thành phần alpha 1 và alpha 2 được chuẩn hóa ở đây đây là alpha 1, đây là alpha 2 thì khi đó Khi đó, vector tổng hợp của mình thay vì nó bị lệch về phía này thì nó sẽ đi đều hơn. Và khi đó thì chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 18,
      "start_timestamp": "0:13:34",
      "end_timestamp": "0:14:03"
    }
  },
  {
    "page_content": "này thì nó sẽ đi đều hơn. Và khi đó thì chúng ta sẽ vẽ lại. Thay vì nó bật qua phải, rồi lại bật qua trái theo một cái góc rất là gắt như thế này, thì nó sẽ bật qua một cái góc là 4,5 độ. Rồi, qua đây nó sẽ bật một cái góc 4,5 độ. Rồi, qua đây nó sẽ bật một cái góc 4,5 độ. Thì chúng ta thấy là chỉ số bước mà nó di chuyển ít hơn nhiều so với đường màu đỏ này. Thì cái đường màu xanh lá đã giúp chúng ta giảm bớt những cái hiện tượng bật qua bật lại. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VK2w0CO8t1M",
      "filename": "VK2w0CO8t1M",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 6)",
      "chunk_id": 20,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Tiếp theo chúng ta sẽ cùng ôn tập toán giải tích nếu như đại số tuyến tính là công cụ để giúp chúng ta có thể biến đổi dữ liệu thì giải tích là cung cấp cho chúng ta một cái công cụ để biểu diễn các cái chuỗi, các phép biến đổi và đồng thời đó là một cái công cụ để giúp chúng ta giải quyết các cái bài toán tối ưu và đặc biệt trong cái môn này của chúng ta, đó là máy học nâng cao chúng ta sẽ dựa trên các cái mô hình dựa Gradient tức là dùng vector đạo hàm để mà chúng ta đi cập nhật tham số và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:54"
    }
  },
  {
    "page_content": "đạo hàm để mà chúng ta đi cập nhật tham số và huấn luyện mô hình khi đó là chúng ta sẽ có một cái công cụ nữa đó chính là đạo hàm và đạo hàm thì ban đầu sẽ giúp chúng ta khảo sát cái hàm số rồi sau đó sẽ giúp chúng ta tìm được các cái điểm cực tiểu hoặc là cực đại thì chi tiết những cái kiến thức nào của toán giải tích sẽ được tìm hiểu trong những phần tiếp theo đầu tiên chúng ta sẽ có cái khái niệm hàm hợp hàm thì dễ rồi, đó là một sự ánh xạ từ x sang cái fx nhưng mà khi chúng ta muốn làm với",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 1,
      "start_timestamp": "0:00:47",
      "end_timestamp": "0:01:42"
    }
  },
  {
    "page_content": "x sang cái fx nhưng mà khi chúng ta muốn làm với những cái hàm phức tạp hơn trong đó có nhiều phép biến đổi nối tiếp nhau thì chúng ta sẽ dùng cái khái niệm gọi là hàm hợp và ký hiệu đó là y sẽ là bằng g, chọn f trong đó f và g là hai cái hàm thành phần, còn y sẽ là một cái hàm hợp của hai cái hàm thành phần đó là f và g thì khi đó là chúng ta ký hiệu như thế này, hoặc ghi dạng liên tục thì là như thế này là y bằng g của fx tức là fx chúng ta tính xong, chúng ta sẽ làm cái đầu vào cho hàm g và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 2,
      "start_timestamp": "0:01:39",
      "end_timestamp": "0:02:22"
    }
  },
  {
    "page_content": "xong, chúng ta sẽ làm cái đầu vào cho hàm g và đây là một số cái ví dụ về hàm hợp ví dụ như fx là bằng x bình phương cộng một, gx là bằng sin x thì khi đó là hàm hợp sẽ là của g và f sẽ là bằng sin của x bình cộng một tương tự như vậy, chúng ta sẽ có các bài tập để chúng ta ôn lại kiến thức về hàm hợp khái niệm tiếp theo và cực kỳ quan trọng đó chính là đạo hàm thì đạo hàm của mình trong giải tích là một công cụ để giúp chúng ta biết đó là sự biến thiên của hàm số tại một cái điểm nào đó là một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 3,
      "start_timestamp": "0:02:18",
      "end_timestamp": "0:03:11"
    }
  },
  {
    "page_content": "thiên của hàm số tại một cái điểm nào đó là một công cụ để mô tả sự biến thiên của hàm tại một cái điểm nào đó ví dụ như trong cái hàm này chúng ta thấy là hàm y bằng fx thì tại vị trí x0 chúng ta thấy là cái hàm của mình, cái độ dốc của mình là nó đang hướng lên, tức là nó đang đồng biến thế thì đây là một công cụ để giúp chúng ta biết trạng thái của hàm tại vị trí x0 là nó đang đi lên hay đi xuống, hoặc là đi ngang ví dụ như tại cái vị trí này, chúng ta thấy là nó đang đi ngang tóm lại đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 4,
      "start_timestamp": "0:03:06",
      "end_timestamp": "0:03:52"
    }
  },
  {
    "page_content": "chúng ta thấy là nó đang đi ngang tóm lại đó là một công cụ để mô tả sự biến thiên và nó ý nghĩa là hệ số góc hay là độ dốc của cái hàm tại cái vị trí đó và nhờ có đạo hàm thì giúp chúng ta khảo sát và tìm ra được các cái điểm cực tiểu ví dụ như là điểm ở đây, hoặc là các cái điểm cực đại thì đây là một cái công cụ rất là hữu hiệu để giúp chúng ta có thể tối ưu hóa một cái hàm số phức tạp và chúng ta sẽ có cái khái niệm đó là hàm đơn biến thì ở đây là một cái ví dụ về hàm đơn biến trong đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 5,
      "start_timestamp": "0:03:47",
      "end_timestamp": "0:04:28"
    }
  },
  {
    "page_content": "đây là một cái ví dụ về hàm đơn biến trong đó là chúng ta sẽ có một cái hàm F như thế này và khi chúng ta khảo sát cái hàm số này thì chúng ta sẽ thấy là có một cái điểm x để cho cái đạo hàm của mình bằng 0 ví dụ như trong trường hợp này là x bằng 1 thì đạo hàm của mình sẽ là bằng 0 và nó sẽ là khi thế vô cái F phải thì tại đây là bằng 0 và bên trái sẽ là dấu âm và bên phải là dấu dương thì khi chúng ta khảo sát cái hướng di chuyển thì nó sẽ đi xuống và đi lên thì từ cái sự khảo sát này, nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 6,
      "start_timestamp": "0:04:26",
      "end_timestamp": "0:05:12"
    }
  },
  {
    "page_content": "xuống và đi lên thì từ cái sự khảo sát này, nó sẽ giúp chúng ta xác định được là hàm của mình sẽ đạt được cái giá trị cực tiểu khi nó đi qua cái điểm x bằng 1 tại vị trí này là đạo hàm của mình bằng 0 thì đây là một cái ví dụ để minh họa cho cái việc là dùng đạo hàm để khảo sát hàm số và sẽ giúp chúng ta xác định được cái vị trí có cái điểm tối ưu cực tiểu hoặc là tối ưu cực đại thì đây là một cái ví dụ với cái đạo hàm F phải của mình là bằng của cái hàm này thì F phải của mình sẽ là bằng x trừ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 7,
      "start_timestamp": "0:05:04",
      "end_timestamp": "0:05:47"
    }
  },
  {
    "page_content": "cái hàm này thì F phải của mình sẽ là bằng x trừ 1 và khi chúng ta giải ra được thì tương đương là x bằng 1 x bằng 1, tức là cái giá trị ở đây rồi tiếp theo đó là đạo hàm của hàm hợp vừa rồi là đạo hàm của một cái hàm đơn biến còn đối với hàm hợp thì chúng ta sẽ có cái sự phối hợp của nhiều hàm nối tiếp nhau và để giải được, giải quyết được cái vấn đề này thì chúng ta sẽ có các cái đạo hàm công thức của đạo hàm hàm hợp như sau đối với cái trường hợp mà Fx và x là một cái biến số tức là hàm bình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 8,
      "start_timestamp": "0:05:44",
      "end_timestamp": "0:06:24"
    }
  },
  {
    "page_content": "hợp mà Fx và x là một cái biến số tức là hàm bình thường của mình thì đạo hàm của một cái hàm bậc một nó sẽ là như thế này, đạo hàm cũng là hàm đa thức rồi đạo hàm có hàm căn, hàm sin, cos, tan, v.v. còn bên phải đó là cái đạo hàm của một cái hàm số mà dạng hàm hợp, ví dụ như k nhân với u trong đó u là một cái hàm hợp của x theo x, thì khi đó là nó sẽ là bằng k nhân u phải rồi sin của u u của hợp đạo hàm của nó sẽ là bằng cos u sau đó nhân cho đạo hàm của u phải tính theo biến x lưu ý u ở đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 9,
      "start_timestamp": "0:06:21",
      "end_timestamp": "0:06:59"
    }
  },
  {
    "page_content": "đạo hàm của u phải tính theo biến x lưu ý u ở đây là một cái hàm phụ thuộc của biến x thì đạo hàm của cái hàm này theo biến x thì nó sẽ là bằng cos u nhân với lại u, u', đạo hàm của u phải x thì đây là cái bảng tra và phục vụ cho chúng ta rất là hiệu quả trong cái việc là tính đạo hàm của hàm hợp và cái công thức này thì có thể là được áp dụng để thử nghiệm và chúng ta có thể làm bài tập để ôn tập với các cái hàm sau thì đây có những cái hàm từ dạng đơn giản như là đa thức cho đến những cái hàm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 10,
      "start_timestamp": "0:06:56",
      "end_timestamp": "0:07:45"
    }
  },
  {
    "page_content": "đơn giản như là đa thức cho đến những cái hàm phức tạp hơn thì chúng ta sẽ dựa vào cái bảng tra này để mà chúng ta có thể tính được đạo hàm của các cái hàm hợp phức tạp này rồi, và sau đó thì chúng ta sẽ cùng tìm hiểu về cái khái niệm đạo hàm của hàm riêng tức là trong trường hợp cái hàm f của mình nó không phải phụ thuộc một biến x, mà nó phụ thuộc vào cả biến y biến z, ví dụ vậy, nhiều biến thì khi đó chúng ta sẽ có cái khái niệm là đạo hàm của f theo biến x đạo hàm của f theo biến y và đạo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 11,
      "start_timestamp": "0:07:42",
      "end_timestamp": "0:08:21"
    }
  },
  {
    "page_content": "f theo biến x đạo hàm của f theo biến y và đạo hàm của f theo biến z tức là chúng ta sẽ tính trên từng cái biến thành phần để xem xét sự phụ thuộc của hàm số theo các cái biến số một cách độc lập tức là chúng ta sẽ xem cho x, f biến thiên như thế nào theo một biến x f biến thiên như thế nào, theo một biến y f biến thiên như thế nào, theo một biến z và đây là cái công thức đạo hàm riêng bậc 1 thì nhờ có cái đạo hàm riêng bậc 1 này thì chúng ta có thể tính toán được cho các cái nguyên hàm tuy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 12,
      "start_timestamp": "0:08:18",
      "end_timestamp": "0:09:03"
    }
  },
  {
    "page_content": "có thể tính toán được cho các cái nguyên hàm tuy nhiên trong cái phạm vi của môn này là chúng ta sẽ không sử dụng nhiều đến các cái tích phân hoặc là nguyên hàm đó có chăng là trong cái phần của mô hình diffusion thì chúng ta phải nhắc lại cái khái niệm tích phân một chút xíu nhưng mà ở góc độ là lập trình thì chúng ta sẽ không cần dùng đến tích phân mà chúng ta dùng nhiều đến cái hàm tính tổng trên những cái dải giá trị cái miền giá trị thì ở đây chúng ta sẽ có một cái ví dụ hàm fxi là một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 13,
      "start_timestamp": "0:09:00",
      "end_timestamp": "0:09:53"
    }
  },
  {
    "page_content": "chúng ta sẽ có một cái ví dụ hàm fxi là một cái hàm như thế này và chúng ta sẽ đi tính đạo hàm của fxi này theo x thì nó sẽ là bằng 4x và đạo hàm của f theo y thì nó sẽ là bằng trừ 3 cuối cùng đó là chúng ta sẽ cùng tìm hiểu đến cái khái niệm gradient toàn bộ môn này thì đều dựa trên gradient để chúng ta xây dựng mô hình nó gọi là mô hình dựa trên gradient tức là các cái mô hình này đều sử dụng gradient như là một cái công cụ để cho chúng ta tối ưu hóa và huấn luyện mô hình vậy thì khái niệm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 14,
      "start_timestamp": "0:09:50",
      "end_timestamp": "0:10:35"
    }
  },
  {
    "page_content": "ưu hóa và huấn luyện mô hình vậy thì khái niệm gradient là gì? từ một cái không gian vector n chiều về một cái giá trị scalar là r là số thực thì gradient là cái vector n phần tử nó là một cái vector n phần tử bao gồm các cái đạo hàm riêng của nó ví dụ f của mình là một cái hàm theo một cái tham số theta là một cái theta trong đó theta là thuộc r thì khi đó gradient của f theo theta nó sẽ là bằng một cái vector gồm đạo hàm của f theo biến theta 1... đạo hàm của f theo theta đạo hàm của f theo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 15,
      "start_timestamp": "0:10:32",
      "end_timestamp": "0:11:29"
    }
  },
  {
    "page_content": "1... đạo hàm của f theo theta đạo hàm của f theo theta n thì trong các cái mô hình máy học thì chúng ta xây dựng là cái tham số theta nhưng mà để sử dụng cái mô hình máy học thì chúng ta sẽ dùng biến f và biến x ở đây thì ở đây chúng ta sẽ có một cái ví dụ là fxi là bằng cái gì? hàm như đã cho trên thì gradient của f theo x thì nó sẽ là bằng một cái vector của hàm f đạo hàm của f theo biến x và đạo hàm của f theo biến y và đạo hàm của f theo biến y thì đạo hàm của x theo y sẽ là bằng 5y trừ cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 16,
      "start_timestamp": "0:11:26",
      "end_timestamp": "0:12:22"
    }
  },
  {
    "page_content": "y thì đạo hàm của x theo y sẽ là bằng 5y trừ cho 14x còn đây là hằng số đối với x nên nó sẽ bỏ đi, cộng 3 còn đạo hàm của f theo y thì sẽ là bằng 5x đối với y thì đây là hằng số do đó chúng ta sẽ là đạo hàm bằng 0 trừ cho 2y và trừ 6 và đạo hàm của x theo y sẽ là bằng 5y trừ cho 2y và trừ 6 thì đây chính là vector gradient theo biến x và y đây là x và y rồi thì đây là kết quả của mình và các mô hình học sâu của chúng ta thì đều dựa trên lý thuyết hoặc dựa trên ký hiệu của gradient mục tiêu của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 17,
      "start_timestamp": "0:12:19",
      "end_timestamp": "0:12:22"
    }
  },
  {
    "page_content": "hoặc dựa trên ký hiệu của gradient mục tiêu của gradient là xác định xem từng thành phần vector của mình từng thành phần x1, x2 cho đến xn nó ảnh hưởng như thế nào lên trên sự tăng giảm của hàm số và khi chúng ta xác định được sự ảnh hưởng đó rồi thì chúng ta sẽ cập nhật lại x1, x2, xn sau cho f của mình tiến về giá trị cực tiểu hoặc giá trị cực đại và tăng giảm của gradient trong mô hình này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=Vm18bFk-RsI",
      "filename": "Vm18bFk-RsI",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 3)",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ đưa vào 1 cái Codeprom và kết quả với 2 phương pháp 1 là Classifier Guidance, chúng ta thấy kết quả không tự nhiên lắm Trong khi đó với Classifier Free Guidance, chúng ta sẽ thấy kết quả cho ra rất tự nhiên và đẹp Đây chính là 1 ví dụ của mô hình mà có điều hướng Vì vậy thì trong tương lai thì nó sẽ có rất nhiều những hướng phát triển khác nhau Ví dụ như là cái Y này của mình thì hiện giờ chúng ta đang hiểu nó là 1 Keprom và Keprom này là dạng Text Nhưng mà tương lai thì nó có thể ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VrmJPvNSoqM",
      "filename": "VrmJPvNSoqM",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:09"
    }
  },
  {
    "page_content": "là dạng Text Nhưng mà tương lai thì nó có thể ở những dạng Prom khác, ví dụ như là 1 Point, 1 Điểm Nó có thể là 1 tín hiệu sóng não, FMRI, nó có thể là 1 Mask của 1 đối tượng nào đó mình cần gen ra Keprom này sẽ rất là đa dạng thể thức và người ta cũng đã có những bước đầu nghiên cứu cho việc sử dụng những Condition khác nhau Và kết quả rất là ấn tượng Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=VrmJPvNSoqM",
      "filename": "VrmJPvNSoqM",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:01:03",
      "end_timestamp": "0:01:47"
    }
  },
  {
    "page_content": "Chúng ta đã biết một số thách thức khi thực thi thuật toán Gradient Descent Và một trong những biến thể đầu tiên để giúp chúng ta giải quyết được những thách thức đó chính là biến thể momentum Ý tưởng của momentum đó là đối với những hàm loss mà có nhiều hơn một điểm cực tiểu Đối với những phương pháp mà Gradient Descent trước đây, khi chạy đến vị trí điểm cực tiểu đầu tiên này thì nó sẽ bị dừng lại Nguyên nhân đó là do đạo hàm của mình triệt tiêu là bằng 0 momentum đã vận dụng được kiến thức về",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:57"
    }
  },
  {
    "page_content": "là bằng 0 momentum đã vận dụng được kiến thức về vật lý, đó là kiến thức về mặt động năng, hiệu bằng chữ V V này sẽ tận dụng được những động năng của quá khứ và truyền đến được cho vị trí hiện tại Từ những vị trí này, vị trí này, vị trí này, nó sẽ truyền đến vị trí hiện tại Do đó mặc dù khi chúng ta di chuyển đến vị trí cực tiểu cực tiểu cục bộ thì nó vẫn có thể nhờ động năng của quá khứ Nó sẽ giúp chúng ta nhảy ra và thoát ra khỏi điểm cực tiểu cục bộ này. Đó chính là ý tưởng của biến thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 1,
      "start_timestamp": "0:00:49",
      "end_timestamp": "0:01:39"
    }
  },
  {
    "page_content": "tiểu cục bộ này. Đó chính là ý tưởng của biến thể momentum Trước khi qua chi tiết cho thuật toán momentum, chúng ta sẽ cùng ôn lại thuật toán Gradient Descent Ở bên tay trái là một sơ đồ đầy đủ, bao gồm các bước khởi tạo tham số theta Rồi chúng ta sẽ tính gradient là bằng công thức đạo hàm như thế này Sau khi tính xong thì chúng ta sẽ cập nhật tham số theta new là bằng theta old, tức là theta cũ Trừ cho alpha nhân cho nabla, tức là gradient Thì ở đây chúng ta dùng từ old và new cho dễ hiểu là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 2,
      "start_timestamp": "0:01:31",
      "end_timestamp": "0:02:24"
    }
  },
  {
    "page_content": "ở đây chúng ta dùng từ old và new cho dễ hiểu là cũ và mới Còn thực tế khi lập trình thì chúng ta có thể bỏ qua hai chữ old và new này Theta là bằng theta trừ cho alpha nhân cho nabla của J theta Công thức này thì nó sẽ hơi bị dài dòng Do đó những phần sau để tiết kiệm không gian và chúng ta sẽ tập trung vào đối tượng chính của chúng ta là công thức cập nhật tham số Thì chúng ta sẽ viết gọn lại theo dạng là lặp cho đến khi hội tụ Và công thức lặp của chúng ta là theta là bằng theta trừ cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 3,
      "start_timestamp": "0:02:18",
      "end_timestamp": "0:03:02"
    }
  },
  {
    "page_content": "lặp của chúng ta là theta là bằng theta trừ cho alpha nhân cho nabla Và chúng ta sẽ dựa trên công thức này để phát triển tiếp Thế thì đầu tiên chúng ta sẽ nói về vấn đề của các phương pháp trước đây Vấn đề thứ nhất là làm sao để chúng ta có thể chọn ra được một cái learning rate tốt Cụ thể là trong công thức của chúng ta nếu như alpha learning rate này nhỏ Thì tốc độ hội tụ của chúng ta sẽ rất chậm Ví dụ như chúng ta có một cái điểm khởi tạo ở đây Thì alpha mà nhỏ quá thì nó sẽ cứ đi từng cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 4,
      "start_timestamp": "0:02:54",
      "end_timestamp": "0:03:46"
    }
  },
  {
    "page_content": "đây Thì alpha mà nhỏ quá thì nó sẽ cứ đi từng cái bước nhỏ như thế này Và rất lâu nó mới có thể đến được cái điểm cực tiểu cục bộ ở đây Mặt khác nếu như cái alpha của mình mà quá lớn Thì ví dụ như chúng ta có cái hàm loss ở đây Thì khi alpha quá lớn nó có thể khiến cho chúng ta Thay vì chúng ta đi từng bước nhỏ như thế này thì nó bị vượt qua cái điểm cực tiểu cục bộ ở đây Và cái việc này thì nó sẽ bật qua bật lại và dần dần nó sẽ bị phân kỳ Nó thoát ra khỏi cái điểm tối ưu của mình Thì đó chính",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 5,
      "start_timestamp": "0:03:42",
      "end_timestamp": "0:04:18"
    }
  },
  {
    "page_content": "ra khỏi cái điểm tối ưu của mình Thì đó chính là cái vấn đề đầu tiên Như vậy thì cái learning rate của chúng ta làm sao nó cần phải được điều chỉnh giảm dần hay còn gọi là dampening Tại vì khi chúng ta điều chỉnh giảm dần thì giả sử như ban đầu chúng ta chọn mà không tốt Cái alpha của mình nó lớn quá Nhưng mà ở những cái vòng lặp tiếp theo thì alpha của mình nó sẽ được giảm dần với một cái hệ số nào đó Thì từ từ nó cũng sẽ giúp cho chúng ta hội tụ được đến cái điểm cực tiểu của mình Như vậy thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 6,
      "start_timestamp": "0:04:16",
      "end_timestamp": "0:04:58"
    }
  },
  {
    "page_content": "được đến cái điểm cực tiểu của mình Như vậy thì với cái vấn đề số 1 thì chúng ta sẽ có cái giải pháp số 1 Đó là alpha ban đầu thì chúng ta sẽ khởi tạo là bằng dù như là một con số là 0.5 là một con số khá là lớn Và công thức của chúng ta sẽ là lặp cho những cái hệ số hội tụ Thì ở đây alpha sẽ là bằng delta nhân cho alpha Trong đó delta là một cái hệ số mà nhỏ hơn 1 Delta là dampening factor là từ 0 cho đến 1 Thì điều gì xảy ra nếu như delta của chúng ta là bằng 0 Thì nếu như delta là bằng 0 thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 7,
      "start_timestamp": "0:04:53",
      "end_timestamp": "0:05:36"
    }
  },
  {
    "page_content": "ta là bằng 0 Thì nếu như delta là bằng 0 thì có nghĩa là chúng ta đã triệt tiêu luôn cái alpha này Và lúc này nó sẽ là bằng 0 và dẫn đến nguyên cái vế này là bằng 0 Thì khi delta là bằng 0 thì mô hình của mình sẽ không có cập nhật trọng số Còn ngược lại nếu như delta là bằng 1 Delta là bằng 1 tức là alpha là bằng alpha Thì cái hệ số dampening này gần như là không có tác dụng tức là alpha giữ nguyên Mà nếu ban đầu chúng ta chọn alpha là một con số quá lớn thì nó có thể sẽ khiến chúng ta không",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 8,
      "start_timestamp": "0:05:32",
      "end_timestamp": "0:06:17"
    }
  },
  {
    "page_content": "số quá lớn thì nó có thể sẽ khiến chúng ta không hội tụ Nó sẽ khiến chúng ta không hội tụ và thậm chí là nó bị phân kỳ Thì đây là cái cải tiến đầu tiên của cái momentum Tiếp theo thì để thuận tiện cho việc các cải tiến thì chúng ta sẽ đặt một cái tên biến mới Nó gọi là biến vận tốc Thế thì đây là cái công thức cập nhật đạo hàm, cập nhật cái tham số của chúng ta theo cách cũ Thì chúng ta sẽ dùng cái alpha của nabla là bằng một cái biến là v, là vận tốc Thì khi đó chúng ta sẽ đưa, chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 9,
      "start_timestamp": "0:06:09",
      "end_timestamp": "0:06:56"
    }
  },
  {
    "page_content": "vận tốc Thì khi đó chúng ta sẽ đưa, chúng ta sẽ viết lại cái công thức bên tay trái Cái mà dải bên tay trái về cái dạng đó là v là bằng alpha nhân cho nabla của loss J theta Thì khi đó là theta sẽ là bằng theta trừ cho vận tốc Thì ở đây là cái đại lượng mà chúng ta sẽ cập nhật Vậy thì cái biến thể tiếp theo nó sẽ dựa trên một cái vấn đề số 2 Đó là cái tốc độ hội tụ nó sẽ chậm hoặc là nó sẽ bị mắc kẹt tại các cái điểm cực tiểu cục bộ Thì cái này chúng ta đã nói ở trong cái phần giới thiệu của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 10,
      "start_timestamp": "0:06:50",
      "end_timestamp": "0:07:35"
    }
  },
  {
    "page_content": "chúng ta đã nói ở trong cái phần giới thiệu của momentum Nếu như chúng ta có hai cái điểm cực tiểu cục bộ hoặc thậm chí là nhiều hơn rất là nhiều Thì tại cái vị trí khởi tạo ở đây thì nó sẽ, cái đạo hàm của mình, cái độ dốc của mình nó rất là lớn Do đó thì nó sẽ di chuyển rất là nhanh Nhưng khi di chuyển đến cái vị trí mà gần với lại cái điểm cực tiểu cục bộ ở đây Thì cái độ dốc của mình nó gần như là song song với trục hoành, tức là nó sẽ gần như bằng không Thì khi đó đạo hàm của mình là bằng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 11,
      "start_timestamp": "0:07:28",
      "end_timestamp": "0:08:15"
    }
  },
  {
    "page_content": "bằng không Thì khi đó đạo hàm của mình là bằng không Mà nếu như vậy thì cái công thức cập nhật này của chúng ta nó sẽ là bằng không Và theta sẽ không được cập nhật Như vậy thì chúng ta sẽ làm sao để mà có thể thoát ra khỏi những cái điểm cực tiểu cục bộ này Bằng cách đó là sử dụng cái khái niệm momentum Momentum sẽ là một cái công thức dạng như là đệ quy Nó sẽ được tính dựa trên cái thông tin vận tốc hoặc là cái động năng hoặc là cái năng lượng trong quá khứ Để mà truyền đến cái vị trí hiện tại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 12,
      "start_timestamp": "0:08:04",
      "end_timestamp": "0:08:52"
    }
  },
  {
    "page_content": "quá khứ Để mà truyền đến cái vị trí hiện tại V này nó sẽ có xu hướng giảm dần qua mỗi bước là do khi chúng ta càng tiến cái đạo hàm này thì nó sẽ bị bằng không Như vậy thì chúng ta sẽ sử dụng cái khái niệm momentum trong vật lý Thì cái momentum này nó sẽ được tính như thế nào Công thức của chúng ta đó là V là bằng beta nhân cho V cộng cho cái thành phần đạo hàm Thì đây chính là cái thành phần động năng của quá khứ Và ở đây nó sẽ xuất hiện thêm một cái hệ số siêu tham số, một cái siêu tham số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 13,
      "start_timestamp": "0:08:48",
      "end_timestamp": "0:09:34"
    }
  },
  {
    "page_content": "một cái hệ số siêu tham số, một cái siêu tham số mới đó là beta Thì thông thường beta ở đây là bằng 0.9 Thì điều này có nghĩa là gì? V sẽ là bằng 90% của V quá khứ Tức là nó đang tận dụng cái động năng của quá khứ Sau đó nó sẽ cộng cho cái alpha của nabla ở đây Thì đây chính là cái thế năng hiện tại Cộng thêm cho beta V, tức là cái động năng của quá khứ Thì đây chính là cái beta của mình, nó sẽ gọi là momentum factor Và thường nó là một cái con số từ 0 cho đến 1 Vậy thì điều gì xảy ra khi beta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 14,
      "start_timestamp": "0:09:32",
      "end_timestamp": "0:10:13"
    }
  },
  {
    "page_content": "số từ 0 cho đến 1 Vậy thì điều gì xảy ra khi beta bằng 0 Khi beta bằng 0, tức là nó gần như chính là cái công thức bên đây Khi beta bằng 0, tức là 0 nhân V bằng 0 Tức là không có thành phần này Thì nó sẽ chuyển về cái công thức bên đây Còn ngược lại nếu mà beta mà bằng 1 thì sao? Nếu beta bằng 1, tức là V sẽ là bằng V cộng cho cái đạo hàm Thế thì nếu như vậy thì cái V này nó sẽ tăng rất là nhanh Tại vì nó là một cái cấp số nhân, nó cứ cộng liên tục Thế thì chúng ta nên chọn một cái beta là một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 15,
      "start_timestamp": "0:10:10",
      "end_timestamp": "0:10:58"
    }
  },
  {
    "page_content": "tục Thế thì chúng ta nên chọn một cái beta là một cái con số trung dung ở giữa Và thường nó là con số khoảng 0.9 để tiết kiệm Nhưng nó cũng không nên quá lớn Nếu nó quá lớn thì nó sẽ cộng dồn Và dẫn đến đó là nó sẽ bùng nổ cái gradient Dẫn đến là nó sẽ không có hội tụ được Vậy thì ở trong cái hình, cái slide ở đây chúng ta sẽ có một cái visualize Một cái trực quan hóa cho cái momentum Với cái giải pháp đầy đủ của chúng ta Đó là alpha ban đầu sẽ được gắn là bằng 0.5 là một con số đủ lớn Và ở đây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 16,
      "start_timestamp": "0:10:55",
      "end_timestamp": "0:11:38"
    }
  },
  {
    "page_content": "gắn là bằng 0.5 là một con số đủ lớn Và ở đây thì chúng ta sẽ có cái dampening alpha Tức là chúng ta sẽ giảm cái alpha sau các cái vòng lặp Và V là cái vận tốc ban đầu chúng ta sẽ khởi tạo là bằng 0 Và đạo hàm là bằng 0 Và delta là cái hệ số dampening Cứ mỗi lần thì alpha sẽ giảm 10 lần Nó sẽ chia cho 10, tức là nhân 0.1, tức là chia 10 Beta là bằng 0.9 thì có nghĩa là cái vận tốc hiện tại bằng 90% vận tốc của quá khứ Cộng cho cái alpha của nabla, tức là cái thế năng hiện tại được tính từ đạo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 17,
      "start_timestamp": "0:11:32",
      "end_timestamp": "0:12:24"
    }
  },
  {
    "page_content": "tức là cái thế năng hiện tại được tính từ đạo hàm Thế thì khi chúng ta sử dụng cái giải pháp đầy đủ này Thì chúng ta sẽ thấy là cái 3 điểm màu đỏ ban đầu chúng ta sẽ rớt xuống Rớt rất là nhanh đến cái vị trí này Rớt qua đây Rớt qua đây Và nhờ có cái động năng của quá khứ đã giúp chúng ta leo lên được cái ngọn đồi này Để từ đó giúp chúng ta có thể thoát ra khỏi được cái điểm cực tiểu cục bộ Để đến một cái khu vực khác và hy vọng rằng nó sẽ có được cái điểm cực tiểu tốt hơn Đây là một cái điểm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 18,
      "start_timestamp": "0:12:18",
      "end_timestamp": "0:13:12"
    }
  },
  {
    "page_content": "cái điểm cực tiểu tốt hơn Đây là một cái điểm cực tiểu mới Thì ở đây nó đã giúp cho chúng ta thoát ra được khỏi cái điểm cực tiểu cục bộ Và ở đây chúng ta sẽ có một cái ví dụ để tính toán trực tiếp với các con số Giả sử như momentum của chúng ta, cái hệ số momentum của chúng ta là bằng 0.9 Thì khi đó ba cái bước cập nhật đầu tiên của chúng ta sẽ có cái cách tính như sau Ở cái vòng lặp đầu tiên thì là vì V0 của mình là ban đầu là bằng 0 Thì không nhân với bao nhiêu? Không nhân với lại beta là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 19,
      "start_timestamp": "0:13:04",
      "end_timestamp": "0:14:02"
    }
  },
  {
    "page_content": "nhân với bao nhiêu? Không nhân với lại beta là cũng bằng 0 Do đó thì cái V1 chỉ có chứa cái thế năng tại cái thời điểm đầu tiên Tức là cái đạo hàm tại cái vị trí này Tức là tại đây là chúng ta có V1 Rồi tại cái vị trí tiếp theo thì là chúng ta sẽ cập nhật lại cái V2 là bằng beta của cái V1 Tức là 0.9 của V1 Cộng cho cái thế năng mới, ví dụ như chúng ta tại đây chúng ta có cái đạo hàm mới thì chúng ta sẽ tính vào đây Và sau cái vòng lặp số 3 đến cái vòng lặp thứ 3 thì V3 sẽ là bằng 0.9 của V2",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 20,
      "start_timestamp": "0:13:54",
      "end_timestamp": "0:14:44"
    }
  },
  {
    "page_content": "cái vòng lặp thứ 3 thì V3 sẽ là bằng 0.9 của V2 0.9 của V2 thì chúng ta sẽ đưa toàn bộ cái biểu thức ở phía trên để chúng ta đem xuống thế vào đây Thì là 0.9 của 0.9G1 cộng G2 rồi cộng cho G3 Thì ở đây nó sẽ là bằng 0.81G1 cộng 0.9G2 cộng G3 Như vậy chúng ta có thể thấy là tại cái thời điểm T bằng 3 thì nó sẽ là bằng 0.81 của cái G đầu tiên Như vậy ban đầu cái hệ số của G1 nó là bằng 1.0 Sang vòng lặp thứ 2 nó rớt xuống còn 0.9 và sang vòng lặp thứ 3 thì nó rớt xuống còn 0.81 Cứ như vậy thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 21,
      "start_timestamp": "0:14:36",
      "end_timestamp": "0:15:14"
    }
  },
  {
    "page_content": "thứ 3 thì nó rớt xuống còn 0.81 Cứ như vậy thì càng về sau cái vai trò của cái G1 này càng lúc càng thấp đi và nó sẽ tiến dần về bằng 0 Và những cái G nào gần với lại cái vị trí T thứ 3 tại cái thời điểm thứ 3 thì cái hệ số của nó càng cao Chúng ta thấy là cái G ngay trước đó là G2 là Gradient 2 thì nó sẽ có hệ số là 0.9 Rồi trước đó nữa sẽ là 0.81 và cứ như vậy thì cái vòng lặp tiếp theo là V4 thì có thể là cái G1 này Nó sẽ tiến về là 0.81 mà nhân với lại 0.9 thì đâu đó nó xấp xỉ là khoảng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 22,
      "start_timestamp": "0:15:10",
      "end_timestamp": "0:15:44"
    }
  },
  {
    "page_content": "nhân với lại 0.9 thì đâu đó nó xấp xỉ là khoảng 0.72 nó lại giảm xuống một nấc nữa Thì khi cập nhật tham số Gradient tại những cái bước mà càng gần thì nó sẽ đóng góp càng nhiều là 0.9 Nó sẽ là 90% ví dụ vậy và 0.81 tức là khoảng 81 Thực ra chúng ta dùng cái từ phần trăm ở đây không có đúng mà V của chúng ta thì nó sẽ có là 0.81 của G1 và 0.9 của G2 và cộng cho 100% của G3 Thì đây là cái động năng của quá khứ để khi mà nó tiến đến cái vị trí cực tiểu cục bộ như thế này thì nhờ có cái động năng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "tiểu cục bộ như thế này thì nhờ có cái động năng quá khứ này Nó sẽ giúp cho chúng ta thoát ra khỏi được cái điểm cực tiểu cục bộ đầu tiên Thì trên đây đó chính là cái minh họa cho cái phiên bản cái cải tiến của Momentum Nó sẽ bao gồm 2 phần thì cái phần đầu tiên liên quan đến dampening cái alpha Nhưng cái phần thứ 2 là quan trọng nhất chính là công thức cập nhật của cái V của chúng ta Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wAAPpfRTckg",
      "filename": "wAAPpfRTckg",
      "title": "[CS315 - Chương 1] Gradient based model - Phần 5 (New)",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ đến với thuật toán backpropagation sau khi chúng ta đã thực hiện được thuật toán lan truyền thuận feedforward rồi Chúng ta sẽ đến với thuật toán lan truyền ngược và vẫn sẽ sử dụng những ví dụ như đã nói ở trước đó là fx, ez sẽ là x, y Về nguyên lý, chúng ta sẽ sử dụng chain rule, tức là quy tắc để tính đạo hàm của hàm hợp Chúng ta sẽ áp dụng chain rule trên đồ thị tính toán và tính tại những giá trị cụ thể, đó là x bằng 3, y bằng trừ 4 và z bằng 5 Bước đầu tiên là đồ thị tính toán,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:01"
    }
  },
  {
    "page_content": "4 và z bằng 5 Bước đầu tiên là đồ thị tính toán, đây là bước số 1 Chúng ta sẽ tạo ra đồ thị tính toán Rồi, thì nó cũng tương tự như trong lan truyền thuận, chúng ta sẽ có các cái node là node cộng và node nhân ở đây và tương ứng đầu ra sẽ là f1 và f2, cái f2 này bản chất nó chính là cái f của mình Sau đó thì chúng ta sẽ chạy cái thuật toán lan truyền thuận Khi chúng ta lan truyền thuận lên thì chúng ta sẽ có cái giá trị f đầu ra chính là bằng trừ 5 Sau đó thì chúng ta sẽ áp dụng cái nguyên tắc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 1,
      "start_timestamp": "0:00:54",
      "end_timestamp": "0:01:41"
    }
  },
  {
    "page_content": "5 Sau đó thì chúng ta sẽ áp dụng cái nguyên tắc của chain rule Thì chúng ta sẽ... cái bước này là bước số 3 ha Bước số 3, còn cái bước số 2 chính là lan truyền thuận Rồi, thì chúng ta áp dụng chain rule trên cái cấu trúc đồ thị tính toán như thế này Đầu tiên, đó là chúng ta sẽ khởi tạo một cái con số 1 Tại vì trong cái nguyên tắc của chain rule thì chúng ta sẽ phải tính các phép nhân rất là nhiều Ví dụ như d của f thứ n, nhân cho d của f thứ n trừ 1 Sau đó d của f n trừ 1, d của d của f n trừ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 2,
      "start_timestamp": "0:01:37",
      "end_timestamp": "0:02:31"
    }
  },
  {
    "page_content": "trừ 1 Sau đó d của f n trừ 1, d của d của f n trừ 2, v.v. Thì chúng ta sẽ phải thực hiện một chuỗi các phép nhân này Do đó khởi tạo nó sẽ là giá trị 1 để có thể nhân, tiếp tục nhân Còn nếu chúng ta khởi tạo bằng 0 thì không nhân với bao nhiêu cũng bằng 0, không được Do đó thì khởi tạo đối với cái phép tích thì chúng ta sẽ sử dụng cái số 1 ở đây Sau đó chúng ta sẽ đi tính đạo hàm của f2 theo f1 Chúng ta sẽ tính đạo hàm của f2 theo f1 Sau đó sẽ nhân với 1, sẽ là như vậy kết quả ở đây Đó là đạo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 3,
      "start_timestamp": "0:02:25",
      "end_timestamp": "0:03:05"
    }
  },
  {
    "page_content": "nhân với 1, sẽ là như vậy kết quả ở đây Đó là đạo hàm của f2 theo f1 Đạo hàm của f2 theo f1 chúng ta đã biết đó là nó chính là bằng z Đạo hàm của f2 theo f1 tức là đạo hàm của cái công thức này Và đạo hàm của cái công thức f2 ở đây đó chính là bằng z Z của chúng ta lúc này nó đang là bằng 5 Do đó chúng ta sẽ lấy cái giá trị này vào và thế vào đây Là 1 nhân với 5 là bằng 5 Sau đó chúng ta sẽ lấy cái công thức này Đạo hàm của f theo x nó sẽ là bằng 1 nhân với đạo hàm của f2 theo f1 dựa trên cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 4,
      "start_timestamp": "0:03:01",
      "end_timestamp": "0:03:56"
    }
  },
  {
    "page_content": "1 nhân với đạo hàm của f2 theo f1 dựa trên cái công thức này Rồi nhân cho đạo hàm của f1 theo x thì đạo hàm của f2 theo f1 chúng ta đã biết nó là bằng z Còn đạo hàm của f1 theo x nó chính là bằng 1 ở đây Đạo hàm của f1 theo x nó sẽ là bằng 1 Như vậy thì nó sẽ là bằng 1 nhân z nhân với lại 1 1 nhân z nhân 1 tức là bằng 5 nhân 1 là bằng 5 Như vậy đạo hàm của f theo x sẽ là bằng 5 Và chúng ta hoàn toàn làm tương tự như vậy cho các biến y và biến z Thì đây là thuật toán để tính sử dụng chain rule",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 5,
      "start_timestamp": "0:03:53",
      "end_timestamp": "0:04:42"
    }
  },
  {
    "page_content": "Thì đây là thuật toán để tính sử dụng chain rule trên cấu trúc đồ thị tính toán Nhưng ở đây thực tế thì sao? Thực tế nếu chúng ta làm như vậy Khi tính đến đạo hàm của f cuối cùng Đạo hàm của f theo x thì nó sẽ có rất nhiều những thao tác tính toán thừa Nó bị lặp lại do đó chúng ta sẽ tránh chain rule Mà chúng ta sẽ trực tiếp kế thừa những cái giá trị đã tính toán ở những bước trước đó để cập nhật cho phía sau Để tiết kiệm chi phí tính toán Không có tính lại Không tính lại những cái thao tác",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 6,
      "start_timestamp": "0:04:36",
      "end_timestamp": "0:05:28"
    }
  },
  {
    "page_content": "có tính lại Không tính lại những cái thao tác thừa Thì tại sao là thừa? Tại vì ở trong quá trình tính toán thì chúng ta sẽ tính đạo hàm của f2 theo f1 Chúng ta đã có cái giá trị ở đây rồi Nhưng mà sang đây chúng ta lại đi tính lại đạo hàm của f2 theo f1 Thì đó là thừa Chúng ta chỉ cần copy cái giá trị từ bên đây qua đây Thì nó sẽ không phải đi tính lại Thì chi tiết cái thuật toán backpropagation Với cái phiên bản đó là chúng ta tránh cái chain rule như thế nào Bước đầu tiên là chúng ta sẽ xây",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 7,
      "start_timestamp": "0:05:26",
      "end_timestamp": "0:06:09"
    }
  },
  {
    "page_content": "rule như thế nào Bước đầu tiên là chúng ta sẽ xây dựng đồ thị tính toán và thực hiện cái thuật toán feedforward Sau khi feedforward xong thì chúng ta sẽ nhận được các cái giá trị tại các cái node Sau đó thì khởi tạo cho cái thuật toán backpropagation Chúng ta sẽ bắt đầu bằng số 1 Sau đó các bước của thuật toán rất đơn giản là như sau Đầu tiên chúng ta sẽ copy cái giá trị đạo hàm ở cái node cha Tức là cái node trước ngay đằng sau đó Kéo về Kéo về đây Sau đó chúng ta sẽ nhân với đạo hàm của cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 8,
      "start_timestamp": "0:06:01",
      "end_timestamp": "0:06:42"
    }
  },
  {
    "page_content": "đây Sau đó chúng ta sẽ nhân với đạo hàm của cái thành phần f2 Chia cho đạo hàm của f1 Tức là lấy cái đạo hàm của cái node phía sau Theo cái đạo hàm của cái node hiện tại Cái node hiện tại của mình chính là f1 Tức là đạo hàm của f2 theo f1 Thì đạo hàm của f2 theo f1 chính là bằng z Z của mình trong trường hợp này là bằng 5 Do đó nó sẽ là bằng 5",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=wus3iZ0TTFk",
      "filename": "wus3iZ0TTFk",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 9)",
      "chunk_id": 9,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với một trong những cái cải tiến đầu tiên của thuật toán Gradient Descent, đó chính là biến thể momentum Momentum có thể nói là một trong những biến thể quan trọng và ý tưởng của nó đã được kế thừa và sử dụng rất nhiều trong các thuật toán optimizer trên các mô hình gradient base Và ý tưởng của momentum là gì? Và tại sao có thể đề xuất ra được cái cải tiến này? Chúng ta sẽ cùng tìm hiểu trong những phần tiếp theo Đầu tiên chúng ta sẽ nhắc lại về thuật toán gradient descent Ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:08"
    }
  },
  {
    "page_content": "ta sẽ nhắc lại về thuật toán gradient descent Ở bên tay trái đó chính là cái thuật toán được biết một cách đầy đủ là khởi tạo tham số, cụ thể đây là theta là bằng một cái random Rồi sau đó chúng ta sẽ đi tính đạo hàm của hàm lỗi theo từng thành phần của theta Sau đó chúng ta sẽ cập nhật lại các cái tham số là theta mới thì sẽ là bằng theta cũ trừ cho alpha nhân cho đạo hàm của hàm lỗi theo theta Và cái bước cập nhật này sẽ được thực hiện đi, thực hiện lại nhiều lần Thế thì để cho gọn chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 1,
      "start_timestamp": "0:00:56",
      "end_timestamp": "0:01:46"
    }
  },
  {
    "page_content": "hiện lại nhiều lần Thế thì để cho gọn chúng ta sẽ lấy cái phần lỗi nhất của cái thuật toán gradient descent, đó chính là cái bước cập nhật tham số này Và chúng ta sẽ lặp cho đến khi nào mà cái theta của mình nó hội tụ, thì cái hội tụ ở đây có nghĩa là nó sẽ không có giảm xuống được nữa Và chúng ta sẽ đến với cái cải tiến đầu tiên của momentum, thì trước khi đến cái cải tiến chúng ta phải nói về cái vấn đề của nó đang gặp là gì Vấn đề số 1 đó là làm sao để một cái learning rate chúng ta có thể",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 2,
      "start_timestamp": "0:01:37",
      "end_timestamp": "0:02:30"
    }
  },
  {
    "page_content": "làm sao để một cái learning rate chúng ta có thể chọn nó một cái learning rate tốt Thì cái vấn đề này xảy ra khi chúng ta quan sát vào cái thuật toán gradient descent, chúng ta thấy cái alpha này đóng vai trò rất là quan trọng trong cái việc hội tụ của mô hình Nếu như alpha của mình mà quá nhỏ thì cái mô hình của mình nó sẽ hội tụ chậm, lấy ví dụ như ở đây là cái hàm loss Và khi mà cái alpha mà quá nhỏ thì nó sẽ nhảy xuống từng cái bước rất là nhỏ, những cái bước dò dẫm rất là nhỏ Và vì nó đi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 3,
      "start_timestamp": "0:02:16",
      "end_timestamp": "0:03:09"
    }
  },
  {
    "page_content": "nhỏ, những cái bước dò dẫm rất là nhỏ Và vì nó đi chậm như vậy nên cái hội tụ nó sẽ chậm Ngược lại nếu alpha mà lớn, thậm chí là rất lớn thì nó có thể nhảy qua bên đây, thoát ra khỏi cái điểm lẽ ra nó phải đến được, nó lại nhảy qua bên đây, xong rồi qua đây Và cứ như vậy là thoát ra khỏi cái điểm tối ưu Vậy thì learning rate cần phải được điều chỉnh giảm dần hay còn gọi là dampening Thế thì tại sao lại như vậy? Nếu như ban đầu chúng ta không biết learning rate là bao nhiêu thì chúng ta sẽ cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 4,
      "start_timestamp": "0:02:52",
      "end_timestamp": "0:03:56"
    }
  },
  {
    "page_content": "learning rate là bao nhiêu thì chúng ta sẽ cho nó một cái giá trị bụi lớn Và có thể chấp nhận là nó sẽ dần dần có thể ban đầu nó sẽ thoát ra khỏi cái điểm cực tiểu Tuy nhiên ở những cái vòng lặp sau nó sẽ giảm dần, nhỏ dần và đến lúc đạt được cái giá trị learning rate mà tối ưu, tức là hội tụ về cái điểm cực tiểu nhưng đồng thời là không đi quá chậm Thì đó là cái ý tưởng của cái cải tiến Vậy thì ở đây chúng ta sẽ có một cái bước khởi tạo đó là alpha ban đầu là bằng 0.5 thì đây là một cái con số",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 5,
      "start_timestamp": "0:03:40",
      "end_timestamp": "0:04:32"
    }
  },
  {
    "page_content": "ban đầu là bằng 0.5 thì đây là một cái con số khá là lớn Và chúng ta sẽ lặp cho đến khi hội tụ thì chúng ta sẽ cho alpha là bằng delta nhân với alpha Trong đó delta chính là cái hệ số dampening, dampening factor nó có giá trị từ 0 cho đến 1 Thì ở đây chúng ta sẽ thử trả lời cho cái câu hỏi là điều gì xảy ra nếu delta bằng 0 Nếu delta bằng 0, tức là alpha sẽ là bằng 0 nhân với cái alpha cũ thì alpha sẽ bị triệt tiêu và khi đó cái phần này nó sẽ là bằng 0, tức là theta sẽ không cập nhật Ngược lại",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 6,
      "start_timestamp": "0:04:26",
      "end_timestamp": "0:05:34"
    }
  },
  {
    "page_content": "bằng 0, tức là theta sẽ không cập nhật Ngược lại nếu delta mà bằng 1, tức là alpha sẽ không giảm mà alpha không giảm, tức là quá trình cập nhật này nó tại những thời điểm đầu tiên nó sẽ có thể bị phân kỳ như thế này Nếu chúng ta không khéo cho delta là lớn hơn 0 và nó phải bé hơn 1 Để thuận tiện cho chúng ta bàn đến những cái cải tiến tiếp theo thì chúng ta sẽ đặt một cái biến, nó gọi là biến vận tốc Thế thì theta bằng theta trừ cho alpha nhân cho đạo hàm thì chúng ta sẽ xét nguyên cái vế này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 7,
      "start_timestamp": "0:05:23",
      "end_timestamp": "0:06:19"
    }
  },
  {
    "page_content": "cho đạo hàm thì chúng ta sẽ xét nguyên cái vế này sẽ là cái biến V, tức là cái vận tốc cập nhật tham số của mình Tại sao dùng từ vận tốc? Tại vì nó thể hiện cho cái việc di chuyển nhanh hay không nhanh, nếu như cái V này lớn thì delta sẽ được cập nhật nhanh Nếu V mà nhỏ thì theta sẽ cập nhật rất chậm, do đó chúng ta sẽ viết lại thuật toán của mình, đó là lặp cho đến khi hội tụ và chúng ta tạo ra một cái biến vận tốc V ở đây Vậy thì vấn đề ở đây là gì? Tốc độ hội tụ sẽ rất chậm hoặc là nó sẽ bị",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 8,
      "start_timestamp": "0:06:00",
      "end_timestamp": "0:07:26"
    }
  },
  {
    "page_content": "là gì? Tốc độ hội tụ sẽ rất chậm hoặc là nó sẽ bị mắc kẹt hay gọi là get stuck tại các điểm cực tiểu cục bộ Nếu dùng từng bước cập nhật, chúng ta sẽ có một cái hàm j là hàm lỗi như sau, nếu như chúng ta khởi tạo, nó sẽ nằm ở những cái điểm mà không phải là cực tiểu toàn cục, mà nó sẽ nằm ở cái phía như thế này Vậy thì khi chúng ta cập nhật nó về đây thì nó sẽ bị mắc kẹt tại cái điểm cực tiểu cục bộ này V sẽ có xu hướng là ban đầu sẽ rất là nhanh, nhưng mà càng đến đây, càng đến cái điểm cực",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 9,
      "start_timestamp": "0:07:11",
      "end_timestamp": "0:08:11"
    }
  },
  {
    "page_content": "nhưng mà càng đến đây, càng đến cái điểm cực tiểu cục bộ thì nó sẽ chậm dần Tại sao lại như vậy? Tại vì khi tham số của mình càng tiến về điểm cực tiểu cục bộ, mà điểm cực tiểu cục bộ có tính chất đó là đạo hàm gần bằng 0 Mà khi đạo hàm xấp xỉ bằng 0 thì tức là, tức là cái v, v này của chúng ta, v là bằng alpha nhân đạo hàm thì nó cũng sẽ xấp xỉ bằng 0 Và khi đó thì theta bằng theta trừ cả một con số rất là bé, tức là nó sẽ đi rất là chậm Tại khi cái v có xu hướng giảm dần và tiến về 0 như vậy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 10,
      "start_timestamp": "0:08:02",
      "end_timestamp": "0:08:55"
    }
  },
  {
    "page_content": "cái v có xu hướng giảm dần và tiến về 0 như vậy thì nó sẽ gây ra cái việc hội tụ chậm Và chúng ta sẽ mượn cái khái niệm trong vật lý là momentum để giải quyết vấn đề này Momentum là gì? Giả sử như ban đầu, chúng ta đặt một cái quả banh ở đây Thì ở trên cao nó sẽ có một cái thế năng, nó sẽ khiến cho cái trái banh nó sẽ rớt xuống Nhưng khi mà trái banh nó rớt xuống đến cái điểm cực tiểu cục bộ ở đây Và lúc đó cái thế năng nó đã bị triệt tiêu bằng 0, thế năng trong trường hợp này là chính là đạo",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 11,
      "start_timestamp": "0:08:50",
      "end_timestamp": "0:09:37"
    }
  },
  {
    "page_content": "0, thế năng trong trường hợp này là chính là đạo hàm Nó sẽ tương đương với đạo hàm ở trên Và thế năng thì nó bằng 0, nhưng bù lại nó sẽ có cái động năng là do quả banh đi từ trên xuống dưới Ban đầu động năng là bằng 0, nhưng mà sau đó rớt xuống dưới thì cái động năng của quả banh nó lớn lên Và nhờ có cái động năng này, nó sẽ tạo ra một cái moment để cho cái quả banh này tương đương với đạo hàm ở trên Rớt xuống được cái điểm cực tiểu mà tốt hơn Và đó chính là cái ý tưởng cho giải pháp số 2 Đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 12,
      "start_timestamp": "0:09:26",
      "end_timestamp": "0:10:21"
    }
  },
  {
    "page_content": "đó chính là cái ý tưởng cho giải pháp số 2 Đó là cái vận tốc của chúng ta thì sẽ được kế thừa từ cái vận tốc của quá khứ V bằng beta nhân V Đây là cái quá khứ Nếu không có cái thành phần beta V này thì V của chúng ta chỉ bao gồm cái thành phần thế năng chính là cái đạo hàm ở đây Nhờ nó khai thác được cái lượng động năng của quá khứ thì khi nó chạm đến cái điểm cực tiểu cục bộ Nó sẽ giúp cho chúng ta thoát ra khỏi cái bụng này Thì cái công thức cải tiến của chúng ta sẽ rất là đơn giản như trên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 13,
      "start_timestamp": "0:10:16",
      "end_timestamp": "0:11:23"
    }
  },
  {
    "page_content": "cải tiến của chúng ta sẽ rất là đơn giản như trên Và beta lúc này nó gọi là momentum factor và beta cũng là từ 0 cho đến 1 Điều gì xảy ra nếu beta bằng 0, beta bằng 1 Nếu beta bằng 0 thì nó sẽ bỏ ra một cái vận tốc của chúng ta Điều gì xảy ra nếu beta bằng 0, beta bằng 1 Nếu beta bằng 0, tức là chúng ta không có cái thành phần động năng này Vậy thì beta bằng 0 chính là cái trường hợp không có cải tiến Rồi, khi beta bằng 1 thì lúc này V sẽ là bằng 9V cộng dồn vào cái thế năng Thì khi đó cái tốc",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 14,
      "start_timestamp": "0:11:12",
      "end_timestamp": "0:12:25"
    }
  },
  {
    "page_content": "9V cộng dồn vào cái thế năng Thì khi đó cái tốc độ tăng của V này rất là cao V nó sẽ là cộng dồn lên, cộng dồn lên, cộng dồn lên Như vậy thì nó sẽ tăng rất là nhanh Nó có thể khiến cho cái vận tốc của mình quá lớn và nó sẽ không có hội tụ mà nó sẽ bị phân kỳ Do đó thì beta nó nên là một con số nhỏ hơn một Tức là nó chỉ lấy một phần, ví dụ như trong trường hợp là beta bằng 0.9 thì nó lấy 90% của cái V quá khứ thôi Thì chúng ta sẽ có cái giải pháp đầy đủ cho cái momentum Đầu tiên chúng ta sẽ khởi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 15,
      "start_timestamp": "0:12:16",
      "end_timestamp": "0:13:06"
    }
  },
  {
    "page_content": "đầy đủ cho cái momentum Đầu tiên chúng ta sẽ khởi tạo alpha là một cái giá trị khá là lớn Và sau đó thì alpha sẽ được cập nhật lại là bằng delta nhân cho alpha, tức là nó đang giảm dần Cái alpha, rồi chúng ta sẽ khởi tạo vận tốc ban đầu Khi chúng ta tưởng tượng quả banh ở trên đây thì cái động năng của nó là bằng 0, nó không có động năng mà nó chỉ có thế năng thôi Thì lúc này V của mình là bằng 0, tức là tượng trưng cho động năng tại thời điểm bắt đầu Delta là cái hệ số giảm, tức là alpha ban",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 16,
      "start_timestamp": "0:13:02",
      "end_timestamp": "0:13:53"
    }
  },
  {
    "page_content": "bắt đầu Delta là cái hệ số giảm, tức là alpha ban đầu là 0.5 nhưng mà sau đó nó sẽ giảm 10 lần Và 0.1 có nghĩa là chia cho 10 thì nó sẽ giảm 10 lần, cứ mỗi lần lặp nó sẽ giảm 10 Và beta là bằng 0.9 Tức là cái động năng, cái vận tốc của mình sẽ là bằng 90% của cái vận tốc quá khứ Sau đó chúng ta cộng thêm cái thành phần thế năng hiện tại, tức là cái đạo hàm Cái này tượng trưng cho cái thế năng hiện tại Nếu như đến cái điểm, gần đến cái điểm cực tiểu, cục bộ ở đây Thì cái thành phần đạo hàm này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 17,
      "start_timestamp": "0:13:50",
      "end_timestamp": "0:14:38"
    }
  },
  {
    "page_content": "tiểu, cục bộ ở đây Thì cái thành phần đạo hàm này nó sẽ xấp xỉ bằng 0 nhưng nó sẽ kế thừa được 90% cái động năng của quá khứ Nên nó sẽ không có bị dừng lại, bị đứng lại V vẫn còn đủ lớn để có thể được chuyển được Và ở đây chúng ta thấy là khi chúng ta, cái điểm màu đỏ đến tại vị trí này Nó sẽ vẫn còn một cái động năng để nhảy qua đây Sau đó tiếp tục nhảy lên, nhảy lên, nhảy lên Và nếu như cái động năng này đủ lớn thì nó sẽ giúp cho chúng ta thoát ra khỏi cái điểm, cái khu vực bên này Thoát ra",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 18,
      "start_timestamp": "0:14:32",
      "end_timestamp": "0:15:41"
    }
  },
  {
    "page_content": "ra khỏi cái điểm, cái khu vực bên này Thoát ra khỏi cái khu vực cực tiểu cục bộ Và để qua một cái khu vực khác Với hy vọng rằng là chúng ta có thể tìm ra được một cái cực tiểu tốt hơn Và ở đây thì chúng ta sẽ thử tính toán trên những cái con số Đầu tiên đó là giả sử như cái momentum của mình là bằng 0.99 Thì khi đó 3 cái bước cập nhật đầu tiên, 3 cái bước cập nhật đầu tiên của mình V ban đầu thì sẽ là bằng G, trong đó G chính là cái gradient Tại cái vị trí khởi tạo chính là G1 ở đây Tức là nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 19,
      "start_timestamp": "0:15:36",
      "end_timestamp": "0:16:27"
    }
  },
  {
    "page_content": "cái vị trí khởi tạo chính là G1 ở đây Tức là nó chỉ bao gồm thế năng thôi, động năng lúc này là 0 Ở đây đúng ra là 0 cộng cho G1 Sau đó V2 sẽ là bằng 90% của cái cũ Sau đó cộng thêm 1 thằng G2, thì nó chính là bằng 0.99 v.1 v.1 trước này là G Nó chính là 0.99 v.1 cộng cho G2 Tiếp tục sang cái điểm thứ 3 V3 sẽ là bằng 0.99 v.2 cộng cho G3 Tức là cái đạo hàm tại thời điểm hiện tại G3 ở đây, cộng cho, nó sẽ cộng cho khoảng 0.99 v.2 Chúng ta thế cái V2 ở cái công thức ở trên xuống đây Thì nó sẽ là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 20,
      "start_timestamp": "0:16:22",
      "end_timestamp": "0:17:36"
    }
  },
  {
    "page_content": "V2 ở cái công thức ở trên xuống đây Thì nó sẽ là bằng 0.99 v.1 cộng cho G2 Chúng ta triển khai vào thì nó sẽ ra là 0.81 v.1 và 0.99 v.2 cộng cho G3 Như vậy thì ở đây chúng ta sẽ có một cái nhận xét Đó là khi cập nhật tham số, thì gradient tại những cái bước càng gần Nó sẽ đóng góp càng nhiều Tức là V tại cái thời điểm thứ 3, tức là cái thời điểm hiện tại chúng ta đang xét Nó sẽ bao gồm là 0.81 v.1 cộng cho 0.991 v.2 cộng cho G3 Tức là cái thế năng tức thời, tức là đạo hàm tức thời của mình Thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 21,
      "start_timestamp": "0:17:31",
      "end_timestamp": "0:18:24"
    }
  },
  {
    "page_content": "tức thời, tức là đạo hàm tức thời của mình Thì chúng ta thấy là tại cái vị trí số 3 G3 đóng vai trò là cái tỷ lệ, cái hệ số là 1 Tức là cao nhất Sau đó là G2 sẽ đóng góp là 0.9 và G3 là 0.81 Như tương tự như vậy thì khi G, khi V mà càng lớn Thì nó sẽ là bằng cái hệ số của những cái V Gn cộng cho Gn-1 cộng cho Gn-2 Và sau đó nó sẽ nhân với những cái hệ số thấp dần Ban đầu sẽ là 1, 0.9, 0.81 Tiếp theo thì nó sẽ là 0.9 nhân cho 0.81 Nó sẽ cộng cho 0.9 nhân cho 0.81 Tức là đâu đó khoảng xấp xỉ là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 22,
      "start_timestamp": "0:18:15",
      "end_timestamp": "0:19:16"
    }
  },
  {
    "page_content": "0.9 nhân cho 0.81 Tức là đâu đó khoảng xấp xỉ là 0.72 của cái G thứ n-3 Càng sau đó hệ số nó càng thấp Đây chính là cái ý tưởng của thuật toán momentum Và nó đã giúp cho chúng ta thoát ra được khỏi cái điểm cực tiểu cục bộ Nhờ cái việc là chúng ta khai thác được những cái động năng của quá khứ 90% của Gn-1, 80% của Gn-2 và 70% của Gn-3 Nó khiến cho chúng ta thoát ra được Và khi thoát ra được thì câu hỏi là lượt có khi nào mà nó cứ đi lên hoài hay không Thì câu trả lời là không, tại vì khi mà nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 23,
      "start_timestamp": "0:19:10",
      "end_timestamp": "0:19:28"
    }
  },
  {
    "page_content": "không Thì câu trả lời là không, tại vì khi mà nó thoát ra đến đây Rồi, thì đến đây cái lúc này thì nó sẽ kế thừa những cái thế năng của cách đây Trước đó thì thế năng tại những thời điểm này rất là thấp Cái khu vực này rất là thấp Thì những cái Gn rất thấp này nó lại đóng góp tỷ trọng cao vào cái vị trí của cái tham số hiện giờ Còn những cái điểm mà có động năng thế năng cao, ví dụ như chỗ này Thì thế năng của nó rất là cao, nhưng mà nó đã đi xa so với cái vị trí này Nên cái hệ số ở đây nó chỉ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "so với cái vị trí này Nên cái hệ số ở đây nó chỉ có thể đóng góp là tầm 0.1, 0.2 thôi Còn những cái đóng góp nhiều nhất vào đây đó là những cái thế năng tại vị trí này Tức là đạo hàm ở những cái khu vực rất là thấp, đó thì nó dẫn đến nó sẽ kéo cái này xuống ngược trở lại Rồi, và khi kéo ngược trở lại thì nó lại tiếp tục chạy qua chạy lại và cho đến khi nào mà chạm được đến cái điểm này Thì đó chính là cái ý tưởng của momentum",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xgJniBOVdL8",
      "filename": "xgJniBOVdL8",
      "title": "[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 5)",
      "chunk_id": 25,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Tiếp theo, chúng ta sẽ cùng tìm về phần 2 của mô hình ngôn ngữ Thiết Trong phần trước, chúng ta đã tìm hiểu về mô hình grounded image Đầu vào có 1 câu prompt, nó sẽ kết hợp với 1 tấm ảnh để đầu ra Nhưng nó sẽ dừng ở Bounding Box, kết hợp với className Đây là bài toán dạng Zero-Shot, tức là chúng ta không huấn luyện đối tượng này Trong phần 2, chúng ta sẽ giải quyết bài toán cũng gần như tương tự Nhưng output của chúng ta không phải là Bounding Box, mà sẽ là một cái segment, cái mask Nó sẽ chi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:38"
    }
  },
  {
    "page_content": "Box, mà sẽ là một cái segment, cái mask Nó sẽ chi tiết hơn, không phải là một cái đường bao xung quanh đối tượng Mô hình ở đây chúng ta sẽ nghiên cứu, đó chính là 2 mô hình Grounded-Dino và SAM Sau đó chúng ta sẽ mở rộng ra mô hình ngôn ngữ LM cho bài toán hiểu nội dung ảnh Và một trong những mô hình có mục tiêu tương tự như GPT, VQA, đó chính là mô hình LLaVA Sau đó chúng ta sẽ cùng tìm hiểu qua một số biến thể của mô hình này Đầu tiên chúng ta sẽ nói về Grounded-Dino Trước Grounded-Dino thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 1,
      "start_timestamp": "0:01:25",
      "end_timestamp": "0:02:22"
    }
  },
  {
    "page_content": "sẽ nói về Grounded-Dino Trước Grounded-Dino thì đã có một cái mô hình nổi đình nổi đám của Meta, MetaAI Đó chính là SegmentAnything, SAM Ý tưởng của cái mô hình này đó là, đầu tiên họ xây dựng một cái bộ dataset lên đến hàng tỷ ảnh Và trong dataset này thì nó sẽ chứa cái mask của các đối tượng, tức là ảnh, cộng với cái mask Và cái mask này thì được đảm bảo là cái chất lượng của nó rất là cao Tức là nó sẽ phủ đúng những đối tượng có bên trong ảnh Đồng thời nó sẽ phủ đầy đủ, không chỉ phủ đúng mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 2,
      "start_timestamp": "0:02:13",
      "end_timestamp": "0:03:09"
    }
  },
  {
    "page_content": "Đồng thời nó sẽ phủ đầy đủ, không chỉ phủ đúng mà phủ đầy đủ các cái bộ phận Thậm chí là ví dụ trong cái hình này chúng ta thấy là nó sẽ có thể phủ được đến cái mức độ chân của cái tripod này Thì đó là về dataset Sau đó họ huấn luyện cái mô hình SegmentAnything Và ý tưởng của cái mô hình SegmentAnything đó là Đầu vào sẽ có một cái tấm ảnh, rồi qua một cái image encoder Thì nó sẽ ra một cái embedding Cái embedding này là cái vector biểu diễn của cái tấm hình Và đầu vào thì nó sẽ có là prompt",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 3,
      "start_timestamp": "0:03:02",
      "end_timestamp": "0:03:53"
    }
  },
  {
    "page_content": "cái tấm hình Và đầu vào thì nó sẽ có là prompt Nhưng mà chúng ta lưu ý là cái prompt của SAM đó là special prompt Tức là những cái prompt mang tính chất gọi là có thông tin về mặt tọa độ Ví dụ như là các cái điểm bounding box hoặc là mask Thế thì ý nghĩa của nó là gì? Ví dụ như trong hình tay phải chúng ta thấy cái prompt của mình Cái chỉ dẫn của mình nó ở dạng là Dạng điểm hay gọi là point Nghĩa là chúng ta sẽ chấm vô đây và cho cái mô hình nó biết là cái đối tượng mà chúng ta cần phải segment",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 4,
      "start_timestamp": "0:03:49",
      "end_timestamp": "0:04:33"
    }
  },
  {
    "page_content": "là cái đối tượng mà chúng ta cần phải segment Nó sẽ có ở cái vị trí này Tương tự như vậy chúng ta cũng sẽ chấm vô đây Để cho cái mô hình biết là cái đối tượng của mình muốn lấy ra cũng ở vị trí này Với 2 cái dấu chấm này nó sẽ giúp chúng ta khoanh vùng Và cái khoanh vùng nó sẽ được vẽ bằng cái đường bao màu xanh ở đây Thì nó sẽ tách ra cái đối tượng này Như vậy thì cái prompt của mình nó sẽ là 1 cái special prompt Là cái prompt ở dạng điểm bounding box hoặc là mask Tương tự như vậy nếu như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 5,
      "start_timestamp": "0:04:28",
      "end_timestamp": "0:05:08"
    }
  },
  {
    "page_content": "box hoặc là mask Tương tự như vậy nếu như chúng ta khoanh vùng 1 cái bounding box như thế này Thì nó sẽ vẽ cho chúng ta cái đường bao chi tiết xung quanh cái đối tượng của mình Như vậy cái input của mình là không phải ở dạng text Và với cái prompt này thì nó sẽ qua 1 cái prompt encoder Rồi sau đó nó sẽ qua cái module gọi là mask decoder Để kết hợp cái thông tin của cái prompt Tức là cái special prompt Và cái image embedding, cái vector biểu diễn của tấm ảnh Để từ đó nó tạo ra cái mask Và cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 6,
      "start_timestamp": "0:05:04",
      "end_timestamp": "0:05:54"
    }
  },
  {
    "page_content": "của tấm ảnh Để từ đó nó tạo ra cái mask Và cái mask này sẽ là cái mask xung quanh cái đối tượng được chỉ dẫn bởi cái prompt ở trên đây Thì cái hình bên đây đó là minh họa là cái mask này được decode ra Với 2 cái chỉ dẫn tại prompt point ở dạng điểm Như vậy thì làm sao chúng ta có thể giải quyết được cái bài toán này Giải quyết được cái bài toán đó là referencing segmentation Tức là chúng ta sẽ đưa cho nó một cái dạng là ngôn ngữ để cho nó hiểu được cái đối tượng Ví dụ như ở đây chúng ta cung",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 7,
      "start_timestamp": "0:05:46",
      "end_timestamp": "0:06:36"
    }
  },
  {
    "page_content": "được cái đối tượng Ví dụ như ở đây chúng ta cung cấp cho nó 1 cái prompt là a cat is hitting another cat Thì một cái con mèo nó đang đá một cái con mèo khác Thì nó sẽ hiểu là chúng ta sẽ khoanh vùng này Thay vì chúng ta chấm 2 cái điểm ở đây Thì đây chính là cái mục tiêu của cái model đó là Grounded-Dino Thì đó chính là làm sao đưa vào, đầu vào cho prompt làm một cái ngôn ngữ mô tả Thế thì cái ý tưởng đó là chúng ta sẽ dùng một cái mô hình phát hiện đối tượng khác Có sẵn để lấy cái bounding box",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 8,
      "start_timestamp": "0:06:28",
      "end_timestamp": "0:07:17"
    }
  },
  {
    "page_content": "đối tượng khác Có sẵn để lấy cái bounding box của nó ra Tức là chúng ta sẽ có một cái object detector Và chúng ta sẽ đưa vào một cái từ khóa Rồi sau đó nó sẽ tìm ra ví dụ như chúng ta có thể sử dụng mô hình là CLIP hoặc là GLIP Cái này là viết tắt, cái này là GLIP Rồi thì khi chúng ta đưa vào cái mô hình kiểu như là ví dụ như CLIP Thì input của mình nó sẽ là một cái prompt Và output của mình nó sẽ ra được một cái bounding box Và prompt này là ở dạng text Thế thì điều gì xảy ra nếu như cái mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 9,
      "start_timestamp": "0:07:13",
      "end_timestamp": "0:07:47"
    }
  },
  {
    "page_content": "ở dạng text Thế thì điều gì xảy ra nếu như cái mô hình của mình nó không thấy được cái đối tượng hoặc là cái đối tượng của mình đó là cái đối tượng mới hoàn toàn Không có trong cái tập dataset Thì khi đó là cái phương pháp A này là không ổn Là do nó không thể hiểu được cái từ khóa Hiểu được cái đối tượng mà thể hiện ở trong cái câu mô tả",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=XNqplvgdCKU",
      "filename": "XNqplvgdCKU",
      "title": "[CS315 - Chương 4] Vision - Language Model (2): Part 1",
      "chunk_id": 10,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ hướng dẫn thực hành với hai kiến trúc là Autoencoder và Variational Autoencoder Đầu tiên là kiến trúc Autoencoder, chúng ta sẽ kết nối với một cái máy Kết nối đã được kết nối rồi, chúng ta sẽ tiến hành chạy đoạn code của mình Đầu tiên là khởi tạo phần thư viện Hàm chính sẽ bao gồm .nn, viết tắt của Neural Network, functional, kích hoạt như sigmoid, relu, và hàm khác Tiếp theo là sẽ sử dụng collab với chế độ có GPU Chúng ta phải kiểm tra lại xem có GPU hay chưa Nếu có GPU RAM thì đã",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:31"
    }
  },
  {
    "page_content": "tra lại xem có GPU hay chưa Nếu có GPU RAM thì đã kết nối được rồi Còn nếu không thì vào runtime, chúng ta chọn change runtime, chọn T4 Kiểm tra xem device của mình, đã kết nối với CUDA, tức là nó đã có GPU rồi Tiếp theo là kết nối kiến trúc Encode và Decoder, trong đó phần vàng vàng, tương ứng là encoder và phần xanh là decoder Trong giai đoạn Encode, ảnh đầu vào sẽ là ma trận kích thước 2828 Tại vì ảnh này được lấy từ tập dữ liệu MNIST, và ảnh này sẽ được flatten để biến thành vector 784",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:01:27",
      "end_timestamp": "0:02:21"
    }
  },
  {
    "page_content": "ảnh này sẽ được flatten để biến thành vector 784 chiều Sau đó chúng ta giảm số chiều xuống là 512 và xuống z Về mặt coding, chúng ta nên để 1 biến là Latent Dim để tùy chỉnh xem có thể là 2, 3, 4, 5, 1 cái kích thước bất kỳ Đầu tiên là lớp constructor, chúng ta sẽ khởi tạo các lớp biến đổi cho encoder Lớp đầu tiên là lớp linear để ánh xạ từ 784 về 512, chúng ta sẽ dùng là neural network.linear và 784 về 512 Và lớp này sẽ được gắn vào một thuộc tính cell.linear1, tức là lớp biến đổi đầu tiên này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:02:15",
      "end_timestamp": "0:03:47"
    }
  },
  {
    "page_content": "cell.linear1, tức là lớp biến đổi đầu tiên này Tương tự như vậy, chúng ta sẽ có lớp linear2, có điều, chúng ta sẽ ánh xạ từ 512 về 2 chiều Tuy nhiên để tổng quát, chúng ta có thể thay đổi số chiều của vector latent, nên chúng ta phải truyền vào biến là Latent Dim Thay vì để 2 hardcode, chúng ta sẽ để là Latent Dim Tiếp theo là hàm forward, hàm forward sẽ nhận dữ liệu đầu vào là 1 ảnh x và đầu ra của mình Đối với encoder, đầu ra của chúng ta chỉ cần ra biến z, là đủ Do đó, bước đầu tiên là chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:03:36",
      "end_timestamp": "0:04:24"
    }
  },
  {
    "page_content": "ra biến z, là đủ Do đó, bước đầu tiên là chúng ta phải flatten Thì để flatten, chúng ta sẽ sử dụng cái hàm, đó là hàm, chúng ta sẽ sử dụng một cái hàm flatten của neural network, đó là hàm torch. Và chúng ta sẽ truyền vào x, start_dim, là bằng 1 Rồi, để cho độ phức tạp thì chúng ta sẽ giữ luôn chính cái biến x, đầu vào là x và đầu ra sẽ gán ngược trở lại vào biến x Lúc này thì x của chúng ta là vector 784 chiều, sau đó chúng ta sẽ đưa về cái vector 512 chiều, cell.linear Và để cho có cái sự",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:04:10",
      "end_timestamp": "0:05:18"
    }
  },
  {
    "page_content": "vector 512 chiều, cell.linear Và để cho có cái sự khác biệt giữa các lớp biến đổi tuyến tính thì chúng ta phải có một cái hàm kích hoạt ở giữa Thế thì, hàm kích hoạt ở đây chúng ta dùng là gì? Thì trong cái lý thuyết về deep learning chúng ta đã được học là có thể dùng hàm sigmoid hoặc hàm relu Tuy nhiên hàm sigmoid có khả năng gây ra hiện tượng vanishing gradient, tức là tiêu biến đạo hàm nên cái tốc độ hội tụ chậm Do đó thì chúng ta sẽ dùng f.relu, tức là hàm rectify linear unit, rồi chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:05:10",
      "end_timestamp": "0:06:09"
    }
  },
  {
    "page_content": "tức là hàm rectify linear unit, rồi chúng ta sẽ trả về x Lúc này x của mình sẽ là một cái vector 512 chiều Tiếp tục như vậy, thì từ 512 xuống 2 thì chúng ta sẽ có cell.linear2 Và lúc này thì chúng ta có sử dụng cái hàm kích hoạt hay không? Nếu chúng ta sử dụng hàm rectify linear unit thì cái giải giá trị của mình là từ 0 cho đến cộng vô cùng Nhưng cái vector z này chúng ta muốn biểu diễn nó xung quanh con số 0 trong cái không gian, do đó nó phải có số âm và số dương Tức là các cái thành phần",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:06:01",
      "end_timestamp": "0:06:49"
    }
  },
  {
    "page_content": "có số âm và số dương Tức là các cái thành phần của vector z của mình nó phải có thành phần âm, thành phần dương, do đó thì chúng ta sẽ không có dùng hàm kích hoạt ở đây Và thay vì tạo biến tạm thì chúng ta sẽ trả ra trực tiếp, thì lúc này đây chính là cái z của mình Và cái kết quả mà return đây chính là cái latent variable z của mình Tương tự như vậy cho hàm decode, thì hàm decode chúng ta sẽ từ 2 chiều đến 52 chiều, hoặc là từ latent dim đến 52, rồi từ 52 về 784 Thì chúng ta sẽ có cell.linear1",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:06:43",
      "end_timestamp": "0:08:06"
    }
  },
  {
    "page_content": "rồi từ 52 về 784 Thì chúng ta sẽ có cell.linear1 Và để cho tổng quát thì chúng ta sẽ để là latent dim và ra là 52 Tiếp theo đó là cell.linear1 Và hàm forward là nó sẽ nhận đầu vào vector z, sau đó nó sẽ biến đổi qua 2 lớp biến đổi kia cell.linear1, nhận đầu vào là z, và đầu ra thì chúng ta cũng sẽ dùng 1 cái hàm kích hoạt, cụ thể ở đây đó là cell.relu Rồi, thế thì nhận đầu vào là z, thì ở đây chúng ta có thể trả về cái biến z luôn, tuy nhiên nếu đúng về mặt, thì chúng ta có thể trả về cái biến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:07:57",
      "end_timestamp": "0:08:48"
    }
  },
  {
    "page_content": "đúng về mặt, thì chúng ta có thể trả về cái biến z Tuy nhiên nếu đúng về mặt, concept về mặt ý nghĩa, chúng ta đang decode để tạo ra cái x-mũ, do đó chúng ta sử dụng luôn cái biến x-mũ, thay vì chúng ta dùng vector z Cái việc đặt tên biến là z cũng không có ảnh hưởng đến kết quả, tuy nhiên để dễ maintain về sau, chúng ta nên đặt biến đúng cái ý nghĩa của nó Sau đó thì cell.linear2, xh Thế thì ở cái lớp cuối cùng này, chúng ta có dùng activation function hay không? Thì chúng ta phải xem coi cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:08:42",
      "end_timestamp": "0:09:26"
    }
  },
  {
    "page_content": "function hay không? Thì chúng ta phải xem coi cái kiểu dữ liệu của cái ảnh này, mỗi một cái điểm ảnh nó sẽ là kiểu gì? Thì cái đầu ra của mình nó sẽ là một cái giá trị scaling từ 0 cho đến 1, do đó ở đây chúng ta sẽ phải dùng một cái hàm để áp một cái giá trị bất kỳ về cái đoạn từ 0 đến 1, đó chính là f.sigmoid Tại sao không dùng relu nữa? Tại vì cái hàm relu nó là giải giá trị từ 0 cho đến cộng vô cùng, còn chúng ta đang muốn từ 0 cho đến 1 Sau khi chúng ta đã có xh xong thì chúng ta sẽ gọi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:09:18",
      "end_timestamp": "0:10:04"
    }
  },
  {
    "page_content": "khi chúng ta đã có xh xong thì chúng ta sẽ gọi hàm reshape xh.reshape Và cái kích thước của cái shape của mình nó sẽ là trừ 1, 1, 2, 8 Trong đó hai cái thành phần cuối là cái kích thước của cái ảnh mà mình sẽ decode ra, và 1 đó là cái số kênh màu của mình, tại vì đây là ảnh mức xám nên nó chỉ có một kênh màu thôi Còn trừ 1 ở đây có nghĩa là chúng ta có thể huấn luyện theo batch truyền vào theo một khối dữ liệu, thì ở đây trừ 1 thì hàm ý đó là nếu đầu vào thì chúng ta có bao nhiêu ảnh để huấn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:09:52",
      "end_timestamp": "0:10:53"
    }
  },
  {
    "page_content": "nếu đầu vào thì chúng ta có bao nhiêu ảnh để huấn luyện, cái batch size là bao nhiêu thì ở đây sẽ là bao nhiêu Rồi, và bây giờ chúng ta sẽ tiến hành chạy hai cái đoạn code encoder và decoder Rồi, thì chúng ta sẽ có một cái lớp đối tượng nữa đó là autoencoder, nó sẽ bao gồm hai thành phần đó là encoder và decoder Rồi khi gọi hàm forward thì chúng ta sẽ nhận cái ảnh đầu vào và gọi cái cell.encoder để tạo ra cái vector latent g Rồi từ vector latent g chúng ta gọi cell.decoder để trả ra cái x mũ,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:10:51",
      "end_timestamp": "0:11:29"
    }
  },
  {
    "page_content": "g chúng ta gọi cell.decoder để trả ra cái x mũ, đây chính là cái x mũ của mình là reconstruct là cái ảnh đã được khôi phục Rồi, ở trong cái hàm train này thì chúng ta sẽ có dùng cái optimizer là adam, mặc định khi chúng ta không rành về optimizer thì chúng ta cứ dùng adam và chúng ta sẽ có nhiều epoch, rồi sau đó chúng ta sẽ chuyển qua dữ liệu, chúng ta thấy là cái dữ liệu này sẽ được lấy từ tập dữ liệu MNIST và trong tập MNIST thì cái data của mình nó sẽ có dữ liệu x và y, trong đó y cho biết",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:11:23",
      "end_timestamp": "0:12:17"
    }
  },
  {
    "page_content": "mình nó sẽ có dữ liệu x và y, trong đó y cho biết đó là ký tự nào nhưng mà chúng ta lưu ý, chúng ta đang huấn luyện theo cái phong cách đó là unsupervised learning, tức là không giám sát do đó thì ở đây chúng ta sẽ không có sử dụng cái y, chúng ta rê chuột vào đây chúng ta thấy không dùng, nhưng khi chúng ta rê vào x thì chúng ta thấy biến x có sử dụng và x sẽ được chuyển vào trong device đó là GPU và khởi tạo optimizer là Zero Grad, tức là Gradient Descent với mặc định ban đầu bằng 0 rồi x hat",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:12:02",
      "end_timestamp": "0:13:03"
    }
  },
  {
    "page_content": "Descent với mặc định ban đầu bằng 0 rồi x hat qua cái autoencoder nhận vào cái biến đầu vào x và nó sẽ ra cái x hat là cái đã được khôi phục lại thì hàm loss ở đây là gì? sẽ là bằng x hat trừ cho x, sau đó chúng ta sẽ mũ 2 lên, rồi sau đó chúng ta sẽ đi tính tổng sau khi tính tổng xong chúng ta sẽ gọi hàm backward để thực hiện cái thuật toán back propagation và tiến hành update lại cái tham số rồi thì đây chính là cái hàm train, tiếp theo thì chúng ta sẽ gọi cái hàm và gọi cái đối tượng là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:12:54",
      "end_timestamp": "0:13:42"
    }
  },
  {
    "page_content": "chúng ta sẽ gọi cái hàm và gọi cái đối tượng là autoencoder với latent dim là bằng 2 câu hỏi là tại sao chúng ta lại chọn latent dim là bằng 2? Đáp án chính là để dễ trực quan hóa, điều gì xảy ra nếu latent dim bằng 4 bằng 5 chúng ta sẽ rất khó để có thể vẽ lên trên cái Colab, sau đó chúng ta chọn dim bằng 2 là vừa đủ nhỏ để có thể vẽ lên trên cái không gian 2 chiều tỉ lệ nén trong trường hợp này nó sẽ là 784 x 2, tức là nó nén khoảng 392 lần, rồi điều gì xảy ra nếu dim bằng 1 thì rõ ràng là nó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:13:33",
      "end_timestamp": "0:14:27"
    }
  },
  {
    "page_content": "điều gì xảy ra nếu dim bằng 1 thì rõ ràng là nó sẽ bị mất mát rất nhiều thông tin và có thể cái việc khôi phục nó khó đạt được đến cái ảnh gốc ban đầu, thì đây chúng ta sẽ phải thử, nhưng mà trước mắt chúng ta sẽ sử dụng cái latent dim là bằng 2 và autoencoder sẽ được đưa vào GPU, rồi dữ liệu được đóng gói và chúng ta sẽ gọi hàm train nó sẽ có no attribute là relu, rồi chúng ta sẽ xem trong cái decoder rồi ở đây nó không phải là cell.relu mà là f.relu, chúng ta sẽ chạy lại Cảm ơn các bạn đã xem",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "chúng ta sẽ chạy lại Cảm ơn các bạn đã xem video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=xSEyCajJWVo",
      "filename": "xSEyCajJWVo",
      "title": "[CS315 - Chương 3] Tutorial - AE (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng tìm hiểu về cách sử dụng một cái mô hình clip đã được tiền huấn luyện trên một bộ dữ liệu vô cùng lớn của OpenAI. Vì vậy, tự huấn luyện được môn clip là khá là không khả thi, vì nó cần lượng data cực kỳ lớn, tài nguyên tính toán, xử lý song song, GPU cũng cực kỳ mắc tiền. Vì vậy, khả duy nhất của chúng ta lúc này là chúng ta sẽ sử dụng một cái môn pre-drain để đi giải quyết những cái tác vụ đã có. Thế thì, đầu tiên chúng ta sẽ cài đặt một số cái thư viện cũng như là đưa cái môn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:03"
    }
  },
  {
    "page_content": "đặt một số cái thư viện cũng như là đưa cái môn clip, cái thư viện của clip về. Sau đó thì chúng ta sẽ thử xem cái phiên bản hiện tại là gì. Chúng ta lưu ý đó là mình sẽ chọn cái runtime của mình, đó là T4, có GPU. Rồi, tiếp theo thì chúng ta sẽ load cái mô hình lên, thế thì để xem xem có hiện giờ là đang có những cái mô hình nào tiền huấn luyện có thể available để cho chúng ta có thể tải về. Vì vậy, chúng ta sẽ sử dụng cái hạng available model. Và ở đây thì chúng ta thấy là đã có 9 cái mô",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:02:02"
    }
  },
  {
    "page_content": "Và ở đây thì chúng ta thấy là đã có 9 cái mô hình, thì chúng ta có thể sử dụng ResNet 50 để cho nó nhẹ cũng được. Không thì dùng VIT B32 cũng được. Ở đây chúng ta sẽ sử dụng ResNet 50. Rồi, tiếp theo thì chúng ta sẽ chuẩn bị cái hạng để tiền sử dụng ảnh, đó chính là hạng Pre-process. Thì hạng này mục tiêu đó là để chuẩn hóa cái dữ liệu ảnh đầu vào của mình. Ban đầu ảnh của mình có thể ở rất nhiều những cái định dạng khác nhau và kích thước khác nhau. Rồi, do đó thì chúng ta sẽ có các cái thao",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 2,
      "start_timestamp": "0:01:46",
      "end_timestamp": "0:02:49"
    }
  },
  {
    "page_content": "nhau. Rồi, do đó thì chúng ta sẽ có các cái thao tác tiền xử lý. Thì các cái thao tác tiền xử lý bao gồm là Resize trên tấm ảnh về 224 x 224, rồi crop cái vùng ở giữa để làm sao cho đạt được cái kích thước là 224. Rồi sau đó chúng ta sẽ đưa về cái tensor và chuẩn hóa. Thì các cái bộ trọng số này là những cái bộ trọng số đã được chuẩn bị trước. Trong cái quá trình tiền huấn luyện của OpenAI thì họ đã ra được những cái bộ giá trị mean và standard deviation này. Sau đó thì đối với hạng ảnh thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 3,
      "start_timestamp": "0:02:39",
      "end_timestamp": "0:03:21"
    }
  },
  {
    "page_content": "deviation này. Sau đó thì đối với hạng ảnh thì chúng ta chỉ đơn giản đó là Resize, Crop vùng ở giữa, sau đó Convert và Chuẩn hóa. Còn đối với văn bản thì chúng ta sẽ có một cái bước gọi là Tokenization. Thì Tokenization là chúng ta thay vì chúng ta sử dụng gốc ban đầu là từ Hello và từ World. Thì thực tế là nó sẽ có một cái bộ token để mà chúng ta đưa cái chuỗi văn bản gốc ban đầu về cái danh sách các cái token đó. Và mặc định thì chúng ta sẽ để cái danh sách các cái token mà chúng ta xử lý tối",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 4,
      "start_timestamp": "0:03:16",
      "end_timestamp": "0:04:04"
    }
  },
  {
    "page_content": "cái danh sách các cái token mà chúng ta xử lý tối đa đó là 70 token. Cho dù câu ngắn hay câu dài nó cũng sẽ đưa về 70 token. Thì đây là cái định dạng mà clip yêu cầu. Sau đó thì chúng ta sẽ cấu hình. Ví dụ như ở đây chúng ta sẽ chọn cái đường dẫn ảnh đến cái thư mục hiện tại. Thì cái thư mục hiện tại là, chúng ta xem cái thư mục gì ha? Thì là Content. Do đó cái DataDir chúng ta sẽ để là Content. Rồi, ở hiện giờ thì chưa có hình. Chúng ta sẽ tải các cái hình này về. Thì ở đây tôi có chuẩn bị sẵn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 5,
      "start_timestamp": "0:03:59",
      "end_timestamp": "0:05:01"
    }
  },
  {
    "page_content": "cái hình này về. Thì ở đây tôi có chuẩn bị sẵn 3 cái tấm hình. Ví dụ đây là cháo bún ha. Rồi. Tiếp theo đó là hình của một cái chú gà. Rồi, ở đây chúng ta rename lại. Đây là Chicken. Rồi, đây là... Đó. Rồi. Thì không biết sao cái ảnh thứ ở giữa chưa có chạy được. Thì chúng ta sẽ xem thử ha. Rồi, cái hình này là... không có tải về được bằng lệnh Wget. Do đó chúng ta sẽ sử dụng một cái hình khác. Chúng ta sẽ sử dụng một cái hình khác. Ví dụ như ở đây là chúng ta... thử tải cái này về. Bằng cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 6,
      "start_timestamp": "0:04:59",
      "end_timestamp": "0:05:50"
    }
  },
  {
    "page_content": "ở đây là chúng ta... thử tải cái này về. Bằng cái link khác. Rồi, ở đây chúng ta sẽ tải về. Rồi, ở đây chúng ta sẽ tải về. Rồi, ở đây chúng ta sẽ tải về. Bằng cái link khác. À, cái link này chính là cái link ban đầu hồi nãy. Rồi, chúng ta sẽ name là Elephant. Rồi, ở đây là... lấy tấm hình này đi. Rồi, chúng ta sẽ lấy cái đường dẫn trên. Và đưa cái link ảnh vào. Rồi, chúng ta đã tải được. Và chúng ta sẽ sửa lại là Elephant. Rồi, như vậy chúng ta đã có 3 cái công cụ này. Bây giờ, đối với cái phần",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 7,
      "start_timestamp": "0:05:48",
      "end_timestamp": "0:07:00"
    }
  },
  {
    "page_content": "có 3 cái công cụ này. Bây giờ, đối với cái phần văn bản, thì chúng ta sẽ có cái định dạng... chúng ta chuẩn bị trước cái định dạng đó là... tên của cái file của mình. Và cái câu mô tả... tương ứng với cái nội dung đó. Cái nội dung trong văn bản. Ví dụ như ở đây chúng ta có tên file là Chicken. Rồi, thì ở đây trong cái hình này Chicken. Rồi, chúng ta có thể xem trực tiếp cái hình... là cái... con gà ở trên... chiếc ghế. Tokenization. Rồi, sau đó thì chúng ta sẽ tạo ra thêm... 3 cái đối tượng còn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 8,
      "start_timestamp": "0:06:57",
      "end_timestamp": "0:07:39"
    }
  },
  {
    "page_content": "chúng ta sẽ tạo ra thêm... 3 cái đối tượng còn lại. Ví dụ như ở đây là... thì chúng ta sẽ xem coi cái nội dung của nó là gì. The dog is on the grass. Và cuối cùng đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=yPzXzbEhUW0",
      "filename": "yPzXzbEhUW0",
      "title": "[CS315 - Chương 4] Tutorial - CLIP",
      "chunk_id": 9,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ cùng đến với một trong những mô hình rất quan trọng trong phần này, đó chính là mô hình GPT-4V Chữ V là viết tắt của chữ Vision, đó có tham gia của một language model, là Generative Pre-trained Transformer Mô hình ngôn ngữ lớn có sự phối hợp với dữ liệu về hình ảnh, tuy nhiên đây là một mô hình closed-source, nên chúng ta không bàn nhiều về kiến trúc của nó Nhưng tư tưởng và cách thức vận hành của nó là vấn đề quan trọng mà chúng ta cần phải thảo luận Sau này thì có những mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:09"
    }
  },
  {
    "page_content": "cần phải thảo luận Sau này thì có những mô hình tương tự với GPT-4V Ví dụ như là mô hình LLaVA, chúng ta sẽ tìm hiểu LLaVA trong những phần tiếp theo đã sử dụng ý tưởng của GPT-4V để phát triển GPT-4V có cái gì đặc biệt so với mô hình trước đây Đầu tiên chúng ta sẽ xem các tình huống sử dụng của GPT-4V, đó là Interleaved Image Text Pair Với cái prompt đầu vào của mình, nó có thể mix với nhiều thể thức khác nhau Ví dụ như ở đây là chúng ta không chỉ có một câu hỏi mà thậm chí chúng ta có đến hai",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 1,
      "start_timestamp": "0:01:03",
      "end_timestamp": "0:01:57"
    }
  },
  {
    "page_content": "có một câu hỏi mà thậm chí chúng ta có đến hai câu hỏi là nó đã phức tạp hơn bình thường rồi Cái tiếp theo đó là cái tấm ảnh, nó cũng sẽ có ba tấm ảnh Và cái câu prompt dạng text ở đây nó sẽ phải đi tương tác với lại các dữ liệu ảnh này để mà nó đi tìm ra câu trả lời Và thậm chí là trong cái ví dụ bên tay phải nó còn phải có cái sự tương tác giữa hai ảnh với nhau Ví dụ với cái câu prompt này thì nó chỉ đơn giản là nó đi tìm cái con số nào để thể hiện số đó là thuế phải trả Thì in the first",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 2,
      "start_timestamp": "0:01:44",
      "end_timestamp": "0:02:39"
    }
  },
  {
    "page_content": "thể hiện số đó là thuế phải trả Thì in the first receipt thì mình đã trả 3,75 tiền thuế Nó nằm ở đâu? Nó nằm ở bottom, đại khái vậy Nằm ở phía dưới của cái hóa đơn này Rồi in the second receipt thì nó lại có tương tự như vậy, nó nằm ở đâu? Mô tả cái chi tiết cái vị trí của nó Thế thì ở đây là một cái ví dụ mà cái câu prompt của mình nó tương tác lần lượt với lại các cái ảnh Thì cái này nó vẫn chưa đủ cái độ phức tạp Cái ví dụ kế bên nó là nó có sự tương tác giữa hai ảnh với nhau Còn ở trên là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 3,
      "start_timestamp": "0:02:35",
      "end_timestamp": "0:03:17"
    }
  },
  {
    "page_content": "sự tương tác giữa hai ảnh với nhau Còn ở trên là các cái ảnh là độc lập nhau, nó chỉ đi trả lời cái câu hỏi là bao nhiêu tax? Thuế phải đóng thôi Còn ở đây là how much should I pay for the beer on the table according to the price on the menu? Thì ở đây nó có hai cái tấm hình Tấm hình đầu tiên là cái chai bia mà họ uống, cái người chụp đang uống Và tấm thứ hai đó là cái tấm hình của cái menu và chúng ta thấy cái tấm hình này cũng khá là xấu Nó chụp nghiêng rồi nó tối Thì GPT-4V nó đã trả lời đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 4,
      "start_timestamp": "0:03:09",
      "end_timestamp": "0:03:53"
    }
  },
  {
    "page_content": "nghiêng rồi nó tối Thì GPT-4V nó đã trả lời đó là nó sẽ lục vào bên trong cái... Đầu tiên là nó sẽ xem cái tấm hình đầu tiên và nó lấy ra được cái tên của cái loại beer Đó là Magna Rồi sau đó nó sẽ đi tra vào bên trong đây là cái beer Magna thì nó nằm ở đâu? Để mà từ đó là nó... Ví dụ đây, nó tìm ra được cái Magna nằm ở đây chẳng hạn Thì nó sẽ trả lời là 6 đô la Và sau đó nó còn lập luận và thực hiện cái thao tác đếm Là trong cái đây có hai chai bia, do đó nó sẽ lấy 6 nhân cho 2 là bằng 12 Như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 5,
      "start_timestamp": "0:03:47",
      "end_timestamp": "0:04:37"
    }
  },
  {
    "page_content": "bia, do đó nó sẽ lấy 6 nhân cho 2 là bằng 12 Như vậy thì ở đây chúng ta thấy cái mô hình này nó còn có cái sự gọi là reasoning Tức là cái sự suy luận Chứ nó không chỉ đơn giản là information extraction, tức là rút trích thông tin ra từ tấm ảnh Mà nó có cái sự reasoning ở đây Thì để đạt được cái reasoning này thì nó sẽ phải nhờ đến cái kết quả hoặc là những thành tựu của GPT Là cái mô hình mà pre-train dành cho cả decoder để phục vụ cho việc là xử lý cái văn bản Hoặc là generate tạo sinh ra văn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 6,
      "start_timestamp": "0:04:29",
      "end_timestamp": "0:05:18"
    }
  },
  {
    "page_content": "lý cái văn bản Hoặc là generate tạo sinh ra văn bản Vậy thì GPT-4V là một cái mô hình cho phép xử lý đa dạng các dữ liệu đầu vào hay còn gọi là multimodality là đa thể thức Và nó có thể xử lý dữ liệu đầu vào là dạng văn bản thông thường Nó có thể gồm một hoặc là nhiều ảnh Ví dụ như trong cái ví dụ này ta thấy là có thể lên đến vài ảnh, ba ảnh Rồi văn bản trong ảnh, tức là trong tấm ảnh nó lại có văn bản Bình thường là mình sẽ có văn bản riêng và ảnh riêng Bây giờ trong ảnh nó lại có văn bản Đó,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 7,
      "start_timestamp": "00:05:13",
      "end_timestamp": "0:06:00"
    }
  },
  {
    "page_content": "ảnh riêng Bây giờ trong ảnh nó lại có văn bản Đó, thì đây là một cái ví dụ trong ảnh là có văn bản Là trong tấm hình menu nó sẽ có các cái tên của các loại đồ uống và giá tiền Rồi visual pointer tức là một cái dạng thức để cho chúng ta tương tác Đối với là một cái dạng prompt, nó là một cái dạng prompt mới Bình thường mình có prompt là dạng text và ảnh Bây giờ cái prompt của mình có thể là dấu mũi tên giống như chúng ta đang vẽ ở đây Cái mũi tên này nó cũng được gọi là một cái prompt Nếu như",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 8,
      "start_timestamp": "00:05:56",
      "end_timestamp": "0:06:39"
    }
  },
  {
    "page_content": "này nó cũng được gọi là một cái prompt Nếu như cái mô hình này giả sử như nó giải không được thì chúng ta có thể chỉ vô đây Giá của cái beer Magna nó là nằm ở đây, mình chỉ vô Mô hình của mình sẽ hiểu được cái visual pointer này như là một cái loại prompt Vậy thì GPT-4V nó có một vài đặc trưng chính, đó là gì Đây là một cái bài toán có thể được thực hiện với GPT-4V Đây là những cái bài toán mà GPT thực hiện được bao gồm những task rất là đơn giản Ví dụ như là mô tả hình ảnh, image description,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 9,
      "start_timestamp": "00:06:34",
      "end_timestamp": "0:07:27"
    }
  },
  {
    "page_content": "Ví dụ như là mô tả hình ảnh, image description, image captioning, rồi nhận dạng ảnh, recognition on different domains Rồi kết hợp kiến thức đa thể thức, multimodal knowledge Trong cái ví dụ ở trên chúng ta thấy là nó có sử dụng cái knowledge của văn bản là text Đồng thời nó cũng có sử dụng cái knowledge của tấm ảnh Rồi nó có sử dụng cái text trong ảnh Thì đó là multimodality Và có thể tương tác với các kiến thức tổng quát Ví dụ như nó có thể hiểu về những người nổi tiếng như là David Beckham",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 10,
      "start_timestamp": "00:07:23",
      "end_timestamp": "0:08:13"
    }
  },
  {
    "page_content": "về những người nổi tiếng như là David Beckham Người nổi tiếng này Rồi các cái địa danh như là Paris, Hà Nội v.v. Địa danh nổi tiếng thì đó là những cái kiến thức tổng quát Rồi và đồng thời nó có khả năng quan trọng là hiểu và suy luận hay gọi là reasoning trên cái văn bản đơn thuần hoặc là văn bản trong ảnh syntax understanding hoặc document reasoning Thì đây chính là những cái khả năng nổi trội của GPT-4V so với những mô hình ngôn ngữ thị giác mà chúng ta đã tìm hiểu ở phía trước Tiếp theo thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 11,
      "start_timestamp": "00:08:09",
      "end_timestamp": "0:08:56"
    }
  },
  {
    "page_content": "chúng ta đã tìm hiểu ở phía trước Tiếp theo thì chúng ta sẽ cùng tìm hiểu về khái niệm visual pointer Ở bên tay phải là một hình ảnh ví dụ về visual pointer Bên cạnh câu mô tả là display the pointed region in the image Và chúng ta sẽ có một tấm ảnh Trong tấm ảnh này, nó sẽ có một đường màu đỏ Đây chính là một ví dụ của visual pointer Với visual pointer sẽ hướng dẫn cho mô hình tập trung vào những phần quan trọng của tấm ảnh Thay vì chúng ta nhìn vô, tấm ảnh này sẽ có cả rừng chữ và số Với đường",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 12,
      "start_timestamp": "00:08:48",
      "end_timestamp": "0:09:37"
    }
  },
  {
    "page_content": "vô, tấm ảnh này sẽ có cả rừng chữ và số Với đường khoanh màu đỏ này, mô hình của mình biết là sẽ tập trung vào đây để phân tích số liệu của mình Với đường màu đỏ này, mô hình GPT-4V đã nêu được Và chúng ta đã đưa ra các phân tích tương ứng của tấm ảnh Và chúng ta đã đưa ra các phân tích tương ứng của tấm ảnh Vậy thì ngoài đường khoanh màu đỏ, nó sẽ còn những dạng visual pointer nào Ví dụ như chúng ta có thể đưa vào tọa độ dạng số, hoặc là coordinate Hoặc chúng ta có thể đưa vào blackbox, trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 13,
      "start_timestamp": "00:09:31",
      "end_timestamp": "0:10:13"
    }
  },
  {
    "page_content": "Hoặc chúng ta có thể đưa vào blackbox, trong đó chúng ta loại bỏ hết tất cả những phần ảnh không liên quan Và chỉ chừa cái vùng ảnh có liên quan đến việc suy luận hoặc là cái việc trả lời câu hỏi của chúng ta Hoặc là nó có thể ở dạng là một cái mũi tên, chỉ vào những đối tượng mà chúng ta đang muốn quan tâm Thì đây có thể là một trong những dạng khá là thú vị và gần với cách thức người tương tác khi mà trao đổi với nhau trên hình ảnh Rồi cái dạng nữa đó là chúng ta có thể dùng một cái box, một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 14,
      "start_timestamp": "0:10:04",
      "end_timestamp": "0:10:56"
    }
  },
  {
    "page_content": "nữa đó là chúng ta có thể dùng một cái box, một cái khung kèm cái ảnh gốc thì nó sẽ có thêm một cái đường màu đỏ để khoanh vùng cái đối tượng chúng ta quan tâm Và có những cái dạng mà freestyle hơn, ví dụ như là hình oval, hoặc là hand drawing, tức là một cái đường nét tự do Với cái visual pointer, nó đã giúp cho cái việc tương tác giữa người và máy tính trở nên thuận tiện hơn Và đây có lẽ là một trong những cái thể thức quan trọng đặc biệt mà GPT-4V nó khác biệt so với lại những cái mô hình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 15,
      "start_timestamp": "0:10:46",
      "end_timestamp": "0:11:41"
    }
  },
  {
    "page_content": "GPT-4V nó khác biệt so với lại những cái mô hình vision language, cái mô hình thị giác ngôn ngữ trước đây Vậy thì một vài cái ví dụ nữa để cho chúng ta thấy cái tính hiệu quả của GPT-4V liên quan đến cái việc là reasoning Nếu như chúng ta đưa vào một cái câu prompt đó là count number of apples in the image thì nó sẽ đếm sai là có 12 quả táo Nâng cấp hơn một chút xíu thì mình sẽ chỉ dẫn cho nó, đó là thêm một cái câu viết đằng sau đó là suy nghĩ step by step Thì nó sẽ đưa ra là có 4 step, rồi",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 16,
      "start_timestamp": "0:11:37",
      "end_timestamp": "0:12:31"
    }
  },
  {
    "page_content": "step by step Thì nó sẽ đưa ra là có 4 step, rồi step 1 là tính như thế nào, step 2 là làm gì, step 3 là làm thế nào, step 4 thậm chí đã kiểm tra lại Nhưng cuối cùng nó vẫn ra sai và chỉ đến khi chúng ta đưa ra một cái chỉ dẫn đầy đủ và các cái bước đủ đơn giản Thì nó mới có thể làm đúng ví dụ, câu đầu giống như nó khen You are an expert in counting things in the image Rồi, hãy đếm những số lượng apple trong tấm ảnh này row by row và đảm bảo rằng là nó ra được cái kết quả chính xác Thế thì nó sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 17,
      "start_timestamp": "0:12:17",
      "end_timestamp": "0:13:19"
    }
  },
  {
    "page_content": "là nó ra được cái kết quả chính xác Thế thì nó sẽ xét trong tấm hình này thì nó sẽ có 4 dòng và với mỗi dòng nó sẽ lần lượt liệt kê ra, nó sẽ đưa ra cái con số đếm Ví dụ như là 4 apple, dòng số 2 là có 4 apple, dòng số 3 là có 3 apple và cuối cùng nó sẽ ra được con số đúng là 11 apple Rồi, thì như vậy, GPT-4V ở đây là một cái ví dụ cho chúng ta thấy là nó có thể đưa ra, chúng ta có thể đưa vào các cái chỉ dẫn cộng với cái tấm ảnh Và cái chỉ dẫn này thì biết nó giống như là một cái câu prompt mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 18,
      "start_timestamp": "00:13:04",
      "end_timestamp": "0:13:55"
    }
  },
  {
    "page_content": "thì biết nó giống như là một cái câu prompt mà chúng ta trò chuyện với chatbot, chỉ dẫn cho nó biết là phải làm như thế nào để mà suy luận Thì đây chính là một cái ví dụ khi sử dụng GPT-4V giống như là chúng ta sử dụng với cái mô hình GPT-4o hoặc GPT-4 của nền tảng ChatGPT Rồi, cái In-context Few-Shot Learning thì ở đây là một cái ví dụ Zero-Shot Đại đa số mọi người khi mà làm việc thì đều hay sử dụng Zero-Shot, tại vì thứ nhất là họ nghĩ rằng cái mô hình của mình là tốt, cái mô hình của mình",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 19,
      "start_timestamp": "00:13:50",
      "end_timestamp": "0:14:37"
    }
  },
  {
    "page_content": "cái mô hình của mình là tốt, cái mô hình của mình là xịn Giờ đến đây là cái gì cũng biết, cái gì cũng biết Cái thứ hai là bản thân mình là cái người sử dụng thì mình cũng lười, mình lười hướng dẫn cho nó nhiều Thì đó là hai cái yếu tố khiến cho Zero-Shot là một trong những cái kỹ thuật được sử dụng rất là phổ biến Ví dụ trong ví dụ này là chúng ta đưa vào cái prompt là In which year had the highest average gas price ở trong tháng 6 Thì ở đây là mô hình trả lời sai là 3,3 đô Nếu mà chúng ta dùng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 20,
      "start_timestamp": "0:14:27",
      "end_timestamp": "0:15:39"
    }
  },
  {
    "page_content": "hình trả lời sai là 3,3 đô Nếu mà chúng ta dùng là Zero-Shot nhưng mà chúng ta kêu nó là think step by step thì kết quả của mình cũng sai Chỉ khi chúng ta đưa vào cái In-context Few-Shot, cụ thể ở đây là hai shot Thì cái In-context Few-Shot này có nghĩa là gì? Chúng ta sẽ cho nó một cái cặp câu hỏi Và ví dụ, câu hỏi ví dụ, cái đáp án thì nó sẽ bám theo cái cặp suy luận đó để mà nó trả lời cho những câu hỏi mới Ví dụ như ở đây là chúng ta hỏi, ở đây chúng ta sẽ đưa cho nó là chỉ dẫn thêm là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 21,
      "start_timestamp": "00:15:30",
      "end_timestamp": "0:16:24"
    }
  },
  {
    "page_content": "đây chúng ta sẽ đưa cho nó là chỉ dẫn thêm là cái đồ thị này Plot the National Gas Price, tức là plot giá gas ở trong nước là từ 2016 cho đến 2019 Rồi nó mô tả ra chi tiết là màu đỏ là gì, màu xanh là gì, màu xanh lá là gì, v.v. Rồi sau đó thì nó sẽ đưa ra tính toán là năm mà có cái High Gas Price là vào tháng 6 năm 2018 Thì ở đây là nó đưa ra những cái Few-Shot, tức là cái kết quả Vậy thì GPT nó đã dựa trên cái lập luận tương tự ở phía trên là với hai shot, đây là shot số 1 Đây là shot số 2 ở",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 22,
      "start_timestamp": "00:16:14",
      "end_timestamp": "0:17:10"
    }
  },
  {
    "page_content": "với hai shot, đây là shot số 1 Đây là shot số 2 ở phía bên dưới, nó sẽ còn một cái câu nữa Ví dụ thì khi chúng ta đưa vào một số liệu mới, ở trên là chúng ta cho ví dụ 2019, 2018 Và với số liệu mới này là 2023 thì nó sẽ tự động lập luận y chang như thế này để tìm ra được giá gas mà cao nhất là bao nhiêu Thì nó bắt chước hai cái shot ở phía trên cho một cái loại dữ liệu mới Và cái kết quả nó ra được đó là tháng 6 năm 2020, thì đó chính là cái hướng dẫn cho cái mô hình, cái cách thức để mà nó lập",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 23,
      "start_timestamp": "0:17:02",
      "end_timestamp": "0:17:49"
    }
  },
  {
    "page_content": "dẫn cho cái mô hình, cái cách thức để mà nó lập luận Và với Few-Shot hay còn gọi là In-context learning Như vậy tổng kết lại chúng ta đã cùng tìm hiểu qua các cái mô hình, mô hình ban đầu như là CLIP Và cho đến bây giờ thì vẫn được dùng nhiều, CLIP thì dùng nhiều cho bài toán là Zero-Shot Image Classification Sau đó chúng ta có phiên bản là GLIP, với cái sự cũng là Zero-Shot nhưng mà cho bài toán Detection Rồi nâng lên là có mô hình CLIP, sau đó là sẽ có Visual Programming Rồi cái mô hình mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 24,
      "start_timestamp": "0:17:43",
      "end_timestamp": "0:18:36"
    }
  },
  {
    "page_content": "đó là sẽ có Visual Programming Rồi cái mô hình mà chúng ta vừa mới tìm hiểu đó chính là GPT-4V Vậy thì cái việc mà chúng ta sẽ có cái nhận định gì khi chúng ta đã tìm hiểu qua các cái mô hình này Đó là cái việc mà chúng ta huấn luyện một cái mô hình từ đầu cho cái mô hình thị giác thì nó cần rất nhiều tài nguyên tính toán Cũng như là cái dữ liệu của chúng ta rất là lớn Nói vui đó là nhiều khi cái dữ liệu của mình nó lớn đến nỗi mà chúng ta không đủ dung lượng để chứa chứ đừng nói đến cái chuyện",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 25,
      "start_timestamp": "00:18:31",
      "end_timestamp": "0:19:06"
    }
  },
  {
    "page_content": "đủ dung lượng để chứa chứ đừng nói đến cái chuyện là chúng ta huấn luyện mô hình Tại vì quy mô nó lên đến Internet Scale Internet Scale Dataset Và do đó thì thông thường chúng ta sẽ sử dụng cái mô hình đã huấn luyện sẵn Nhưng mà quan trọng là chúng ta sẽ phải biết được cái công năng của từng mô hình, của từng phần trong mô hình là gì Ví dụ như khi chúng ta nhìn vào cái mô hình CLIP thì chúng ta biết cái mô hình nào là mô hình chúng ta sẽ sử dụng để cho cái công việc gọi là Unimodal encoding Và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 26,
      "start_timestamp": "0:18:48",
      "end_timestamp": "0:19:54"
    }
  },
  {
    "page_content": "để cho cái công việc gọi là Unimodal encoding Và khi nào thì chúng ta sẽ sử dụng cái mô hình, mà cross-modal hay là image-text, image-text là text matching Và khi nào thì chúng ta sẽ sử dụng cái language model ở phía sau để cho cái tác vụ là text generation Thì chúng ta biết được cái công năng của từng mô hình và dùng mô hình nào là phù hợp cho cái bài toán của chúng ta Cái thứ hai đó là phối hợp các cái thành phần huấn luyện sẵn đó cho cái bài toán của mình Ví dụ như chúng ta khai thác cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 27,
      "start_timestamp": "00:19:50",
      "end_timestamp": "0:20:35"
    }
  },
  {
    "page_content": "toán của mình Ví dụ như chúng ta khai thác cái module để mã hóa hình ảnh hoặc module mã hóa văn bản Tại vì cái việc mà chúng ta cho hình ảnh và văn bản tương tác với nhau để học ra được encoding thì nó sẽ giúp cho chúng ta có cái tính tổng quát, có cái tính tương tác và phân biệt được ngữ nghĩa một cách rõ ràng hơn so với việc chúng ta chỉ học dựa trên văn bản không hoặc chỉ học dựa trên hình ảnh không Và sử dụng các kỹ thuật Prompt Engineering một cách hiệu quả Ví dụ như chúng ta sử dụng cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 28,
      "start_timestamp": "0:20:26",
      "end_timestamp": "0:21:12"
    }
  },
  {
    "page_content": "một cách hiệu quả Ví dụ như chúng ta sử dụng cái In-context learning với kỹ thuật Few-Shot Prompting Chúng ta sẽ cho nó khoảng hai, ba ví dụ về cái instruction và cái instruction và cái kết quả của mình Thì kết quả, cái Result thì nó sẽ bắt chước cái instruction và cái Result này Khi chúng ta có một cái new instruction thì nó sẽ giúp cho chúng ta dự đoán ra được cái kết quả Nó sẽ đưa ra một cái kết quả dự đoán Thì đó là ý tưởng của In-context learning và đây là một trong những kỹ thuật dùng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 29,
      "start_timestamp": "0:21:04",
      "end_timestamp": "0:21:54"
    }
  },
  {
    "page_content": "learning và đây là một trong những kỹ thuật dùng cũng rất là phổ biến Rồi hướng dẫn mô hình suy luận một cách có hệ thống, chúng ta sẽ cho nó suy nghĩ theo kiểu step by step Rồi có thể chỉ dẫn cho nó chi tiết hơn là chúng ta sẽ chia nó ra thành bước 1, bước 2, bước 3 như thế nào Bước 1 chi tiết là sao? Càng đơn giản thì mô hình sẽ dễ thực hiện theo Rồi hướng dẫn cho nó cách suy luận Và cuối cùng đó là sử dụng Visual Pointer thì đây là một kỹ thuật để giúp cho chúng ta có thể hỗ trợ cho người",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 30,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "để giúp cho chúng ta có thể hỗ trợ cho người dùng Tạo ra một cái prompt một cách đơn giản và tự nhiên Chúng ta có thể tạo ra một cái visual pointer là dạng mũi tên, nó có thể là một cái box hoặc là một cái scribble như thế này Một cái đường mà zigzag Vậy thì trên đây đó là một vài cái mô hình đầu tiên khi nói về mô hình ngôn ngữ thị giác Trong những phần tiếp theo thì chúng ta sẽ nói về những cái mô hình hiện đại hơn, được train trên những dữ liệu lớn hơn Và phục vụ cho các cái bài toán mà",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 31,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "liệu lớn hơn Và phục vụ cho các cái bài toán mà chúng ta đã đề cập trước đây, ví dụ như bài toán segmentation Và bài toán sinh ngôn ngữ text generation Cụ thể đó là cái mô hình là LLaVA Còn đối với cái segmentation thì chúng ta có thể sử dụng hai cái mô hình, đó là SAM Grounding DINO Đây là hai cái mô hình Zero-Shot Segmentation Và mô hình SEEM là một cái mô hình tương tác đa thể thức Trong những phần tiếp theo chúng ta sẽ tìm hiểu về các cái mô hình này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zbR5lDFTKTM",
      "filename": "zbR5lDFTKTM",
      "title": "[CS315 - Chương 4] Vision - Language Model (1): Part 6",
      "chunk_id": 32,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ lựa chọn một phân bố xác suất prior tức là tiền nghiệm, là Normal Gaussian Tức là chúng ta có rất nhiều những dạng phân bố khác nhau, tuy nhiên một trong những phân bố rất phổ biến đó là phân bố chuẩn là Normal Gaussian Chúng ta mong muốn phân bố không gian ẩn của mình sẽ là một phân bố giống với phân bố Gauss Và cụ thể luôn là Normal Gaussian, tức là với mu là bằng 0 và sigma bình phương là bằng 1, thì đây là phân bố ẩn tiền nghiệm Và mình sẽ huấn luyện mô hình để cho Q của z cho",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:09"
    }
  },
  {
    "page_content": "Và mình sẽ huấn luyện mô hình để cho Q của z cho trước x với tham số phi là tuân theo phân bố Gauss Vì vậy, phân bố đồng đều sẽ xoay xung quanh tâm của không gian ẩn, ví dụ như chúng ta có một không gian ẩn thì mình sẽ tìm cách đưa nó về cùng một tâm với nhau Vì vậy, phân bố của mình sẽ xoay xung quanh tâm không gian ẩn, tức là mu bằng 0, khuyến khích cho đặc trưng phân bố đồng đều xoay xung quanh tâm không gian ẩn Vì vậy, phân bố đều sẽ xoay xung quanh tâm không gian ẩn, tức là nếu như ở trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:53",
      "end_timestamp": "0:02:09"
    }
  },
  {
    "page_content": "quanh tâm không gian ẩn, tức là nếu như ở trong mô hình autoencoder không có hình thông thường, thì mình sẽ tìm cách đưa nó về cùng một tâm Vì vậy, phân bố của mình sẽ xoay xung quanh tâm không gian ẩn, tức là nếu như ở trong mô hình autoencoder không có hình thông thường, thì mình sẽ tìm cách đưa nó về cùng một tâm Vì vậy, phân bố của mình sẽ xoay xung quanh tâm không gian ẩn, tức là mu bằng 0, khuyến khích cho đặc trưng phân bố đồng đều xoay xung quanh tâm không gian ẩn Vì vậy, phân bố của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:49",
      "end_timestamp": "0:03:11"
    }
  },
  {
    "page_content": "xung quanh tâm không gian ẩn Vì vậy, phân bố của mình sẽ tìm cách đưa nó về cùng một tâm Cái công thức khoảng cách độ lỗi giữa qi và p thì nó được tính như thế nào? Nó sẽ được tính dựa trên công thức KL divergence giữa hai phân phối Và khi chúng ta triển khai với p là bằng phân bố Normal Gauss là mu bằng 0 và sigma bình bằng 1, thì chúng ta sẽ có công thức đó là bằng một phần tổng của g chạy từ 0 cho đến k trừ 1 của sigma z cộng cho mu z bình phương trừ 1 Trừ cho log của sigma z, trong đó k",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:58",
      "end_timestamp": "0:04:14"
    }
  },
  {
    "page_content": "phương trừ 1 Trừ cho log của sigma z, trong đó k chính là số chiều của vector của mình K chính là số chiều của không gian ẩn Và khi đó nó cũng chính là số chiều của mu, nó cũng chính là số chiều của sigma luôn Rồi, khi chúng ta huấn luyện một mô hình VAE, thành phần chính quy hóa này nó khuyến khích cái chuyện gì? Đó là khi chúng ta cho cái loss này càng tiến về 0, tức là càng giảm Rõ ràng là với công thức này chúng ta sẽ thấy sigma z sẽ có xu hướng tiến về 0 Ngược lại, ở đây chúng ta thấy có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:04:07",
      "end_timestamp": "0:05:19"
    }
  },
  {
    "page_content": "hướng tiến về 0 Ngược lại, ở đây chúng ta thấy có cái dấu trừ log của sigma z, thì nó lại khuyến khích cái sigma này là không quá nhỏ Nó sẽ khuyến khích Cái sigma z không quá nhỏ Còn cái mu tiến về 0, tức là cái phân bố của mình, nó sẽ kéo từ một cái khu vực rất là xa, nó sẽ kéo về tiến về cái góc tọa độ 00 này Đây là một cái mu ban đầu, nó sẽ kéo cái mu này về góc tọa độ Rồi, đồng thời sigma z nếu như cái phân bố của mình nó quá lớn, thì nó sẽ kéo cho cái sigma này tiến về đủ nhỏ Nhưng nhờ có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:05:05",
      "end_timestamp": "0:06:01"
    }
  },
  {
    "page_content": "kéo cho cái sigma này tiến về đủ nhỏ Nhưng nhờ có cái log của sigma z này thì nó sẽ khiến cho cái sigma của mình không quá nhỏ Chứ còn nếu mà nó nhỏ quá thì có phải là thay vì chúng ta đưa về một phân bố thì cuối cùng nó sẽ đưa về một điểm không? Phân bố của mình nó sẽ tiến về một điểm, như vậy là nó tương tự như autoencoder rồi Như vậy thì cái sigma nó sẽ kéo về, đừng có quá lớn nhưng mà cũng đừng có quá nhỏ để hy vọng rằng là cái phân bố của mình nó thực sự là một cái phân bố có yếu tố ngẫu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:05:55",
      "end_timestamp": "0:06:35"
    }
  },
  {
    "page_content": "mình nó thực sự là một cái phân bố có yếu tố ngẫu nhiên Chứ còn nếu mà sigma mà tiến về bằng 0, tức là nó sẽ co về một điểm, tức là nó sẽ đưa về một cái mô hình deterministic, tức là một cái mô hình tất định Chứ không có yếu tố xác suất như trong cái mô hình VAE Thì với cái công thức này nó sẽ khuyến khích hai cái chuyện đấy, một đó là cái phân bố Q này sẽ tiến về 0, tiến về cái gốc tọa độ Cái thứ hai đó là mu z, nó sẽ tiến về một cái phân bố mà có cái độ lệch vừa đủ, chứ nó không có quá nhỏ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:06:26",
      "end_timestamp": "0:07:26"
    }
  },
  {
    "page_content": "mà có cái độ lệch vừa đủ, chứ nó không có quá nhỏ nhưng nó cũng không quá to Thì đây là cái công thức chính quy hóa Và chúng ta có những cái tính chất gì từ cái việc chính quy hóa này, nó sẽ có những tính chất gì Đầu tiên đó là cái tính liên tục, tức là những cái điểm gần nhau trong không gian thì nội dung hoàn toàn tương tự nhau khi giải mã Chúng ta đang nói đến cái ý này Thì ở bên trái là một cái mô hình không có được chính quy, tức là chúng ta chỉ có cái sai số giữa x trừ cho x mũ thôi Sai",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:07:09",
      "end_timestamp": "0:08:07"
    }
  },
  {
    "page_content": "ta chỉ có cái sai số giữa x trừ cho x mũ thôi Sai số tái tạo thôi, chỉ có sai số tái tạo Thì nếu không có thành phần chính quy hóa thì nó sẽ không đảm bảo được Thứ nhất đó là hai điểm gần nhau trong không gian ẩn, là cái điểm màu xanh lá mạ và màu đỏ ở đây thì nó gần nhau trong không gian tiền ẩn Nhưng khi mà giải mã thì nó không có tương tự nhau, ví dụ cái điểm màu xanh lá này, xanh lá mạ này thì nó sẽ ra hình vuông Trong khi cái điểm màu đỏ thì lại tạo ra một cái hình giống hình tam giác, thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:56",
      "end_timestamp": "0:08:33"
    }
  },
  {
    "page_content": "lại tạo ra một cái hình giống hình tam giác, thì hai cái hình này nó không có tương tự nhau, mặc dù hai cái điểm này nó gần nhau Cái thứ hai đó là đối với cái việc mà không chính quy hóa, nó sẽ có thể khiến cho cái điểm của cái không gian ẩn được giải mã nhưng mà không có ý nghĩa Ví dụ như ở đây chúng ta chỉ có hình tam giác, hình tròn, hình vuông, nhưng mà có một cái điểm ở đây là cái điểm mà nó không quá gần ba cái điểm này thì khi chúng ta giải mã nó ra một cái hình gì đấy mà nó không có ý",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:08:29",
      "end_timestamp": "0:09:12"
    }
  },
  {
    "page_content": "mã nó ra một cái hình gì đấy mà nó không có ý nghĩa Ví dụ như trong cái chữ số viết tay thì khi chúng ta decode ra lẽ ra nó phải ra là số, chữ số thì 0 cho đến 9 nhưng cuối cùng nó sẽ ra một cái gì đấy, nó không phải là con số Tức là một cái dữ liệu không có ý nghĩa, thì nếu như không có chính quy hóa nó sẽ khiến cho chúng ta bị hai cái vấn đề này Ngoài ra thì nhờ có chính quy hóa nó sẽ giúp cho chúng ta giải quyết được cái vấn đề đó, đó là cái tính liên tục của dữ liệu của cái điểm biểu diễn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "00:09:04",
      "end_timestamp": "0:09:59"
    }
  },
  {
    "page_content": "tính liên tục của dữ liệu của cái điểm biểu diễn trong không gian ẩn Thì hai cái vector z và z phải nằm trong không gian ẩn mà giống nhau, gần nhau thì khi decode ra nó cũng phải giống nhau Tính chất thứ hai, đó là tính đầy đủ là lấy mẫu từ không gian ẩn thì cái nội dung của mình nó sẽ phải có ý nghĩa, thì đây là một cái ví dụ này không có ý nghĩa Còn nếu như chúng ta sử dụng một cái mô hình chính quy hóa, tức là bên cạnh cái sai số tái tạo nó có thêm cái thành phần chính quy hóa là được biểu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:09:43",
      "end_timestamp": "0:10:20"
    }
  },
  {
    "page_content": "có thêm cái thành phần chính quy hóa là được biểu diễn bởi cái công thức là d của kl, đó là KL divergence của qi và p Cái này là viết tắt nha, thì các cái điểm gần nhau thì được giải mã tương tự và có ý nghĩa, ví dụ chúng ta thấy cái điểm màu cam và cái điểm màu tím thì hai cái hình này khi chúng ta giải mã thì chúng ta thấy cái dáng dấp nó cũng giống nhau Mặc dù cái điểm màu tím thì nó sẽ hơi bo ở đây một chút, hơi bo tròn, nhưng nếu xét về hình thù thì nó cũng gần giống với hình tam giác, do",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:09:59",
      "end_timestamp": "0:11:06"
    }
  },
  {
    "page_content": "thù thì nó cũng gần giống với hình tam giác, do đó thì hai cái điểm này khi chúng ta dạy nó sẽ có cái tính tương tự nhau và nó hoàn toàn là có ý nghĩa của nó, nó có cái lý do của nó Rồi, thì đây chính là cái sự khác biệt của việc có chính quy hóa và không có chính quy hóa khi chúng ta huấn luyện với cái mô hình VAE Thế thì một cái biểu diễn khác là sau khi chúng ta đã huấn luyện xong mô hình VAE, thì cái phân bố chuẩn tiền nghiệm sẽ đảm bảo được cái yếu tố về tính liên tục và tính đầy đủ Cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "0:10:59",
      "end_timestamp": "0:11:38"
    }
  },
  {
    "page_content": "cái yếu tố về tính liên tục và tính đầy đủ Cái tính liên tục nó thể hiện ở chỗ đó là những cái điểm nào mà gần nhau thì khi decode nó sẽ giống nhau và cái tính đầy đủ đó là mọi điểm của mình Trong cái không gian thì khi chúng ta decode ra nó đều có cái ý nghĩa của nó chứ không phải là một cái nội dung vô nghĩa Thì sau đây chúng ta sẽ nói có một cái ví dụ rõ hơn về cái chuyện này Chúng ta thấy ở đây có 3 cái phân bố màu đỏ màu xanh và màu vàng Thì ở đây là cái tâm cụm màu đỏ thì khi chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": "0:11:28",
      "end_timestamp": "0:12:24"
    }
  },
  {
    "page_content": "Thì ở đây là cái tâm cụm màu đỏ thì khi chúng ta decode ra nó sẽ ra cái hình tam giác Còn đây là tâm cụm của bồ màu xanh decode ra là ra hình tròn Thế thì một cái điểm ở lưng chừng ngay chính giữa tròn và tam giác thì chúng ta thấy cái hình này nó đều có cái ý nghĩa khá là phù hợp Đúng không? là cái hình này nó sẽ có cái bo tròn giống như cái hình tròn Nhưng đồng thời nó sẽ có cái nét thẳng, 3 cái nét thẳng Giống như tam giác Đó, thì cái điểm trung điểm này nó sẽ giống giống, nó sẽ giúp chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 16,
      "start_timestamp": "0:12:17",
      "end_timestamp": "0:13:02"
    }
  },
  {
    "page_content": "điểm này nó sẽ giống giống, nó sẽ giúp chúng ta tạo ra cái tính gọi là cái tính liên tục Và đồng thời nó cũng có ý nghĩa, nó cũng có ý nghĩa chứ không phải là không Nếu mà cái ở giữa này mà nó ra một cái điểm nào đó mà chúng ta không thể giải thích được thì đó là không có ý nghĩa Rồi khi chúng ta tiến càng gần hơn về cái tâm thì chúng ta thấy là cái tam giác nó bớt bo tròn đi Đúng không? nó bớt bo tròn đi Hay nói cách khác, đó là nó dần nó nhọn đi để giống cái tam giác này Còn khi mà cái điểm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 17,
      "start_timestamp": "0:12:54",
      "end_timestamp": "0:13:02"
    }
  },
  {
    "page_content": "đi để giống cái tam giác này Còn khi mà cái điểm này tiến về phía tâm của cầm thì chúng ta thấy nó sẽ càng lúc nó sẽ càng tròn trịa hơn Này, tròn, tròn hơn Tương tự như vậy cho các cái điểm còn lại, ví dụ như đây là trung điểm giữa hình tròn và hình vuông Thì chúng ta thấy cái hình này nó vừa có cái dáng dấp của hình vuông nhưng đồng thời nó sẽ có cái bo tròn Và nó sẽ có những cái bo tròn như thế này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZMtZ2jeujIU",
      "filename": "ZMtZ2jeujIU",
      "title": "[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Như vậy thì chúng ta đã cùng tìm hiểu về những phương pháp để tạo sinh hình ảnh tuy nhiên những phương pháp trên bao gồm VAE, Diffusion thậm chí là GAN đó là chúng ta sẽ khởi tạo ngẫu nhiên một vector Z và từ đó nó sẽ tạo ra một tấm hình của mình qua hàm decoder nhưng mà quá trình decoder này thì chúng ta không kiểm soát được đầu ra của mình thì trong thực tế chúng ta sẽ có những nhu cầu đó là làm sao để kiểm soát được ảnh đầu ra tạo ra những tấm ảnh mà chúng ta muốn với nội dung mà chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:00:53"
    }
  },
  {
    "page_content": "tấm ảnh mà chúng ta muốn với nội dung mà chúng ta muốn Vậy thì, cái phần điều hướng ảnh tạo sinh là một cái phần để giúp chúng ta trả lời được câu hỏi đó là Làm sao để sinh ảnh được từ văn bản? Văn bản chỉ là một trong những cách để giúp chúng ta điều hướng cái ảnh của mình Trên hình đó là quá trình sinh ảnh mà không có điều kiện Tức là với một vector Z ngẫu nhiên qua hàm decoder với tham số theta mà chúng ta đã huấn luyện thì nó sẽ giúp chúng ta tạo ra các hình ảnh, ví dụ như là chó, mèo, gấu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 1,
      "start_timestamp": "0:00:48",
      "end_timestamp": "0:01:39"
    }
  },
  {
    "page_content": "tạo ra các hình ảnh, ví dụ như là chó, mèo, gấu và bò nằm trong phân bố P theta X như thế này và quá trình sinh ảnh mà có điều kiện thì chúng ta sẽ đưa vào conditional signal, tức là một tín hiệu có điều kiện là I Ví dụ như trong ngữ cảnh này sẽ là a cat wearing sunglasses thì cái y này sẽ được đưa vào quá trình decoder tại mỗi step và khi đưa vào thì chúng ta sẽ điều hướng hoặc là bẻ lái thì đây là một cái từ mang tính hình tượng thôi đó là bẻ lái cái hướng Bình thường nếu như một cái vector z",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 2,
      "start_timestamp": "0:01:30",
      "end_timestamp": "0:02:08"
    }
  },
  {
    "page_content": "cái hướng Bình thường nếu như một cái vector z bất kỳ thì nó sẽ đưa đến cái khu vực ảnh mà ví dụ như có cái đối tượng không liên quan đến cái nội dung mình đang muốn Nhưng mà nhờ có conditional signal tham gia qua quá trình decode thì nó sẽ bẻ hướng để chúng ta đến vào khu vực ảnh mà có những con mèo đeo kính cool như thế này. Ở đây chúng ta sẽ có một mô hình để giúp chúng ta sinh ảnh có điều kiện. Ở đây là công thức của sinh ảnh không có điều kiện. Đối với sinh ảnh mà có điều kiện, chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 3,
      "start_timestamp": "0:02:01",
      "end_timestamp": "0:02:54"
    }
  },
  {
    "page_content": "Đối với sinh ảnh mà có điều kiện, chúng ta sẽ thêm vô một biến nữa là biến y. Đây chính là conditional signal. Đây là conditional signal. Sau này khi tổng quát lên, y này không nhất thiết phải là văn bản. nó có thể là một cái mask, nó có thể là một cái điểm v.v. thì công thức của chúng ta thay vì là S theta của Xt, t thì chúng ta sẽ thêm cái thành phần là y vào đây và khi đó thì cái St này sẽ xấp xỉ với lại cái gradient của log p Xt cho trước y Đây là conditional score Công thức trước là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 4,
      "start_timestamp": "0:02:44",
      "end_timestamp": "0:03:42"
    }
  },
  {
    "page_content": "y Đây là conditional score Công thức trước là unconditional score Bây giờ chúng ta sẽ chuyển sang conditional score chúng ta sẽ đưa vô một xác suất có điều kiện là i Chứ cho trước i, thì xác suất để tìm ra xt khi cho trước i là bao nhiêu? Chúng ta sẽ triển khai Và dựa trên định lý Bayes thì công thức này xuất phát từ triển khai như sau đó là cái log của Px t cho trước y thì nó sẽ là bằng log của Pxt cho trước y thì nó sẽ là bằng Pxt nhân với lại Pi cho trước xt tất cả chia cho Pi Với công thức",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 5,
      "start_timestamp": "0:03:35",
      "end_timestamp": "0:04:53"
    }
  },
  {
    "page_content": "Pi cho trước xt tất cả chia cho Pi Với công thức này, chúng ta sẽ triển khai ra và có được là bằng đạo hàm của log của PxT Nhân thì chúng ta sẽ đưa về dấu cộng, đó là cộng cho log của Py cho trước xT Chia thì chúng ta sẽ chuyển thành là dấu trừ cho log của Pi Với công thức này, chúng ta thấy là vì chúng ta đang muốn tính đạo hàm theo XT chúng ta đang tính đạo hàm theo XT Đây là đạo hàm theo XT Trong con mắt của XT, thì y của mình là hằng số Do đó chúng ta sẽ loại bỏ đi thành phần này đi Tại vì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 6,
      "start_timestamp": "0:04:46",
      "end_timestamp": "0:05:42"
    }
  },
  {
    "page_content": "chúng ta sẽ loại bỏ đi thành phần này đi Tại vì đạo hàm của một cái hằng số đối với xt thì nó sẽ là bằng 0 Do đó thì công thức này sẽ đưa về công thức ở trên Đó là log của pxt cộng cho log của pi cho trước xt Và với cái công thức này thì chúng ta sẽ thấy là cái xt của mình Khi chúng ta khôi phục, chúng ta decode Bình thường nó sẽ đi theo con đường này là Unconditioned là màu xanh lá Màu xanh lá tương ứng cho Unconditioned Bình thường nó sẽ đi theo đường màu xanh dương Và qua màu xanh lá thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 7,
      "start_timestamp": "0:05:36",
      "end_timestamp": "0:06:30"
    }
  },
  {
    "page_content": "theo đường màu xanh dương Và qua màu xanh lá thì chúng ta sẽ điều hướng đi qua mũi tên màu xanh và cộng 2 cái đó lại thì nó sẽ ra cái mũi tên màu cam. Thế thì bình thường là chúng ta sẽ đi theo cái con đường này. Nhờ có cái vector gradient của log y cho trước xt, nó bẻ lái để biến thành cái vector màu cam này. Chúng ta lưu ý ở đây nó sẽ có thêm một cái hệ số nữa, nó gọi là classifier guidance. Nếu như trong công thức chúng ta biến đổi ở phía trước là chúng ta không có cái gamma ở đây thì hàm ý",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 8,
      "start_timestamp": "0:06:22",
      "end_timestamp": "0:07:08"
    }
  },
  {
    "page_content": "là chúng ta không có cái gamma ở đây thì hàm ý đó là một cái Unconditional Score nó sẽ kết hợp với một cái Adversarial Gradient tức là cái vector điều hướng theo tỷ lệ đó là 1,1 nhưng mà chúng ta muốn nó nhanh điều hướng thì chúng ta sẽ tăng cái hệ số tỷ lệ đó lên hoặc là chúng ta muốn chậm lại thì chúng ta sẽ giảm cái hệ số tỷ lệ đó xuống Như vậy trong công thức này, gamma sẽ là hệ số để giảm tốc độ điều hướng của mình Vector màu cam sẽ là tổng hợp của vector màu đỏ trong điều kiện là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 9,
      "start_timestamp": "0:06:59",
      "end_timestamp": "0:08:01"
    }
  },
  {
    "page_content": "là tổng hợp của vector màu đỏ trong điều kiện là Unconditional Kết hợp với adversarial thì nó sẽ đưa ra, bẻ cái hướng, thay vì chúng ta đi theo hướng này để mà tìm được đến đây thì bây giờ nó bẻ hướng lại, nó sẽ đi theo cái hướng này để đến cái ảnh mà có cái điều kiện giống với lại cái Y của mình thì đó chính là cái Classifier Guidance thế thì cái mô hình này sẽ được thực hiện như thế nào Trước tiên chúng ta sẽ nói về vai trò của Classifier Guidance, tức là gamma hồi nãy của mình Nếu chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 10,
      "start_timestamp": "0:07:53",
      "end_timestamp": "0:08:43"
    }
  },
  {
    "page_content": "tức là gamma hồi nãy của mình Nếu chúng ta chọn gamma là bằng một, tức là dùng công thức gốc ban đầu Thì kết quả của mình sẽ không được điều hướng đủ tốt và đủ nhanh Dẫn đến là nó sẽ tạo ra những hình thù không có thật Tại sao không có thật? Tại vì nó vừa pha trộn của một cái ảnh, của một đối tượng có một đối tượng thật mà lẽ ra với vector Z tạo ra tạo ra cái x0 khi có sự tham gia của gamma vào thì gamma này nó bẻ lái nhưng nó bẻ chưa đủ nhanh dẫn đến đó là kết quả của mình nó tạo ra đối tượng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 11,
      "start_timestamp": "0:08:40",
      "end_timestamp": "0:09:17"
    }
  },
  {
    "page_content": "đến đó là kết quả của mình nó tạo ra đối tượng lai lai ở giữa đây là cái x0 còn đây là cái x0 mới thì lẽ ra là chúng ta hướng đến chỗ này nhưng mà cái gamma của chúng ta chưa đủ nên thay vì là nó bẻ lái bình thường là đến đây đúng không thì nó sẽ bẻ lái đến giữa chừng và ở cái khúc giữa chừng này thì nó tạo ra những tấm ảnh như thế này trong khi đó nếu chúng ta cho classifier guidance tức là cái gamma lớn hơn ví dụ như gamma trong trường hợp này bằng 10 thì nó sẽ bẻ lái mạnh hơn để mà nó đến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 12,
      "start_timestamp": "0:09:14",
      "end_timestamp": "0:09:59"
    }
  },
  {
    "page_content": "bằng 10 thì nó sẽ bẻ lái mạnh hơn để mà nó đến được đến cái xnew giống với lại cái nội dung mà chúng ta mong muốn đó là Pembroke Welsh Corgi Đây là một cái giống chó rất là hiếm Vậy thì quá trình sinh ở trên là quá trình sinh có điều kiện và nó có một cái Classifier Guidance Vậy thì chúng ta sẽ huấn luyện cái mô hình này như thế nào Thì cái cách thức huấn luyện đó là chúng ta sẽ có thêm một cái module chúng ta sẽ có thêm một cái mạng nữa, nó gọi là một cái Classifier hay còn gọi là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 13,
      "start_timestamp": "0:09:47",
      "end_timestamp": "0:10:41"
    }
  },
  {
    "page_content": "nữa, nó gọi là một cái Classifier hay còn gọi là Off-the-shelf Classifier Và cứ với mỗi cái i mà chúng ta đưa vào thì chúng ta sẽ đi huấn luyện cho một cái classifier như vậy là một cái i sẽ có một cái classifier riêng Và như vậy thì nó sẽ khiến cho cái mô hình của mình nó không có tính linh động Nó không có tính linh động vì khi chúng ta muốn tạo ra một cái đối tượng mới Bình thường chúng ta tạo ra 2 con mèo đeo kính, bây giờ chúng ta muốn tạo ra 1 con chó Welsh Corgi đeo kính chẳng hạn thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 14,
      "start_timestamp": "0:10:33",
      "end_timestamp": "0:11:28"
    }
  },
  {
    "page_content": "ra 1 con chó Welsh Corgi đeo kính chẳng hạn thì lúc đó chúng ta sẽ phải train 1 cái classifier mới cho cái y đó thì nó sẽ khiến cho cái mô hình của mình nó chạy không có tính thực tiễn cao do đó thì chúng ta sẽ chuyển sang 1 cái mô hình, nó gọi là cái mô hình mà sinh có điều kiện nhưng mà với Classifier Free Guidance, tức là không có classifier Vậy thì công thức của mình sẽ được sửa lại đó là bằng 1 trừ gamma nhân cho log của PXT thì đây là cái Unconditional Score kết hợp với Conditional Score",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 15,
      "start_timestamp": "0:11:22",
      "end_timestamp": "0:12:19"
    }
  },
  {
    "page_content": "Unconditional Score kết hợp với Conditional Score và ở đây chúng ta sẽ huấn luyện trên chính mô hình Diffusion của mình luôn Đây chính là U-Net trong diffusion. U-Net trong diffusion này chúng ta sẽ huấn luyện bằng cách đưa 2 tình huống. Tình huống thứ nhất là chúng ta sẽ đưa một vector rỗng vào. Mục tiêu của mình tương đương như một mô hình sinh ảnh nhưng mà không có điều hướng. và chúng ta sẽ đưa y vào, thì y này sẽ là mẫu dữ liệu huấn luyện của chúng ta và y này sẽ cho trước một số mẫu",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 16,
      "start_timestamp": "0:12:17",
      "end_timestamp": "0:13:02"
    }
  },
  {
    "page_content": "của chúng ta và y này sẽ cho trước một số mẫu condition mà chúng ta muốn huấn luyện để từ đó nó sẽ estimate ra cái x, xt, t, y Thứ nhất là chúng ta sẽ không có thêm, không có classifier mà chúng ta sẽ huấn luyện trên chính cái mô hình của diffusion của mình luôn trên chính cái decoder của mình luôn và khi chúng ta huấn luyện trên cái decoder này thì chúng ta sẽ có hai tình huống một đó là chúng ta sẽ truyền vô một cái condition là rỗng đây là một cái condition rỗng Mục tiêu của nó là tạo ra tấm",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 17,
      "start_timestamp": "0:12:52",
      "end_timestamp": "0:13:35"
    }
  },
  {
    "page_content": "cái condition rỗng Mục tiêu của nó là tạo ra tấm ảnh không có cần điều hướng và đưa vào 1 condition trong data set của mình để chuẩn bị trước, đó chính là y. Mục tiêu của mình là điều hướng đến cái này là không điều hướng, còn cái này là có điều hướng. sau khi chúng ta huấn luyện xong, chúng ta cứ sử dụng decoder này để đưa y vào và nó sẽ tạo sinh ra mô hình của mình thì cái sơ đồ này sẽ tương tự như nó sẽ lấy từ mô hình mà chúng ta đã học trong những slide trước bình thường là chúng ta chỉ đưa",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 18,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "những slide trước bình thường là chúng ta chỉ đưa vào xt và t, bây giờ chúng ta sẽ đưa vào thêm y nữa để làm được việc này thì chúng ta có thể sử dụng các mô hình của Transformer với attention sử dụng key-value của attention để điều hướng thì cái i này có thể là query",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=ZS8Ny8QSPQQ",
      "filename": "ZS8Ny8QSPQQ",
      "title": "[CS315 - Chương 3] Deep Generative Models (2) - Part 6 (Phần 1)",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Chúng ta sẽ xem cái ma trận W này có cái giá trị là bao nhiêu Chúng ta sẽ thấy là cái W này sẽ là một cái Array, là một cái List bao gồm hai phần tử Thì phần tử đầu tiên chính là cái số trọng số, số filter của phép biến đổi Convolution đầu tiên Và thành phần thứ hai chính là cái BIAS, tại vì chúng ta có sử dụng BIAS W0 chính là cái trọng số của mình Rồi để xem coi cái trọng số này có kích thước bao nhiêu Chúng ta là chấm shape, trong đó 3, 3, 1, 6, 3, 3 chính là cái kích thước của cái channel Và",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:02"
    }
  },
  {
    "page_content": "3, 3 chính là cái kích thước của cái channel Và 1 chính là cái input, dimension của input của đầu vào của mình, nó chỉ có một channel thôi Nó sẽ là một, và output của mình sẽ là 6, 6 cái filter Vậy thì để trực quan, chúng ta sẽ có số filter là 6, rồi chúng ta sẽ duyệt qua Y từ 0 cho đến 5 để truyền vô đây Rồi đây là W0, W0.shape chính là 3, 3, 1, 6, thì chúng ta sẽ lấy cái chỉ số Y chạy ở đây trước Rồi sau đó lấy chỉ số Z chạy ở đây, thì ở đây một cách tổng quát trong cái lớp Convolution số 2",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:56",
      "end_timestamp": "0:01:39"
    }
  },
  {
    "page_content": "một cách tổng quát trong cái lớp Convolution số 2 Rồi sau đó thì số 1 này sẽ chuyển thành là số 16, do đó thì ở đây chúng ta sẽ để là Y chạy cho một cái rank Rank này thì ở đây chúng ta để là 1, nhưng mà sắp tới có thể để là 16 Đây chính là 6 cái filter ở cái lớp đầu tiên, thì chúng ta có thể hiểu cái ý nghĩa của cái filter này Đây chính là chúng ta lấy cái sai số, cái sự chênh lệch của cái vùng phía bên phải, phía dưới so với lại cái vùng ở phía trái bên trên Ý nghĩa của filter này đó là lấy",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:31",
      "end_timestamp": "0:02:15"
    }
  },
  {
    "page_content": "trái bên trên Ý nghĩa của filter này đó là lấy cái sự chênh lệch giữa cái hàng ở giữa so với lại hai cái hàng ở phía trên và phía dưới Thì mỗi một cái filter này nó sẽ thể hiện một cái đặc trưng nào đó Rồi tiếp theo là chúng ta sẽ tiến hành thử nghiệm với một số cái biến thể khác nhau Trước khi qua thử nghiệm một số biến thể khác nhau thì chúng ta sẽ thử cái hàm Predict Cái hàm Predict thì CNN.Predict Rồi, thì chúng ta sẽ truyền vào cái istat và mẫu dữ liệu thứ, ví dụ như là mẫu dữ liệu thứ 300",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:11",
      "end_timestamp": "0:03:10"
    }
  },
  {
    "page_content": "mẫu dữ liệu thứ, ví dụ như là mẫu dữ liệu thứ 300 Rồi Ok, ở đây thì hàm Predict, chúng ta sẽ xem lại cái hàm Predict của mình Truyền vào cell.model.istat, ok, bây giờ chúng ta sẽ xem tiếp cái istat của mình đã được load rồi và đã được chuẩn hóa rồi, đúng không? Rồi Ok, bây giờ chúng ta sẽ thử truyền vào như thế này Rồi, chúng ta sẽ xem cái istat của mình Rồi, ah, istat của mình là cái mạng kích thước là 28 x 28, do đó chúng ta phải reset, chúng ta phải reset nó về cái dạng là 28 x 1 Rồi sau đó",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:02:54",
      "end_timestamp": "0:04:21"
    }
  },
  {
    "page_content": "ta phải reset nó về cái dạng là 28 x 1 Rồi sau đó chúng ta mới đưa vào để cho cái mô hình của mình có thể Predict được, CNN.Predict Rồi Cũng chưa được ha Rồi, ah, ở đây cái số này sẽ phải để lên trước, đúng không? Cái này nó sẽ phải để lên trước, dạ là 1,28 Ok, được rồi, tức là nó sẽ phải để cái chỉ số của cái thứ tự lên trước, nó sẽ hơi ngược, hơi ngược Rồi, bây giờ chúng ta sẽ thử xem cái nhãn này nó sẽ ra cái giá trị là bao nhiêu? Tại vì ở đây nó chỉ trả ra 1 cái vector one-hot, chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:04:10",
      "end_timestamp": "0:05:20"
    }
  },
  {
    "page_content": "nó chỉ trả ra 1 cái vector one-hot, chúng ta sẽ phải có thêm 1 cái hàm nữa đó là argmax là np.argmax Rồi, nó sẽ là 4 Và bây giờ chúng ta sẽ xem coi cái mẫu thứ 300 này, x, y, test của mình, thứ 300 nó là bằng bao nhiêu? Nó là 4 Rồi, bây giờ chúng ta sẽ thử những cái mẫu khác ha, chúng ta sẽ thử những cái mẫu khác, ở đây chúng ta sẽ để là Predict Rồi Rồi, ở đây sẽ là nhãn dự đoán là Predict Rồi, còn ở đây sẽ là nhãn thực tế Và ở đây, cái chỉ số này chúng ta sẽ tham số hóa nó là idx là bằng 100,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:05:12",
      "end_timestamp": "0:06:23"
    }
  },
  {
    "page_content": "chúng ta sẽ tham số hóa nó là idx là bằng 100, và chúng ta sẽ để đây là idx Rồi, thì đại đa số chúng ta thấy là cái độ chính xác rất là cao, chúng ta thử rất nhiều những cái nhãn khác nhau ha Thì nó đều ra là dự đoán và thực tế khớp nhau Bây giờ, trong cái mạng CNN thì chúng ta thấy nó có rất nhiều những cái module khác nhau Và tại thời điểm hiện tại thì chúng ta sẽ chưa hiểu rõ cái vai trò của từng module này Do đó thì chúng ta sẽ làm một cái thí nghiệm, nó gọi là Ablation Study với các cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:06:17",
      "end_timestamp": "0:06:53"
    }
  },
  {
    "page_content": "thí nghiệm, nó gọi là Ablation Study với các cái biến thể khác nhau Bằng cách, đó là chúng ta sẽ lần lượt thay đổi một số cái cấu hình của cái chương trình của mình Chúng ta sẽ thay đổi một số cái cấu hình Thì cái biến thể đầu tiên, đó là chúng ta sẽ bỏ đi cái thay cái hàm sigmoid bằng relu Chúng ta sẽ thay cái sigmoid bằng relu, như vậy thì chúng ta sẽ copy cái code ở đây đem xuống Rồi, chúng ta sẽ đem lên cái hàm này thay cái sigmoid bằng relu Như vậy thì bản chất là cái biến thể này chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:06:48",
      "end_timestamp": "0:07:57"
    }
  },
  {
    "page_content": "Như vậy thì bản chất là cái biến thể này chúng ta không cần phải cài đặt lại Mà chúng ta chỉ sửa cái tham số của mình thôi Chúng ta chỉ sửa cái tham số khi gọi cái hàm build thôi Rồi, và ở đây là relu Sau đó thì chúng ta sẽ tiến hành là cnn.train, X_train, y_train, oh Và lưu ý ở đây chúng ta sẽ để cái history là history số 2 Rồi, bây giờ chúng ta sẽ tiến hành build cái này Và tranh thủ trong thời gian chờ đợi thì chúng ta sẽ thử Viết code trước cho cái phần là vẽ cái giá trị loss Chúng ta sẽ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:07:52",
      "end_timestamp": "0:08:59"
    }
  },
  {
    "page_content": "cho cái phần là vẽ cái giá trị loss Chúng ta sẽ thêm một cái đường nữa đó là history số 2 Rồi, và ở đây sẽ là train loss v1 Đây sẽ là train loss v2, trong đó v2 đó là dùng relu Rồi, tương tự như vậy, bây giờ chúng ta sẽ chờ đợi Chúng ta sẽ viết trước cái code cho các biến thể tiếp theo Biến thể bỏ hết các lớp pooling thì chúng ta làm cũng rất là nhanh Pooling đúng không? Thì chúng ta sẽ bỏ, xóa đi Và lưu ý đó là phải để gối đầu các cái biến Ví dụ như ở đây c1 thì sẽ được truyền trực tiếp sang",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:08:55",
      "end_timestamp": "0:09:53"
    }
  },
  {
    "page_content": "dụ như ở đây c1 thì sẽ được truyền trực tiếp sang đây Rồi c3 thì sẽ truyền trực tiếp sang đây Vì vậy là chúng ta đã xong cái biến thể số 3 Chúng ta sẽ để là cnn v3 Rồi, bây giờ chúng ta sẽ cài cho cái biến thể cuối cùng Ok, ở đây khi bỏ cái relu thì chúng ta thấy là nó đã chạy xong rồi Và chúng ta sẽ quan sát thử Ok, chúng ta sẽ vẽ Thì nhìn vào cái sơ đồ này Ok, ở đây chúng ta sẽ phải gom nó lại Gom 2 cái legend này lại Rồi, vẽ lại Rồi, chúng ta sẽ thấy là cái relu phiên bản số 2 Nó giảm rất là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "0:09:49",
      "end_timestamp": "0:10:31"
    }
  },
  {
    "page_content": "sẽ thấy là cái relu phiên bản số 2 Nó giảm rất là nhanh, đúng không? Nó giảm rất là nhanh Nó nằm bên dưới cái đường màu xanh Thì điều đó có nghĩa là gì? Điều đó là, ví dụ tại cái epoch số 5 Thì cái phương pháp v2, tức là khi sử dụng relu Nó cho cái loss thấp hơn so với cái phiên bản số 1, tức là dùng sigmoid Tức là nó đã giúp cho mình hội tụ nhanh hơn Nhưng mà đương nhiên, khi số epoch càng lớn thì cả 2 thằng cũng sẽ tiệm cận về Nhưng mà nó sẽ tốn thời gian hơn Thì tập MNIST là tập rất tuyến",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:10:25",
      "end_timestamp": "0:11:12"
    }
  },
  {
    "page_content": "tốn thời gian hơn Thì tập MNIST là tập rất tuyến tính, rất là dễ, rất là đơn giản Nó sẽ không thể nào thể hiện được cái sự khuếch đại Cái tốc độ mà train của relu nhanh hơn so với sigmoid như thế nào Khi chúng ta train với tập dữ liệu lớn như MNIST, thì chúng ta sẽ thấy rõ relu hiệu quả hơn rất là nhiều Rất là nó sẽ giảm xuống, chúng ta sẽ thấy sự sụt giảm về loss của nó rất là nhanh Thì đó chính là ý nghĩa của biến thể đầu tiên Đó là bỏ sigmoid và thay thế là bằng relu, thì tốc độ hội tụ của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:11:04",
      "end_timestamp": "0:12:18"
    }
  },
  {
    "page_content": "và thay thế là bằng relu, thì tốc độ hội tụ của nó sẽ nhanh hơn Còn về độ chính xác, theo thời gian dài, đâu đó nó vẫn sẽ xấp xỉ với sigmoid Nhưng mà với thời gian mà mình có thể chờ đợi được để có thể huấn luyện, thì việc dùng sigmoid sẽ chậm hơn rất là nhiều Tiếp theo, đó là chúng ta sẽ bỏ hết các lớp pooling Rồi, chúng ta đã cài đặt rồi Và bây giờ chúng ta sẽ sử dụng nó Rồi, ở đây chúng ta sẽ để là CNN v3 và History ở đây sẽ là History số 3 Rồi, ở đây chúng ta sẽ khôi phục ngược trở lại,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "0:12:14",
      "end_timestamp": "0:13:08"
    }
  },
  {
    "page_content": "3 Rồi, ở đây chúng ta sẽ khôi phục ngược trở lại, chúng ta sẽ khôi phục ngược trở lại là sigmoid Rồi, chạy Rồi, bây giờ chúng ta sẽ vẽ hàm loss khi có đồng thời cả 3 cái History 123 Rồi v3 thì ở đây sẽ là without pooling Without pooling Rồi, chúng ta có thể thu gọn lại một chút xíu Rồi, tranh thủ trong khi chờ đợi thì chúng ta sẽ cài luôn cái phiên bản thứ 4 Cái phiên bản này, đó chính là chúng ta bỏ hết các lớp convs Một điều rất là thú vị đó là chúng ta đặt sự nghi ngờ rằng là cái mạng convs",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": "0:13:01",
      "end_timestamp": "0:13:55"
    }
  },
  {
    "page_content": "chúng ta đặt sự nghi ngờ rằng là cái mạng convs thì cái vai trò của convs rõ ràng rất là lớn Nhưng bây giờ chúng ta sẽ làm một thí nghiệm đó là bỏ hết cái convs thì xem điều gì sẽ xảy ra Thì đó chính là chỉ ý nghĩa của cái phiên bản số 4 Rồi, bây giờ may quá cái phiên bản số 3 nó đã chạy xong và chúng ta sẽ xem thử Rồi, chúng ta thấy là nếu như không có cái pooling thì cái loss của mình gần như không giảm, nó cứ giữ nguyên Ah, loss gần như không giảm, nó cứ giữ nguyên Rõ ràng là cái vai trò của",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 16,
      "start_timestamp": "0:13:47",
      "end_timestamp": "0:15:21"
    }
  },
  {
    "page_content": "giảm, nó cứ giữ nguyên Rõ ràng là cái vai trò của pooling cũng rất là quan trọng Nếu không có pooling thì cái loss của mình gần như là đi ngang, nó không giúp cho mình giảm xuống Rồi Ok, bây giờ chúng ta sẽ qua cái phiên bản tiếp theo, đó là không có cái lớp convs Ở đây chúng ta phải sử dụng cái biến thể đầu tiên để mình code, chứ nếu không là sẽ nhầm lẫn Rồi, không có convs chúng ta sẽ bỏ đi lớp này, bỏ đi lớp này Rồi, và ở đây chúng ta sẽ truyền vào là input, S2 sẽ truyền vào đây Tức là chúng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 17,
      "start_timestamp": "0:15:07",
      "end_timestamp": "0:15:58"
    }
  },
  {
    "page_content": "vào là input, S2 sẽ truyền vào đây Tức là chúng ta sẽ giảm cái kích thước liên tiếp 2 lần Rồi, ok, ở đây sẽ là CNN v4 Rồi, bây giờ chúng ta sẽ gọi cái hàm này khởi tạo để là v4, history là 4 Ah, run Và tương tự như vậy chúng ta sẽ vẽ cái chart ở đây Rồi, chúng ta sẽ có history là 4 Train loss ở đây sẽ là v4, without convolution Rồi, chúng ta thấy là cái loss của mình cũng có giảm, tuy nhiên cái tốc độ giảm của nó khá là chậm Tốc độ giảm khá chậm, thì điều này cũng minh chứng là cái việc là cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 18,
      "start_timestamp": "0:15:49",
      "end_timestamp": "0:16:31"
    }
  },
  {
    "page_content": "thì điều này cũng minh chứng là cái việc là cái convolution của mình đã giúp cho cái việc huấn luyện nhanh hơn Mặc dù accuracy thì nó cũng có xu hướng là nó càng lúc càng tăng, đúng không? Nếu không có convolution, tốc độ nó sẽ chậm hơn rất nhiều Rồi, cái đường màu đỏ là v4, thì chúng ta thấy là nó nằm ở phía trên, nếu không có convolution thì nó sẽ nằm phía trên Vì vậy, cái phiên bản mà hoàn thiện nhất của chúng ta chính là cái phiên bản màu cam ở đây, là đường nằm ở dưới cùng Tương ứng phiên",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 19,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "ở đây, là đường nằm ở dưới cùng Tương ứng phiên bản số 2 là thay cái sigmoid bằng relu, trong đó vẫn phải giữ vừa có pooling và vừa có convolution Như vậy, đây chính là cái bài tập tutorial để giúp chúng ta hiểu được vai trò của từng phép biến đổi ở bên trong mạng CNN Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=zxd9u6PjOtw",
      "filename": "zxd9u6PjOtw",
      "title": "[CS315 - Chương 2] Tutorial - CNN (Phần 2)",
      "chunk_id": 20,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "Tiếp theo, chúng ta sẽ cùng tiến hành ôn tập một trong những kiến thức toán nền tảng rất quan trọng trong môn này, đó chính là đại số tuyến tính. Tại sao chúng ta cần phải tìm hiểu về đại số tuyến tính? Vì nó giúp chúng ta có được công cụ để chúng ta có thể biểu diễn được dữ liệu. Cái thứ hai là một công cụ để giúp chúng ta có thể biến đổi dữ liệu từ cái dạng này sang dạng khác. Và hay nói trong ngôn ngữ của không gian đại số tuyến tính thì chúng ta biến đổi từ không gian này sang một không gian",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 0,
      "start_timestamp": "0:00:14",
      "end_timestamp": "0:01:08"
    }
  },
  {
    "page_content": "ta biến đổi từ không gian này sang một không gian khác. Còn trong chủ đề về mô hình máy học thì nó sẽ biến đổi từ đặc trưng từ dạng này sang dạng khác. Từ đặc trưng đơn giản lên đặc trưng vừa, đặc trưng vừa lên đặc trưng cấp cao. Nhờ cái công cụ là đại số tuyến tính. Vậy thì đầu tiên chúng ta sẽ tìm hiểu về các khái niệm cơ bản trong đại số tuyến tính, đó chính là khái niệm về tensor. Khi nói tensor thì chúng ta có thể nâng từ số chiều từ không chiều cho đến nhiều chiều. Thì tensor không chiều",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 1,
      "start_timestamp": "0:00:52",
      "end_timestamp": "0:01:47"
    }
  },
  {
    "page_content": "chiều cho đến nhiều chiều. Thì tensor không chiều tương đương với một cái giá trị scalar để biểu diễn cho những cái đại lượng vô hướng. Ngoài ra thì chúng ta sẽ có cái tensor một chiều để biểu diễn cho dạng là vector. Vector sẽ là tập hợp của các giá trị vô hướng là scalar. Thì đây là một cái tensor. Nếu mà dùng để biểu diễn dữ liệu thì có thể dùng để biểu diễn các thuộc tính hoặc các đặc trưng của một đối tượng nào đó. Và khi chúng ta nâng nó lên từ một chiều lên hai chiều thì nó tương đương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 2,
      "start_timestamp": "0:01:40",
      "end_timestamp": "0:02:29"
    }
  },
  {
    "page_content": "lên từ một chiều lên hai chiều thì nó tương đương với việc chúng ta lấy nhiều cái tensor 1D ghép lại với nhau. Ví dụ như trong hình này thì chúng ta thấy là nó sẽ ghép các cái cột này lại. Và mỗi một cái đặc trưng này thì nó sẽ là một đối tượng. Như vậy thì hoặc là một đặc trưng, một loại đặc trưng. Như vậy thì toàn bộ cái ma trận này hay còn gọi là 2D tensor này sẽ là một tập hợp các cái đối tượng hoặc là một tập hợp các cái đặc trưng. Và khi chúng ta nâng lên là ba chiều thì chúng ta sẽ có",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 3,
      "start_timestamp": "0:02:25",
      "end_timestamp": "0:03:08"
    }
  },
  {
    "page_content": "chúng ta nâng lên là ba chiều thì chúng ta sẽ có các cái lát cắt khác nhau. Ví dụ như mỗi một cái lát cắt này sẽ là một tập hợp các cái đặc trưng. Ghép các cái lát cắt đó lại với nhau thì chúng ta sẽ có một tensor ba chiều. Và nhiều cái tensor ba chiều chồng lên thì chúng ta sẽ có 4D. Rồi cứ như vậy thì chúng ta lại nối, thì chúng ta thấy cái quy luật này nó sẽ cứ lặp đi lặp lại để chúng ta có thể trực quan hóa được cái dữ liệu của mình. Thì chúng ta sử dụng cái tensor. Và đây là một trong",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 4,
      "start_timestamp": "0:03:03",
      "end_timestamp": "0:03:46"
    }
  },
  {
    "page_content": "chúng ta sử dụng cái tensor. Và đây là một trong những cái công cụ rất là hiệu quả. Nhưng mà thông thường trong lập trình thì thường chúng ta sẽ dùng đến 4D tensor. Thường chúng ta sẽ dùng đến một cấp độ là 4D tensor. Trong đó cái chiều đầu tiên có thể là cái chiều về số lượng cái mẫu dữ liệu của mình. Ví dụ như là batch size, tức là cái kích thước dữ liệu của mình. Sau đó là chúng ta sẽ đến cái chiều độ sâu, depth. Thì ở đây chính là cái số đặc trưng của mình. Số đặc trưng của một cái layer.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 5,
      "start_timestamp": "0:03:39",
      "end_timestamp": "0:04:22"
    }
  },
  {
    "page_content": "trưng của mình. Số đặc trưng của một cái layer. Sau đó sẽ đến là width và height. Tương ứng là hai cái chiều không gian của mình. Chiều ngang và chiều cao trong chiều trục không gian của mình. Thì đây là một cái dạng biểu diễn hoặc ứng dụng của 4D tensor khi chúng ta áp vào bên trong cái dữ liệu khi huấn luyện với các môn học sâu. Ngoài ra thì chúng ta sẽ có một số cái phép toán. Cái phép toán đầu tiên và được sử dụng rất là nhiều đó chính là phép chuyển vị. Mục tiêu của cái phép chuyển vị này",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 6,
      "start_timestamp": "0:04:12",
      "end_timestamp": "0:04:53"
    }
  },
  {
    "page_content": "chuyển vị. Mục tiêu của cái phép chuyển vị này đó là để biến các cái vector dạng cột của ma trận thành dòng. Biến từ cột thành dạng dòng hoặc ngược lại. Ví dụ như ma trận A chúng ta đang ở dạng cột chúng ta sẽ biến nó thành dòng. Thì mục tiêu của cái việc là chuyển về cái dạng chuyển vị để phục vụ cho cái việc là tương tác nhân giữa các cái vector với nhau. Hoặc là nhân giữa các cái ma trận với nhau. Sao cho nó đồng bộ. Tiếp theo đó là cái phép cộng vector. Thì việc cộng vector nó cũng khá là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 7,
      "start_timestamp": "0:04:45",
      "end_timestamp": "0:05:32"
    }
  },
  {
    "page_content": "cộng vector. Thì việc cộng vector nó cũng khá là đơn giản. Chúng ta sẽ cộng theo từng phần tử. Ví dụ như ở đây chúng ta có x2 và y2 thì cộng cho cái phần tử x2 và y2 chúng ta sẽ ra được cái vector mới như thế này. Và chiếu trong cái không gian thì cái vector x của mình và vector y thì khi chúng ta cộng lại nó sẽ biến thành một cái vector khác. Ví dụ như đây là x cộng y. Vector x cộng y này hiểu một cách nôm na. Ý nghĩa của nó là vector x là đặc trưng ban đầu. Nó sẽ bị điều hướng và chuyển hướng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 8,
      "start_timestamp": "0:05:29",
      "end_timestamp": "0:06:22"
    }
  },
  {
    "page_content": "ban đầu. Nó sẽ bị điều hướng và chuyển hướng sang một cái hướng khác. Vector y ở đây chúng ta sẽ tương đương với việc chúng ta đưa vector y lên. Và khi đó x cộng y thì nó đã bị điều hướng về hướng tại vị trí mới là ở đây. Y là giống như là một vector để chúng ta thay đổi hướng. Cái này trong vật lý chúng ta thấy dùng rất là nhiều. Trong máy học thì cũng vậy. Các phép cộng hai ma trận và hai vector. Phép cộng ma trận thì nâng số chiều lên thay vì chúng ta cộng trên hai tensor một chiều, tức là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 9,
      "start_timestamp": "0:06:14",
      "end_timestamp": "0:06:52"
    }
  },
  {
    "page_content": "chúng ta cộng trên hai tensor một chiều, tức là vector. Thì chúng ta sẽ cộng hai tensor hai chiều. Và chúng ta cũng sẽ cộng theo element-wise, tức là cộng theo từng phần tử. Thì chúng ta sẽ lấy phần tử này, cộng với phần tử này để cộng với phần tử này. Thì chúng ta sẽ lấy phần tử này, cộng với phần tử này để ra được phần tử ở đây. Là thực hiện theo đúng thứ tự và vị trí. Tương tự như vậy thì chúng ta sẽ có phép tích Hadamard cho từng phần tử. Tức là lấy tại một vị trí, nhân với một vị trí tương",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 10,
      "start_timestamp": "0:06:48",
      "end_timestamp": "0:07:32"
    }
  },
  {
    "page_content": "là lấy tại một vị trí, nhân với một vị trí tương ứng. Sau đó sẽ ra được giá trị tại vị trí đó. Nhân element-wise. Và khi đó thì kích thước của ma trận Output của mình sẽ là giống như là một phần tử. Giống với lại cái kích thước của hai ma trận Output vào. Thì cái phép này hiểu một cách nôm na là chúng ta đang đi nhân từng phần tử và chúng ta sẽ nhân trọng số. Ví dụ như ma trận A là một đặc trưng gốc. Đây là đặc trưng gốc. Còn ma trận B tương ứng là một trọng số. Thể hiện cái vai trò của từng",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 11,
      "start_timestamp": "0:07:26",
      "end_timestamp": "0:08:09"
    }
  },
  {
    "page_content": "là một trọng số. Thể hiện cái vai trò của từng đặc trưng ở trên ma trận A. Thế thì khi chúng ta lấy cái đặc trưng A này, chúng ta nhân với lại cái trọng số tại vị trí này. Để tạo ra một cái đặc trưng mới có cái sự gia giảm về cái việc mà tính toán. Ví dụ như đặc trưng này. Mình nhân với một cái hệ số là bằng 0 đi. Mình nhân với một cái trọng số là bằng 0. Thì cái kết quả ra ở đây sẽ là bằng 0. Thì hàm ý đó là cái đặc trưng ở đây sẽ không được sử dụng. Nhưng nếu ví dụ ở đây chúng ta có một cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 12,
      "start_timestamp": "0:08:06",
      "end_timestamp": "0:08:48"
    }
  },
  {
    "page_content": "dụng. Nhưng nếu ví dụ ở đây chúng ta có một cái đặc trưng và trọng số ở đây là bằng 1. Thì hàm ý đó là chúng ta sẽ lấy toàn bộ cái đặc trưng này. Vào đây, chép qua đây. Còn nếu như cái trọng số của chúng ta là 0.5. Thì tức là chúng ta chỉ lấy 50% cái lượng thông tin tại cái vị trí này để chép qua đây. Thì ý nghĩa về mặt tương tác trong máy tính trong mô hình máy học. Đó là có thể là một cái phép nhân trọng số từng phần tử. Rồi khi chúng ta nói đến cái phép nhân thì chúng ta phải chú ý. Đó là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 13,
      "start_timestamp": "0:08:45",
      "end_timestamp": "0:09:27"
    }
  },
  {
    "page_content": "đến cái phép nhân thì chúng ta phải chú ý. Đó là cái phép vừa rồi là tích phần tử từng phần tử. Còn bây giờ chúng ta sẽ có cái khái niệm nhân nữa. Nhưng mà nhân theo kiểu là phép chiếu. Thì đây chính là một cái phép chiếu. Bản chất của đó là một phép chiếu. Ví dụ, chúng ta nhân vô hướng 2 cái vector. Cái này còn có một cái từ khóa khác gọi là dot và dot. Thì bản chất của cái phép nhân A, Máy vector A với vector B, Trong cái không gian n chiều, Vector này gồm có n chiều. Về mặt tính toán thì",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 14,
      "start_timestamp": "0:09:24",
      "end_timestamp": "0:10:10"
    }
  },
  {
    "page_content": "Vector này gồm có n chiều. Về mặt tính toán thì chúng ta sẽ lấy từng phần tử nhân. Nhưng mà sau đó chúng ta sẽ đi cộng lại hết lại với nhau. Để ra một cái tổng. Và đây sẽ là một cái giá trị là scalar. Và ý nghĩa về mặt đại số của nó đó là gì? Vector A và vector B ở đây thì chúng ta sẽ chiếu A xuống B. Chiếu A xuống B. Và được một cái điểm này. Thì cái giá trị tích vô hướng của A và B chính là cái độ dài của đoạn thẳng. Ví dụ đây là OH, đây là H. Của OH nhân với lại OB. Đây là OA. Thì nó sẽ là",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 15,
      "start_timestamp": "0:10:06",
      "end_timestamp": "0:10:49"
    }
  },
  {
    "page_content": "Của OH nhân với lại OB. Đây là OA. Thì nó sẽ là bằng OH nhân với lại OB. Và nó sẽ là một cái giá trị scalar. Thì ở một góc độ khác, Cái phép tích vô hướng này có thể hiểu là cái sự tương đồng giữa hai vector A và B. Nếu như hai vector A và B lớn thì cái độ tương đồng của nó sẽ cao. Còn ở một cái góc độ đặc trưng, Chúng ta đang chuyển đổi từ một cái điểm A chiếu xuống dưới một cái điểm B để đưa về cái không gian của B. Và chúng ta có một chú ý đó là A chiếu lên B cũng là bằng B chiếu xuống A. Do",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 16,
      "start_timestamp": "0:10:42",
      "end_timestamp": "0:11:31"
    }
  },
  {
    "page_content": "là A chiếu lên B cũng là bằng B chiếu xuống A. Do đó A chuyển vị nhân B sẽ là bằng B nhân A. Sau đó chúng ta nâng cấp lên. Đó là phép nhân giữa ma trận với lại vector. Thay vì chúng ta thực hiện giữa vector với vector, Bây giờ chúng ta sẽ làm hàng loạt. Chúng ta sẽ có vector x và chúng ta sẽ lần lượt nhân hàng loạt với lại vector A, A1, A2, A3, cho đến An. Và các cái giá trị tích vô hướng đó sẽ được đưa vào cái vector như thế này. Đó là A1 x A2 chuyển về x, A n chuyển về x. Thì đây chúng ta",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 17,
      "start_timestamp": "0:11:24",
      "end_timestamp": "0:12:11"
    }
  },
  {
    "page_content": "A2 chuyển về x, A n chuyển về x. Thì đây chúng ta đang thực hiện nhân hàng loạt x với lại các cái vector hàng của ma trận A. Và cái phép này thì hiểu nôm na nó cũng là một cái phép chiếu hoặc là một cái phép chuyển không gian. Chuyển không gian. Ví dụ như chúng ta có một cái không gian là như thế này. Và một cái điểm trong cái không gian thì khi chúng ta chiếu xuống dưới một cái mặt phẳng nào đó, ví dụ vậy. Rồi, thì khi chúng ta chiếu xuống, để đại diện cho cái mặt phẳng này, đại diện cho cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 18,
      "start_timestamp": "0:12:07",
      "end_timestamp": "0:12:51"
    }
  },
  {
    "page_content": "đại diện cho cái mặt phẳng này, đại diện cho cái mặt phẳng này, mặt phẳng P đi, thì nó sẽ có cái tham số và tham số đó chính là cái ma trận A của mình. Và khi chiếu, khi chiếu xuống cái không gian của A thì chúng ta sẽ chuyển từ một cái vector là 3 chiều, Ví dụ vậy, thuộc R3, chuyển xuống một cái không gian 2 chiều thì lúc đó là chúng ta chỉ còn là một cái điểm kích sởi, nhưng mà nằm trong cái không gian chỉ có 2 chiều, chứ không gian mặt phẳng. Ở đây là một cái phép chiếu từ một cái không gian",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 19,
      "start_timestamp": "0:12:45",
      "end_timestamp": "0:13:26"
    }
  },
  {
    "page_content": "Ở đây là một cái phép chiếu từ một cái không gian lớn chiều là 3 chiều xuống một cái không gian mặt phẳng là 2 chiều. Và ngược lại, chúng ta cũng sẽ có cái phép chiếu từ không gian thấp chiều lên không gian cao chiều. Ví dụ từ không gian 2 chiều lên không gian 3 chiều. Và tiếp theo thì chúng ta sẽ có cái phép nhân giữa ma trận với ma trận, tức là chúng ta cũng sẽ thực hiện hàng loạt giữa các cái cặp AI với lại BZ. A sẽ là chạy theo, từ trên xuống dưới là theo hàng, còn B sẽ là theo cột, là từ",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 20,
      "start_timestamp": "0:13:20",
      "end_timestamp": "0:14:05"
    }
  },
  {
    "page_content": "dưới là theo hàng, còn B sẽ là theo cột, là từ trái sang phải. Và khi lấy hai cái ma trận này nhân với nhau thì chúng ta sẽ ra một cái ma trận, trong đó các cái phần tử của mình thì sẽ được nhân lần lượt từ trái sang phải và từ trên xuống dưới. Thì chúng ta sẽ ra được cái ma trận như thế này. Và đây cũng kiểu một cách nôm na, đó là một cái phép chiếu, nhưng mà chiếu hàng loạt trên rất nhiều ma trận và các cái không gian. Và tính chất của cái việc mà nhân ma trận với ma trận đó là, thứ nhất cái",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 21,
      "start_timestamp": "0:13:58",
      "end_timestamp": "0:14:39"
    }
  },
  {
    "page_content": "mà nhân ma trận với ma trận đó là, thứ nhất cái phép nhân ma trận này không có tính giao hoán, tức là A nhân B thì không có bằng B nhân A. Cái thứ hai đó là cái kết hợp, cái tính chất kết hợp là A nhân B, tất cả nhân C thì sẽ là bằng A nhân BC. Tính chất kết hợp theo kiểu là, cái này giống như phân phối từ A, B cộng C thì sẽ là A nhân B và A cộng C. Cái này là cái phép tính chất phân phối. Và chúng ta sẽ chuyển vị, thì ma trận A mà chuyển vị, rồi chuyển vị lại thì nó sẽ bằng A. Thì khi đó là A,",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 22,
      "start_timestamp": "0:14:36",
      "end_timestamp": "0:14:39"
    }
  },
  {
    "page_content": "chuyển vị lại thì nó sẽ bằng A. Thì khi đó là A, B, tất cả chuyển vị sẽ bằng là B chuyển vị nhân với A chuyển vị. Rồi A cộng B chuyển vị sẽ là bằng A chuyển vị cộng cho B chuyển vị. Và một số cái ma trận đặc biệt, ví dụ như là ma trận đơn vị, thì đây là một cái ma trận mà có tính chất đó là X mà nhân với lại một cái ma trận chuyển vị thì nó sẽ bằng chính X. Hiểu một cách nôm na đây giống như là số 1, 1 nhân với cái gì thì cũng bằng cái số 9. ma trận nghịch đảo là một cái ma trận vuông, là một",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 23,
      "start_timestamp": null,
      "end_timestamp": null
    }
  },
  {
    "page_content": "trận nghịch đảo là một cái ma trận vuông, là một cái ma trận vuông mà thỏa mãn tính chất đó là A nhân với lại A. Nghịch đảo thì nó sẽ là bằng ma trận đơn vị.",
    "metadata": {
      "video_url": "https://youtube.com/watch?v=_HLKpylxwMw",
      "filename": "_HLKpylxwMw",
      "title": "[CS315 - Chương 0] Giới thiệu môn học (Phần 2)",
      "chunk_id": 24,
      "start_timestamp": null,
      "end_timestamp": null
    }
  }
]