"""
File: coordinator.py
Ch·ª©c nƒÉng:
- ƒêi·ªÅu ph·ªëi pipeline thu th·∫≠p d·ªØ li·ªáu YouTube cho m·ªôt playlist
- L·∫•y playlist metadata
- L·∫•y transcript (∆∞u ti√™n API ‚Üí fallback Whisper)
- Chu·∫©n ho√° v√† l∆∞u transcript v√†o .txt
- C·∫≠p nh·∫≠t playlists_index.json ƒë·ªÉ qu·∫£n l√Ω nhi·ªÅu playlist

C·∫•u tr√∫c th∆∞ m·ª•c (t√≠nh t·ª´ root project, v√≠ d·ª•: Rag_QABot/):
- Rag_QABot/
    - loader/
        - youtube_fetchers.py
        - coordinator.py   (file n√†y)
    - data/
        - playlists_index.json
        - logs/
        - <playlist_folder>/
            - metadata.json
            - transcripts/
                - <video_id>.txt
            - audio/        (audio t·∫°m cho Whisper, file .wav s·∫Ω b·ªã x√≥a sau)
"""

from __future__ import annotations

from pathlib import Path
from typing import Dict, Any, List, Optional
import json
import datetime
import argparse
import time

# ================================================================
# Import t·ª´ youtube_fetchers.py
#   L∆ØU √ù: file n√†y n·∫±m c√πng th∆∞ m·ª•c v·ªõi coordinator.py
#   V√† b·∫°n CH·∫†Y b·∫±ng: python -m loader.coordinator t·ª´ root repo
# ================================================================
from youtube_fetchers import (
    PlaylistMetadataFetch,
    TranscriptAPIFetcher,
    TranscriptWhisperFetcher,
    normalize_api_segments,
    normalize_whisper_segments,
    segments_to_txt_with_timestamp,
    extract_playlist_id,
    save_json,
)

# =====================================================================
# ƒê∆∞·ªùng d·∫´n: data/ n·∫±m C√ôNG C·∫§P v·ªõi th∆∞ m·ª•c loader/
# =====================================================================
# __file__ = <root>/loader/coordinator.py
# parents[0] = <root>/loader
# parents[1] = <root>
ROOT_DIR = Path(__file__).resolve().parents[1]
DATA_ROOT = ROOT_DIR / "data"
LOGS_DIR = DATA_ROOT / "logs"
INDEX_FILE = DATA_ROOT / "playlists_index.json"


# =====================================================================
# Helper
# =====================================================================
def ensure_dirs() -> None:
    """T·∫°o th∆∞ m·ª•c data/ v√† data/logs/ n·∫øu ch∆∞a c√≥"""
    DATA_ROOT.mkdir(exist_ok=True)
    LOGS_DIR.mkdir(exist_ok=True)


def load_index() -> Dict[str, Any]:
    """ƒê·ªçc playlists_index.json (n·∫øu ch∆∞a c√≥ th√¨ tr·∫£ v·ªÅ khung r·ªóng)"""
    if not INDEX_FILE.exists():
        return {"playlists": []}
    try:
        return json.loads(INDEX_FILE.read_text(encoding="utf-8"))
    except Exception:
        return {"playlists": []}


def save_index(data: Dict[str, Any]) -> None:
    """L∆∞u playlists_index.json"""
    INDEX_FILE.parent.mkdir(exist_ok=True)
    INDEX_FILE.write_text(
        json.dumps(data, indent=2, ensure_ascii=False), encoding="utf-8"
    )
    print(f"üíæ ƒê√£ c·∫≠p nh·∫≠t index: {INDEX_FILE}")


def upsert_index(
    index: Dict[str, Any], playlist_info: Dict[str, Any], folder_name: str
) -> None:
    """
    C·∫≠p nh·∫≠t ho·∫∑c th√™m m·ªõi playlist trong playlists_index.json
    """
    pid = playlist_info["playlist_id"]
    playlists = index.setdefault("playlists", [])

    for item in playlists:
        if item["playlist_id"] == pid:
            item.update(
                {
                    "title": playlist_info.get("title"),
                    "folder_name": folder_name,
                    "total_videos": playlist_info.get("total_videos"),
                    "processed_videos": playlist_info.get("processed_videos"),
                    "failed_videos": playlist_info.get("failed_videos"),
                    "updated_at": datetime.datetime.now().isoformat(),
                }
            )
            return

    playlists.append(
        {
            "playlist_id": pid,
            "folder_name": folder_name,
            "title": playlist_info.get("title"),
            "total_videos": playlist_info.get("total_videos"),
            "processed_videos": playlist_info.get("processed_videos", 0),
            "failed_videos": playlist_info.get("failed_videos", 0),
            "created_at": datetime.datetime.now().isoformat(),
        }
    )


def save_txt(content: str, path: str | Path) -> str:
    """
    L∆∞u n·ªôi dung ra file .txt
    """
    path = Path(path)
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")
    print(f"üíæ ƒê√£ l∆∞u transcript TXT: {path}")
    return str(path)


def is_youtube_block_error(err: Exception | str) -> bool:
    """
    Nh·∫≠n di·ªán l·ªói YouTube block IP t·ª´ message
    """
    msg = str(err)
    return "YouTube is blocking requests from your IP" in msg


# =====================================================================
# COORDINATOR
# =====================================================================
class DataCoordinator:
    def __init__(self, sleep_between_videos: float = 2.0):
        """
        sleep_between_videos: th·ªùi gian ngh·ªâ (gi√¢y) gi·ªØa 2 video
        ƒë·ªÉ h·∫°n ch·∫ø b·ªã YouTube block v√¨ qu√° nhi·ªÅu request.
        """
        ensure_dirs()
        self.index = load_index()
        self.api_fetcher = TranscriptAPIFetcher()
        self.sleep_between_videos = sleep_between_videos

    # ------------------------------------------------------------
    # Run pipeline cho 1 playlist
    # ------------------------------------------------------------
    def process_playlist(self, playlist_url_or_id: str, limit: Optional[int] = None):
        """
        playlist_url_or_id: URL ho·∫∑c ID playlist
        limit: n·∫øu mu·ªën gi·ªõi h·∫°n s·ªë video x·ª≠ l√Ω (vd: 10), c√≤n None th√¨ x·ª≠ l√Ω h·∫øt
        """
        pid = extract_playlist_id(playlist_url_or_id)
        if not pid:
            raise ValueError("Kh√¥ng t√¨m th·∫•y playlist id h·ª£p l·ªá!")

        print(f"üîé ƒêang x·ª≠ l√Ω playlist: {pid}")
        meta_fetcher = PlaylistMetadataFetch(pid)
        playlist_data = meta_fetcher.convert_to_json_data()
        folder_name = meta_fetcher.playlist_name

        # Th∆∞ m·ª•c playlist: data/<playlist_folder>/
        playlist_folder = DATA_ROOT / folder_name
        playlist_folder.mkdir(parents=True, exist_ok=True)

        # L∆∞u metadata.json
        metadata_path = playlist_folder / "metadata.json"
        save_json(playlist_data, metadata_path)

        # Th∆∞ m·ª•c transcripts: data/<playlist_folder>/transcripts/
        transcripts_dir = playlist_folder / "transcripts"
        transcripts_dir.mkdir(exist_ok=True)

        # Th∆∞ m·ª•c audio ri√™ng cho playlist: data/<playlist_folder>/audio/
        audio_dir = playlist_folder / "audio"
        audio_dir.mkdir(exist_ok=True)

        # Whisper fetcher d√πng audio_dir c·ªßa playlist n√†y
        whisper_fetcher = TranscriptWhisperFetcher(audio_dir=str(audio_dir))

        # Ghi log: data/logs/<playlist_folder>.log
        log_file = LOGS_DIR / f"{folder_name}.log"
        log_f = log_file.open("a", encoding="utf-8")
        log_f.write(f"\n\n=== Process start {datetime.datetime.now()} ===\n")

        videos = playlist_data["videos"]
        if limit is not None:
            videos = videos[:limit]

        total_videos = len(videos)
        success_count = 0
        fail_count = 0

        # Flag ƒë·ªÉ bi·∫øt c√≥ b·ªã YouTube block hay kh√¥ng
        blocked_by_youtube = False

        # ------------------------------------------------------------
        # L·∫∑p qua t·ª´ng video trong playlist
        # ------------------------------------------------------------
        for idx, vid in enumerate(videos, start=1):
            video_id = vid["video_id"]
            video_title = vid["title"]

            if blocked_by_youtube:
                msg = "‚õî B·ªè qua video v√¨ ƒë√£ b·ªã YouTube block IP tr∆∞·ªõc ƒë√≥."
                print(msg)
                log_f.write(msg + "\n")
                fail_count += 1
                continue

            log_f.write(
                f"\n>>> VIDEO {idx}/{total_videos}: {video_id} | {video_title}\n"
            )
            print(f"\nüé¨ VIDEO {idx}/{total_videos}: {video_id} | {video_title}")

            txt_path = transcripts_dir / f"{video_id}.txt"

            # Skip n·∫øu transcript ƒë√£ t·ªìn t·∫°i
            if txt_path.exists():
                print("‚è≠ Transcript ƒë√£ t·ªìn t·∫°i, b·ªè qua.")
                log_f.write("‚è≠ Skipped (exists)\n")
                success_count += 1
                time.sleep(self.sleep_between_videos)
                continue

            # --------------------------------------------------------
            # 1) Try API transcript
            # --------------------------------------------------------
            api_segments = None
            try:
                api_segments = self.api_fetcher.fetch_transcript_from(video_id)
            except Exception as e:
                print(f"‚ö† L·ªói API transcript: {e}")
                log_f.write(f"‚ö† API error: {e}\n")
                if is_youtube_block_error(e):
                    blocked_by_youtube = True

            if api_segments and not blocked_by_youtube:
                log_f.write("‚úì API transcript OK\n")
                print("üìÑ L·∫•y transcript API th√†nh c√¥ng.")

                segments = normalize_api_segments(api_segments)
                txt = segments_to_txt_with_timestamp(segments)
                save_txt(txt, txt_path)
                success_count += 1
                time.sleep(self.sleep_between_videos)
                continue

            # --------------------------------------------------------
            # 2) Fallback ‚Üí Whisper
            # --------------------------------------------------------
            if blocked_by_youtube:
                msg = "‚õî B·ªã YouTube block IP ‚Üí kh√¥ng th·ª≠ Whisper ƒë·ªÉ tr√°nh spam."
                print(msg)
                log_f.write(msg + "\n")
                fail_count += 1
                continue

            print("‚ö† API transcript kh√¥ng c√≥ ‚Üí d√πng Whisper...")
            log_f.write("‚ö† API failed ‚Üí Whisper\n")

            try:
                whisper_data = whisper_fetcher.fetch_transcript_from(
                    video_id, cleanup=True, show_segments=True
                )
                segments = normalize_whisper_segments(whisper_data["segments"])
                txt = segments_to_txt_with_timestamp(segments)
                save_txt(txt, txt_path)
                success_count += 1
                log_f.write("‚úì Whisper transcript OK\n")
            except Exception as e:
                err_msg = f"‚ùå Whisper failed: {e}"
                print(err_msg)
                log_f.write(err_msg + "\n")
                fail_count += 1
                if is_youtube_block_error(e):
                    blocked_by_youtube = True

            # ngh·ªâ m·ªôt ch√∫t sau m·ªói video
            time.sleep(self.sleep_between_videos)

        # ------------------------------------------------------------
        # C·∫≠p nh·∫≠t playlists_index.json
        # ------------------------------------------------------------
        playlist_data["processed_videos"] = success_count
        playlist_data["failed_videos"] = fail_count

        upsert_index(self.index, playlist_data, folder_name)
        save_index(self.index)

        log_f.write(
            f"\n=== Done {datetime.datetime.now()} | success={success_count}, fail={fail_count} ===\n"
        )
        log_f.close()

        print("\nüéâ Ho√†n t·∫•t pipeline cho playlist!")
        print(f"üìÅ L∆∞u t·∫°i: {playlist_folder}")
        print(f"üìÑ Log: {log_file}")
        if blocked_by_youtube:
            print(
                "‚õî L∆∞u √Ω: C√≥ d·∫•u hi·ªáu YouTube block IP, n√™n ngh·ªâ m·ªôt th·ªùi gian tr∆∞·ªõc khi ch·∫°y l·∫°i."
            )


# =====================================================================
# CLI
# =====================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="YouTube Data Coordinator")
    parser.add_argument(
        "playlist",
        type=str,
        help="Playlist URL ho·∫∑c playlist ID",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Gi·ªõi h·∫°n s·ªë video x·ª≠ l√Ω (vd: 5). M·∫∑c ƒë·ªãnh: x·ª≠ l√Ω t·∫•t c·∫£.",
    )
    parser.add_argument(
        "--sleep",
        type=float,
        default=2.0,
        help="S·ªë gi√¢y ngh·ªâ gi·ªØa 2 video ƒë·ªÉ tr√°nh b·ªã YouTube block. M·∫∑c ƒë·ªãnh: 2.0",
    )

    args = parser.parse_args()

    coord = DataCoordinator(sleep_between_videos=args.sleep)
    coord.process_playlist(args.playlist, limit=args.limit)
