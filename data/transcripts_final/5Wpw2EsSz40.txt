0:00:14 - 0:00:21, Vậy thì bây giờ chúng ta sẽ lấy một cái ví dụ có tính chất số học để cho các bạn có thể dễ dàng tính toán thử nghiệm.
0:00:21 - 0:00:24, Còn ví dụ ở trên thì nó mang tính chất về lý thuyết.
0:00:24 - 0:00:31, Ở đây chúng ta sẽ chọn ra m và n là hai con số đủ nhỏ để chúng ta có thể tính tay một cách dễ dàng.
0:00:31 - 0:00:35, Còn một cách tổng quát thì ở trong slide trước chúng ta đã đề cập rồi.
0:00:35 - 0:00:44, Ví dụ như ở đây m là bằng 2, như vậy là mô hình của mình sẽ bao gồm có m cộng 1 tham số, đó là theta 0, theta 1 và theta 2.
0:00:45 - 0:01:03, Và giả sử cái số mẫu dữ liệu train của chúng ta là chỉ có n bằng 2, tức là chỉ có hai mẫu thôi, thì khi đó là n sẽ bé hơn m cộng 1, tại vì 2 thì bé hơn 2 cộng 1 là bằng 3.
0:01:03 - 0:01:22, Và giả sử như cái hai cái mẫu dữ liệu này chúng ta có là đây là x thứ nhất, đây là x thứ hai, rồi đây là y thứ nhất và đây là y thứ hai, thì chúng ta có hai mẫu dữ liệu.
0:01:22 - 0:01:38, X1, Y1, X2, Y2, thì đồng thời chúng ta sẽ có một cái mẫu dữ liệu test sau khi huấn luyện mô hình, thì chúng ta chỉ được phép sử dụng cái dữ liệu Xtest và Ytest này sau khi huấn luyện xong thôi.
0:01:38 - 0:01:45, Cái này sẽ không tham gia vào cái quá trình huấn luyện.
0:01:45 - 0:01:51, Về nguyên tắc là chúng ta không được phép cho tập test tham gia vào huấn luyện.
0:01:51 - 0:01:58, Thì từ cái dữ liệu train chúng ta đã có ở đây, đây là dữ liệu train.
0:01:58 - 0:02:13, Chúng ta sẽ thế vào cái mô hình của mình, thì trong cái mô hình ở trên đây, đó là một cái công thức tuyến tính, thì khi thế vào chúng ta sẽ có theta 0 trừ 1, tức là trừ theta 1.
0:02:13 - 0:02:20, Thế là 1, 1, tức là cộng cho theta 2 và tất cả là bằng 1, thì số 1 ở đây.
0:02:20 - 0:02:33, Rồi, cái phương trình thứ 2 đó là theta 0 cộng cho 2 theta 1 và trừ theta 2 và tất cả sẽ là bằng 2.
0:02:33 - 0:02:39, Thế thì đây là một cái hệ phương trình ba ẩn nhưng mà chỉ có hai phương trình thôi.
0:02:39 - 0:02:47, Thế thì sau khi chúng ta tìm cách chúng ta giải cái hệ phương trình này và rõ ràng cái hệ phương trình này là có vô số nghiệm.
0:02:47 - 0:02:56, Nhưng khi chúng ta huấn luyện cái mô hình xong thì chúng ta chỉ được phép chọn ra đúng một bộ tham số của mình, sao cho nó tối ưu nhất.
0:02:56 - 0:03:03, Vì vậy, thì giả sử chúng ta có cái bộ tham số là theta 0 là bằng 0, theta 1 là bằng 3 và theta 2 là bằng 6,
0:03:03 - 0:03:13, thì chúng ta dễ dàng thế được cái bộ 3 cái giá trị này vào cái công thức ở trên thì nó đúng cho cả hai phương trình.
0:03:13 - 0:03:25, Ví dụ với theta 0 là bằng 0, rồi thì ở đây sẽ là trừ theta 1, tức là trừ 3 cộng cho theta 2 là bằng 4, thì nó đúng là bằng 1.
0:03:26 - 0:03:44, Tương tự như vậy cho cái phương trình số 2 khi chúng ta thế vào, 0 cộng cho 2 nhân 3 là bằng 6, trừ cho 4, thế theta 2 là bằng 4, là bằng 2.
0:03:44 - 0:03:54, Ví dụ như vậy là cái phương trình này cũng đúng, như vậy thì khi thế vào cái tập train, khi thế vào cái mô hình chúng ta đã chọn ra ở đây vào tập train,
0:03:54 - 0:04:07, thì chúng ta đúng 2 trên 2 mẫu, tức là đúng 100%. Đây là một cái biểu hiện đầu tiên của overfitting, đó chính là độ chính xác trên tập train rất cao.
0:04:07 - 0:04:20, Nhưng khi chúng ta lấy cái bộ tham số của mô hình này thế vào cái mẫu dữ liệu test, thì chúng ta thấy nó không có đúng nữa. Tại vì sao?
0:04:20 - 0:04:38, Tại vì khi thế vào thì chúng ta sẽ có là 0 cộng cho 3 nhân với lại 2 là bằng 6, cộng cho theta 2 là bằng 4, thì là 6 cộng 4 là bằng 10, rõ ràng là nó khác 3.
0:04:38 - 0:04:51, Do đó thì tập dữ liệu test của mình là sai và chúng ta hoàn toàn có thể ngẫu nhiên chọn ra các mẫu test khác, thì cái xác suất để mà cái nghiệm này nè,
0:04:51 - 0:05:00, cái nghiệm mà chúng ta đã huấn luyện, đã tìm ra được với chỉ có 2 phương trình thì xác suất của nó, đúng cái mẫu dữ liệu test là cực kỳ thấp.
0:05:00 - 0:05:13, Như vậy thì ở đây là chúng ta đúng 0%. Như vậy thì tập Train thì đúng đến 100% rất cao nhưng mà cái tập Test thì chỉ có 0% thôi, tức là rất thấp.
0:05:14 - 0:05:25, Thì đây chính là cái hiện tượng Overfit, nó Overfit trên tập Train. Thì hy vọng là qua cái ví dụ này chúng ta có thể hình dung được cái hiện tượng Overfitting là gì,
0:05:25 - 0:05:33, và một cái ví dụ minh họa cũng như là sử dụng kiến thức toán cấp 3 để hình dung cái hiện tượng Overfitting.
0:05:33 - 0:05:41, Thế thì nguyên nhân và giải pháp thì nguyên nhân của cái hiện tượng Overfitting này chính là cái số tham số của mình nó quá nhiều.
0:05:41 - 0:05:52, Cụ thể trong cái ví dụ trước là chúng ta có 3 tham số nhưng cái số mẫu chúng ta lưu ý là ở đây phải có mệnh đề và,
0:05:52 - 0:06:05, nó nhiều nhưng mà đồng thời là cái số mẫu dữ liệu của mình nó phải ít. Thì ở đây là 3 tham số nhưng mà chỉ có 2 mẫu dữ liệu.
0:06:05 - 0:06:21, Thì đây là cái vấn đề xảy ra đồng thời là và. Ví dụ vừa rồi nó đã nêu một cái tình huống là xảy ra đồng thời là số tham số và nhiều hơn số mẫu.
0:06:21 - 0:06:30, Vậy thì giải pháp đó là gì? Chúng ta sẽ có thể tiếp cận một cách trực tiếp hoặc gián tiếp để giải quyết cái hiện tượng Overfitting.
0:06:30 - 0:06:39, Và chúng ta sẽ làm như sau. Vì cái tham số nhiều nên ở đây chúng ta sẽ tìm cách giảm số tham số xuống.
0:06:39 - 0:06:46, Hay nói cách khác đó là chúng ta làm cho mô hình của mình đơn giản hơn. Đơn giản hóa mô hình.
0:06:46 - 0:07:02, Và cái nguyên nhân đó là do dữ liệu của mình nó ít. Thì bây giờ chúng ta sẽ tìm cách là đẩy cái dữ liệu lên, tăng cái số mẫu dữ liệu huấn luyện.
0:07:02 - 0:07:06, Ở đây chúng ta sẽ là bổ sung thêm dữ liệu.
0:07:15 - 0:07:21, Và ở đây chúng ta sẽ dùng cái mệnh đề hoặc. Tức là dùng một trong hai cách. Ở trên là và, ở dưới là hoặc.
0:07:21 - 0:07:26, Và một số kỹ thuật cụ thể, ví dụ như là Dropout, Regularization, tăng cường.
0:07:26 - 0:07:31, Sửa lỗi Regularization là chính quy hóa và tăng cường dữ liệu.
0:07:31 - 0:07:43, Thì đối với kỹ thuật Regularization thì cái hàm lỗi của mình là bên cạnh cái sai số giữa giá trị dự đoán và cái giá trị ground truth thì chúng ta có thể bổ sung thêm thành phần chính quy hóa.
0:07:43 - 0:07:51, Trong cái công thức hàm lỗi ở đây chúng ta thấy loss của y, ngã và y, đây chính là cái sai số giữa giá trị dự đoán và ground truth.
0:07:51 - 0:07:55, Và thành phần chính quy hóa mà chúng ta đang muốn đề cập chính là ở đây.
0:07:55 - 0:08:00, Thì cái mục tiêu của chúng ta thêm cái thành phần chính quy hóa này đó là gì?
0:08:00 - 0:08:08, Thì khi quá trình huấn luyện chúng ta tìm min, tìm min của z, tức là chúng ta đang muốn cái giá trị này nó giảm xuống.
0:08:08 - 0:08:13, Thì bên cạnh là cái loss giảm, tức là cái sai số giữa y và y, ngã nó giảm.
0:08:13 - 0:08:20, Thì đồng thời, đây là dấu cộng, là đồng thời chúng ta cũng sẽ cho cái thành phần chính quy này giảm xuống luôn.
0:08:20 - 0:08:24, Mà khi cái thành phần chính quy này giảm xuống thì điều này có nghĩa là gì?
0:08:24 - 0:08:28, Đó là cái theta y của mình nó sẽ giảm xuống.
0:08:28 - 0:08:38, Và cái hàm bình phương này, cái hàm theta y bình phương này mà đạt được giá trị nhỏ nhất khi theta y của mình nó tiến đến 0.
0:08:38 - 0:08:57, Mà khi theta y của mình nó tiến đến 0, tức là nó khuyến khích mô hình giảm bớt tham số một cách gọi là không tường minh, giảm bớt.
0:08:58 - 0:09:08, Tham số. Thế thì một cái tham số mà được gắn bằng 0, tức là cái trọng số này là gần như không đáng kể,
0:09:08 - 0:09:13, và không có ảnh hưởng đến cái mô hình của mình, không tham gia vào cái quyết định, dự đoán của mô hình của mình.
0:09:13 - 0:09:17, Thì đây là cái cách thức giảm bớt tham số một cách không tường minh.
0:09:17 - 0:09:23, Bên cạnh cái hướng tiếp cận đó là giảm một cách tường minh. Đó là chúng ta sẽ nghiên cứu về mặt mô hình làm sao đó,
0:09:23 - 0:09:35, để cho theta y của mình giảm bớt số lượng theta y. Còn ở đây giả sử chúng ta có số lượng theta y là bằng m cộng một.
0:09:35 - 0:09:45, Thì ở đây là chạy từ 0 cho đến m. Thì ở đây là chúng ta có m cộng một tham số, thì chúng ta không giảm xuống là một con số nhỏ hơn,
0:09:45 - 0:09:49, Thì ở đây là chúng ta có m cộng một tham số, thì chúng ta không giảm xuống là một con số nhỏ hơn,
0:09:49 - 0:09:54, một cách tường minh chúng ta sẽ thêm cái thành phần Regularization này, để khi mà tối ưu cái mô hình này xong,
0:09:54 - 0:09:58, thì đâu đó sẽ có các tham số theta y tiến về 0.
0:09:58 - 0:10:09, Thì một số cái mô hình trong hồi quy có sử dụng cái thành phần Regularization và hướng đến cái việc là theta y tiến giảm về 0,
0:10:09 - 0:10:18, đó chính là mô hình Lasso. Thì đây là một trong những mô hình rất là nổi tiếng dùng trong cái việc đó là giảm bớt cái độ phức tạp của mô hình.
0:10:18 - 0:10:27, Như vậy, bản chất ở đây chính là chúng ta đã ngầm giảm tham số của mô hình, hay nói cách khác đó là giảm một cách không tường minh.
0:10:27 - 0:10:35, Kỹ thuật tiếp theo đó là Dropout. Thì tại một cái vòng lặp huấn luyện, ví dụ chúng ta set một cái mạng Neural Network,
0:10:35 - 0:10:42, thì chúng ta sẽ loại bỏ bớt một số Neuron và không tham gia vào quá trình huấn luyện.
0:10:42 - 0:10:48, Bên trái là một cái mạng Neural Network đầy đủ, nhưng mà khi huấn luyện, đây là khi huấn luyện thôi.
0:10:52 - 0:10:58, Chúng ta bỏ bớt hai cái Neuron này, và khi chúng ta bỏ bớt hai Neuron này thì vô hình chung các cái trọng số,
0:10:58 - 0:11:01, tức là các cái cạnh nối đến các cái Neuron này cũng được loại bỏ đi.
0:11:01 - 0:11:08, Thì chúng ta thấy là so với lại cái mô hình bên trái thì cái số lượng tham số khi chúng ta huấn luyện,
0:11:08 - 0:11:15, khi chúng ta huấn luyện tại cái thời điểm này là ít hơn hẳn so với lại cái mạng Neural Network.
0:11:15 - 0:11:20, Thì đây cũng là một cái kỹ thuật mà chúng ta ngầm giảm bớt cái số lượng tham số đi.
0:11:20 - 0:11:25, Bản chất là chúng ta đã ngầm thực hiện cái việc này.
0:11:28 - 0:11:33, Và lưu ý là cái cách này là chúng ta chỉ thực hiện khi quá trình huấn luyện thôi,
0:11:33 - 0:11:39, nhưng mà sau khi huấn luyện xong, chúng ta sẽ hoàn trả lại cái mô hình của mình đúng với các cái trọng số này.
0:11:39 - 0:11:45, Với mỗi một cái iteration thì chúng ta sẽ ngẫu nhiên chọn ra một vài cái Neuron,
0:11:45 - 0:11:51, thì cái việc này sẽ giúp cho chúng ta không có khuyến khích mô hình học thuộc.
0:11:51 - 0:11:56, Không khuyến khích mô hình học thuộc.
0:11:58 - 0:12:05, Tại vì nếu như chúng ta để nguyên cái số tham số này, thì nó cứ lặp đi lặp lại các cái mẫu đó thì nó sẽ học thuộc.
0:12:05 - 0:12:11, Còn vô tình chúng ta bỏ cái Neuron này ra thì nó sẽ không có phụ thuộc vào hai cái Neuron này.
0:12:11 - 0:12:16, Tại vì hai cái Neuron này có khả năng là hai cái Neuron là phụ trách cái việc học thuộc.
0:12:16 - 0:12:25, Và kỹ thuật cuối cùng đó là tăng cường dữ liệu. Đây là một kỹ thuật rất là nổi tiếng và nó đơn giản.
0:12:25 - 0:12:28, Nó rất là đơn giản. Tại vì nó dễ thực hiện.
0:12:28 - 0:12:33, Nhưng mà cái gì đơn giản thì nó sẽ có cái mặt hạn chế của nó, đó là cái chi phí cao.
0:12:33 - 0:12:40, Cái chi phí nó cao. Nếu chúng ta thu thập bằng tay thì có thể chúng ta sẽ phải tốn cái chi phí để thuê người gán nhãn.
0:12:40 - 0:12:45, Trong hai cái lĩnh vực xử lý hình ảnh và văn bản, chúng ta có hai cái kỹ thuật tăng cường dữ liệu.
0:12:45 - 0:12:50, Một đó là đối với hình ảnh thì chúng ta có thể sử dụng các phép biến đổi.
0:12:50 - 0:12:59, Ví dụ như là thay đổi cái texture, giảm bớt cái texture của đối tượng đi, loại bỏ đi cái yếu tố màu sắc để ra cái ảnh mức xám.
0:12:59 - 0:13:06, Rồi chúng ta tăng cường cái biên cạnh lên. Hoặc là chúng ta lấy cái salient, tức là những cái biên cạnh mà nổi bật nhất.
0:13:06 - 0:13:10, Hoặc là chúng ta làm các cái thao tác là transformation.
0:13:10 - 0:13:16, Tức là cái thao tác biến đổi về mặt hình học, như flip, quay, tỷ lệ, tịnh tiến, v.v.
0:13:16 - 0:13:26, Từ đó, từ một ảnh mức xám, thì từ một ảnh chúng ta sẽ tạo ra N ảnh và cái N ảnh này thì N ảnh phiên bản khác nhau.
0:13:29 - 0:13:33, Còn đối với lĩnh vực về xử lý ngôn ngữ tự nhiên, thì chúng ta cũng có một số kỹ thuật.
0:13:33 - 0:13:40, Trong đó đơn giản và dễ hiểu nhất đó chính là kỹ thuật Back Translation.
0:13:40 - 0:13:46, Tức là với cái văn bản gốc, thì chúng ta chuyển nó dịch nó sang cái ngôn ngữ khác.
0:13:46 - 0:13:50, Thí dụ như là tiếng Anh, sau đó chúng ta dịch ngược trở lại, sang trở lại tiếng Anh.
0:13:50 - 0:13:56, Thì từ tiếng Anh sang tiếng Pháp, xong rồi từ tiếng Pháp dịch ngược lại tiếng Anh, thì chúng ta đã có một cái phiên bản mới.
0:13:56 - 0:14:00, Đây là một cái phiên bản mới cho cái ngôn ngữ của mình.
0:14:00 - 0:14:12, Như vậy là trong bài này chúng ta đã cùng tìm hiểu về nguyên lý của hiện tượng Overfitting và nguyên lý của cái việc là chống lại cái hiện tượng Overfitting.
0:14:12 - 0:14:20, Đó là giảm tham số xuống hoặc là chúng ta giảm cái độ phức tạp của mình xuống và tăng cường cái dữ liệu lên.
0:14:30 - 0:14:36, Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.