0:00:14 - 0:00:23, Chúng ta sẽ hướng dẫn thực hành với hai kiến trúc là Autoencoder và Variational Autoencoder
0:00:23 - 0:00:33, Đầu tiên là kiến trúc Autoencoder, chúng ta sẽ kết nối với một cái máy
0:00:37 - 0:00:47, Kết nối đã được kết nối rồi, chúng ta sẽ tiến hành chạy đoạn code của mình
0:00:47 - 0:00:53, Đầu tiên là khởi tạo phần thư viện
0:00:53 - 0:01:13, Hàm chính sẽ bao gồm .nn, viết tắt của Neural Network, functional, kích hoạt như sigmoid, relu, và hàm khác
0:01:13 - 0:01:23, Tiếp theo là sẽ sử dụng collab với chế độ có GPU
0:01:23 - 0:01:27, Chúng ta phải kiểm tra lại xem có GPU hay chưa
0:01:27 - 0:01:31, Nếu có GPU RAM thì đã kết nối được rồi
0:01:31 - 0:01:39, Còn nếu không thì vào runtime, chúng ta chọn change runtime, chọn T4
0:01:39 - 0:01:47, Kiểm tra xem device của mình, đã kết nối với CUDA, tức là nó đã có GPU rồi
0:01:47 - 0:01:59, Tiếp theo là kết nối kiến trúc Encode và Decoder, trong đó phần vàng vàng, tương ứng là encoder và phần xanh là decoder
0:01:59 - 0:02:07, Trong giai đoạn Encode, ảnh đầu vào sẽ là ma trận kích thước 2828
0:02:07 - 0:02:15, Tại vì ảnh này được lấy từ tập dữ liệu MNIST, và ảnh này sẽ được flatten để biến thành vector 784 chiều
0:02:15 - 0:02:21, Sau đó chúng ta giảm số chiều xuống là 512 và xuống z
0:02:21 - 0:02:39, Về mặt coding, chúng ta nên để 1 biến là Latent Dim để tùy chỉnh xem có thể là 2, 3, 4, 5, 1 cái kích thước bất kỳ
0:02:39 - 0:02:51, Đầu tiên là lớp constructor, chúng ta sẽ khởi tạo các lớp biến đổi cho encoder
0:02:51 - 0:03:13, Lớp đầu tiên là lớp linear để ánh xạ từ 784 về 512, chúng ta sẽ dùng là neural network.linear và 784 về 512
0:03:13 - 0:03:24, Và lớp này sẽ được gắn vào một thuộc tính cell.linear1, tức là lớp biến đổi đầu tiên này
0:03:24 - 0:03:36, Tương tự như vậy, chúng ta sẽ có lớp linear2, có điều, chúng ta sẽ ánh xạ từ 512 về 2 chiều
0:03:36 - 0:03:47, Tuy nhiên để tổng quát, chúng ta có thể thay đổi số chiều của vector latent, nên chúng ta phải truyền vào biến là Latent Dim
0:03:47 - 0:03:52, Thay vì để 2 hardcode, chúng ta sẽ để là Latent Dim
0:03:52 - 0:04:00, Tiếp theo là hàm forward, hàm forward sẽ nhận dữ liệu đầu vào là 1 ảnh x và đầu ra của mình
0:04:00 - 0:04:05, Đối với encoder, đầu ra của chúng ta chỉ cần ra biến z, là đủ
0:04:05 - 0:04:09, Do đó, bước đầu tiên là chúng ta phải flatten
0:04:10 - 0:04:24, Thì để flatten, chúng ta sẽ sử dụng cái hàm, đó là hàm, chúng ta sẽ sử dụng một cái hàm flatten của neural network, đó là hàm torch.
0:04:29 - 0:04:34, Và chúng ta sẽ truyền vào x, start_dim, là bằng 1
0:04:35 - 0:04:44, Rồi, để cho độ phức tạp thì chúng ta sẽ giữ luôn chính cái biến x, đầu vào là x và đầu ra sẽ gán ngược trở lại vào biến x
0:04:44 - 0:04:56, Lúc này thì x của chúng ta là vector 784 chiều, sau đó chúng ta sẽ đưa về cái vector 512 chiều, cell.linear
0:04:56 - 0:05:05, Và để cho có cái sự khác biệt giữa các lớp biến đổi tuyến tính thì chúng ta phải có một cái hàm kích hoạt ở giữa
0:05:05 - 0:05:10, Thế thì, hàm kích hoạt ở đây chúng ta dùng là gì?
0:05:10 - 0:05:18, Thì trong cái lý thuyết về deep learning chúng ta đã được học là có thể dùng hàm sigmoid hoặc hàm relu
0:05:18 - 0:05:27, Tuy nhiên hàm sigmoid có khả năng gây ra hiện tượng vanishing gradient, tức là tiêu biến đạo hàm nên cái tốc độ hội tụ chậm
0:05:27 - 0:05:38, Do đó thì chúng ta sẽ dùng f.relu, tức là hàm rectify linear unit, rồi chúng ta sẽ trả về x
0:05:38 - 0:05:43, Lúc này x của mình sẽ là một cái vector 512 chiều
0:05:43 - 0:05:51, Tiếp tục như vậy, thì từ 512 xuống 2 thì chúng ta sẽ có cell.linear2
0:05:51 - 0:06:01, Và lúc này thì chúng ta có sử dụng cái hàm kích hoạt hay không?
0:06:01 - 0:06:09, Nếu chúng ta sử dụng hàm rectify linear unit thì cái giải giá trị của mình là từ 0 cho đến cộng vô cùng
0:06:09 - 0:06:19, Nhưng cái vector z này chúng ta muốn biểu diễn nó xung quanh con số 0 trong cái không gian, do đó nó phải có số âm và số dương
0:06:19 - 0:06:29, Tức là các cái thành phần của vector z của mình nó phải có thành phần âm, thành phần dương, do đó thì chúng ta sẽ không có dùng hàm kích hoạt ở đây
0:06:29 - 0:06:37, Và thay vì tạo biến tạm thì chúng ta sẽ trả ra trực tiếp, thì lúc này đây chính là cái z của mình
0:06:43 - 0:06:49, Và cái kết quả mà return đây chính là cái latent variable z của mình
0:06:49 - 0:07:05, Tương tự như vậy cho hàm decode, thì hàm decode chúng ta sẽ từ 2 chiều đến 52 chiều, hoặc là từ latent dim đến 52, rồi từ 52 về 784
0:07:05 - 0:07:10, Thì chúng ta sẽ có cell.linear1
0:07:15 - 0:07:22, Và để cho tổng quát thì chúng ta sẽ để là latent dim và ra là 52
0:07:24 - 0:07:30, Tiếp theo đó là cell.linear1
0:07:35 - 0:07:45, Và hàm forward là nó sẽ nhận đầu vào vector z, sau đó nó sẽ biến đổi qua 2 lớp biến đổi kia
0:07:45 - 0:07:53, cell.linear1, nhận đầu vào là z, và đầu ra thì chúng ta cũng sẽ dùng 1 cái hàm kích hoạt, cụ thể ở đây đó là cell.relu
0:07:57 - 0:08:06, Rồi, thế thì nhận đầu vào là z, thì ở đây chúng ta có thể trả về cái biến z luôn, tuy nhiên nếu đúng về mặt, thì chúng ta có thể trả về cái biến z
0:08:06 - 0:08:14, Tuy nhiên nếu đúng về mặt, concept về mặt ý nghĩa, chúng ta đang decode để tạo ra cái x-mũ, do đó chúng ta sử dụng luôn cái biến x-mũ, thay vì chúng ta dùng vector z
0:08:26 - 0:08:35, Cái việc đặt tên biến là z cũng không có ảnh hưởng đến kết quả, tuy nhiên để dễ maintain về sau, chúng ta nên đặt biến đúng cái ý nghĩa của nó
0:08:36 - 0:08:41, Sau đó thì cell.linear2, xh
0:08:42 - 0:08:48, Thế thì ở cái lớp cuối cùng này, chúng ta có dùng activation function hay không?
0:08:49 - 0:08:55, Thì chúng ta phải xem coi cái kiểu dữ liệu của cái ảnh này, mỗi một cái điểm ảnh nó sẽ là kiểu gì?
0:08:55 - 0:09:09, Thì cái đầu ra của mình nó sẽ là một cái giá trị scaling từ 0 cho đến 1, do đó ở đây chúng ta sẽ phải dùng một cái hàm để áp một cái giá trị bất kỳ về cái đoạn từ 0 đến 1, đó chính là f.sigmoid
0:09:10 - 0:09:18, Tại sao không dùng relu nữa? Tại vì cái hàm relu nó là giải giá trị từ 0 cho đến cộng vô cùng, còn chúng ta đang muốn từ 0 cho đến 1
0:09:18 - 0:09:26, Sau khi chúng ta đã có xh xong thì chúng ta sẽ gọi hàm reshape
0:09:27 - 0:09:30, xh.reshape
0:09:32 - 0:09:37, Và cái kích thước của cái shape của mình nó sẽ là trừ 1, 1, 2, 8
0:09:37 - 0:09:51, Trong đó hai cái thành phần cuối là cái kích thước của cái ảnh mà mình sẽ decode ra, và 1 đó là cái số kênh màu của mình, tại vì đây là ảnh mức xám nên nó chỉ có một kênh màu thôi
0:09:52 - 0:10:04, Còn trừ 1 ở đây có nghĩa là chúng ta có thể huấn luyện theo batch truyền vào theo một khối dữ liệu, thì ở đây trừ 1 thì hàm ý đó là nếu đầu vào thì chúng ta có bao nhiêu ảnh để huấn luyện, cái batch size là bao nhiêu thì ở đây sẽ là bao nhiêu
0:10:05 - 0:10:12, Rồi, và bây giờ chúng ta sẽ tiến hành chạy hai cái đoạn code encoder và decoder
0:10:14 - 0:10:22, Rồi, thì chúng ta sẽ có một cái lớp đối tượng nữa đó là autoencoder, nó sẽ bao gồm hai thành phần đó là encoder và decoder
0:10:23 - 0:10:31, Rồi khi gọi hàm forward thì chúng ta sẽ nhận cái ảnh đầu vào và gọi cái cell.encoder để tạo ra cái vector latent g
0:10:31 - 0:10:39, Rồi từ vector latent g chúng ta gọi cell.decoder để trả ra cái x mũ, đây chính là cái x mũ của mình
0:10:46 - 0:10:47, là reconstruct
0:10:51 - 0:10:53, là cái ảnh đã được khôi phục
0:01:05 - 0:11:04, Rồi, ở trong cái hàm train này thì chúng ta sẽ có dùng cái optimizer là adam, mặc định khi chúng ta không rành về optimizer thì chúng ta cứ dùng adam
0:11:05 - 0:11:14, và chúng ta sẽ có nhiều epoch, rồi sau đó chúng ta sẽ chuyển qua dữ liệu, chúng ta thấy là cái dữ liệu này sẽ được lấy từ tập dữ liệu MNIST
0:11:14 - 0:11:22, và trong tập MNIST thì cái data của mình nó sẽ có dữ liệu x và y, trong đó y cho biết đó là ký tự nào
0:11:23 - 0:11:29, nhưng mà chúng ta lưu ý, chúng ta đang huấn luyện theo cái phong cách đó là unsupervised learning, tức là không giám sát
0:11:30 - 0:11:39, do đó thì ở đây chúng ta sẽ không có sử dụng cái y, chúng ta rê chuột vào đây chúng ta thấy không dùng, nhưng khi chúng ta rê vào x thì chúng ta thấy biến x có sử dụng
0:11:39 - 0:11:53, và x sẽ được chuyển vào trong device đó là GPU và khởi tạo optimizer là Zero Grad, tức là Gradient Descent với mặc định ban đầu bằng 0
0:11:54 - 0:12:02, rồi x hat qua cái autoencoder nhận vào cái biến đầu vào x và nó sẽ ra cái x hat là cái đã được khôi phục lại
0:12:02 - 0:12:17, thì hàm loss ở đây là gì? sẽ là bằng x hat trừ cho x, sau đó chúng ta sẽ mũ 2 lên, rồi sau đó chúng ta sẽ đi tính tổng
0:12:17 - 0:12:32, sau khi tính tổng xong chúng ta sẽ gọi hàm backward để thực hiện cái thuật toán back propagation và tiến hành update lại cái tham số
0:12:32 - 0:12:44, rồi thì đây chính là cái hàm train, tiếp theo thì chúng ta sẽ gọi cái hàm và gọi cái đối tượng là autoencoder với latent dim là bằng 2
0:12:44 - 0:12:54, câu hỏi là tại sao chúng ta lại chọn latent dim là bằng 2? Đáp án chính là để dễ trực quan hóa, điều gì xảy ra nếu latent dim bằng 4 bằng 5
0:12:54 - 0:13:03, chúng ta sẽ rất khó để có thể vẽ lên trên cái Colab, sau đó chúng ta chọn dim bằng 2 là vừa đủ nhỏ để có thể vẽ lên trên cái không gian 2 chiều
0:13:03 - 0:13:21, tỉ lệ nén trong trường hợp này nó sẽ là 784 x 2, tức là nó nén khoảng 392 lần, rồi điều gì xảy ra nếu dim bằng 1 thì rõ ràng là nó sẽ bị mất mát rất nhiều thông tin
0:13:21 - 0:13:33, và có thể cái việc khôi phục nó khó đạt được đến cái ảnh gốc ban đầu, thì đây chúng ta sẽ phải thử, nhưng mà trước mắt chúng ta sẽ sử dụng cái latent dim là bằng 2
0:13:33 - 0:13:42, và autoencoder sẽ được đưa vào GPU, rồi dữ liệu được đóng gói và chúng ta sẽ gọi hàm train
0:13:42 - 0:13:52, nó sẽ có no attribute là relu, rồi chúng ta sẽ xem trong cái decoder
0:13:52 - 0:14:02, rồi ở đây nó không phải là cell.relu mà là f.relu, chúng ta sẽ chạy lại
0:14:22 - 0:14:27, Cảm ơn các bạn đã xem video hấp dẫn