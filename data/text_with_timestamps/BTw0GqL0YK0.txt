00:00:00 - 00:00:25, Chúng ta sẽ cài đặt thực toán RadarLesson và cài đặt biến thể nâng cao của RadarLesson, đó là Momentum
00:00:26 - 00:00:37, Trong thực toán RadarLesson, chúng ta dùng 1 hàm chỉ có 1 điểm cực tiểu thôi, do đó nó sẽ không thể minh họa được cho tình huống Momentum
00:00:37 - 00:00:44, Chúng ta sẽ dùng 1 hàm có nhiều hơn 1 điểm cực tiểu, và cụ thể đó là hàm có 2 điểm cực tiểu
00:00:44 - 00:00:55, Thì cái hàm này chúng ta có thể chọn là 1 công thức là 1 hàm mật 4, là bằng theta mũ 4 cộng cho theta mũ 3 trừ cho 5 theta bình còn 3
00:00:56 - 00:01:03, Thì ở đây nó sẽ có 2 điểm cực tiểu, và cái giá trị mình khởi tạo ở đây thì nó là 1 cái giá trị đủ nhỏ thôi
00:01:03 - 00:01:09, Tại vì nếu vì cái hàm này là hàm mật 4, nếu chúng ta để con số là 12 thì con số nó sẽ rất là lớn
00:01:09 - 00:01:15, Do đó chúng ta sẽ chọn 1 con số đủ nhỏ, theta khởi tạo bằng đầu có thể là bằng mũ 4 thôi
00:01:16 - 00:01:25, Và alpha cũng tương tự như vậy, alpha là 1 cái con số rất là lớn, trong trường hợp này là 0.5 là 1 con số rất là lớn
00:01:25 - 00:01:36, Chúng ta có thể sử dụng 1 cái alpha khoảng là 0.01 để cho nó đủ nhỏ
00:01:36 - 00:01:43, Tại vì khi chúng ta làm với cái hàm lớn như thế này thì dùng con số alpha lớn nó sẽ khiến cho mình bị phân kỳ
00:01:44 - 00:01:51, Tiếp theo là chúng ta sẽ cài đặt các công thức ở đây
00:01:57 - 00:02:10, Thì đầu tiên chúng ta sẽ sửa lại cái hàm của mình, hàm j là theta mũ 4 cộng cho theta mũ 3 trừ cho 5 nhân theta bình phương cộng 3
00:02:11 - 00:02:27, Và sẽ sửa lại cái hàm đạo hàm, 4 nhân theta mũ 3 cộng cho 3 nhân theta bình phương trừ cho 10 nhân theta
00:02:28 - 00:02:41, Sau đó chúng ta sẽ tiến hành cài đặt, theta bằng đầu là 12, nó sẽ rất là lớn, ở đây chúng ta sẽ sửa lại nó phải mần 4 thôi
00:02:42 - 00:02:58, Rồi alpha là 0.1 và v bằng đầu sẽ được gán bằng 0, rồi delta là 0.1 và beta là 0.9
00:02:58 - 00:03:09, Trong cái công thức cập nhật thì chúng ta vẫn sẽ tính đạo hàm nhưng mà chúng ta sẽ có thêm alpha là bằng alpha hạ nhân với delta
00:03:09 - 00:03:19, Tức là cứ mỗi một lần lập là nó sẽ giảm xuống 10 lần, lưới thì con số này chúng ta sẽ tìm cách chúng ta tune nó để cho nó trực quan được
00:03:19 - 00:03:28, Thứ 2 là v sẽ là bằng beta nhân với lại v quá khứ, tức là v trước đó, cộng cho alpha nhân với lại đạo hàm
00:03:28 - 00:03:34, Thì đạo hàm ở đây chúng ta đã được tính sẵn trong cái biến đó là derivative, dẫn đến là chúng ta không cần phải tính lại nữa
00:03:34 - 00:03:37, Và ở đây theta sẽ là bằng theta trừ cho v
00:03:37 - 00:03:40, Rồi bây giờ chúng ta sẽ trực quan hóa nó
00:03:44 - 00:03:48, Rồi để trực quan hóa thì chúng ta sẽ run ở đây
00:03:48 - 00:03:58, Vì cái khoảng giá trị của mình là rất là lớn nên nếu chúng ta để cái biên trái và biên phải là trừ 10 và 12 như ở đây
00:03:58 - 00:04:07, Vì vậy chúng ta sẽ phải sửa lại khoảng giá trị là từ trừ 4 cho đến 4 thôi
00:04:12 - 00:04:19, Khi chạy chúng ta thấy là cái đồ thị của mình nhìn nó có vẻ hơi không có được mượt mà nó bị gấp gấp gốc khúc
00:04:19 - 00:04:27, Thì để giảm cái hiện tượng này chúng ta sẽ cho cái khoảng lấy mẫu nhỏ xuống đó là khoảng 0.1
00:04:28 - 00:04:30, Rồi sau đó chúng ta sẽ chạy lại
00:04:30 - 00:04:34, Chúng ta thấy là cái hàm của mình đã cái đường thẳng của mình nhìn nó mượt hơn
00:04:35 - 00:04:37, Và khi chạy thì chúng ta thấy là
00:04:39 - 00:04:41, Đó đến đây thì nó lại rất là chậm
00:04:42 - 00:04:43, Nó là rất là chậm
00:04:43 - 00:04:44, Thì nguyên nhân đó là do đâu?
00:04:46 - 00:04:50, Nguyên nhân đó là do cái decay rate của alpha
00:04:52 - 00:04:55, Alpha tại một thời điểm cứ mỗi một ngồng lập
00:04:55 - 00:04:59, Thì alpha là bằng alpha nhân với lại delta
00:05:01 - 00:05:04, Tức là alpha là bằng alpha nhân 0.1
00:05:04 - 00:05:06, Hay nói cách khác đó là alpha chia 10 đi
00:05:08 - 00:05:11, Alpha ban đầu của mình đã đủ nhỏ rồi mà mình còn chia 10 nữa
00:05:11 - 00:05:12, Đúng không?
00:05:12 - 00:05:18, Thì dẫn đến đó là đến đây nó gần như không có sự tham gia của đạo hàm hiện tại
00:05:18 - 00:05:20, Dẫn đến là tại những vị trí này
00:05:20 - 00:05:22, Đạo hàm hiện tại nó rất là bé
00:05:23 - 00:05:26, Do đó thì mình sẽ sửa lại cái hệ số này
00:05:26 - 00:05:27, Nâng nó lên
00:05:27 - 00:05:30, Delta là bằng 0.2
00:05:32 - 00:05:33, Tức là giảm vừa thôi
00:05:34 - 00:05:36, Rồi chúng ta lưu và chạy
00:05:38 - 00:05:41, Thì chúng ta thấy là nó nhảy xa hơn
00:05:41 - 00:05:46, Lý do đó là vì nó lấy được cái đạo hàm thực sự tại cái vị trí này
00:05:46 - 00:05:49, Còn nếu mà chúng ta chia cho 10 thì cái phần đạo hàm
00:05:50 - 00:05:52, Mà nó cập nhật vô cái bước nhảy của mình rất là ít
00:05:52 - 00:05:57, Ban đầu đã là 0.01 là tương đối nhỏ là vừa
00:05:57 - 00:05:59, Nhưng mà lần sau lại chia 10
00:05:59 - 00:06:01, Rồi lần tiếp theo lại chia 10 nữa
00:06:01 - 00:06:04, Thì cái phần đạo hàm tại vị trí này nó gần như không tham gia vô
00:06:04 - 00:06:08, Vì do đó chúng ta giảm nó bớt bớt thôi là khoảng 0.2
00:06:08 - 00:06:10, Và khi chúng ta giảm xuống
00:06:10 - 00:06:14, Thì chúng ta thấy là tại cái vị trí này
00:06:14 - 00:06:17, Nó đã thoát ra được khỏi cái điểm cực tiểu của bộ
00:06:17 - 00:06:19, Nó đã thoát khỏi được cái điểm cực tiểu của bộ ở đây
00:06:19 - 00:06:23, Và nó trượt xuống đây để mà nó chạm được đến cái điểm cực tiểu
00:06:23 - 00:06:30, Thứ 2 thì đây chính là cái ý nghĩa của thuộc toán Momentum
00:06:30 - 00:06:34, Bây giờ nếu chúng ta sửa lại thêm một chút xíu
00:06:34 - 00:06:40, Là ví dụ như ở đây chúng ta để là cho Delta này lên 0.3
00:06:40 - 00:06:41, Thì điều gì sẽ xảy ra
00:06:42 - 00:06:45, Nếu cho Delta lên 0.3
00:06:45 - 00:06:47, À Delta lên 0.3
00:06:52 - 00:06:54, Thì nó cũng sẽ thoát ra được
00:06:54 - 00:06:57, Nhưng đến đây là nó vẫn còn quá mạnh
00:06:57 - 00:07:02, Vẫn đến là nó sẽ cứ thế mà đi lên tiếp luôn
00:07:02 - 00:07:07, Do là cái thành phần Delta của mình
00:07:07 - 00:07:09, Là nó nhận được cái alpha
00:07:09 - 00:07:14, Cho cái thành phần alpha ban đầu của mình là một con số chưa có đủ nhỏ
00:07:14 - 00:07:18, Do đó muốn để cho nó là 0.3 ở đây
00:07:18 - 00:07:20, Thì chúng ta phải giảm tiếp alpha nữa
00:07:20 - 00:07:25, Tức là một khi chúng ta tăng Delta lên thì chúng ta phải giảm alpha để cho nó cân bằng
00:07:25 - 00:07:29, Ví dụ ở đây sẽ là 0.01
00:07:29 - 00:07:33, Rồi, chúng ta sẽ chạy lại
00:07:38 - 00:07:40, Nếu chúng ta giảm nhỏ quá
00:07:40 - 00:07:42, Alpha mà bép quá bé
00:07:42 - 00:07:47, Thì đến đây là cái thành phần đạo hàm nó không còn đóng góp gì nhiều vô nữa
00:07:47 - 00:07:49, Nó không còn đóng góp gì nhiều vô nữa
00:07:49 - 00:07:51, Và đến đây là nó bị dừng luôn
00:07:51 - 00:07:57, Với những cái ví dụ này chúng ta thấy việc tune các siêu tham số rất là quan trọng
00:07:57 - 00:08:00, Nếu như chúng ta tune mà không đúng
00:08:00 - 00:08:03, Một số quá nhỏ, một số quá lớn
00:08:03 - 00:08:05, Thì dẫn đến đó là hai tình huống
00:08:05 - 00:08:08, Tình huống đầu tiên là như chúng ta thấy ở đây
00:08:08 - 00:08:10, Khi alpha quá nhỏ
00:08:10 - 00:08:12, Thì cái thành phần đạo hàm ở đây
00:08:12 - 00:08:16, Nó tham gia vô cái việc mà cập nhật tham số cũng rất là ít
00:08:16 - 00:08:18, Và nó mau chóng nó bị tiêu biến đi
00:08:18 - 00:08:20, Dẫn đến là nó sẽ bị đứng ở đây luôn
00:08:22 - 00:08:29, Rồi, do đó chúng ta phải chọn alpha vừa đủ để có thể bắt đầu được
00:08:31 - 00:08:35, Rồi, khi chúng ta chọn alpha vừa đủ rồi
00:08:35 - 00:08:38, Nhưng mà cái delta của mình nó lại quá lớn
00:08:38 - 00:08:42, Thì dẫn đến đó là nó sẽ lấy cái giá trị đạo hàm
00:08:42 - 00:08:45, Nó không có giảm đủ nhanh
00:08:45 - 00:08:47, Nó không có giảm alpha đủ nhanh
00:08:47 - 00:08:51, Dẫn đến là nó còn kế thừa cái thành phần đạo hàm rất là lớn ở trên đây
00:08:51 - 00:08:55, Để mà nó kéo qua đây và cập nhật tiếp
00:08:58 - 00:09:01, Do đó thì ở đây chúng ta phải giảm xuống là khoảng 0.2
00:09:01 - 00:09:04, Giảm xuống là khoảng 0.2
00:09:04 - 00:09:06, Và chúng ta sẽ chạy lại
00:09:06 - 00:09:13, Giảm xuống 0.2 thì có vẻ như là vừa đủ để nó vừa thoát ra khỏi điểm cực tiểu
00:09:13 - 00:09:16, Chúng ta vừa thoát ra khỏi điểm cực tiểu cục bộ
00:09:16 - 00:09:19, Và tiến đến một điểm cực tiểu tốt hơn
00:09:19 - 00:09:24, Thì là khi chúng ta chọn alpha và delta vừa đủ
00:09:24 - 00:09:28, Còn nếu chúng ta chọn delta mà nhỏ quá
00:09:28 - 00:09:31, Thì cái việc giảm alpha này quá nhanh
00:09:31 - 00:09:35, Cái việc giảm alpha quá nhanh dẫn đến đó là những cái vòng lập sau
00:09:35 - 00:09:40, Nó sẽ bị dừng trước lúc thoát ra khỏi điểm cực tiểu
00:09:40 - 00:09:46, Đến đây là bắt đầu nó sẽ không thoát ra khỏi được điểm cực tiểu của bộ ở đây rồi
00:09:50 - 00:09:53, Thì đó chính là cái điểm yếu của mình
00:09:53 - 00:09:57, Khi chúng ta chọn tham số quá nhiều
00:09:57 - 00:09:59, Khi mô thuật toán của mình mà nó có quá nhiều tham số
00:09:59 - 00:10:02, Thì cái thuật toán Adam là một cái thuật toán mà
00:10:02 - 00:10:06, Nó khá là bình vững và ổn định với các cái siêu tham số
00:10:06 - 00:10:10, Khi chúng ta chọn những cái alpha và theta mắc định ban đầu
00:10:10 - 00:10:12, Thì nó có thể là ra một cái toán tốt hơn
00:10:12 - 00:10:16, Tuy nhiên Adam nó sẽ phù hợp cho những cái mô hình
00:10:16 - 00:10:19, Mà có nhiều tham số
00:10:19 - 00:10:23, Còn ở đây chúng ta đang chỉ sử dụng một cái hàm một biến theta thôi
00:10:23 - 00:10:28, Còn Adam và root mean square propagation
00:10:28 - 00:10:33, Thì nó lại phù hợp cho những cái mô hình mà có nhiều hơn hai tham số
00:10:33 - 00:10:38, Rồi như vậy thì ở đây chúng ta sẽ trả lại cái tham số để mà có thể chạy được
00:10:38 - 00:10:44, Đó chính là 0.2 và alpha là bằng 0.1
00:10:48 - 00:10:53, Rồi thì chúng ta thấy là nó đã di chuyển rất là nhanh ở kết điểm thực tiểu của bộ đầu tiên
00:10:53 - 00:10:56, Và sau đó thì nó sẽ vượt qua được
00:10:57 - 00:11:02, Thì đối với cái thuật toán này chúng ta sẽ có một cái chú ý
00:11:02 - 00:11:08, Đó là vì ở đây nó may mắn nó không chạm được đến cái điểm mà đủ nhỏ
00:11:08 - 00:11:10, Tức là cái điểm mà đạo hàm đủ nhỏ
00:11:10 - 00:11:13, Chứ nếu nó chạm vô được cái điểm đủ nhỏ này
00:11:13 - 00:11:18, Mà nó gặp cái lệnh if này thì nó sẽ thoát ra khỏi cái chương trình của mình luôn
00:11:18 - 00:11:22, Do đó đa số các cái thuật toán momentum
00:11:23 - 00:11:28, Và hướng luyện các cái optimizer không có dùng cái điều kiện này
00:11:28 - 00:11:30, Mà họ sẽ chạy với một số vòng lập nhất định
00:11:30 - 00:11:34, Tại vì nếu vô tình chúng ta chạm được cái điểm thực tiểu của bộ
00:11:34 - 00:11:37, Thì nó sẽ thoát ra khỏi cái chương trình của mình luôn
00:11:37 - 00:11:40, Do đó thì mình sẽ sửa lại một lần nữa
00:11:40 - 00:11:42, Thay vì chúng ta dùng cái điều kiện này
00:11:44 - 00:11:48, Thì chúng ta sẽ cho một cái vòng lập ở đây là form
00:11:48 - 00:11:51, iInRange
00:11:51 - 00:11:54, Của chúng ta cho nó chạy khoảng 100 lần
00:11:56 - 00:11:57, Rồi chúng ta sẽ dừng
00:11:57 - 00:12:01, Và ở đây chúng ta sẽ bỏ qua cái biến epsilon
00:12:02 - 00:12:06, Thì đây chính là cái biến thể momentum
00:12:08 - 00:12:09, Và thuật toán nó vẫn chạy được
00:12:09 - 00:12:12, Cho đến khi nào mà nó gặp đủ 200 vòng lập
00:12:12 - 00:12:17, Thì nó sẽ kết thúc cái thuật toán momentum của mình
00:12:19 - 00:12:24, Rồi, trong phần này chúng ta đã cùng cài đặt thử tán momentum
00:12:24 - 00:12:27, Và cho thấy được cái hiệu quả của nó
00:12:27 - 00:12:29, Thuát ra khỏi điểm thực tiểu của bộ
00:12:29 - 00:12:33, Nhưng mà nó sẽ có một vấn đề đó là cái siêu thăm số của mình
00:12:33 - 00:12:38, Chúng ta sẽ phải chọn những cái siêu thăm số cho phù hợp
00:12:38 - 00:12:43, Mặc định ban đầu đó là alpha của mình nên là con số đủ nhỏ
00:12:43 - 00:12:48, Đối với những hàm đa thức trên thế này là 0.01
00:12:48 - 00:12:51, Nhưng mà sau này khi chúng ta làm với các mô hình học sâu
00:12:51 - 00:12:53, Thì alpha nó có thể nhỏ hơn nữa
00:12:53 - 00:12:56, Ví dụ như là 0.0001 tức là 10 mũ trường 4
00:12:56 - 00:13:01, Và các learning rate, các hệ số này
00:13:01 - 00:13:05, Thì chúng ta những biến thể sau nó cũng đã cải tiến
00:13:05 - 00:13:08, Để cho kể cả khi ban đầu V bằng 0
00:13:08 - 00:13:12, Nhưng mà cái thuật toán của mình nó vẫn có thể chạy nhanh ở những vòng lập đầu tiên
00:13:12 - 00:13:16, Vì vậy thì chúng ta kết thúc cái bài thực hành momentum ở đây
