00:00:00 - 00:00:23, Chúng ta sẽ lược qua một số biến thể khác của các mô hình thị giác, công ngữ thị giác
00:00:23 - 00:00:27, Mô hình đầu tiên là Mô hình Clam
00:00:27 - 00:00:35, Ý tưởng của Mô hình này là có chứa một dạng token đặc biệt, đó là set
00:00:35 - 00:00:51, Mô hình này là một trong những chủ đề đặc đáo và mới trong thời gian gần đây
00:00:51 - 00:01:03, Mô hình ngôn ngữ sẽ nói thông qua mask, khai thác được mô hình ngôn ngữ cho một bài toán liên quan đến segmentation
00:01:03 - 00:01:14, Thay vì chúng ta cần phải có một mô hình chuyên dụng để segment được hình ảnh của đối tượng
00:01:14 - 00:01:27, Mô hình LM sẽ output ra prompt và chỉ việc decode là có thể tạo ra mask của đối tượng
00:01:27 - 00:01:38, Tức là kết quả segmentation đến từ lak language model, chứ không phải từ một mô đoàn chuyên dụng cho bài toán segmentation
00:01:38 - 00:01:44, Một ý tưởng cũng tương tự như vậy, đó chính là mô đình route hot
00:01:44 - 00:01:50, Nó có chứa một token đặc biệt, đó là GRD, tức là biết chắc tắc của chữ routing
00:01:50 - 00:02:03, Ý tưởng của nó là sử dụng một multi-language model để khi chúng ta retrieve mask retrieval head
00:02:03 - 00:02:16, Từ mask retrieval head này, chúng ta sẽ mật lại với các class có trong đối tượng hình của mình để tạo ra một ảnh mask đẹp
00:02:17 - 00:02:31, Bên cạnh việc trả ra một ngôn ngữ để mô tả tấm hình, chúng ta có thể trả ra một dạng ngôn ngữ nhưng có cấu trúc
00:02:31 - 00:02:38, Ngôn ngữ có cấu trúc là Syntrap, tức là có một ví dụ
00:02:38 - 00:02:44, Girl on chair, man sitting on chair, but...
00:02:44 - 00:02:53, Đây chính là một cấu trúc wrap, một cấu trúc có ngữ nghĩa
00:02:53 - 00:03:06, Thay vì chúng ta trả ra một văn bản phi cấu trúc như thế này, chúng ta sẽ trả ra đồng thời thêm Syntrap để cho biết được các đối tượng đã tương tác với nhau như thế nào
00:03:06 - 00:03:10, Và những thông tin đó được lưu trưởng như đồ thị
00:03:12 - 00:03:20, Và một bài tán nữa cũng đã được đề cập trong mô hình trước đây, đó là mô hình SIM
00:03:20 - 00:03:31, Thế thì bài báo ở đây là making last multimodal model understand RB3 VisualProm
00:03:31 - 00:03:40, VisualProm ở đây chính là dấu mũi tên, chúng ta dùng dấu mũi tên để làm tương tác và chỉ thị
00:03:40 - 00:03:47, Chỉ dẫn kèm theo text prompt là What is the person marked with the red arrow honey?
00:03:47 - 00:04:01, Chúng ta kết hợp cả cái cầu prompt dạy text với lại cái VisualProm để mà tăng cái khả năng tương tác cũng như là sử lý cái khả năng dễ hiểu dễ tương tác của người dùng
00:04:01 - 00:04:10, Và một cái mô hình khác nữa đó là chúng ta đã cải tiến cái mô hình thị giác máy tính khác
00:04:10 - 00:04:18, Ở đây chúng ta thấy là chúng ta có sử dụng các cái mô hình của bên mục thị giác máy tính như là mô hình captioning để verbalization
00:04:18 - 00:04:24, Tức là cái tấm ảnh của mình thay vì chúng ta rút trích nó dưới dạng là VisualFeature
00:04:27 - 00:04:32, Vì ở đây chúng ta sẽ verbalization, tức là chúng ta sẽ mô tả bằng lời nó
00:04:32 - 00:04:43, Vì cái việc tấm ảnh nó sẽ biến thành cái dạng mô tả nguồn ngữ chi tiết thì chúng ta sẽ hành sự nó giống như là với văn bản thôi
00:04:43 - 00:04:49, Thì khi đó chúng ta có thể khai thác được các sức mạnh của các mô hình nguồn ngữ lớn
00:04:49 - 00:04:56, Thì đây chính là cái ý tưởng là biến cái tấm ảnh thành một cái dạng mô tả bằng lời chi tiết
00:04:57 - 00:05:02, Và nó nằm trong cái bài tạp báo đó là MOAI
00:05:02 - 00:05:11, Thế thì tổng kết lại chúng ta đã tìm hiểu qua rất nhiều những cái mô hình khác nhau trong phần này
00:05:11 - 00:05:18, Thì đầu tiên đó là cái mô hình RoundingDino thì nó sẽ sử dụng cái ngôn ngữ để query thông tin hình ảnh
00:05:18 - 00:05:25, Và ở cái output của mình nó sẽ là cái dạng segment, segmentation
00:05:26 - 00:05:28, Tức là một cái phân đoạn ảnh
00:05:28 - 00:05:34, Và đầu vào của mình sẽ là một cái prompt dạng ngôn ngữ text
00:05:34 - 00:05:43, Thế thì cái RoundingDino này nó sẽ phải kết hợp với một cái mô hình segmentation rất là tốt
00:05:43 - 00:05:50, Mà dựa trên cái VisualProm hoặc là SpecialProm là chính là mô hình SAM
00:05:50 - 00:05:56, Tại vì cái mô hình RoundingDino này thì nó chỉ tạo ra được cái BoundingBox
00:05:56 - 00:06:03, Chúng ta lấy cái BoundingBox này đưa vào SAM để mà nó segment ra chính xác đối tượng của mình
00:06:03 - 00:06:12, Thế thì có cái cách để mà không cần phải sử dụng SAM mà chúng ta có một cái mô hình end-to-end để mà segment, đó chính là SIM
00:06:12 - 00:06:19, Và SIM nó có một cái điểm thú vị khác đó là nó đa thể thức trong cái VisualProm
00:06:19 - 00:06:23, Nó có thể là một điểm, cái VisualProm của mình nó có thể là một điểm
00:06:23 - 00:06:29, Một BoundingBox, một cái Mask hoặc là một cái StripWall, một cái đường nét nguệt nguệt
00:06:29 - 00:06:34, Và đồng thời là nó có hợp trợ các cái phương thức là Composite
00:06:34 - 00:06:44, Cũng như là CompositeProm, tức là có sự kết hợp của cả VisualProm, TextProm, vâng
00:06:44 - 00:06:54, Hoặc SIM cũng có thể đưa vào dưới dạng là ReferringProject
00:06:57 - 00:07:00, Tức là chúng ta sẽ không biết cái đối tượng đó là gì
00:07:00 - 00:07:07, Thì chúng ta sẽ query, đưa vào KeepRom, dạng là TimeChill
00:07:07 - 00:07:12, Thì chúng ta sẽ tìm cái đối tượng giống như cái đối tượng trong kỷ ảnh TimeChill của mình
00:07:13 - 00:07:18, Thì đây là hai cái mô hình phục vụ cho cái bài toán Segmentation
00:07:19 - 00:07:25, Sau đó thì chúng ta sẽ có những cái mô hình liên quan đến cái việc là khai thác mô hình nguồn ngựa lớn
00:07:25 - 00:07:31, Cho các cái bài toán của nguồn ngựa thị giác, đó là mô hình lava
00:07:31 - 00:07:36, Và mô hình lava nó đã đưa cái trạp trường ảnh về cùng không gian với lại cái mô hình LOM
00:07:36 - 00:07:40, Thông qua một cái ProjectionLayer
00:07:43 - 00:07:46, Thì nó sẽ đưa về cái không gian của LOM
00:07:46 - 00:07:51, Sau đó thì nó sẽ tận dụng được cái tri thức đã được huấn luyện trước đó của LOM
00:07:51 - 00:07:54, Để mà có thể giải quyết được các cái bài toán phục tạp
00:07:55 - 00:07:59, Và lava đã cải thiện được ba yếu tố đó là
00:07:59 - 00:08:04, Nó có thể được cải thiện thông qua việc tăng cái chất ngượng của bộ dữ liệu lên
00:08:04 - 00:08:06, Tăng cái độ phân giải của ảnh
00:08:06 - 00:08:09, Cũng như là tăng cái độ lớn của mô hình lên
00:08:09 - 00:08:13, Thì cái điều này cũng khá là thú vị
00:08:13 - 00:08:16, Đó là nó cho cái kết quả một cái mô hình open source
00:08:16 - 00:08:21, Và cho cái kết quả cao hơn các cái mô hình closed source ở một số cái task
00:08:21 - 00:08:27, Và hai cái mô hình open source, hai mô hình closed source được so sánh ở đây chính là
00:08:27 - 00:08:35, GmanEye, Flash, Ultra
00:08:35 - 00:08:39, GmanEye Ultra hoặc là GmanEye Pro
00:08:39 - 00:08:45, Còn cái phiên bản ở đây của GBT, đó là GBT 4V
00:08:45 - 00:08:47, Là 4vision
00:08:47 - 00:08:53, Thì cái lava cho cái kết quả tốt hơn hai cái mô hình này ở một số cái task
00:08:53 - 00:08:54, Chắc định
00:08:54 - 00:09:01, Thế thì cuối cùng đó là chúng ta có thể tùy biến cái đầu vào và đầu ra của lava
00:09:01 - 00:09:04, Để giải quyết được những cái bài toán khác nhau
00:09:04 - 00:09:08, Tại vì khi chúng ta cấu hình những cái đầu vào và đầu ra
00:09:08 - 00:09:10, Thì sau đó chúng ta sẽ file tune lại
00:09:10 - 00:09:13, Còn cái cơ chế chung của lava
00:09:13 - 00:09:18, Nó vẫn là đưa cái đặt trưng ảnh để về cái không gian của cái mô hình ngôn ngữ lớn
00:09:18 - 00:09:23, Và khai thác được cái mô hình ngôn ngữ lớn cho cái việc giải quyết các cái bài toán khác nhau phức tạp
00:09:23 - 00:09:29, Thì trên đây đó là chúng ta đã tổn kết qua những cái mô hình
00:09:29 - 00:09:31, Thị giác ngôn ngữ
00:09:31 - 00:09:34, Mô ngữ thị giác vision language model
00:09:34 - 00:09:37, Mà đã được học trong cái phần số 2 này
