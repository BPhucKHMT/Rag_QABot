00:00:00 - 00:00:20, Chúng ta sẽ cùng đến với phần cài đặt minh họa cho học trương phản Contrasted Mini
00:00:20 - 00:00:25, Đây là một kỹ thuật được sử dụng trong hữu luyện với Moon Clip
00:00:25 - 00:00:33, Với dụng minh họa này, hình này là lấy từ papergop của Moon Clip
00:00:33 - 00:00:38, Và trong sơ đồ này, chúng ta thấy là một văn bản của mình
00:00:38 - 00:00:45, Thì qua text encoder, chúng ta có thể sử dụng class retrain model
00:00:45 - 00:00:51, Nhưng mà để cho đơn giản, với cài đặt, chúng ta tập trung nhiều vào phần học trương phản
00:00:51 - 00:00:58, Nên ở đây chúng ta sẽ sử dụng dữ liệu mô phẩm, đó là một random vector
00:00:58 - 00:01:03, Và tương tự như vậy cho dữ liệu ảnh, chúng ta cũng sẽ sử dụng random vector
00:01:03 - 00:01:08, Thế hiện ở trong hai cái hạng pos.random
00:01:08 - 00:01:16, Và như vậy chúng ta sẽ tiến hành các bước thực hiện với contrasted learning này
00:01:16 - 00:01:26, Đó là chúng ta sẽ có một bước từ vector mô phẩm chúng ta sẽ chuẩn hóa để tạo ra các vector
00:01:26 - 00:01:31, T1, T2, T3 cho đến Tn này
00:01:31 - 00:01:41, Với mỗi t, nó sẽ là một emitting cho một văn bản
00:01:41 - 00:01:47, Còn với một ảnh y1, y2 v.v., nó sẽ là một vector biểu diễn cho một ảnh
00:01:47 - 00:01:53, Trong cái ví dụ này chúng ta thấy nó có tất cả là n ảnh
00:01:53 - 00:02:00, Thì ở đây chúng ta sẽ có n chính là số lượng cập hình ảnh văn bản
00:02:00 - 00:02:03, Trong một bát dữ liệu mà chúng ta nem đi để huyện
00:02:03 - 00:02:12, Và mỗi một vector này y1, t1, in, tn
00:02:12 - 00:02:16, Bịểu diễn bằng một vector có kích thước là d
00:02:16 - 00:02:23, D là bằng 8, để tạo ra ma trận y
00:02:23 - 00:02:28, Vì tức là emitting của ảnh y1 cho đến in
00:02:28 - 00:02:33, Thì chúng ta sẽ tạo torch.random n như d
00:02:33 - 00:02:39, Trong đó n là số ảnh và d chính là số chiều của mỗi vector biểu diễn
00:02:39 - 00:02:46, Thì nếu đúng ra thì nó sẽ lấy từ một pretrained model
00:02:46 - 00:02:52, Và chúng ta feed qua n ảnh
00:02:52 - 00:02:57, Nhưng ở đây để cho đơn giản thì chúng ta tạo ra vector nổ nhiên
00:02:57 - 00:03:02, Sau đó thì tương tự như vậy thì te
00:03:02 - 00:03:08, Nếu đúng là te nó sẽ phải tương đồng với ire
00:03:08 - 00:03:12, Tức là emitting của ảnh nó sẽ tương đồng với ire
00:03:12 - 00:03:19, Tuy nhiên ở đây chúng ta mong muốn là không phải sử dụng các dữ điều thật
00:03:19 - 00:03:23, Nếu chúng ta sử dụng chính te này là i luôn
00:03:23 - 00:03:30, Thì ma trận này sẽ tiến về một ma trận đương vị
00:03:30 - 00:03:35, Nhưng mà vì chúng ta muốn nó có cái tương chất gọi là ngộ nhiên
00:03:35 - 00:03:38, Và không có sự tương đồng một cách tuyệt đối
00:03:38 - 00:03:56, Nên ở đây chúng ta sẽ cộng thêm một cái đại lượng nhiễu để cho tạo ra sự sai khát giữa ảnh và văn bản đủ nhậu
00:03:56 - 00:04:03, Sau đó thì chúng ta sẽ tiến hành chuẩn hóa hai vector này
00:04:03 - 00:04:07, Thì để chuẩn hóa thì chúng ta phải biết thêm một cái hàm
00:04:07 - 00:04:11, Đó là hàm norm L2
00:04:11 - 00:04:16, Thế thì ở đây chúng ta sẽ kệ đặt tu đô này
00:04:16 - 00:04:19, Đó là L2Norm
00:04:19 - 00:04:26, Rồi, thì ở đây chúng ta sẽ đép và chúng ta sẽ truyền vào một cái vector V
00:04:26 - 00:04:30, Về đây chúng ta để lại vector đây
00:04:30 - 00:04:53, Sau đó Vector sẽ là bằng Vector chia cho norm của norm L2
00:04:53 - 00:05:09, Rồi, thì ở đây nếu chúng ta chuẩn hóa trên full toàn bộ với mỗi một vector như thế này thì mọi chuyện là đơn giản rồi
00:05:09 - 00:05:18, Nhưng mà ở đây vì chúng ta đưa vét đồ vào nó không phải là một vector mà nó là một cái ma trận Te và E
00:05:18 - 00:05:25, Mà chúng ta đang muốn lấy theo một cái trục là theo trục của N
00:05:25 - 00:05:35, Tức là với mỗi một cái dữ liệu thì chúng ta sẽ đi chuẩn hóa trên cái trục của đặc trưng thôi
00:05:35 - 00:05:37, Tức là cái trục D này thôi
00:05:37 - 00:05:42, Do đó thì ở đây chúng ta sẽ để lại cái dimension là bằng trường 1
00:05:42 - 00:05:47, Rồi, thì nó sẽ đi chuẩn hóa theo cái trục D này
00:05:47 - 00:05:59, Rồi, ngoài ra thì chúng ta sẽ không có thay đổi số chiều do đó ở đây chúng ta sẽ để keepDim là bằng trường trung
00:05:59 - 00:06:10, Thì đây chính là cái hàm chuẩn hóa N2 và chúng ta sẽ đặt hàm này cho cái biến là Te và sẽ gán ngược trở lại là Te
00:06:10 - 00:06:17, Rồi tương tự như vậy là Ea cũng sẽ là gán ngược trở lại cho Ea tức là ImageEmitting
00:06:17 - 00:06:23, Tiếp theo thì chúng ta sẽ đi tính cái Logit bằng cách đó là tích vô hướng
00:06:23 - 00:06:27, Tạm thời là chúng ta sẽ không có dùng cái TemporatorToeT
00:06:27 - 00:06:31, Chúng ta sẽ để Te.
00:06:31 - 00:06:42, Thì ở đây chúng ta có thể dùng hàm dot vào dot hoặc là chúng ta sử dụng hàm của torch đó là .matbool
00:06:42 - 00:06:48, Rồi, và chúng ta sẽ truyền là Ea và Te
00:06:53 - 00:07:05, Rồi, thì sau khi chúng ta xử lý xong thì chúng ta sẽ ra được một cái Logit
00:07:05 - 00:07:14, Tức là cái kết quả của cái phép nhân tích vô hướng giữa hai cái ma trận
00:07:14 - 00:07:16, Thực ra là ma trận là chúng ta đang xử lý hàng loài
00:07:16 - 00:07:22, Còn đúng ra thì nó sẽ là xử lý cho từng cái cặp vector 1 với nhau
00:07:22 - 00:07:32, Và ở đây chúng ta chú ý là khi chúng ta để đảm bảo được cái việc nhân tích vô hướng thì cái Te này nó sẽ phải chuyển vị
00:07:32 - 00:07:37, Tại vì ban đầu cái Te và Ea đều cùng có kích thước là Nd
00:07:37 - 00:07:43, Muốn nhân được với nhau thì cái Te là Nd, thì phải nhân, cái Ea là Nd
00:07:43 - 00:07:51, Thì nhân với lại cái Te nó sẽ là Dn, tức là cái ma trận kích thước là Nd
00:07:51 - 00:07:59, Sẽ nhân với cái ma trận là Dn
00:07:59 - 00:08:02, Đó là lý do tại sao chúng ta phải chuyển vị
00:08:02 - 00:08:09, Và đầu ra của mình nó sẽ trả về là một cái ma trận kích thước là Nd
00:08:09 - 00:08:16, Thì đúng như trong cái Soto này là kích thước của mình sẽ là N, nhân cho N
00:08:16 - 00:08:22, Rồi, và chút nữa chúng ta cũng sẽ thử nghiệm xem khi chúng ta thêm tô vô thì nó sẽ như thế nào
00:08:22 - 00:08:27, Rồi bây giờ chúng ta sẽ kết nối với lại cái máy
00:08:27 - 00:08:33, Thì thật ra ở đây chúng ta cũng không cần phải có overview do là chúng ta tính toán dị liệu cũng không có nặng
00:08:33 - 00:08:43, Rồi, torch innotify thì ở đây chắc là chúng ta chưa chạy cái lạc này
00:08:43 - 00:08:48, March, ở đây chắc là dư một cái dấu
00:08:48 - 00:09:04, Rồi, bây giờ chúng ta sẽ chạy lại cái code này
00:09:04 - 00:09:13, Và sau khi chúng ta trực qua hóa cái logic thì chúng ta thấy là vì nó có cái ế tố nhiễu nên cái ma trận của mình
00:09:13 - 00:09:25, Nó có thể là phát sáng cái đường ở giữa nhưng mà nó sẽ có cái đại lượng nhiễu nên chúng ta sẽ thấy là nó sẽ lè ra và phát sáng ở một số khu vực như thế này
00:09:25 - 00:09:34, Rồi, và đương nhiên khi contrasting learning thì chúng ta sẽ cố gắng là để cho cái ma trận này càng tiến về cái ma trận đương vị
00:09:34 - 00:09:41, Rồi, sau đó chúng ta sẽ tạo cái ma trận đương vị đó trong những cái phòng sau
00:09:41 - 00:09:47, Rồi, trước hết thì chúng ta sẽ visualize cái dòng số 3 ở đây
00:09:47 - 00:09:49, Nhìn nó như thế nào
00:09:49 - 00:09:56, Thì để visualize dòng số 3 chúng ta sẽ lấy logic 3, 2 chấm, tức là lấy nguyên một cái dòng
00:09:56 - 00:10:03, Và ở đây chúng ta sẽ truyền là none 3 chấm, tức là chúng ta sẽ lấy hết tất cả cái ô này để vẽ lên
00:10:03 - 00:10:10, Rồi, chúng ta thấy bản chất nó chính là cái ô này đẹp xuống thôi
00:10:10 - 00:10:17, Thì ở đây chúng ta đang trực quan hóa cái dòng số 3 lên
00:10:17 - 00:10:19, Và đây là cái logic
00:10:19 - 00:10:25, Sau đó thì chúng ta sẽ viết cái hàng để mà tạo cái label
00:10:25 - 00:10:29, Thì ở đây chúng ta sẽ tạo một cái biến đó là label
00:10:29 - 00:10:31, One Hot
00:10:31 - 00:10:36, Thì nó sẽ là bằng F.One Hot
00:10:38 - 00:10:41, Rồi, truyền cái label vào
00:10:41 - 00:10:44, Và số class của mình nó sẽ là bằng n
00:10:44 - 00:10:49, Và để cho cái mô hình này có thể huấn đuyện nguyên hưởng được
00:10:49 - 00:10:52, Thì chúng ta sẽ có thể là đưa vào GPU
00:10:52 - 00:10:55, Tuy nhiên thì ở đây chúng ta thấy là cái kích thước ma trận quá nhỏ
00:10:55 - 00:11:00, Chúng ta không cần phải truyền vào GPU mà chúng ta có thể dùng trực tiếp CPU để có thể tính toán được
00:11:00 - 00:11:04, Nên ở đây thì chúng ta chỉ cần gọi cái hàng như thế này là được
00:11:04 - 00:11:09, Rồi sau đó thì chúng ta sẽ trực quan hóa cái ma trận này
00:11:09 - 00:11:17, Thì chúng ta thấy là nếu đúng thì cái ma trận ở trên là sẽ phải đưa về đúng với lại cái ma trận nương vị như thế này
00:11:17 - 00:11:24, Rồi, bây giờ chúng ta sẽ trực quan cái hàng số 3 của cái ma trận nương vị này lên
00:11:24 - 00:11:27, Bằng cách đó là chúng ta sẽ gọi cái hàng imshow
00:11:27 - 00:11:30, Chúng ta copy cái cấu rời phía trên xuống
00:11:30 - 00:11:34, plt.imshow
00:11:35 - 00:11:40, Chúng ta sẽ imshow cái label quanh hot
00:11:47 - 00:11:50, Rồi, và cũng lấy cái dòng số 3
00:11:51 - 00:11:53, Chúng ta sẽ lấy dòng số 3 đúng không?
00:11:53 - 00:11:55, Rồi, lấy dòng số 3, 2 chấm
00:11:55 - 00:11:58, Rồi, nâng
00:12:01 - 00:12:12, Rồi, thì ở đây chúng ta thấy là lẽ ra chúng ta phải show cái logit và cái one hot
00:12:12 - 00:12:15, Do đó thì chúng ta sẽ show cái logit trước
00:12:19 - 00:12:24, Cái ví dụ hồi nãy thì chúng ta nhập sai lỗi chúng ta
00:12:24 - 00:12:30, Rồi, thì nó đã lấy cái dòng thứ 3 đem xuống đây
00:12:30 - 00:12:38, Sau đó chúng ta sẽ show cái one hot để cho chắc chúng ta sẽ copy xuống
00:12:38 - 00:12:44, Rồi, ở đây chúng ta sẽ phải tạo một cái figure mới
00:12:54 - 00:13:05, Rồi, thì đây chính là cái dữ liệu của cái logit, tức là cái mà chúng ta nhân tích vô hướng giữa hai cái embedding
00:13:05 - 00:13:10, Còn cái bên hàng dưới cùng sẽ là cái route tool mà lẽ ra chúng ta hướng về
00:13:10 - 00:13:17, Vì là cái ti, tức là cái embedding của ảnh và embedding của băng bảng bắt đầu được lấy giống nhau, chỉ là cộng thêm nhiễu
00:13:17 - 00:13:20, Nên chúng ta thấy là tại vị trí này nó đã bật lên là 1 rồi
00:13:20 - 00:13:28, Nếu đúng thì giá trị bắt đầu với môn khởi tạo của mình sẽ lộn rộn chứ không phải là phát sáng như thế này
00:13:28 - 00:13:36, Vì đây chúng ta đang mô phỏng, cái việc mà contrast dialog nên chúng ta sẽ dùng cái dữ liệu dạng random như vậy
00:13:36 - 00:13:40, Rồi, thì cái hàm mất mát ở đây chúng ta tiếp theo sẽ sử dụng chính là
00:13:40 - 00:13:44, Sử dụng cái hàm cross entropy giữa hai cái vector này
00:13:45 - 00:13:58, Và khi đó thì chúng ta sẽ tính cái T3, tức là cái tax bar với lại y0, T3 với lại y1, T3 với y2 v.v.
00:13:58 - 00:14:03, Thì chúng ta sẽ tính theo hàng rồi sau đó chúng ta sẽ tính theo cột
00:14:03 - 00:14:07, Thì đầu tiên là chúng ta sẽ lấy cột rước thay vì hàng
00:14:07 - 00:14:11, Tóm lại đó là chúng ta sẽ tính theo từng hàng và từng cột
00:14:12 - 00:14:18, Trong cái sơ đồ này, với cái dòng số 3 là chúng ta sẽ tính theo hàng
00:14:18 - 00:14:25, Tức là với ảnh số 3 chúng ta sẽ đi so với tất cả các cái văn bản để xem coi là cái sai số của mình là bao nhiêu
00:14:25 - 00:14:34, Và đối xứng lại thì chúng ta cũng sẽ có cái ký cạnh là cột số 3 là cái văn bản đúng ra phải trả về
00:14:34 - 00:14:39, Thì nó sẽ đi so với lại những cái ảnh khác
00:14:39 - 00:14:43, Thì chúng ta sẽ tính cái loss theo tổng hàng và cột
00:14:43 - 00:14:50, Thế thì nếu mà chúng ta tính theo từng hàng và cột như vậy thì chúng ta sẽ phải biết một cái vòng for
00:14:50 - 00:14:55, Nhưng mà để có thể thực hiện trọn vẹn thì chúng ta cũng tính rất là dễ
00:14:55 - 00:15:01, Đó là chúng ta chỉ việc lấy lossA nè là bằng 9 cái logic.
00:15:01 - 00:15:05, Chúng ta sẽ nhân với lại cái...
00:15:05 - 00:15:07, Chúng ta sẽ lấy để...
00:15:07 - 00:15:13, Xin lỗi ở đây chúng ta không phải là nhân vô hướng và chúng ta sẽ dùng cái hàng cross entropy
00:15:13 - 00:15:21, Chúng ta sẽ dùng cái hàng cross entropy để mà tính như vậy thì f.cross entropy
00:15:21 - 00:15:30, Rồi chúng ta sẽ truyền vào cái logic và cái one-hot vector tức là cái label của mình
00:15:30 - 00:15:40, Thì ở trong trường hợp này cái label của mình chính là cái nhãn mà chúng ta đã setup ở phía trên
00:15:40 - 00:15:43, Đây, cái label này
00:15:43 - 00:15:54, Thì được gán từ một, tức là ảnh thứ nhất, nhãn là một, ảnh thứ hai, nhãn là hai, và cái cặp ảnh thứ n, nhãn là n
00:15:54 - 00:15:58, Rồi, chúng ta sẽ show...
00:15:58 - 00:16:03, Chúng ta sẽ đi tính cái loss này bằng cách lấy logic nhưng bên lại cái label
00:16:03 - 00:16:11, Rồi, bây giờ chúng ta sẽ tính cái hàng loss này là logic và label
00:16:11 - 00:16:16, Rồi, sau đó chúng ta sẽ đi pin nó ra
00:16:16 - 00:16:23, Rồi, chúng ta sẽ tính tương tự như vậy cho cái loss của t, tức là theo text
00:16:23 - 00:16:25, Với text tức là gì?
00:16:28 - 00:16:34, Chúng ta sẽ đi cố định cái text, ví dụ text là t3 và chúng ta sẽ cho y chạy từ trên xuống
00:16:34 - 00:16:46, Thế thì bản chất cái cách tính của t3 với trên theo hàng y3 và t3 thì chúng ta chỉ cần lật cái ma trận lại là xong
00:16:47 - 00:16:50, Rồi, sau đó ở đây chúng ta sẽ sửa lại cái code
00:16:53 - 00:16:58, Đó là chấm, chúng ta thêm một cái thành phần chuyển vị vào đây ha
00:16:58 - 00:17:02, Thì chúng ta sẽ lấy logic này, chuyển vị, cross entropy
00:17:02 - 00:17:09, Và loss tổng hợp thì sẽ là bằng trung bình cộng của hai loss này
00:17:09 - 00:17:15, Đó là bằng loss của y cộng cho loss của t
00:17:17 - 00:17:20, Rồi, thì bây giờ chúng ta sẽ lần lượt chạy cái code
00:17:20 - 00:17:25, Đây là theo cột ha, đây là trực và hóa theo cột
00:17:25 - 00:17:31, Chúng ta lấy ra, thì nếu đúng cái cột này, nó sẽ phải hướng về cái vector này
00:17:31 - 00:17:34, Và nó sẽ mật sáng lên tại cái hàng thứ 3
00:17:34 - 00:17:37, Rồi, bây giờ chúng ta sẽ tính thử
00:17:37 - 00:17:42, Thì cái loss của mình đó là loss theo trực y, nó ra là 2,410
00:17:42 - 00:17:47, Và theo cái trực t, rất là văn bản, thì là 2,2406
00:17:47 - 00:17:50, Và trung bình cộng là 248
