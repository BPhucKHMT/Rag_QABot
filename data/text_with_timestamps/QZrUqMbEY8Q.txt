00:00:00 - 00:00:22, Chào các bạn, chúng ta sẽ cùng đến với chủ đề đầu tiên trong mô máy học nâng cao, đó chính là mô hình dựa trên Radian.
00:00:23 - 00:00:26, Tại sao chúng ta cần phải tìm hiểu mô hình dựa trên Radian?
00:00:26 - 00:00:33, Thì hiện nay các mô hình hiện đại và có rất nhiều những ứng dụng trong thực tế
00:00:33 - 00:00:40, Ví dụ như các mô hình ngôn ngữ lớn, chat jpt, các mô hình sinh ảnh như diffusion model
00:00:40 - 00:00:47, Đều được huấn luyện dựa trên một phương pháp dựa trên Radian, tức là chúng ta tính đạo hàm
00:00:47 - 00:00:52, Và cái phương pháp này là nguyên lý của nó là gì?
00:00:52 - 00:01:03, Và tại sao nó có những ưu điểm để các mô hình hiện đại đều tập trung để sử dụng Radian làm nền tảng để huấn luyện?
00:01:03 - 00:01:06, Chúng ta sẽ cùng tìm hiểu trong bài học ngày hôm nay
00:01:07 - 00:01:14, Đầu tiên chúng ta sẽ cùng tìm hiểu về ý tưởng của mô hình dựa trên Radian
00:01:14 - 00:01:19, Ý tưởng của mô hình dựa trên Radian thì chúng ta sẽ nhận dữ liệu đầu vào là x
00:01:19 - 00:01:23, Thì x này có thể là bất cứ loại dữ liệu nào
00:01:23 - 00:01:31, Ví dụ như nó có thể là dữ liệu dạng vector, nó cũng có thể là dữ liệu dạng ma trận hoặc là tensor
00:01:35 - 00:01:43, Với hai loại là vector, ma trận hoặc là tensor, chúng ta có thể biểu diễn rất nhiều những loại dữ liệu khác nhau
00:01:43 - 00:01:49, Ví dụ như có thể biểu diễn dữ liệu văn bản, dữ liệu dạng hình ảnh, video
00:01:49 - 00:01:58, Và khi chúng ta đưa qua mô hình thì mô hình của mình sẽ được ký hiệu bằng một hàm, đó là hàm fx
00:01:58 - 00:02:04, Nhưng chúng ta lưu ý là đối với hàm fx ở đây nó sẽ có một tham số, đó là tham số theta
00:02:04 - 00:02:09, Cũng tương tự như trong tán phổ thông của chúng ta
00:02:09 - 00:02:25, Ví dụ như chúng ta giải tìm m, tìm tham số m sau cho phương trình bật 2
00:02:25 - 00:02:46, Ví dụ như x bình trừ m x cộng 3 m bình trừ 1 bằng 0 có 2 nghìn
00:02:46 - 00:02:54, Ví dụ vậy, đây là ký toán mà hồi phổ thông chúng ta được làm qua
00:02:54 - 00:03:02, Tham số chính là m của mình và dạng thức của hàm của mình là hàm bật 2
00:03:02 - 00:03:13, Chúng ta có thể ký hiệu f của m x bằng 0, trong đó fmx là công thức ở vế bên tay trái
00:03:13 - 00:03:21, Chúng ta xác định được dạng thù của hàm f rồi
00:03:21 - 00:03:32, Tuy nhiên trong đó chúng ta sẽ có nhiều tham số để quyết định việc dự đoán m chính xác đến mức độ nào
00:03:32 - 00:03:39, Chúng ta phải tìm tham số sau cho hàm fx, nó thỏa mãn việc đó là dự đoán chính xác
00:03:39 - 00:03:50, Đầu ra của hàm fx là y ngã và đây là giá trị mà chúng ta được dự đoán từ mô hình
00:03:50 - 00:03:58, Đương nhiên là việc dự đoán một giá trị nào đó chúng ta luôn mong muốn là nó sẽ sắp xỉ với giá trị thực tế
00:03:58 - 00:04:03, Giá trị thực tế chúng ta sẽ ký hiệu là bằng y
00:04:03 - 00:04:12, Để cho giá trị dự đoán sắp xỉ được với giá trị thực tế thì chúng ta phải có một hàm gọi là hàm lỗi
00:04:12 - 00:04:14, Ký hiệu là chữ j
00:04:14 - 00:04:22, Hàm lỗi này sẽ có biến số, lúc này nó không phải là x nữa mà biến số của mình lúc này nó sẽ là theta
00:04:22 - 00:04:28, Biến số của nó sẽ là theta và x,y của mình nó sẽ đóng vai trò giống như là tham số
00:04:28 - 00:04:39, Nó sẽ khác so với lại hồi xưa, khi mà chúng ta đặt cái tên biến mà là x,y thì nó sẽ ngầm hiểu đó là biến số
00:04:39 - 00:04:46, Còn trong trường hợp này thì cái hàm lỗi của mình x,y sẽ là tham số và nó chính là cái dữ liệu huấn luyện
00:04:46 - 00:04:50, Đó chính là cái dữ liệu huấn luyện
00:04:50 - 00:05:01, Và mình sẽ phải tìm cái biến số theta làm sao cho cái việc giự đoán này là chính xác nhất
00:05:01 - 00:05:10, Và cái việc tìm cái giá trị theta cho cái này chính xác nhất thì nó sẽ tương đương với cái việc là chúng ta đi tìm một cái hàm min
00:05:10 - 00:05:15, Tìm theta sao cho hàm lỗi là đạt giá trị nhỏ nhất
00:05:15 - 00:05:21, Thế thì ba cái công việc chúng ta cần phải làm khi xây dựng một cái mô hình dựa trên radian
00:05:21 - 00:05:28, Một, đó là chúng ta sẽ xác định xem cái hàm fx của mình nó sẽ có cái giảng thức như thế nào
00:05:28 - 00:05:38, Thứ hai, đó là chúng ta sẽ thiết kế cái hàm lỗi là g theta x sao cho cái việc mà giự đoán càng chính xác thì cái lỗi của mình thấp
00:05:38 - 00:05:50, Nhưng đó chưa phải là một cái tiêu chí để thiết kế một cái hàm lỗi càng chính xác thì càng nhỏ
00:05:50 - 00:05:56, Nhưng cái đó chưa phải là một cái tiêu chí duy nhất mà chúng ta sẽ còn rất nhiều những cái tiêu chí khác
00:05:56 - 00:06:06, Mình có thể kể một vài cái tiêu chí ví dụ như là nó có thể hoạt động tốt khi chúng ta làm việc hoạt động tốt
00:06:07 - 00:06:16, khi huấn luyện với dữ liệu mà mất cân bằng
00:06:22 - 00:06:31, Tức là cái y này của mình nó sẽ có nhiều class ví dụ vậy và có những class thì xuất hiện rất nhiều nhưng có những cái class rất ít
00:06:31 - 00:06:45, Thì cái hàm lỗi này nó phải làm sao để cho hướng cái mô hình đến cái việc là kể cả những mẫu dữ liệu mà ít thì vẫn có thể được cho cái vai trò ngang bằng với lại những cái mẫu như nhiều
00:06:45 - 00:06:54, Rồi ngoài ra thì chúng ta sẽ có những cái tiêu chí nữa ví dụ như hàm lỗi như thế nào để cho cái việc huấn luyện nhanh, hội tụ, huấn luyện nhanh
00:06:54 - 00:06:59, Tức là nó sẽ mau chóng để mà tìm ra được cái tham số tốt nhất
00:06:59 - 00:07:08, Rồi cái việc thiết kế hàm mô hình của vậy nó cũng sẽ dựa trên cái tính chất của y, cái giá trị thực tế vx để mà chúng ta sẽ thiết kế
00:07:08 - 00:07:14, Ví dụ như nếu y mà phụ thuộc một cách tiến tính với x thì chúng ta sẽ có các cái hàm tiến tính
00:07:14 - 00:07:21, Nhưng nếu mà y phụ thuộc một cách phi tuyến với là x thì chúng ta sẽ có các cái hàm là phi tuyến tính
00:07:21 - 00:07:34, Rồi sau này là tùy thuộc vx của mình, nó là dữ liệu dạng vector, dạng ma trận hay là dữ liệu như thế nào đó mà chúng ta cũng sẽ có những kiểu thiết kế khác nhau
00:07:34 - 00:07:45, Và cái công việc cuối cùng khi chúng ta làm với một cái mô hình mà dựa trên variant, đó chính là chúng ta sẽ tìm một cái tham số tối ưu của hàm mô hình
00:07:45 - 00:07:56, Tức là chúng ta sẽ đi tìm cái theta, theta sao? Sao cho cái lỗi ở đây là nhỏ nhất? Thì lỗi mà nhỏ nhất là cái dự đoán càng chính xác
00:07:56 - 00:08:08, Tiếp theo thì chúng ta sẽ cùng so sánh với các cái mô hình khác, thì một số mô hình mà không có dựa trên gradient, ví dụ như chúng ta có Canary's neighbor
00:08:08 - 00:08:19, Thì bằng dù đây là một cái thuật toán máy học nhưng mà nó không thực sự là huấn luyện và bản chất của nó chỉ là truy vấn để tìm ra ca cái láng viền gần nhất
00:08:19 - 00:08:35, Và sau đó sẽ dựa trên nhãn của ca cái láng viền đó để từ đó nó dùng cái cơ chế đó gọi là voting để mà lấy ra những cái tập nhãn mà có xuất hiện nhiều nhất để từ đó gắn cái nhãn nhiều nhất đó vào cho cái đặc trưng của mình
00:08:35 - 00:08:48, Thì đây chính là cái ý tưởng của Canary's neighbor. Hướng tiếp cận thứ 2 đó chính là 9-Bayes, thì đây là dựa trên các cái mô hình sát xuất mà cụ thể đó là chúng ta dựa trên công thức sát xuất có điều kiện như là công thức Bayes
00:08:48 - 00:08:54, Thì ước lượng cái phương pháp này thì nó sẽ ước lượng các cái tam số một cách tường minh
00:08:54 - 00:09:07, Cái ước tiếp cận thứ 3 đó chính là Decision Tree với các ý thuật toán ví dụ như là Card ID 3C405 thì nó dựa trên luật để phân chia thành các cái nhãnh quyết định
00:09:07 - 00:09:18, Ví dụ như ở đây chúng ta sẽ có một cái node, nó sẽ chia ra làm 2, 2 nhãnh ví dụ vậy rồi sau đó chúng ta lại tiếp tục có những cái luật, nó sẽ có những cái luật lại tiếp tục chia xuống
00:09:18 - 00:09:32, Ví dụ như ở trên đây, cái luật của mình sẽ là trời có may hay không, thì nếu có thì nó sẽ tiếp tục hỏi là cái độ ẩm của mình là cao hay thấp
00:09:32 - 00:09:41, Nếu mà độ ẩm cao thì nó sẽ kết luận là mưa, ví dụ vậy, thì đây là một cái mô hình khá là hiệu quả và dễ hiểu
00:09:41 - 00:09:50, Và mở rộng cho cái mô hình Decision Tree đó chính là Random Forest thì như cái tên gọi của mình, Random Forest nó sẽ kết hợp nhiều cái cây thành phần
00:09:50 - 00:10:00, Ví dụ như ở đây chúng ta có một cây thì Random Forest có thể kết hợp thêm nhiều cái cây khác để có thể tạo ra thành một cái khu rừng
00:10:00 - 00:10:13, Và Random Forest là một trong những thực toán, một cái mô hình mà có thể chống được cái Overfitting và có cái tính tổng quát khá là cao để chúng ta chọn được cái tham số phù hợp
00:10:13 - 00:10:19, Thế thì cả 4 cái mô hình này đều là nằm trong cái nhóm đó là học có giám sát
00:10:19 - 00:10:29, Và thực toán không giám sát thì chúng ta sẽ có các thực toán liên quan đến cái Clustering
00:10:29 - 00:10:45, Ví dụ như là có Kamin DBscan Hierarchical Clustering, thì ý tưởng của các thực toán này cũng là những thực toán lập việc cập nhật tâm cụm
00:10:45 - 00:10:48, Tức là chúng ta sẽ lập đi lập lại việc cập nhật tâm cụm
00:10:48 - 00:10:56, Và khác biệt so với các mô hình dựa trên Radian đó là chúng ta không tính cái Vector đạo hạng, không dựa trên Radian
00:10:56 - 00:11:02, Và trong cái bảng sau thì chúng ta sẽ so sánh các mô hình trên các khí cạnh khác nhau
00:11:02 - 00:11:06, Khí cạnh đầu tiên đó là cái cơ chế để tối ưu hóa mô hình của mình
00:11:06 - 00:11:12, Thì các thực toán dựa trên Radian thì đều dựa trên thực toán Radian Ascent
00:11:12 - 00:11:20, Và các biến thể của nó, ví dụ như Stochastic Radiant Ascent, Adam, Root Mean Square Propagation
00:11:20 - 00:11:23, thì đây đều là những cái mô thực toán tối ưu hóa
00:11:23 - 00:11:28, Và các mô hình dựa trên Radian thì đều dựa trên các giải thuật này
00:11:28 - 00:11:35, Trong khi đó các mô hình không dựa trên Radian, thì cơ chế để tối ưu hóa dựa trên một công thức tử mình
00:11:35 - 00:11:43, hoặc dựa trên các chiến thuật tham lam, horroristic, ví dụ như là 9BS Decision Tree, K-Neris Neighbor
00:11:43 - 00:11:47, Sét trên khí cạnh về khả năng diễn dải mô hình
00:11:47 - 00:11:51, thì các mô hình dựa trên Radian thì thường có tính diễn dải khá là thấp
00:11:51 - 00:11:55, hay một cái cách gọi khác đó là thường có dạng Black Box, hộp đen
00:11:55 - 00:12:00, thì khả năng diễn dải của mình là sẽ thấp
00:12:01 - 00:12:10, Tuy nhiên các nghiên cứu gần đây thì họ cũng đã tìm cách trực quan hóa mô hình dựa trên Radian
00:12:10 - 00:12:21, nó vận hành như thế nào, rồi giải thích cơ chế của nó để làm sao cho mô hình có thể tối ưu hóa được việc mà dựa đoán
00:12:21 - 00:12:24, thì các nghiên cứu đó gần đây cũng được trú tâm rất nhiều
00:12:24 - 00:12:31, Trong khi đó thì mô hình không dựa trên Radian thì nó có tính giải thích dễ dàng hơn
00:12:31 - 00:12:35, và đặc biệt là những mô hình như là Decision Tree, Random Forest
00:12:35 - 00:12:40, chúng ta nhìn vô cái cấu trúc cây thôi là chúng ta có thể hiểu được mô hình vận hành như thế nào
00:12:40 - 00:12:48, Sét trên cái hiệu quả của các tác vụ phục tạp thì thuộc toán các mô hình dựa trên Radian
00:12:48 - 00:12:55, thì nó sẽ cho kết quả rất tốt trên những lĩnh vực như là thị giác máy tính hoặc là xử lý ngôn ngữ tự nhiên
00:12:55 - 00:13:00, trong đó là trên những dữ liệu là Unstructured Data
00:13:04 - 00:13:11, ví dụ như là dữ liệu hình ảnh, dữ liệu văn bản, rồi dữ liệu âm thanh
00:13:11 - 00:13:18, và thì đây là những dữ liệu mô hình dựa trên Radian làm việc rất tốt
00:13:18 - 00:13:23, trong khi đó mô hình không dựa trên Radian thì thường tốt trên dữ liệu bản
00:13:23 - 00:13:31, và có quy mô nhỏ ví dụ như là dữ liệu bản thì nó bao gồm các cục ABC
00:13:31 - 00:13:39, và từng cái cục này thì nó sẽ có kiểu dữ liệu cố định và ý nghĩa của nó là cố định
00:13:39 - 00:13:45, các mô hình không dựa trên Radian thì làm việc rất tốt trên dữ liệu này
00:13:45 - 00:13:48, đó là những dữ liệu Structured Data
00:13:53 - 00:13:57, và cuối cùng đó là xét trên khía cạnh chi phí huấn luyện
00:13:57 - 00:14:01, các mô hình dựa trên Radian thì thường có chi phí huấn luyện rất cao
00:14:01 - 00:14:07, do nó cần rất nhiều tài nguyên tính toán, bộ nhớ, GPU, TPU
00:14:07 - 00:14:12, do các mô hình dựa trên Radian có số lượng tham số rất lớn
00:14:12 - 00:14:19, ngược lại thì chi phí huấn luyện của các mô hình không dựa trên Radian thì ít tốn kém hơn
00:14:19 - 00:14:26, như vậy chúng ta đã lượt qua những khía cạnh và chúng ta thấy mô hình dựa trên Radian
00:14:26 - 00:14:33, nó có những điểm yếu cố hữu ví dụ như là mô hình của mình khả năng diễn giải sẽ thấp hơn
00:14:33 - 00:14:38, so với những mô hình như là Decision Tree và chi phí huấn luyện của nó sẽ cao hơn
00:14:38 - 00:14:43, tuy nhiên gần đây thì tại sao mô hình dựa trên Radian lại càng trở nên phổ biến
00:14:43 - 00:14:49, nó có nhiều lý do, lý do đầu tiên đó là dưới sự phát triển của các mạng xã hội
00:14:49 - 00:14:55, thì các dữ liệu của mình sẽ ngày càng phong phú hơn và được lưu dụng công cấp
00:14:55 - 00:15:04, thì ở giai đoạn đầu, ví dụ như là vào những năm 2010, thì cái quý mô dữ liệu của chúng ta đâu đó chỉ khoảng là 1-2 triệu ảnh
00:15:04 - 00:15:14, nhưng mà sau đó đến vào những năm 2020, cụ thể đó là công ty OpenAI được đầu tư thì họ xây dựng những mô hình
00:15:14 - 00:15:19, ví dụ như mô hình clip được huấn luyện trên tập dữ liệu rất lớn lên đến hàng trăm triệu mẫu dữ liệu
00:15:19 - 00:15:29, và gần đây hơn nữa thì vào những năm 2020, thì có tập dữ liệu Lion lên đến 5 tỷ ảnh
00:15:29 - 00:15:38, thì có thể nói là để huấn luyện được trên những quý mô dữ liệu lên hàng tỷ ảnh thì chỉ có thể có tập gàn công nghệ lớn họ mới có thể làm được mà thôi
00:15:38 - 00:15:47, và một trong những lý do nữa để khiến mô hình dựa trên Radiant trường càng trở nên phổ biến đó là tài nguyên của mình
00:15:47 - 00:15:52, tài nguyên cụ thể là tài nguyên tính toán, nó ngày càng mạnh và đồng thời nó sẽ ngày càng rẻ
00:15:52 - 00:15:55, thì nói về phần cứng thì nó sẽ càng càng rẻ
00:15:55 - 00:16:02, và nhờ có tài nguyên tính toán sắp sau này, nó sẽ giúp chúng ta huấn luyện các mô hình nhanh chóng hơn
00:16:02 - 00:16:06, cuối cùng đó là sự hoàn thiện của các mô hình
00:16:06 - 00:16:10, chúng ta thấy đó là trước đây thì chúng ta có cái mạng Neural Network
00:16:10 - 00:16:16, thì nó không có hiệu quả trong việc huấn luyện với các dự lực lớn và các bài tảng phức tạp
00:16:16 - 00:16:25, nhưng mà gần đây thì chúng ta thấy là có cái kiến trúc như là CNN, ANN, Convolutional Neural Network, Recurrent Neural Network
00:16:25 - 00:16:30, và gần đây nhất chính là Transformer, đó là những cái kiến trúc đã hoàn thiện hơn
00:16:30 - 00:16:38, giúp chúng ta có thể hấp thụ được lượng dữ liệu tốt hơn và có thể khai thác được hiệu quả tài nguyên của GPU
00:16:38 - 00:16:43, do đó thì các mô hình dự trên Radiant đang ngày càng trở nên phổ biến
00:16:43 - 00:16:49, và không chỉ như vậy mà các thành tựu mới nhất của trí tuệ nhân tạo gần đây
00:16:49 - 00:16:57, ví dụ như là Chatchity Pity, Chimney, chúng ta thấy đó là đều có kiến trúc dự trên Transformer
00:16:58 - 00:17:07, và cái kiến trúc dự trên Transformer này, đó là dự trên, đã đều được huấn luyện dự trên thuộc toán, đó là Radiant Descent
00:17:07 - 00:17:17, thì đây chính là một cái ví dụ minh chứng cho cái thành tựu của các mô hình dự trên Radiant
00:17:27 - 00:17:32, Cảm ơn các bạn đã xem video hấp dẫn
