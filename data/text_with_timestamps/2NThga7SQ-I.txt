00:00:00 - 00:00:22, Chúng ta sẽ cài đặt một cái mạng Convergional Network và tập dữ liệu mà chúng ta sẽ sử dụng ở đây chính là tập dữ liệu Amnest.
00:00:22 - 00:00:27, Đây là một trong những tập dữ liệu rất là kinh điển khi làm trong định vực về thị giác máy tính.
00:00:27 - 00:00:34, Ảnh đầu vào của tập dữ liệu này sẽ có kích thước 28 x 28, đúng bằng cái kích thước ở đây.
00:00:34 - 00:00:41, Và kiến trúc mạng CNN ở đây chúng ta sẽ sử dụng đó là kiến trúc mạng LENET được có từ những năm 1998.
00:00:41 - 00:00:46, Và kiến trúc mạng này thực sự mà nó cũng không có sâu, nó chỉ bao gồm 2 lớp convolution.
00:00:46 - 00:00:52, Và 2 lớp convolution này thì sử dụng các filter có kích thước là 3 x 3.
00:00:52 - 00:00:59, Và đối với lớp convolution đầu tiên thì chỉ có 6 filter.
00:00:59 - 00:01:06, Đối với lớp convolution thứ 2 thì sẽ có kích thước 3 x 3, nhân cho 6.
00:01:06 - 00:01:13, Tại vì đầu vào của lớp convolution này chính là feature map này, mà feature map này có depth là bằng 6.
00:01:13 - 00:01:22, Vì đó ở đây sẽ là 6. Tuy nhiên thì trong quá trình mà chúng ta kể đạp thì chúng ta cũng không cần phải chỉ ra tượng minh là số input của mình là bao nhiêu.
00:01:22 - 00:01:27, Tự cái deep learning framework sẽ tính cho mình cái con số này.
00:01:27 - 00:01:31, Chúng ta chỉ cần cho biết cái kích thước bẻ ngang, bẻ cao của filter là được.
00:01:31 - 00:01:40, Và đồng thời chúng ta cũng cho deep learning framework biết số filter đầu ra mong muốn là trong phép convolution thứ 2 chính là 16.
00:01:40 - 00:01:50, Các phép biến đổi subsumling ở đây thực chất chính là phép biến đổi max pooling.
00:01:50 - 00:02:03, Và phần cuối của mạng cna này chính là các lớp biến đổi fully connected để tạo ra các filter có kích thước là 120, 84 và 10.
00:02:03 - 00:02:10, Trong đó 10 thì tương ứng với lại số lớp đầu ra của mình là các con số từ 0 cho đến 9.
00:02:10 - 00:02:18, Vậy thì trong phần tiếp theo chúng ta sẽ tiến hành kể đạp mạng convolution neural network này.
00:02:18 - 00:02:38, Bước đầu tiên chúng ta sẽ khởi tạo các tập dataset của mình.
00:02:38 - 00:02:45, Trong keras nó đã có phương thức giúp cho mình loát dataset rất dễ dàng.
00:02:45 - 00:02:50, Đó là keras.dataset và chúng ta sẽ import tập dữ liệu là mnit.
00:02:50 - 00:03:01, Sau đó chúng ta chỉ bị gọi là mnit.loatdata thì tự động nó sẽ lấy từ trên mạng internet về giải nén và đưa vào các cặp biến là istrain, etrain và isted, eted.
00:03:01 - 00:03:05, Chúng ta sẽ quan sát thử kích thước của các ký biến này.
00:03:05 - 00:03:11, Istrain có kích thước là 60.000 x 28 x 28.
00:03:11 - 00:03:14, 60.000 này tương ứng là tổng số mẫu.
00:03:14 - 00:03:20, 28 x 28 là kích thước về ngang và về cao của ảnh chiếu số vĩt tài.
00:03:20 - 00:03:24, Etrain có kích thước là 60.000.
00:03:24 - 00:03:32, Vì ứng với từng cái istrain nó sẽ có một cái giá trị label, một cái nhãn output của etrain.
00:03:32 - 00:03:36, Thì ở đây chúng ta sẽ thử quan sát một số mẫu dữ liệu.
00:03:36 - 00:03:46, Để quan sát thì chúng ta sẽ sử dụng thư viện đó là map-runlib.pyplot.s.plt.
00:03:46 - 00:03:49, Vì ứng với tổng số mẫu.
00:03:49 - 00:03:56, Chúng ta sẽ sử dụng cái hàm imshow với cái biến là istrain.
00:03:56 - 00:04:02, Istrain này nó có các cái chiều 60.000 x 28 x 28.
00:04:02 - 00:04:07, Ở chiều đầu tiên chúng ta sẽ lấy ra tại một cái vị trí nào đó, đó là index.
00:04:07 - 00:04:15, Và trong trường hợp này thì chúng ta sẽ cho index là bằng 123, cái con số bất kỳ trong khoảng từ 0 cho đến 60.000.
00:04:15 - 00:04:19, Rồi thành phần vào lại thì sẽ là 2.2.
00:04:19 - 00:04:23, Tức là chúng ta sẽ lấy toàn bộ cái nội dung của tấm ảnh ra để chúng ta hiển thị.
00:04:23 - 00:04:29, Rồi sau đó chúng ta sẽ thực hiện thì thấy là cái ảnh này mình đoán đoán nó hình như là số 7.
00:04:29 - 00:04:37, Thì muốn biết chính xác đó là nhãn bao nhiêu thì chúng ta sẽ im ra là nhãn của dữ liệu.
00:04:37 - 00:04:45, Rồi ở đây chúng ta sẽ lấy là istrain và chúng ta cũng sẽ truyền vào cái trị số là index.
00:04:45 - 00:04:51, Rồi đúng như dự đoán thì cái nhãn này chính là, nhãn của dữ liệu này chính là số 7.
00:04:51 - 00:04:56, Và chúng ta có thể thay đổi các cái trị số này, ví dụ như là 10.000.
00:04:56 - 00:05:02, Rồi, thì đây là tương ứng nhãn của nó sẽ là số 3.
00:05:02 - 00:05:10, Cuối theo, đó là chúng ta sẽ tiền xử lý chúng ta sẽ chuẩn hóa cái dữ liệu istrain và istag của mình.
00:05:10 - 00:05:17, Bằng cách đó là thay vì đưa cái miền giá trị từ 0 đến 255, thì chúng ta sẽ đưa về cái miền giá trị là từ 0 cho đến 1.
00:05:17 - 00:05:19, Để giúp cho cái quá trình huấn luyện nó được nhanh hơn.
00:05:20 - 00:05:29, Và đồng thời là cái giá trị y của mình cũng sẽ được chuyển đổi từ cái dạng nhãn là cái chỉ số từ 0 cho đến 9.
00:05:29 - 00:05:32, Chúng ta sẽ đưa nó về cái dạng One Hot Encoding.
00:05:32 - 00:05:36, Vì dạng One Hot Encoding, thì One Hot Encoding nó như là gì?
00:05:36 - 00:05:44, Ví dụ số 0, thì chúng ta sẽ đưa một cái vector trong đó có duy nhất một cái phần tử bật lên là 1.
00:05:44 - 00:05:47, Và tất cả các phần tử còn lại sẽ để là số 0.
00:05:48 - 00:05:56, Và tương tự như vậy cho số 2 đi, thì nó sẽ bật lên là 0, ở đây là 0, ở đây là 0 và nó sẽ bật lên ở đây.
00:05:56 - 00:05:59, Và tất cả các phần tử còn lại sẽ để là số 0.
00:05:59 - 00:06:02, Thì đây là cái dạng One Hot Encoding.
00:06:03 - 00:06:09, Rồi bước tiếp theo, đó là chúng ta sẽ tiến hành cài đặt cái thực toán huấn luyện hay cụ thể đó là cài đặt cái mô hình.
00:06:09 - 00:06:21, Thì cái mạng CNN, ở đây chúng ta sẽ có các phương thức như là Build, Trend, Constructor, Load, Get Way.
00:06:21 - 00:06:31, Ở đây có các phương thức Get Way là chúng ta sẽ chưa cài đặt, chúng ta sẽ cài đặt để đưa lên Trend xong hành cùng với lại hàm Trend để kẹo chúng ta quên.
00:06:31 - 00:06:38, Xin lỗi, chúng ta sẽ đưa lên Trend ngang với lại phương thức là Build để không một chút nữa chúng ta sẽ quên.
00:06:38 - 00:06:45, Cái quá trình Trend của mạng CNN rất là lâu, nếu mà chúng ta quên thực hiện cái gì đấy và chúng ta thực hiện lại thì nó sẽ tốn thời gian rất là nhiều.
00:06:45 - 00:06:51, Thì ở đây chúng ta sẽ phải cho cái model nó biết đó là Input Dimension.
00:06:51 - 00:07:06, Rồi, đồng thời là các cấu hình, ví dụ như số lượng filter là 6, số lượng filter là 16, rồi số các output của các lớp Fully Connected là 12084.
00:07:06 - 00:07:09, Thì chúng ta sẽ phải tham số hóa 4 cái bộ số này.
00:07:09 - 00:07:17, Ruyên cái con số cuối cùng đó là 10, đó chính là số lượng cái nhãn mà mình cần nhiệm diện rồi thì nó sẽ cố định là 10.
00:07:17 - 00:07:23, Rồi, mình ý trước tập chữ điều này là có 10 mẫu, 10 loại, 10 nhãm, 10 class.
00:07:23 - 00:07:29, Và đồng thời thì chúng ta cũng sẽ tham số hóa cái hàm kích hoạt Activation Function.
00:07:29 - 00:07:33, Rồi, Activation Function.
00:07:33 - 00:07:44, Rồi, chúng ta sẽ có n Convolution số 1, n Convolution số 2, n FC1, n FC2.
00:07:44 - 00:07:52, Và mặt nhiên thì hàm Activation chúng ta sẽ để là SIGMOY.
00:07:52 - 00:07:58, Rồi, Convolution thì mặt nhiên chúng ta sẽ để là 6, giống như trong cái thiết kế ở đây.
00:07:58 - 00:08:06, Convolution số 2 thì mặt nhiên chúng ta sẽ để là 16. FC1 thì chúng ta sẽ để là 120.
00:08:06 - 00:08:11, Và FC2 thì chúng ta sẽ để là 84.
00:08:11 - 00:08:20, Rồi, sau đó thì chúng ta sẽ tiến hành cài đặt các thành phần của cái mạng này.
00:08:20 - 00:08:28, Bằng cách đó là chúng ta sẽ tiến hành lần lượt qua các lớp đối tượng, qua lớp biến đổi.
00:08:28 - 00:08:31, Lớp đầu tiên chính là lớp Input.
00:08:31 - 00:08:43, Rồi, Input thì chúng ta sẽ cho biết cái shape của nó sẽ là bằng Input Dimension.
00:08:43 - 00:08:48, Rồi, và chúng ta sẽ trả ra một cái biến tên là Input.
00:08:49 - 00:09:02, Rồi, tương tự như vậy thì chúng ta sẽ tiến hành thực hiện phép biến đổi Convolution.
00:09:02 - 00:09:06, Thì ở đây là Convolution chúng ta sẽ sử dụng Convolution 2D.
00:09:06 - 00:09:16, Và nó sẽ có các tham số. Đầu tiên là số lượng filter thì chúng ta sẽ để là số lượng Convolution số 1.
00:09:16 - 00:09:28, Cái tham số thứ 2 là Convolution thì như hồi nãy chúng ta đã gặp, đó là kích thước của cái Convolution này chính là kích thước của nó sẽ là 3 x 3.
00:09:35 - 00:09:43, Rồi, Stripe thì ở đây chúng ta sẽ để mặt định là 1, vậy là chúng ta sẽ không để cái Stripe ở đây.
00:09:43 - 00:09:48, Rồi, Padding thì chúng ta sẽ để là same.
00:09:48 - 00:09:55, Tại vì trong cái sô đồ này chúng ta thấy, trong sô đồ này chúng ta thấy là ảnh đầu vào và ảnh đầu ra có kích thước chống nhau.
00:09:55 - 00:10:06, Ảnh đầu vào là 28, 28 thì ảnh đầu ra là 28, 28. Ảnh đầu vào là 14, 14 thì ảnh đầu ra cũng sẽ là 14 như 14.
00:10:07 - 00:10:17, Thì qua cái phép biến đổi Convolution thì chúng ta thấy là cái kích thước bề ngang và bề cao là không thay đổi khi thực hiện cái phép Convolution.
00:10:17 - 00:10:19, Và đó chúng ta sẽ để Padding là bằng same.
00:10:20 - 00:10:38, Rồi, thì chắc là mình sẽ phải đền cái bias là use. Bias là bằng true.
00:10:38 - 00:10:47, Rồi, thì cơ bản đó là nó đã đầy đủ những cái... à nó còn thiếu một cái nữa đó là cái activation.
00:10:47 - 00:10:58, Activation này sẽ để trước bias. Bias sẽ là bằng activation.
00:10:58 - 00:11:17, Rồi, như vậy thì chúng ta đã cài đặt cho cái đối tượng tên là Convolution2D và chúng ta sẽ phải truyền vào cho nó là cái input.
00:11:17 - 00:11:22, Và trả ra nó sẽ ra là cái biến tên là C1, giống như trong cái sô đồ ở đây.
00:11:22 - 00:11:32, Rồi, tiếp theo thì chúng ta sẽ thử chạy. Ok, nó sẽ báo lỗi.
00:11:32 - 00:11:38, À, 3x3, ok, nó không hiểu 3x3 là gì. 3,3.
00:11:38 - 00:11:46, Rồi, hết lỗi rồi. Bây giờ chúng ta sẽ thực hiện cái phép Pulling. Pulling thì tương ứng nó chính là cái MaxPulling2D ở đây.
00:11:46 - 00:11:55, Và chúng ta sẽ có cái tham số là PullSize thì mặc nhiên nó sẽ sử dụng đó là 2x2.
00:11:55 - 00:12:07, Do đó thì một cái tự minh chúng ta sẽ để ở đây là 2x2. Với cái Pulling mà bằng 2x2 như thế này thì cái kích thước mình sẽ được giảm xuống một nửa.
00:12:07 - 00:12:19, Ở đây thì chúng ta sẽ để Stride là bằng 2. Sau khi thực hiện cái Pulling này thì cái kích thước của nó sẽ giảm xuống một nửa.
00:12:19 - 00:12:29, Rồi, ngoài ra thì có Patting thì chúng ta sẽ để là Shame.
00:12:30 - 00:12:40, Rồi, và chúng ta sẽ truyền cái đồ vào cho nó chính là C1 và đầu ra sẽ là S2, giống như trong cái phiên mạng, trong cái kế kế ở đây.
00:12:40 - 00:12:49, Rồi, đối với cái phép biến đổi Cognition tiếp theo chúng ta sẽ copy xuống. Nhưng mà khi copy thì cần phải lưu ý là sửa lại.
00:12:49 - 00:12:55, Thay vì ở đây để là Input thì nó sẽ để là S2. S2.
00:12:55 - 00:13:06, Rồi, và đầu ra sẽ là C3. Và số Cognition ở đây, số Filter ở đây, nó sẽ là Nconf2. Kích thước không thay đổi.
00:13:06 - 00:13:16, Lưu ý là hồi nãy, kích thước là 3x3 và nó sẽ tự biết cái Input S2, kích thước cái Depth là bao nhiêu thì nó sẽ chọn cái Filter cho phù hợp.
00:13:16 - 00:13:22, Cho đó chúng ta không cần phải tường minh để chỉ ra là kích thước 3x3 nhưng bao nhiêu.
00:13:22 - 00:13:31, Rồi, Activation thì chúng ta cũng tái xuyên lại. Tiếp theo, nó sẽ chuyển sang cái phép là Pooling.
00:13:31 - 00:13:42, Rồi, thì đầu vào chúng ta sẽ có là C3 và nó sẽ tạo ra là S4. Và cái cấu hình thì cũng tương tự. Cấu hình cũng sẽ tương tự.
00:13:43 - 00:13:48, Rồi, bây giờ chúng ta sẽ tiếp tục cài đặt cho cái phép biến đổi Fully Connected.
00:13:48 - 00:13:52, Tì để thực hiện được cái Fully Connected này, chúng ta sẽ phải có một cái bước là Flatten.
00:13:52 - 00:14:02, Thì chúng ta sẽ gọi cái đối tượng Flatten ở đây và truyền vào cái S4 để trả ra là FC.
00:14:02 - 00:14:11, Ở đây thì nó sẽ đặt tên là FC4 đi ha. Rồi, tại vì thực sự mà nó phép Flatten nó không có biến đổi gì hết.
00:14:11 - 00:14:16, Tiếp theo thì chúng ta sẽ thực hiện cái phép Fully Connected, nó chính là Dense.
00:14:16 - 00:14:23, Rồi, và time số đầu tiên là số lượng unit, tức là số lượng output neuron sẽ trả ra.
00:14:23 - 00:14:28, Thì chúng ta sẽ lấy cái time số FC1 này đưa vào.
00:14:28 - 00:14:39, Rồi, Activation thì chúng ta sẽ để là App Function.
00:14:39 - 00:14:46, Rồi, Use by App là bằng tru.
00:14:46 - 00:14:53, Rồi, và chúng ta sẽ truyền vào cái biến đó là FC4.
00:14:53 - 00:15:06, Thì trong cái sơ đồ ở đây, nó để là C5, nhưng mà để đúng với lại cái tên của nó, đó là Fully Connected, thì chúng ta sẽ đặt tên lại đó là FC5.
00:15:06 - 00:15:18, Rồi, tương tự như vậy, cho cái biến đổi tiếp theo, chúng ta sẽ để đầu vào là FC5, đầu ra sẽ là FC6, và số neuron đầu ra sẽ là FC2.
00:15:18 - 00:15:24, Rồi, cuối cùng, đó chính là output.
00:15:24 - 00:15:30, Thì FC6 sẽ được truyền vào đây, và đầu ra sẽ là output.
00:15:30 - 00:15:38, Và số neuron của mình sẽ là 10, tại vì mình biết trước, cái đầu ra của mình sẽ là 10 class.
00:15:38 - 00:15:46, Riêng cái hàm Activation Function thì chúng ta sẽ phải để là softmax, tại vì đây là phân lớp đa lớp, chứ không phải là phân lớp nhịp phân.
00:15:46 - 00:15:49, Nếu mà phân lớp nhịp phân thì chúng ta sẽ sử dụng SIPMODE.
00:15:49 - 00:15:56, Rồi, cuối cùng thì chúng ta sẽ đóng gói toàn bộ input và output trong cái biến tên là MODEL.
00:15:56 - 00:16:02, Sale.model sẽ là bằng MODEL, rồi input và output.
00:16:02 - 00:16:10, Rồi, như vậy thì chúng ta đã cài xong cho cái phần build mô hình.
00:16:10 - 00:16:13, Đối với cái hàm DRAIN thì chúng ta sẽ sử dụng optimizer là ADAM.
00:16:13 - 00:16:20, ADAM thì đây là một trong những cái optimizer rất là hiệu quả, nó giúp cho chúng ta thoát ra được những cái điểm cực tiểu cục bộ.
00:16:20 - 00:16:30, Hàm LOST thì chúng ta sẽ sử dụng CROSS ENTOPY, CATEORICAL CROSS ENTOPY, tức là chúng ta thực hiện phân lớp nhiều lớp.
00:16:30 - 00:16:34, Rồi, độ đo thì chúng ta sẽ sử dụng độ đo để đánh giá là ACHO DRAXY.
00:16:34 - 00:16:48, Về WAVE thì chúng ta sẽ trả về Sale.model.layer và chúng ta sẽ truyền vào cái chỉ số của cái layer mà mình muốn trả về, xong rồi gọi hàm GET WAVE.
00:16:52 - 00:16:56, Rồi, như vậy thì chúng ta đã cài xong cái mạng CNN.
00:16:56 - 00:17:00, Và bước tiếp theo thì chúng ta sẽ khởi tạo các cái mô hình.
00:17:00 - 00:17:12, Rồi, CNN.build và ở đây thì chúng ta sẽ copy xuống các cái tham số để tránh bị sơ sót.
00:17:12 - 00:17:23, Đầu tiên input dimension thì cái ảnh này của mình nếu thông thường chúng ta sẽ để là 28,28.
00:17:23 - 00:17:32, Tuy nhiên cái convolution, cái mô hình convolution nó chỉ có thể thực hiện được khi nó phải là 1 cái tensor 3 chiều.
00:17:32 - 00:17:36, Do đó ở đây thì chúng ta sẽ để là 28,28.1.
00:17:36 - 00:17:39, Và activation thì chúng ta sẽ để là sigmoid.
00:17:39 - 00:17:43, Rồi, convolution số 1 chúng ta sẽ để là 6.
00:17:43 - 00:17:45, Convolution số 2 thì chúng ta sẽ để là 16.
00:17:45 - 00:17:48, Và FC ở đây chúng ta sẽ để là 1.
00:17:48 - 00:17:50, FC Lức số 1 chúng ta sẽ để là 120.
00:17:50 - 00:17:53, FC số 2 thì chúng ta sẽ để là 84.
00:17:53 - 00:17:58, Và hàm activation ở đây thì chúng ta sẽ để là hàm sigmoid.
00:17:58 - 00:18:01, Rồi, bây giờ chúng ta sẽ chạy thử.
00:18:01 - 00:18:03, Và chương trình thì chạy được rồi.
00:18:03 - 00:18:10, Bây giờ chúng ta sẽ xem coi là cái mạng CNN này chấm summary xem có thể thực hiện được hay không.
00:18:10 - 00:18:14, Tại xem cái kích thước, cái kiến trúc của cái mạng CNN này.
00:18:14 - 00:18:21, Thì chúng ta có thể thấy trong cái mạng CNN này nó thỏa mãn được đúng như kiến trúc mà chúng ta mong muốn.
00:18:21 - 00:18:28, Là bao gồm thực hiện cái FC số 1 với 6 filter, thực hiện convolution số 2 với 16 filter.
00:18:28 - 00:18:34, Rồi, và cái chích thước của các tensor thì cũng giảm dần.
00:18:34 - 00:18:38, Đó là từ 28 xuống 14 xuống 7 giống như trong thiết kế ở đây.
00:18:38 - 00:18:47, Và số neuron của mình sẽ là, xin lỗi số tham số của mình, nó sẽ là 100.000 tham số.
00:18:47 - 00:18:48, 100.000 tham số.
00:18:48 - 00:18:50, Bây giờ chúng ta sẽ tiến hành trend.
00:18:50 - 00:18:56, Chúng ta sẽ truyền vào 2 tham số đó là isTrend và isTrend.
00:18:56 - 00:18:58, Tuy nhiên isTrend nó phải ở dạng là one hot.
00:19:01 - 00:19:03, Rồi, thì cái việc trend này đâu đó nó có thể tốn.
00:19:03 - 00:19:05, Ồ, ở đây chúng ta quên mất một cái việc.
00:19:05 - 00:19:15, Đó là sau này để mà có thể vẽ được cái tham loss, vẽ được cái giá trị loss theo số epoch.
00:19:15 - 00:19:19, Chúng ta sẽ phải gán vào một cái biến, vâng, history.
00:19:19 - 00:19:25, Rồi sau đó thì ở đây chúng ta mới có thể thực hiện được cái việc trực quan hóa này.
00:19:25 - 00:19:37, Rồi, để trực quan hóa cho cái mô hình, thì chúng ta sẽ phải lấy ra các cái filter.
00:19:37 - 00:19:41, Ở đây chúng ta sẽ lấy ra filter ở cái lớp đầu tiên.
00:19:41 - 00:19:45, Đó chính là cnn.getWay.
00:19:45 - 00:19:49, GetWay ở đây chúng ta sẽ để cái layer số 1.
00:19:49 - 00:19:52, Tại vì layer số 0 chính là cái input rồi.
00:19:52 - 00:19:54, Layer số 1 chính là cái phép convolution.
00:19:55 - 00:19:58, Rồi, chúng ta sẽ cùng quan sát.
00:20:00 - 00:20:03, Nhưng mà đương nhiên là phải chờ cái mô hình này nó húi ra xong,
00:20:03 - 00:20:07, thì chúng ta mới có thể thấy được cái hầm loss này nó chạy như thế nào.
00:20:07 - 00:20:14, Ở đây thì chúng ta quan sát thấy là cái loss của mình nó đã giảm từ 0.18 trong cái epoch đầu tiên.
00:20:14 - 00:20:18, Giảm xuống còn 0.13, giảm xuống còn 0.10.
00:20:18 - 00:20:24, Và đến cái epoch thứ 25, 26 thì giảm xuống còn 0.01.
00:20:24 - 00:20:31, Và hy vọng là đến cái epoch số 30 thì cái loss của mình nó đã giảm xuống còn 0.007.
00:20:31 - 00:20:38, Và accuracy cho tập dữ liệu trend nó đã lên đến 99.85%.
00:20:40 - 00:20:43, Rồi, chúng ta quan sát thì cái loss giảm rất là tốt.
00:20:43 - 00:20:46, Chúng ta quan sát cái trend loss này giảm rất là tốt.
00:20:48 - 00:20:58, Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.
