00:00:00 - 00:00:18, Chúng ta sẽ cùng đến với bài tutorial bài thực hành đề mạng gan.
00:00:18 - 00:00:22, Trên hình là một số thành tự của gan trong vài năm gần đây.
00:00:22 - 00:00:31, Nếu như năm 2014, chất lượng hình ảnh của mình rất tệ và không màu,
00:00:31 - 00:00:35, sau 1 năm sau đó hình ảnh của mình đã có màu.
00:00:35 - 00:00:42, Và đến năm 2018, hình ảnh của mình đã có độ quan giải rất cao và gần như là thật.
00:00:43 - 00:00:53, Với công nghệ Insight Cogam, nó cũng có thể cho phép chúng ta chuyển đổi qua lại giữa 2 cái thế giới ảnh, 2 cái không gian ảnh khác nhau.
00:00:53 - 00:00:57, Ví dụ như chuyển từ phong cách ảnh mô nét sang ảnh đời thực,
00:00:57 - 00:01:04, hoặc là chuyển từ ảnh ngựa bằng sang ngựa bình thường, cũng như là chuyển từ ngựa bình thường sang ngựa bằng.
00:01:04 - 00:01:09, Hoặc là biến ảnh từ mùa hè sang mùa của đông.
00:01:09 - 00:01:12, Trên đây là 1 số thành tự của mạng GAM.
00:01:12 - 00:01:20, Về kiến trúc, tổng thể của GAM sẽ bao gồm 2 mô đương chính, đó là Generator và Discriminator.
00:01:20 - 00:01:27, Generator sẽ nhận đầu vào 1 vector latent z và tạo ra 1 fake sample.
00:01:27 - 00:01:34, Kết hợp với real sample ở đây, chúng ta sẽ qua Discriminator để huấn luyện
00:01:34 - 00:01:38, nhằm làm sao có thể phân biệt được ảnh real, ảnh thật và ảnh giả.
00:01:40 - 00:01:44, Và sau đó thì chúng ta sẽ có un loss để huấn luyện 2 cái mạng này.
00:01:45 - 00:01:47, Thế thì chi tiết chúng ta có thể đọc thêm ở đây.
00:01:48 - 00:01:58, Và cài đặt thì chúng ta sẽ khởi tạo 1 số cái hàm và đối tượng của torch phục vụ cho những cái phần cài đặt phía sau.
00:01:59 - 00:02:03, Về chi tiết của cái kiến trúc mạng GAM thì nó sẽ có kiến trúc như sau.
00:02:04 - 00:02:09, Đầu tiên đó là cái vector z, là cái random noise của mình sẽ là 1 vector 100 chiều
00:02:09 - 00:02:11, theo cái phân bố Gaussian.
00:02:12 - 00:02:18, Và nó sẽ biến thành cái vector 128 chiều rồi 784 chiều.
00:02:18 - 00:02:28, Thì 784 chiều này chính là cái kích thước mà khi chúng ta flatten từ 1 cái tấm ảnh hoặc là kích thước 28 x 28.
00:02:28 - 00:02:37, Về discriminator thì chúng ta sẽ từ vector 784 xuống vector 108 và xuống vector 1 chiều.
00:02:37 - 00:02:39, Hay là scalar.
00:02:39 - 00:02:40, Tại sao lại như vậy?
00:02:40 - 00:02:44, Tại vì ở đây discriminator chỉ phân biệt 2 trạng thái là real or fake.
00:02:44 - 00:02:50, Do đó chúng ta chỉ cần 1 neuron là có thể đưa về 2 trạng thái là 0 và 1 là được rồi.
00:02:50 - 00:02:55, Thế thì bây giờ chúng ta sẽ tiến hành cài đặt cái discriminator.
00:02:56 - 00:02:58, Thì cái discriminator là cái phần 1 xanh ở đây.
00:02:58 - 00:03:02, Đầu vào sẽ là 1 cái ảnh có kích thước là 784.
00:03:06 - 00:03:10, Và nó sẽ biến thành vector 128 chiều thông qua cái nốt linear.
00:03:11 - 00:03:14, Sau đó thì chúng ta sẽ có 1 cái hàm activation function.
00:03:14 - 00:03:16, Nó như đây là Nicky, Ralu.
00:03:18 - 00:03:21, Tạo ra 1 cái vector 128 chiều.
00:03:21 - 00:03:25, Rồi vector 128 chiều sẽ biến thành 1 cái neuron 1 chiều.
00:03:26 - 00:03:30, Thông qua cái nốt biến đổi linear luôn.
00:03:30 - 00:03:35, Thế thì cái hàm forward của mình nhận đồ vào là x là 1 cái tấm ảnh.
00:03:35 - 00:03:43, Thì nó sẽ chuyển đổi về cái vector là 784.
00:03:43 - 00:03:46, Thành vector 784.
00:03:46 - 00:03:49, Và BS ở đây chính là cái bar size của mình.
00:03:49 - 00:03:51, Đây chính là cái bar size của mình.
00:03:51 - 00:03:54, Là số mẫu dữ điện chiếu huấn luyện tại 1 thời điểm.
00:03:54 - 00:04:01, Sau đó chúng ta chuyển x vào cái lớp FC1 và non-linear để tạo ra h.
00:04:01 - 00:04:05, Thì h trong trường hợp này là vector 128 chiều.
00:04:05 - 00:04:09, H sau đó được nối tiếp và qua cái FC để tạo ra cái output.
00:04:09 - 00:04:16, Cái output này sau đó sẽ được qua cái hàm sigmoid để đưa về cái không gian sát xuất từ 0 cho đến 1.
00:04:16 - 00:04:18, Sau đó chúng ta sẽ return cái output.
00:04:18 - 00:04:23, Thì cái output của mình nó sẽ là cái sát xuất để cho biết có thuộc về lớp số 1 hay không.
00:04:24 - 00:04:30, Đối với generator thì chúng ta hoàn làm hoàn toàn cũng tương tự.
00:04:30 - 00:04:33, Chúng ta sẽ có cái lớp FC để từ cái zdim.
00:04:33 - 00:04:36, Cụ thể ở đây zdim là bằng 100.
00:04:36 - 00:04:40, Biến thành vector 128.
00:04:40 - 00:04:43, Vector 128 sau đó sẽ qua cái leaky run loop.
00:04:43 - 00:04:47, Rồi sau đó sẽ là biến thành vector 784.
00:04:47 - 00:04:50, Thì đây là cái hàm forward.
00:04:50 - 00:04:53, Từ cái input của mình là cái latency.
00:04:53 - 00:04:56, Sau đó sẽ qua cái FC và 5 linear.
00:04:56 - 00:05:00, Rồi sau đó qua cái FC2 và hàm tang.
00:05:00 - 00:05:04, Thì hàm tang ở đây là giải giá trị từ trường 1 cho đến 1.
00:05:04 - 00:05:07, Nó có chứa cái giá trị từ 0 cho đến 1.
00:05:07 - 00:05:13, Tức là cái miền giá trị của cái ảnh của mình.
00:05:13 - 00:05:17, Không có nghĩa là đen và 1 không có nghĩa là sáng.
00:05:18 - 00:05:24, Rồi sau đó chúng ta sẽ biến thành cái ảnh chức thước 28x28 và trả về.
00:05:24 - 00:05:28, Thì chúng ta sẽ chạy 2 cái code block này.
00:05:28 - 00:05:34, Rồi sau khi chạy xong thì chúng ta sẽ tiến hành lock dữ liệu mlist.
00:05:34 - 00:05:37, Và chúng ta sẽ show 1 cái tấm hình.
00:05:37 - 00:05:42, Ví dụ như chúng ta show cái hình là 1, 4, 5.
00:05:42 - 00:05:44, Thì đây là 1 chiếc dài.
00:05:44 - 00:05:46, Ví dụ như là 1, 2, 3.
00:05:46 - 00:05:48, Đây là chiếc áo.
00:05:50 - 00:05:54, Rồi tiếp theo thì chúng ta sẽ kiểm tra xem cái batch size của mình.
00:05:54 - 00:05:58, À cái discriminator của mình là có ổn hay không.
00:05:58 - 00:06:02, Chúng ta sẽ truyền vào cái batch và xem cái kết thước.
00:06:02 - 00:06:06, Thì cái batch size của mình nó sẽ có kết thước đó là 64.
00:06:06 - 00:06:10, Và ảnh của mình đó là 28x28.
00:06:10 - 00:06:16, Rồi sau khi chúng ta qua cái discriminator thì nó sẽ tạo ra 1 cái touch có kết thước là 64.
00:06:16 - 00:06:18, Nhưng 1 trong đó 64 chính là batch size.
00:06:18 - 00:06:22, Và 1 chính là cái kết thước ảnh của mình.
00:06:22 - 00:06:24, Rồi, xin lỗi ảnh.
00:06:24 - 00:06:28, 1 chính là cái output, cái sát xuất của mình.
00:06:28 - 00:06:32, Rồi sau đó chúng ta sẽ show cái tấm ảnh này lên.
00:06:32 - 00:06:34, Thì đây là cái data set.
00:06:34 - 00:06:40, Và những kẻ ảnh mà có cái vật phẩm thời trang.
00:06:40 - 00:06:46, Vì dạ như là dày, quần, áo, quần.
00:06:46 - 00:06:50, Thế thì bây giờ chúng ta sẽ tiến hành huấn luyện 1 cái mạng GAN.
00:06:50 - 00:06:54, Thì mạng GAN của mình, lý thuyết đó chính là bài tài án Mini-Mach Game.
00:06:54 - 00:07:00, Thì đây là cái công thức của cái hàm biến đổi để huấn luyện.
00:07:00 - 00:07:04, Đầu tiên cái vế bên trong cùng đó là hàm max.
00:07:04 - 00:07:06, Tức là chúng ta sẽ đi huấn luyện D trước.
00:07:06 - 00:07:08, Tức là Disprimandator trước.
00:07:08 - 00:07:12, Disprimandator nó phải có khả năng phân biệt đối tượng 1 cách chắc định.
00:07:12 - 00:07:18, Thì khi đó nó mới có thể thách thức cái G.
00:07:18 - 00:07:20, Sao cho nó khó được.
00:07:20 - 00:07:24, Do đó thì ở đây chúng ta sẽ sử dụng, ở đây nhìn chung.
00:07:24 - 00:07:29, Nhìn chung đó là chúng ta công thức tương tự như công thức của Binary Cross entropy.
00:07:29 - 00:07:34, Là so sánh giữa cái giá trị dự đoán và giá trị thực tế.
00:07:34 - 00:07:41, Thì chúng ta sẽ sử dụng cái hàm Criterion này để huấn luyện cái mô hình ở bên dưới.
00:07:41 - 00:07:45, Rồi, bây giờ chúng ta sẽ kiểm tra xem cái thiết bị của mình ở đây.
00:07:45 - 00:07:46, Đó là thiết bị gì?
00:07:46 - 00:07:48, Thì đây là GPU.
00:07:48 - 00:07:55, Và mỗi chúng ta sẽ tạo ra đối tượng đó là Disprimandator và Generator.
00:07:55 - 00:07:57, Và trình nó vào GPU.
00:07:57 - 00:08:05, Rồi, với mỗi một cái optimizer G và D, chúng ta sẽ đi train cho G và D ở đây.
00:08:05 - 00:08:13, Tức là mỗi một cái mô đun Disprimandator và Generator sẽ dùng một cái optimizer riêng, chứ không phải tìm chung.
00:08:13 - 00:08:17, Và dữ liệu label real và label fake.
00:08:17 - 00:08:22, Lấy bộ view thì sẽ có nhãn là 1 và lấy bộ fake thì sẽ có nhãn là 0.
00:08:22 - 00:08:27, Sau đó thì chúng ta sẽ fix cái noise của mình.
00:08:27 - 00:08:34, Là cái random noise là từ... là 63, 64 và kích thước đó là 100.
00:08:34 - 00:08:36, Fbox là 10.
00:08:36 - 00:08:39, Thì ở đây chúng ta sẽ lần nược huấn luyện.
00:08:39 - 00:08:43, Step số 1 là chúng ta sẽ đi tối u Disprimandator trước.
00:08:43 - 00:08:49, Tức là huấn luyện cho bộ phân loại này có khả năng phân loại được ảnh thật và ảnh giả trước.
00:08:49 - 00:08:55, Sau đó chúng ta mới sang Step số 2 để đi huấn luyện cho Generator.
00:08:55 - 00:09:01, Rồi, thì ở đây chúng ta sẽ lấy ra cái Xreel và truyền vào GPU.
00:09:01 - 00:09:06, Rồi sau đó chúng ta sẽ khởi tạo cái optimizer D.
00:09:06 - 00:09:10, Và chúng ta sẽ truyền cái Xreel này vào cái Disprimandator.
00:09:10 - 00:09:12, Thì đây chính là cái sát xuất.
00:09:12 - 00:09:15, Đây chính là cái sát xuất thuộc về lớp Reel.
00:09:15 - 00:09:23, Và lossD của Reel tức là cái giá trị loss cho cái Disprimandator.
00:09:23 - 00:09:34, Đối với cái phần dữ liệu Reel là dữ liệu thật thì chúng ta sẽ truyền vào cái giá trị dự đoán và cái nhãn của mình là label Reel.
00:09:34 - 00:09:38, Thì mục tiêu là làm sao cho cái giá trị này là nhỏ nhất.
00:09:41 - 00:09:48, Mặt khác thì chúng ta sẽ truyền cái dữ liệu giả vào.
00:09:48 - 00:09:50, Và dữ liệu giả này từ đâu ra?
00:09:50 - 00:09:57, Nó là từ 1 random noise, bass size là 64 và vector random noise này có kích thước là 100 chiều.
00:09:57 - 00:10:02, Rồi sau đó chúng ta sẽ gọi cái hàm G để tạo ra cái Xen.
00:10:02 - 00:10:07, Vì cái Xen của mình trong trường hợp này đó chính là cái...
00:10:07 - 00:10:10, Xen của mình đó chính là cảnh anh Phách.
00:10:10 - 00:10:16, Rồi, bây giờ chúng ta sẽ truyền cái Xen này vào Disprimandator.
00:10:16 - 00:10:22, Thì cái DGZ này chính là cái sát xuất thuộc về cái lớp Reel.
00:10:22 - 00:10:26, Và khi tính hàm loss thì chúng ta sẽ...
00:10:26 - 00:10:35, Cái hàm loss cho Phách thì chúng ta sẽ truyền vào DGZ và truyền vào cái label Phách.
00:10:37 - 00:10:39, Thì cái nhãn của mình sẽ là nhãn Phách.
00:10:39 - 00:10:45, Và mục tiêu của mình sẽ là làm sao cho cái loss này là nhỏ nhất.
00:10:45 - 00:10:50, Kết hợp với cái loss ở trên, chúng ta sẽ có cái loss tổng là D.
00:10:50 - 00:10:55, Thế thì câu hỏi là tại sao ở trong cái công thức này thì người ta lại đi tìm Max.
00:10:55 - 00:10:59, Mà phía dưới thì chúng ta lại đi tìm Min.
00:10:59 - 00:11:02, Tại vì chúng ta dùng cái hàm loss Binary Cross entropy.
00:11:02 - 00:11:08, Thì bản chất ở đây là một, khi chúng ta tìm Max cái công thức loss này...
00:11:08 - 00:11:16, Thì nó tương đương với cái việc là Cross entropy của hai cái thành phần Reel và Phách bên dưới là thấp nhất.
00:11:16 - 00:11:26, Khi cái thằng này, loss D này càng tiến về 1, xác suốt 1 thì cái loss này sẽ càng tiến về 0.
00:11:26 - 00:11:35, Và ngược lại, cái thành phần này cũng vậy. Tiến về 0 thì 1 trừ cho 0 sẽ là bằng 1.
00:11:35 - 00:11:37, Tức là cái loss này cũng bằng 0.
00:11:37 - 00:11:43, Thì thay vì tìm Max ở cái trạng thái như thế này để mà nó đạt được là bằng 0.
00:11:43 - 00:11:47, Vì vậy chúng ta sẽ tìm Min với Binary Cross entropy.
00:11:47 - 00:11:51, Tức là chúng ta đi tìm cái ngược lại của nó.
00:11:51 - 00:11:55, Do đó cái công thức này nó là hoàn toàn tương đương.
00:11:55 - 00:12:00, Và chúng ta sẽ chạy thức tán Backpropagation và cập nhật lại cái tham số cho D.
00:12:00 - 00:12:08, Sau đó chúng ta sẽ sang bước số 2 là hởi tạo optimizer cho G, generator.
00:12:08 - 00:12:13, Bước đầu tiên đó là chúng ta sẽ tạo ra cái dữ liệu từ noise.
00:12:13 - 00:12:18, Thì chúng ta sẽ bắt trước cái cốt ở trên.
00:12:18 - 00:12:21, Chúng ta sẽ bắt trước cái cốt ở trên.
00:12:21 - 00:12:29, Rồi, thì ở đây chúng ta sẽ có là xgen là bằng G của OG.
00:12:29 - 00:12:32, Rồi, chấm detect.
00:12:39 - 00:12:42, Ở đây thì chúng ta chưa có detect.
00:12:44 - 00:12:53, Rồi, sau đó thì chúng ta sẽ tạo ra cái kết quả dự đoán dự trên dữ liệu.
00:12:53 - 00:13:10, Thì ở đây chúng ta sẽ gọi cái hàm đó là d của xgen và nó chính là d của d của g của gen.
00:13:10 - 00:13:13, Đấy, giống như cái công thức ở đây.
00:13:13 - 00:13:15, Sau đó chúng ta sẽ truyền vào.
00:13:15 - 00:13:18, Thế thì cái sự khác biệt ở đây là gì?
00:13:18 - 00:13:23, Nếu như ở trên là chúng ta tìm cách phân biệt đúng và sai.
00:13:23 - 00:13:28, Thì ở phía dưới cũng là binary cross entropy nhưng mà chúng ta sẽ phải đảo ngược lại cái nhãn.
00:13:28 - 00:13:35, Ở đây là dữ liệu fake nhưng mà chúng ta muốn ép cái mode G.
00:13:35 - 00:13:43, Ep cái mode G tạo ra cái dữ liệu giống thật nên chúng ta sẽ cho cái nhãn của mình là nhãn thật.
00:13:43 - 00:13:48, Đây chính là cái sự khác biệt.
00:13:48 - 00:13:54, Và ngoài ra thì trong cái công thức ở trên chúng ta thấy là có cái thành phần lock của d.
00:13:54 - 00:14:00, Nhưng mà khi chúng ta tối uG thì d ở đây nó là hàng số.
00:14:00 - 00:14:05, Nó không phải là một cái hàm cố định nên nó sẽ không tham gia vào cái quá trình huấn luyện g.
00:14:05 - 00:14:07, Giờ đó chúng ta có thể bỏ đi cái thành phần này.
00:14:08 - 00:14:19, Rồi, do đó lockG nó chỉ có thành phần là dGz tức là cái loss cho cái dữ liệu của mình, dữ liệu fake của mình.
00:14:19 - 00:14:24, Rồi sau đó chúng ta sẽ gọi hàm backpropagation và chúng ta train.
00:14:24 - 00:14:30, Thì cái quá trình train này nó có thể tốn của chúng ta khoảng 5-10 phút.
00:14:30 - 00:14:35, Tùy vào cái sức mạnh tính toán của cái máy của mình.
00:14:36 - 00:14:44, Rồi thì sau khi đã huấn luyện xong đầy đủ với 10 epoch thì nó sẽ ra được cái ảnh như thế này.
00:14:44 - 00:14:57, Thì chúng ta thấy là cái ảnh mà khi chúng ta tái tạo lại thì chúng ta thấy cái bóng dán của áo, của quần, của dày, v.v.
00:14:57 - 00:15:06, Thì bây giờ để trực quan chúng ta sẽ show cái quá trình mà huấn luyện từ đầu cho đến lúc mà chúng ta dừng cái quá trình huấn luyện.
00:15:06 - 00:15:17, Thì ở những cái vòng lập đầu tiên chúng ta thấy là nó sẽ ra cái random noise, giống như thế này.
00:15:17 - 00:15:19, Nó sẽ ra cái random noise.
00:15:19 - 00:15:25, Sau đó thì sang vòng lập tiếp theo thì nó đã ra có hình thù hơn.
00:15:25 - 00:15:30, Có điều là một số khu vực nó vẫn còn mờ.
00:15:30 - 00:15:39, Sau đó đến những epoch cuối cùng thì chúng ta đã thấy là nó ra hình hài tốt hơn.
00:15:39 - 00:15:42, Có dày, có quần áo.
00:15:42 - 00:15:50, Thì ở trong cái ví dụ này là cho chúng ta thấy cái mạng GAN nó đã dần học được phân bố của dữ liệu thật của mình.
00:15:50 - 00:15:59, Thế thì để cải tiến cái mạng GAN này chúng ta có rất nhiều giải pháp như là cải tiến các siêu tham số hoặc là thay đổi cái kiến trúc hàm.
00:15:59 - 00:16:08, Nhưng mà một trong những cái cải tiến mà quan trọng chúng ta cần phải kệ đặt đó là chúng ta sử dụng cái CNN.
00:16:08 - 00:16:18, Cụ thể là chúng ta sử dụng cái 2D Transform Convolution để làm cái Generator và sử dụng mạng CNN cho cái Discriminator.
00:16:18 - 00:16:30, Thì chúng ta sẽ tham khảo thêm trong các link ở đây để có thể hoàn tất và cày cái phần cày đặt của cái mạng GAN khi sử dụng cái Convolution Neural Network.
00:16:38 - 00:16:44, Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.
