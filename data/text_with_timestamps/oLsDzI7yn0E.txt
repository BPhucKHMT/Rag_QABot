00:00:00 - 00:00:25, Như vậy, trong phần này chúng ta đã cùng nghiên cứu về vấn đề Overfitting.
00:00:25 - 00:00:32, Đây là một vấn đề kinh điển trong lĩnh vực học máy và có hai lý do.
00:00:32 - 00:00:39, Một là do mùi quá phức tạp, tham số quá nhiều, trong khi đó dữ liệu của mình quá ít.
00:00:39 - 00:00:44, Và để giải quyết vấn đề Overfitting, chúng ta sẽ có một trong hai cách.
00:00:44 - 00:00:51, Đó là 1 là tăng data length và 2 là chúng ta giảm tham số của mùa hình xuống.
00:00:51 - 00:01:01, Nhưng mà đương nhiên các công ty công nghệ muốn mùa hình của mình có tính chất tổng quả cao và có khả năng nhớ được dữ liệu,
00:01:01 - 00:01:05, thì họ làm điều ngược lại ở khía cạnh số lượng tham số.
00:01:05 - 00:01:16, Các công ty công nghệ lớn tăng số lượng param lên, nhưng đồng thời data của họ tăng lên cũng rất nhiều để cho tương ứng.
00:01:17 - 00:01:24, Tại vì họ không có thiếu tài nguyên tính toán và dữ liệu nên cái việc này là khả thi đến với họ.
00:01:24 - 00:01:31, Rồi, vấn đề thứ 2 là chính là cái vấn đề về Vanishing Gradient.
00:01:31 - 00:01:40, Đây là một trong những vấn đề rất là đau đầu khi chúng ta làm với các thuật toán, các mùa hình học sâu.
00:01:40 - 00:01:46, Tại vì với những mùa hình học sâu thì chúng ta sẽ phải nhân đạo hàm rất là nhiều lần.
00:01:46 - 00:01:56, Và xu hướng khi mà cần tiến đến cái giá trị thực tiểu thì đạo hàm của mình sẽ càng giảm, dẫn đến đó là cái gradient của mình sẽ giảm, dẫn đến là cái mùa hình của mình không bị chậm.
00:01:56 - 00:02:04, Sau đó thì đối với 2 cái vấn đề này, chúng ta đã có những cái cải tiến của các biến thể liên quan đến mạng CNN
00:02:04 - 00:02:14, và các mùa hình dựa trên chuỗi, ví dụ như là RNN và Transformer.
00:02:14 - 00:02:27, Trong đó Transformer là mùa hình sinh sao để muộn. Nó đã tận dụng được rất nhiều thành tựu của các kiến trúc trước đó.
00:02:27 - 00:02:44, Ví dụ như là Skip Connection, Ví dụ như là LayerNorm, Ví dụ như là cái optimizer là AdamW, Ví dụ như là StackLayer.
00:02:44 - 00:03:01, Ví dụ như là
00:03:01 - 00:03:13, Ví dụ như là TransGPT, Ví dụ như là Transformer.
00:03:13 - 00:03:22, Và việc huấn luyện các mùa hình mà Transformer hiện nay thì đã có rất nhiều những doanh nghiệp công ty,
00:03:22 - 00:03:31, hoặc là tổ chức nghiên cứu lớn mà thường là tổ chức nghiên cứu ở bên trong doanh nghiệp lớn để tạo ra các mùa hình
00:03:31 - 00:03:37, cho cộng đồng có thể sử dụng, ví dụ như là DeepSix, Ví dụ như là Lama, v.v.
00:03:37 - 00:03:45, Các mùa hình này đã góp phần cho việc nghiên cứu các mùa hình học sau hiện đại ngày càng trở nên thuận tiện hơn.
00:03:45 - 00:03:51, Trên đây là bài giảng về bá trình tiến hóa của các mùa hình học sau.
