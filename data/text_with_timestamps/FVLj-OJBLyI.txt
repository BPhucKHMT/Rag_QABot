00:00:00 - 00:00:19, Trên đây là mả giả cài đặt thuật ván clip, rất đơn giản
00:00:19 - 00:00:24, Đầu tiên là image encoder này, chúng ta có thể lấy pre-trained model
00:00:24 - 00:00:28, ví dụ như ResNet hoặc Vision Transformer là VIT
00:00:28 - 00:00:34, Còn ResNet thì chúng ta có thể sử dụng các pre-trained model ví dụ như ResNet 101
00:00:34 - 00:00:42, Text Engoder thì chúng ta có thể sử dụng mô hình Continuous Belt Work là Work2Vac
00:00:46 - 00:00:52, Hoặc là mô hình Text Transformer sử dụng Bird
00:00:52 - 00:00:58, Đây là last pre-trained model sử dụng Transformer
00:00:58 - 00:01:02, và được sử dụng rất nhiều trong lĩnh vực xử lý nguồn người tự nhiên
00:01:02 - 00:01:10, Một ảnh y khi đưa qua image encoder thì chúng ta sẽ ra được một feature
00:01:10 - 00:01:14, là if, phí tác của chữ feature representation
00:01:14 - 00:01:18, và nó sẽ có cái kích thước đó là n, nhưng đi
00:01:18 - 00:01:22, N là số ảnh của mình
00:01:22 - 00:01:34, và di là số chiều của vector biểu diễn
00:01:34 - 00:01:42, Mỗi text encoder và image encoder sẽ có số chiều khác nhau
00:01:42 - 00:01:46, Do đó di tức là phí tác của chữ image là dimension của image
00:01:46 - 00:02:08, text encoder sẽ trả về biến tf là n, và mỗi mô tả sẽ được biểu diễn bởi vector dt
00:02:08 - 00:02:12, t là phí tác của chữ text, và t là số chiều của vector biểu diễn văn bảng
00:02:12 - 00:02:20, Và chúng ta sẽ có một genre multimodal emitting
00:02:20 - 00:02:28, tức là chúng ta sẽ đưa cái di và dt này về cùng một cái không gian
00:02:28 - 00:02:32, tức là đưa cùng về cùng một cái vector có cùng một cái thước
00:02:32 - 00:02:40, Thế thì một cái vector di chiều chúng ta sẽ nhân dot product với lợi một cái ma trận là w,i
00:02:40 - 00:02:46, để chuyển từ một vector di chiều sang vector de chiều
00:02:46 - 00:02:50, Thì hai cái thao tác này mục đích của mình đó là chuyển
00:02:50 - 00:03:10, Cái không gian đặc trưng của văn bảng và hình ảnh về cùng một không gian
00:03:10 - 00:03:18, Thế thì không gian ở đây cụ thể là không gian gồm có de chiều
00:03:18 - 00:03:24, Và đương nhiên là chúng ta sẽ normalize nó lại để cho cái việc huấn luyện của mình dễ hơn
00:03:24 - 00:03:26, và đỡ bị hình tượng overfitting hơn
00:03:26 - 00:03:32, Sau đó thì chúng ta sẽ đi tính scale dot product, chúng ta sẽ đi tính tích vô hướng
00:03:32 - 00:03:38, Rồi có thêm một cái nhân thêm cái exp, tức là cái hàm e mũ t
00:03:38 - 00:03:44, Thì mục tiêu của cái này đó là nằm trong cái công thức của contrasted log
00:03:44 - 00:03:50, Để mà có thêm cái time số là t
00:03:50 - 00:03:54, t ở đây chính là nó biết tác của chữ là temporator
00:03:54 - 00:04:04, Thì khi t của mình mà nó càng lớn thì nó sẽ khiến cho cái mô hình của mình nó sẽ nhọn hơn
00:04:04 - 00:04:10, và nó sẽ phân biệt rất là rõ đối tượng này với đối tượng kia
00:04:10 - 00:04:18, Nhưng mà thực tế thì chúng ta sẽ thấy có nhiều cái hình ảnh mà nó có sự giao thoa với nhau
00:04:18 - 00:04:22, Ví dụ như trong cái ảnh đó nó sẽ có hai con vật vừa chó vừa mèo
00:04:22 - 00:04:26, thì nó phải không nên quá gắt để mà đưa về một cái phân lớp nào đó
00:04:26 - 00:04:30, hoặc là bản chất là thậm chí trong nếu mà chỉ có một con chó thôi
00:04:30 - 00:04:34, thì chúng ta thấy là cái con chó nó cũng sẽ có cái hình thụ đâu đó cũng sẽ giống con mèo
00:04:34 - 00:04:43, do đó thì chúng ta không nên để cái t này tiến về một, mà chúng ta cho nó ở mức giữa đoạn đó là khoảng 0.2
00:04:43 - 00:04:45, ví dụ 0.1, 0.2, ví dụ vậy
00:04:45 - 00:04:53, Còn nếu mà tiến về 0, thì tiến về 1, 1 thì nó sẽ quá gắt
00:04:53 - 00:04:57, Còn nếu mà tiến về 0 thì nó lại quá mềm, nó lại quá mềm
00:04:57 - 00:05:01, và nó sẽ không có sự phân biệt rõ ràng giữa đối tượng này với đối tượng kia
00:05:01 - 00:05:05, do đó t, chúng ta sẽ cho nó khoảng là ở mức giữa giữa
00:05:05 - 00:05:13, và khi chúng ta đã tính được cái logit này rồi, tức là cái độ tương đồng giữa hai cái ảnh và văn bản này rồi
00:05:13 - 00:05:21, Vì vậy, chúng ta sẽ tiến hành đi tính logs và ở đây sẽ có hai cái loại logs đối xứng với nhau
00:05:21 - 00:05:23, Logs Y và Logs T
00:05:23 - 00:05:30, Trong đó Y, tức là chúng ta sẽ lấy một cái ảnh, ví dụ trong cái ma trận của chúng ta ở đằng trước
00:05:30 - 00:05:34, Trong cái ma trận của chúng ta, ví dụ chúng ta xét ở hàng này đi
00:05:35 - 00:05:39, Chúng ta xét ở cái ma trận này và tại cái O này
00:05:39 - 00:05:45, thì chúng ta sẽ có Y, có nghĩa là chúng ta sẽ lấy theo hàng
00:05:45 - 00:05:50, tức là các cái giá trị logs theo hàng
00:05:50 - 00:05:52, và
00:05:52 - 00:05:59, Logs T, tức là chúng ta sẽ lấy theo hình ảnh
00:05:59 - 00:06:03, Logs T chúng ta sẽ lấy theo cột như thế này
00:06:03 - 00:06:08, Thì cái việc mà chúng ta tính cả logs theo hàng và theo cột
00:06:08 - 00:06:11, thì để giúp cho cái mô hình của mình nó có cái tính đối xứng
00:06:11 - 00:06:15, khi mà so sánh giữa hình ảnh với một loạt các cái văn bản
00:06:15 - 00:06:17, so sánh giữa hình ảnh nè
00:06:17 - 00:06:22, với một loạt các cái văn bản là T1, T2, T3, Tn
00:06:22 - 00:06:29, nhưng đồng thời nó cũng sẽ có sự so sánh giữa một văn bản với một loạt các hình ảnh
00:06:29 - 00:06:32, một văn bản với một loạt các hình ảnh
00:06:32 - 00:06:34, nó thể hiện ở cái cột này
00:06:34 - 00:06:36, thì đó là cái sự tổng hợp
00:06:36 - 00:06:40, Còn cái label ở đây thì nó sẽ có label Arrange
00:06:40 - 00:06:45, tức là 12012... cho đến n trường 1
00:06:45 - 00:06:49, thì ý của nó là cái nhãn của các đối tượng của mình
00:06:49 - 00:06:52, sẽ là đối với ảnh thứ nhất
00:06:52 - 00:06:56, thì cái nhãn của mình sẽ là đối tượng đầu tiên
00:06:56 - 00:06:59, ảnh thứ hai thì cái nhãn của mình sẽ là thứ hai
00:06:59 - 00:07:03, thì ý của nó là nó đang muốn làm theo chuột đường chéo này của mình
00:07:03 - 00:07:09, và khi chúng ta đã có cái logs này rồi thì chúng ta sẽ dùng tục toán gradient descent
00:07:09 - 00:07:13, các tục toán optimizer dự dự trên gradient descent để hướng luyện
00:07:13 - 00:07:19, và vấn đề đó là làm sao chúng ta có được cái bộ dữ liệu để hướng luyện
00:07:19 - 00:07:24, đó là một cái ảnh và một cái văn bản mô tả
00:07:24 - 00:07:28, thế thì chúng ta sẽ lấy từ trên internet
00:07:28 - 00:07:33, trên internet thì ví dụ như Instagram là có khoảng hơn 3 tỷ đuổi ảnh
00:07:33 - 00:07:38, và chúng ta có một số meta data ứng với cái mọi ảnh đó
00:07:38 - 00:07:42, thì cái tên phai ảnh có thể chứa cái thông tin của nội dung ảnh
00:07:42 - 00:07:45, chứa là đâu đó trên mạng xã hội của chúng ta
00:07:45 - 00:07:50, cái nguồn dữ liệu mô tả này thì đã được người dùng người ta mô tả rồi
00:07:50 - 00:07:54, và chúng ta chỉ việc là khai thác cái lượng dữ liệu này
00:07:54 - 00:07:59, và OpenAI thì xây dựng một cái bộ dữ liệu là WIT
00:07:59 - 00:08:04, là Web Image Text thì bao gồm là 400 triệu cặp dữ liệu ảnh và văn bản
00:08:04 - 00:08:09, rồi 500 ngàn truy vấn dựa trên danh sách các từ xuất hiện trên wiki.da
00:08:09 - 00:08:13, tức là các ảnh này có cái nội dung về chủ đề gì
00:08:13 - 00:08:18, thì cũng sẽ đa dạng hóa bằng cái việc đó là
00:08:18 - 00:08:23, chúng ta sẽ truy vấn bằng 500 ngàn câu truy vấn
00:08:23 - 00:08:30, được lấy từ trên nguồn bạch khoa toàn thư để tăng tính đa dạng của data set
00:08:30 - 00:08:40, và cái kết quả của clip đó là gì
00:08:40 - 00:08:45, clip cho phép chúng ta có thể Zero-soft Transfer rất là hiệu quả
00:08:45 - 00:08:50, và sau khi clip đã ra đời thì có rất nhiều mô hình khai thác clip
00:08:50 - 00:08:55, để làm các mô hình như là phân loại hình ảnh phát hiện đối tượng
00:08:55 - 00:09:00, phân đoạn ngữ nghĩa đối tượng, bài toán captioning, bài toán mô tả hình ảnh
00:09:00 - 00:09:05, rất là nhiều
00:09:05 - 00:09:10, và cái số độ trên đây là việc sử dụng contrastive loss
00:09:10 - 00:09:15, cho sự hiệu quả gấp hơn rất nhiều lần so với các phương pháp hướng luyện khác
00:09:15 - 00:09:20, cụ thể đó là để cho được độ chính xác trên Zero-soft
00:09:20 - 00:09:25, đôi đó khoảng 15%
00:09:25 - 00:09:34, thì tập dữ liệu của chúng ta chỉ cần là khoảng 33 triệu ảnh
00:09:34 - 00:09:39, trong khi đó nếu như chúng ta sử dụng phương pháp dạng prediction
00:09:39 - 00:09:43, hoặc sử dụng một mô hình ngôn ngữ transformer để hướng luyện
00:09:43 - 00:09:47, thì nó sẽ phải tốn lên đến 134 triệu
00:09:47 - 00:09:52, và ở đây sẽ là 400 triệu
00:09:52 - 00:09:57, như vậy thì cái ý của cái biểu đồ này cho biết là phương pháp hướng luyện của contrastive loss
00:09:57 - 00:10:02, của clip cho sự hiệu quả rất là cao, gấp 4 lần
00:10:02 - 00:10:06, ít nhất là gấp 4 lần
00:10:06 - 00:10:11, tuy nhiên cái hạn chế của nó là nó sẽ kém trừ tượng
00:10:11 - 00:10:14, nó sẽ kém hiệu quả trên các bài toán có tính trừ tượng cao
00:10:14 - 00:10:18, trong đó có các đối tượng tương tác với nhau chi tiết
00:10:18 - 00:10:25, thì nó sẽ không có hiệu quả hoặc là những bài toán như là đếm bập thể
00:10:25 - 00:10:30, những bài toán đếm, đó cũng là một bài toán nằm trong nhóm trừ tượng cao
00:10:30 - 00:10:34, và cái kết quả kém trên dữ liệu có phân phối khác
00:10:34 - 00:10:39, ví dụ như chúng ta hướng luyện trên tập dữ liệu trên mạng internet
00:10:39 - 00:10:44, nhưng khi chúng ta sử dụng nó trên tập dữ liệu mnx
00:10:44 - 00:10:48, thì có thể kết quả nó lại không có tốt bằng
00:10:48 - 00:10:53, và do đó chúng ta cần phải cẩn thận trong việc lựa chọn tập dữ liệu
00:10:53 - 00:10:58, khi chúng ta tiến hành tránh giá, đó chính là những điểm hạn chế của clip
00:11:09 - 00:11:14, Cảm ơn các bạn đã xem video hấp dẫn
