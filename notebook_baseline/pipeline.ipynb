{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "langchain 0.3.25 requires langchain-core<1.0.0,>=0.3.58, but you have langchain-core 1.0.3 which is incompatible.\n",
      "langchain 0.3.25 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.40 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "mdit-py-plugins 0.3.0 requires markdown-it-py<3.0.0,>=1.0.0, but you have markdown-it-py 4.0.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires cachetools<6,>=4.0, but you have cachetools 6.2.1 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "langchain 0.3.25 requires langchain-core<1.0.0,>=0.3.58, but you have langchain-core 1.0.3 which is incompatible.\n",
      "langchain 0.3.25 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.40 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "mdit-py-plugins 0.3.0 requires markdown-it-py<3.0.0,>=1.0.0, but you have markdown-it-py 4.0.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires cachetools<6,>=4.0, but you have cachetools 6.2.1 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires cachetools<6,>=4.0, but you have cachetools 6.2.1 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires cachetools<6,>=4.0, but you have cachetools 6.2.1 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires cachetools<6,>=4.0, but you have cachetools 6.2.1 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
      "streamlit 1.37.1 requires cachetools<6,>=4.0, but you have cachetools 6.2.1 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.1 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "langchain-community 0.3.24 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.40 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "streamlit 1.37.1 requires cachetools<6,>=4.0, but you have cachetools 6.2.1 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 12.0.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.4 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "langchain-community 0.3.24 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.40 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "streamlit 1.37.1 requires cachetools<6,>=4.0, but you have cachetools 6.2.1 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 12.0.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.2.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --force transformers==4.52.4\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -q --force accelerate==1.7.0\n",
    "!pip install -q --force langchain==0.3.25\n",
    "!pip install -q --force langchainhub==0.1.21\n",
    "!pip install -q --force langchain-chroma==0.2.4\n",
    "!pip install -q --force langchain_experimental==0.3.4\n",
    "!pip install -q --force langchain-community==0.3.24\n",
    "!pip install -q --force langchain_huggingface==0.2.0\n",
    "!pip install -q --force python-dotenv==1.1.0\n",
    "!pip install -q --force pypdf\n",
    "!pip install langchain_openai\n",
    "!pip install langchain-google-genai\n",
    "!pip install rank_bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35bc60a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__ )\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10335a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env in project root\n",
    "load_dotenv()\n",
    "\n",
    "googleAPIKey = os.getenv('googleAPIKey')\n",
    "gptkey =  os.getenv('myAPIKey')\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = googleAPIKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f489afdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\Phuc1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoModelForSequenceClassification,AutoTokenizer, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain import hub\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f13b12",
   "metadata": {},
   "source": [
    "## Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa42b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dir = \"C:\\\\uit_HK5\\\\CS431\\\\final_project\\\\data\\\\metadata.json\"\n",
    "transcript_dir = \"C:\\\\uit_HK5\\\\CS431\\\\final_project\\\\data\\\\transcripts_final\"\n",
    "output_dir = \"C:\\\\uit_HK5\\\\CS431\\\\final_project\\\\data\\\\semantic_chunks\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d51e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class Loader:\n",
    "    @staticmethod\n",
    "    def parse_transcript(file_path: str) -> tuple[str, list[dict], str]:\n",
    "        \"\"\"Đọc file transcript, tách từng dòng thành block có start-end-text\"\"\"\n",
    "        full_text = \"\"\n",
    "        position_map = []  # lưu vị trí start của mỗi đoạn text trong full_text\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line or \"[âm nhạc]\" in line.lower():\n",
    "                    continue\n",
    "                filename = os.path.basename(file_path).replace(\".txt\", \"\") # lấy file name\n",
    "                match = re.match(r\"(\\d+:\\d+:\\d+)\\s*-\\s*(\\d+:\\d+:\\d+),\\s*(.+)\", line)\n",
    "                if match:\n",
    "                    start, end, text = match.groups()\n",
    "                    pos = len(full_text)\n",
    "                    full_text += text + \" \"\n",
    "                    position_map.append({\n",
    "                        \"start\": start,\n",
    "                        \"end\": end,\n",
    "                        \"text\": text,\n",
    "                        \"pos_start\": pos, # vị trí bắt đầu của đoạn text trong full_text\n",
    "                        \"pos_end\": len(full_text) # vị trí kết thúc của đoạn text trong full_text\n",
    "                    })\n",
    "\n",
    "        return full_text.strip(), position_map, filename\n",
    "    \n",
    "    def map_metadata(self, metadata_path: str, filename: str) -> tuple[Union[str, None], Union[str, None]]:\n",
    "        \"\"\"Đọc file metadata và trả về dict mapping id -> metadata\"\"\"\n",
    "\n",
    "        with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            metadata_list = json.load(f)\n",
    "        metadata = metadata_list[\"videos\"]\n",
    "\n",
    "        video_title, video_url = next(((item[\"title\"], item[\"url\"]) for item in metadata if item[\"video_id\"] == filename), (None, None))\n",
    "\n",
    "        return video_title, video_url\n",
    "    \n",
    "    def load_dir(self, transcript_dir: str, metadata_path: str) -> list[dict]:\n",
    "        \"\"\"Đọc tất cả file transcript trong thư mục và trả về danh sách dict chứa full_text, position_map, filename, title, url\"\"\"\n",
    "        import glob\n",
    "\n",
    "        file_paths = glob.glob(os.path.join(transcript_dir, \"*.txt\"))\n",
    "        data = []\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            full_text, position_map, filename = self.parse_transcript(file_path)\n",
    "            title, url = self.map_metadata(metadata_path, filename)\n",
    "\n",
    "            data.append({\n",
    "                \"full_text\": full_text,\n",
    "                \"position_map\": position_map,\n",
    "                \"filename\": filename,\n",
    "                \"title\": title,\n",
    "                \"url\": url\n",
    "            })\n",
    "\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3959c9a9",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260c581",
   "metadata": {},
   "source": [
    "## Semantic"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7573b359",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec452405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyparsing import line\n",
    "\n",
    "\n",
    "class TranscriptChunker:\n",
    "    def __init__(self, open_api_key: str):\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            openai_api_key=open_api_key\n",
    "        )\n",
    "        self.splitter = SemanticChunker(\n",
    "            embeddings=self.embeddings,\n",
    "            breakpoint_threshold_type=\"percentile\",\n",
    "            breakpoint_threshold_amount=85,\n",
    "            min_chunk_size=300,\n",
    "\n",
    "            add_start_index=True,\n",
    "            buffer_size=1\n",
    "        )\n",
    "        self.loader = Loader()\n",
    "\n",
    "    def chunk_dir(self, transcript_dir: str, metadata_path: str, output_dir: str) -> list:\n",
    "        data = self.loader.load_dir(transcript_dir, metadata_path)\n",
    "        all_chunks = []\n",
    "\n",
    "        for item in data:\n",
    "            full_text = item[\"full_text\"]\n",
    "            position_map = item[\"position_map\"]\n",
    "            filename = item[\"filename\"]\n",
    "            title = item[\"title\"]\n",
    "            url = item[\"url\"]\n",
    "\n",
    "            # dùng lại logic mapping timestamp\n",
    "            chunks = self.splitter.create_documents(\n",
    "                texts=[full_text],\n",
    "                metadatas=[{\n",
    "                    \"video_url\": url,\n",
    "                    \"filename\": filename,\n",
    "                    \"title\": title\n",
    "                }]\n",
    "            )\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                start_index = chunk.metadata.pop(\"start_index\")\n",
    "                end_index = start_index + len(chunk.page_content)  # tự tính end_index\n",
    "\n",
    "                \n",
    "                # tìm timestamp đầu tiên bao phủ đoạn text này\n",
    "                matched_ts = [\n",
    "                    pos for pos in position_map\n",
    "                    if not (pos[\"pos_end\"] < start_index or pos[\"pos_start\"] > end_index)\n",
    "                ]\n",
    "\n",
    "                if matched_ts:\n",
    "                    chunk.metadata[\"start_timestamp\"] = matched_ts[0][\"start\"]\n",
    "                    chunk.metadata[\"end_timestamp\"] = matched_ts[-1][\"end\"]\n",
    "                else:\n",
    "                    chunk.metadata[\"start_timestamp\"] = None\n",
    "                    chunk.metadata[\"end_timestamp\"] = None\n",
    "\n",
    "                chunk.metadata[\"chunk_id\"] = i\n",
    "            all_chunks.extend(chunks)\n",
    "        # lưu tất cả chunks vào file json\n",
    "        output_path = os.path.join(output_dir, \"semantic_chunks.json\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump([{\n",
    "                \"page_content\": chunk.page_content,\n",
    "                \"metadata\": chunk.metadata\n",
    "            } for chunk in all_chunks], f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Saved {len(all_chunks)} chunks to {output_path}\")\n",
    "        return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "990fd650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 461 chunks to C:\\uit_HK5\\CS431\\final_project\\data\\semantic_chunks\\semantic_chunks.json\n"
     ]
    }
   ],
   "source": [
    "splitter = TranscriptChunker(\n",
    "    open_api_key= gptkey\n",
    ")\n",
    "data = splitter.chunk_dir(transcript_dir, metadata_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60d6dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Như vậy thì trong phần số 2 này thì chúng ta đã cùng tìm hiểu về những chủ đề sau. Đầu tiên là chúng ta tìm hiểu về maximum likelihood cho cái log của PX. Chúng ta mong muốn có được một mô hình để tạo ra một cái ảnh x giống thật, giống với lại cái Pdata. Thế thì để đạt được cái việc này thì cái likelihood của log P này phải là lớn nhất. Và khi đưa cái log của PX này lên cực đại thì nó sẽ đưa đến một cái giải pháp, đó là chúng ta sẽ đẩy cái chặn dưới của log P. Thì đó chính là cái ELBO là evidence lower bound.\n",
      "0:00:14 0:01:06\n",
      "https://youtube.com/watch?v=--6FInuIyys\n",
      "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết\n",
      "-----\n",
      "Đẩy cái ELBO này lên, maximum ELBO này lên. Và khi chúng ta maximum ELBO này lên thì chúng ta sẽ có hai cái mô hình, đó là VAE và mô hình diffusion. Và đối với cái mô hình diffusion thì chúng ta sẽ có cái bước gọi là khuếch tán thuận. Và trong cái khuếch tán thuận này thì chúng ta sẽ thêm nhiễu vào cái ảnh của mình. Và ở đây là chúng ta không có tham số để học, không có tham số huấn luyện. Cái điều này nó giúp cho chúng ta đơn giản hóa cái việc huấn luyện của cái mô hình diffusion mà chỉ dành cái dư địa để huấn luyện cho cái phần denoising, phần khử nhiễu. Chúng ta chỉ học khử nhiễu và học bằng cả ba cách. Cách đầu tiên đó là chúng ta sẽ tối ưu để sao cho cái x mũ theta xấp xỉ với lại x0. Cách thứ hai đó là chúng ta tối ưu cái epsilon theta sao cho xấp xỉ với lại cái epsilon. Và cách số ba đó là chúng ta sẽ tối ưu để cho cái x mũ theta xấp xỉ với lại cái gradient của log p theta. Thì đây giống như là cái hướng để khử nhiễu của mình.\n",
      "0:00:58 0:02:29\n",
      "https://youtube.com/watch?v=--6FInuIyys\n",
      "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết\n",
      "-----\n",
      "Thì đây là ba cái cách. Và sau đó thì chúng ta đã tìm hiểu về cách để điều hướng với hai kỹ thuật đó là classifier guidance. Với mỗi một cái condition mới, thì một cái condition chúng ta sẽ ra một cái classifier. Như vậy thì nó sẽ không có linh động trong cái việc là update hoặc là thay cái condition. Chúng ta sẽ có kỹ thuật khác cải tiến đó chính là classifier free guidance. Tức là chúng ta sẽ bỏ luôn cái classifier này mà chúng ta chỉ đi fine-tune lại cái mô hình diffusion. Chỉ fine-tune lại diffusion, không có dùng thêm cái classifier nào để cho nó có thể là train được từ đầu, fine-tune từ đầu đến cuối. Sau đó chúng ta đã nói qua những cái vấn đề về độ phân giải khi chúng ta làm việc với latent, xin lỗi khi làm việc với diffusion. Và cái kỹ thuật mà cascade diffusion thì nó rất là cồng kềnh. Vì nó phải sử dụng đến hai ba cái mô hình nối tiếp nhau và độc lập nhau. Nó không có end to end, tức là kết nối từ đầu đến cuối. Do đó thì chúng ta có cái mô hình latent diffusion và mở ra một cái hướng nó gọi là end to end diffusion. Thì latent diffusion có thể nói là một trong những cái mô hình mà cho cái impact rất là lớn trong cộng đồng nghiên cứu. Là vì nó đã giúp cho chúng ta tính toán nhanh, rồi cái mô hình của mình đạt được cái độ phân giải rất là cao, chất lượng rất là tốt.\n",
      "0:02:26 0:04:16\n",
      "https://youtube.com/watch?v=--6FInuIyys\n",
      "[CS315 - Chương 3] Deep Generative Models (2) - Tổng kết\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "#test print first 3 chunks\n",
    "for chunk in data[:3]:\n",
    "    print(chunk.page_content)\n",
    "    print(chunk.metadata[\"start_timestamp\"], chunk.metadata[\"end_timestamp\"])\n",
    "    print(chunk.metadata[\"video_url\"])\n",
    "    print(chunk.metadata[\"title\"])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fcf4a",
   "metadata": {},
   "source": [
    "## recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ef65d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "class TranscriptChunker:\n",
    "    def __init__(self):\n",
    "        # Recursive chunker\n",
    "        self.splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,        # kích thước chunk tối đa\n",
    "            chunk_overlap=50       # overlap giữa các chunk\n",
    "        )\n",
    "        self.loader = Loader()  # giả sử bạn đã định nghĩa Loader\n",
    "\n",
    "    def chunk_dir(self, transcript_dir: str, metadata_path: str, output_dir: str) -> list:\n",
    "        data = self.loader.load_dir(transcript_dir, metadata_path)\n",
    "        all_chunks = []\n",
    "\n",
    "        for item in data:\n",
    "            full_text = item[\"full_text\"]\n",
    "            position_map = item[\"position_map\"]\n",
    "            filename = item[\"filename\"]\n",
    "            title = item[\"title\"]\n",
    "            url = item[\"url\"]\n",
    "\n",
    "            # chia chunk bằng recursive splitter\n",
    "            text_chunks = self.splitter.split_text(full_text)\n",
    "\n",
    "            chunks = []\n",
    "            start_idx = 0\n",
    "            for i, chunk_text in enumerate(text_chunks):\n",
    "                end_idx = start_idx + len(chunk_text)\n",
    "\n",
    "                # tìm timestamp đầu tiên bao phủ đoạn text này\n",
    "                matched_ts = [\n",
    "                    pos for pos in position_map\n",
    "                    if not (pos[\"pos_end\"] < start_idx or pos[\"pos_start\"] > end_idx)\n",
    "                ]\n",
    "\n",
    "                metadata = {\n",
    "                    \"video_url\": url,\n",
    "                    \"filename\": filename,\n",
    "                    \"title\": title,\n",
    "                    \"chunk_id\": i,\n",
    "                    \"start_timestamp\": matched_ts[0][\"start\"] if matched_ts else None,\n",
    "                    \"end_timestamp\": matched_ts[-1][\"end\"] if matched_ts else None\n",
    "                }\n",
    "\n",
    "                chunks.append(Document(page_content=chunk_text, metadata=metadata))\n",
    "                start_idx = end_idx\n",
    "\n",
    "            all_chunks.extend(chunks)\n",
    "\n",
    "        # lưu tất cả chunks vào file json\n",
    "        output_path = os.path.join(output_dir, \"recursive_chunks.json\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump([{\n",
    "                \"page_content\": chunk.page_content,\n",
    "                \"metadata\": chunk.metadata\n",
    "            } for chunk in all_chunks], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Saved {len(all_chunks)} chunks to {output_path}\")\n",
    "        return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d1f024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1476 chunks to C:\\uit_HK5\\CS431\\final_project\\data\\semantic_chunks\\recursive_chunks.json\n"
     ]
    }
   ],
   "source": [
    "splitter = TranscriptChunker()\n",
    "data = splitter.chunk_dir(transcript_dir, metadata_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d4c43",
   "metadata": {},
   "source": [
    "## lưu db recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c746f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"            # đa ngôn ngữ, gọn nhẹ, khuyên dùng\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name,model_kwargs={\"device\": \"cuda\"})\n",
    "\n",
    "## lưu vào db\n",
    "vector_db = Chroma.from_documents(documents=data, embedding=embedding, persist_directory=\"../database_recursive\")\n",
    "vector_retriever = vector_db.as_retriever( search_type=\"mmr\", search_kwargs={\"k\": 40, \"fetch_k\": 80, \"lambda_mult\": 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6704daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# 🔹 Lấy toàn bộ embedding và metadata từ Chroma\n",
    "# (nếu bạn đã load vector_db = Chroma.from_documents(...) như trên)\n",
    "data = vector_db.get()  \n",
    "\n",
    "vectors = vector_db.get(include=[\"embeddings\"])\n",
    "vectors = np.array(vectors[\"embeddings\"])\n",
    "documents = data[\"documents\"]\n",
    "metadatas = data[\"metadatas\"]\n",
    "\n",
    "# 🔹 Nếu bạn có nhiều loại document, có thể trích ra từ metadata\n",
    "doc_types = [m.get(\"title\", \"unknown\") for m in metadatas]\n",
    "colors = [\"blue\" if t == \"unknown\" else \"red\" for t in doc_types]\n",
    "\n",
    "# 🔹 Giảm số chiều xuống 2D để trực quan hóa\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=1)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# 🔹 Vẽ biểu đồ scatter 2D\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=6, color=colors, opacity=0.8),\n",
    "    text=[\n",
    "        f\"<b>Loại:</b> {t}<br><b>Văn bản:</b> {d[:200]}...\" \n",
    "        for t, d in zip(doc_types, documents)\n",
    "    ],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='📊 Phân bố embedding trong Chroma Vector Store (2D)',\n",
    "    xaxis_title='TSNE Dimension 1',\n",
    "    yaxis_title='TSNE Dimension 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40),\n",
    ")\n",
    "\n",
    "# 🔹 Hiển thị trực tiếp trên browser\n",
    "fig.show(renderer=\"browser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956e70cc",
   "metadata": {},
   "source": [
    "## Reranking by crossencoder + create hybrid search with semantic search + bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d62483",
   "metadata": {},
   "source": [
    "## Load db + vector retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5adf85b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_38344\\3508899957.py:10: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma( embedding_function= embedding, persist_directory=\"../database\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"            # đa ngôn ngữ, gọn nhẹ, khuyên dùng\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name,model_kwargs={\"device\": \"cpu\"})\n",
    "\n",
    "## lưu vào db\n",
    "vector_db = Chroma( embedding_function= embedding, persist_directory=\"../database\")\n",
    "vector_retriever = vector_db.as_retriever( search_type=\"mmr\", search_kwargs={\"k\": 40, \"fetch_k\": 80, \"lambda_mult\": 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61de74fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.16023540496826172 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start= time.time()\n",
    "response = vector_retriever.get_relevant_documents(\"diffusion là gì\")\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c7c8a",
   "metadata": {},
   "source": [
    "## Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e227cd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "rerank_model_name = \"BAAI/bge-reranker-base\"\n",
    "tok = AutoTokenizer.from_pretrained(rerank_model_name)\n",
    "reranker = AutoModelForSequenceClassification.from_pretrained(rerank_model_name)\n",
    "reranker.to(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reranker.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d3db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def batch_crossencoder_scores(q: str, texts: List[str], batch_size: int = 64, max_len: int = 512) -> List[float]:\n",
    "    scores = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        inputs = tok([q]*len(batch), batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device=\"cuda\" if torch.cuda.is_available() else \"cpu\") for k, v in inputs.items()} # chuyển lên gpu\n",
    "        logits = reranker(**inputs).logits.squeeze(-1)\n",
    "        scores.extend(logits.tolist())\n",
    "    return scores\n",
    "\n",
    "\n",
    "def crossencoder_rerank(docs, query: str, top_k: int = 10):\n",
    "    texts = [d.page_content for d in docs]\n",
    "    scores = batch_crossencoder_scores(query, texts, batch_size=16, max_len=512)\n",
    "    ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    BAD_HINTS = (\"Cảm ơn các bạn đã xem\", \"đăng ký kênh\", \"subscribe\", \"like và share\")\n",
    "    final_docs = []\n",
    "    for d, s in ranked:\n",
    "        if all(h.lower() not in d.page_content.lower() for h in BAD_HINTS):\n",
    "            final_docs.append(d)\n",
    "        if len(final_docs) >= top_k:\n",
    "            break\n",
    "    return final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d9c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_38344\\3792054541.py:5: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = vector_retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking Time taken: 1.1450636386871338 seconds\n",
      "[0]  | [CS315 - Chương 3] Deep Generative Models (2) - Part 1 | https://youtube.com/watch?v=SCNZncN1Hvk\n",
      "    0:00:14 → 0:01:11\n",
      "   Chúng ta sẽ cùng đến với các mô hình tạo sinh học sau Deep Generated Model phần 2, mô hình Diffusion. Các mô hình tạo sinh hình ảnh đều có gốc gác sử dụng mô hình phát tán, mô hình Diffusion Model. Đây có thể nói là một trong những mô hình có tính ứng dụng rất cao do tạo ra những ảnh có độ phân giải...\n",
      "--------------------------------------------------------------------------------\n",
      "[1]  | [CS315 - Chương 0] Giới thiệu môn học (Phần 1) | https://youtube.com/watch?v=RU8d6QAuX0k\n",
      "    0:04:07 → 0:05:48\n",
      "   Đó chính là mô hình dựa trên xác suất và cụ thể của một mô hình dựa trên xác suất đó chính là mô hình khuếch tán là Diffusion Model. Sau đó sang tuần thứ 11 thì chúng ta sẽ cùng tìm hiểu về những mô hình học sâu nhưng mà có sự tham gia của ngôn ngữ và thị giác hay còn gọi là Vision Language Model. Đ...\n",
      "--------------------------------------------------------------------------------\n",
      "[2]  | [CS315 - Chương 3] Deep Generative Models (2) - Part 4 | https://youtube.com/watch?v=NJVpvCzceRk\n",
      "    0:00:14 → 0:01:08\n",
      "   Rồi trong những phần trước thì chúng ta đã cùng tìm hiểu về sự khác nhau giữa VAE, Variational Autoencoder và Diffusion Cả hai mô hình VAE và Diffusion đều dựa trên lý thuyết đó là chúng ta sẽ cực đại hóa log của PX này, tức là làm sao cho kỳ ảnh X của mình giống thật nhất. Thay vì chúng ta cực đại ...\n",
      "--------------------------------------------------------------------------------\n",
      "[3]  | [CS315 - Chương 3] Deep Generative Models (2) - Part 8 | https://youtube.com/watch?v=nZc5vWo2Rrg\n",
      "    0:00:14 → 0:01:10\n",
      "   Tiếp theo chúng ta sẽ bàn về tốc độ của mô hình Diffusion Đối với mô hình Diffusion thì vấn đề lớn nhất là nó phải sampling rất nhiều bước trung gian để có thể encode và decode Như vậy thì làm sao để có thể sinh ra ảnh với tốc độ nhanh hơn Nguyên nhân là trong quá trình thêm nhiễu vào, nhiễu sau sẽ ...\n",
      "--------------------------------------------------------------------------------\n",
      "[4]  | [CS315 - Chương 3] Deep Generative Models (2) - Part 4 | https://youtube.com/watch?v=NJVpvCzceRk\n",
      "    0:13:08 → 0:14:21\n",
      "   Như vậy thì làm sao chúng ta có thể khử nhiễu được? Vì dựa trên cái công thức của cái ELBO mà chúng ta đã có ở những slide trước. Qua một số cái phép biến đổi, thì ở đây là do số lượng phép biến đổi quá nhiều. Nên chúng ta chỉ ghi cái kết quả cuối cùng ở đây thôi. Thì nó sẽ có ba cái thành phần số h...\n",
      "--------------------------------------------------------------------------------\n",
      "[5]  | [CS315 - Chương 3] Deep Generative Models (2) - Tổng kết | https://youtube.com/watch?v=--6FInuIyys\n",
      "    0:02:26 → 0:04:16\n",
      "   Thì đây là ba cái cách. Và sau đó thì chúng ta đã tìm hiểu về cách để điều hướng với hai kỹ thuật đó là classifier guidance. Với mỗi một cái condition mới, thì một cái condition chúng ta sẽ ra một cái classifier. Như vậy thì nó sẽ không có linh động trong cái việc là update hoặc là thay cái conditio...\n",
      "--------------------------------------------------------------------------------\n",
      "[6]  | [CS315 - Chương 3] Deep Generative Models (2) - Part 4 | https://youtube.com/watch?v=NJVpvCzceRk\n",
      "    0:16:35 → 0:17:31\n",
      "   Đây chính là cái sự đặc thù riêng của cái diffusion model. Như vậy thì làm sao để có thể huấn luyện được cái hàm P này. Sao cho nó khớp với lại cái q. Thì ở trong cái hình này, nó minh họa một cái trực quan. Đó là cái quá trình, cái màu tím ở đây, tương ứng là cái màu hồng ở đây. Là cái phân bố của ...\n",
      "--------------------------------------------------------------------------------\n",
      "[7]  | [CS315 - Chương 3] Deep Generative Models (2) - Part 8 | https://youtube.com/watch?v=nZc5vWo2Rrg\n",
      "    0:01:08 → 0:12:20\n",
      "   Và ngược lại khi chúng ta denoise cũng như thế. Như vậy thì thời gian chạy của diffusion sẽ là bằng t nhân cho thời gian chạy của GAN và VAE. Vậy thì chúng ta sẽ nhắc lại công thức tạo sinh của mô hình của mình. Trong mô hình tạo sinh của mình thì công thức sử dụng theo cách thức số 2 của chúng ta đ...\n",
      "--------------------------------------------------------------------------------\n",
      "[8]  | [CS315 - Chương 3] Deep Generative Models (2) - Part 4 | https://youtube.com/watch?v=NJVpvCzceRk\n",
      "    0:01:28 → 0:02:11\n",
      "   X0 sẽ là ảnh đầu vào được sampling theo phân bố của data X. Vậy thì công thức ở trên sẽ được đưa về và bài toán mô hình Diffusion model sẽ đưa về việc cực đại hóa kỳ vọng của x1 cho đến XT cho trước X0. Thì đây chính là latent của mình. Và xT sẽ là gồm x0 cho đến XT, nó mở, trộn lại với nhau. Còn cô...\n",
      "--------------------------------------------------------------------------------\n",
      "[9]  | [CS315 - Chương 3] Deep Generative Models (2) - Part 7 | https://youtube.com/watch?v=79WZow7G8fE\n",
      "    0:02:32 → 0:03:21\n",
      "   Và nó sẽ dễ gây ra cái hiện tượng đó là lan truyền lỗi. Ví dụ điều gì xảy ra nếu như cái ảnh 64 x 64 này nó có những cái artifact, tức là những cái dấu hiệu để mà không có được đẹp và có những cái lỗi trong hình ảnh. Vì vậy thì nó sẽ lan truyền cái lỗi đó đến những cái ảnh sau mà không có cái cơ chế...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "## test reranker\n",
    "start= time.time()\n",
    "query = \"diffusion là gì\"\n",
    "docs = vector_retriever.get_relevant_documents(query)\n",
    "reranked_docs = crossencoder_rerank(docs, query, top_k=10)\n",
    "end = time.time()\n",
    "print(f\"Reranking Time taken: {end - start} seconds\")\n",
    "\n",
    "for i, d in enumerate(reranked_docs):\n",
    "    m = d.metadata\n",
    "    print(f\"[{i}]  | {m.get('title', '')} | {m.get('video_url', '')}\")\n",
    "    print(f\"    {m.get('start_timestamp', '?')} → {m.get('end_timestamp', '?')}\")\n",
    "    text = d.page_content.replace(\"\\n\", \" \").strip()\n",
    "    print(\"   \" + (text[:300] + (\"...\" if len(text) > 300 else \"\")))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4592cfd",
   "metadata": {},
   "source": [
    "## bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bd28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# ===== 1. Load docs từ Chroma =====\n",
    "raw = vector_db.get(include=[\"documents\", \"metadatas\"])\n",
    "docs = []\n",
    "\n",
    "for content, metadata in zip(raw[\"documents\"], raw[\"metadatas\"]):\n",
    "    docs.append(Document(\n",
    "        page_content=content,\n",
    "        metadata={\n",
    "            \"filename\": metadata.get(\"filename\", \"\"),\n",
    "            \"video_url\": metadata.get(\"video_url\", \"\"),\n",
    "            \"start_timestamp\": metadata.get(\"start_timestamp\", \"\")\n",
    "        }\n",
    "    ))\n",
    "\n",
    "# ===== 2. BM25 retriever từ LangChain =====\n",
    "if docs:\n",
    "    bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "    bm25_retriever.k = 30     # số lượng trả về\n",
    "else:\n",
    "    bm25_retriever = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b04b0e",
   "metadata": {},
   "source": [
    "## Hybrid : semantic search + keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf61a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 3. Hybrid retriever =====\n",
    "if bm25_retriever is None:\n",
    "    hybrid_retriever = EnsembleRetriever(\n",
    "        retrievers=[vector_retriever],\n",
    "        weights=[1]\n",
    "    )\n",
    "else:\n",
    "    hybrid_retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, vector_retriever],\n",
    "        weights=[0.5, 0.5]   # chỉnh theo ý muốn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7c0314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_31336\\254254511.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = hybrid_retriever.get_relevant_documents(\"diffusion là gì\") if bm25_retriever else []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'filename': '--6FInuIyys', 'video_url': 'https://youtube.com/watch?v=--6FInuIyys', 'start_timestamp': '0:02:26'}, page_content='Thì đây là ba cái cách. Và sau đó thì chúng ta đã tìm hiểu về cách để điều hướng với hai kỹ thuật đó là classifier guidance. Với mỗi một cái condition mới, thì một cái condition chúng ta sẽ ra một cái classifier. Như vậy thì nó sẽ không có linh động trong cái việc là update hoặc là thay cái condition. Chúng ta sẽ có kỹ thuật khác cải tiến đó chính là classifier free guidance. Tức là chúng ta sẽ bỏ luôn cái classifier này mà chúng ta chỉ đi fine-tune lại cái mô hình diffusion. Chỉ fine-tune lại diffusion, không có dùng thêm cái classifier nào để cho nó có thể là train được từ đầu, fine-tune từ đầu đến cuối. Sau đó chúng ta đã nói qua những cái vấn đề về độ phân giải khi chúng ta làm việc với latent, xin lỗi khi làm việc với diffusion. Và cái kỹ thuật mà cascade diffusion thì nó rất là cồng kềnh. Vì nó phải sử dụng đến hai ba cái mô hình nối tiếp nhau và độc lập nhau. Nó không có end to end, tức là kết nối từ đầu đến cuối. Do đó thì chúng ta có cái mô hình latent diffusion và mở ra một cái hướng nó gọi là end to end diffusion. Thì latent diffusion có thể nói là một trong những cái mô hình mà cho cái impact rất là lớn trong cộng đồng nghiên cứu. Là vì nó đã giúp cho chúng ta tính toán nhanh, rồi cái mô hình của mình đạt được cái độ phân giải rất là cao, chất lượng rất là tốt.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:02:32'}, page_content='Và nó sẽ dễ gây ra cái hiện tượng đó là lan truyền lỗi. Ví dụ điều gì xảy ra nếu như cái ảnh 64 x 64 này nó có những cái artifact, tức là những cái dấu hiệu để mà không có được đẹp và có những cái lỗi trong hình ảnh. Vì vậy thì nó sẽ lan truyền cái lỗi đó đến những cái ảnh sau mà không có cái cơ chế, nó không có cơ chế để sửa lỗi. Thế thì cái mô hình này cascade diffusion này thì nó sẽ không có phù hợp để mà có thể ứng dụng được. Lý do đó là vì thứ nhất là nó sẽ lan truyền lỗi.'), Document(metadata={'filename': 'nZc5vWo2Rrg', 'video_url': 'https://youtube.com/watch?v=nZc5vWo2Rrg', 'start_timestamp': '0:01:08'}, page_content='Và ngược lại khi chúng ta denoise cũng như thế. Như vậy thì thời gian chạy của diffusion sẽ là bằng t nhân cho thời gian chạy của GAN và VAE. Vậy thì chúng ta sẽ nhắc lại công thức tạo sinh của mô hình của mình. Trong mô hình tạo sinh của mình thì công thức sử dụng theo cách thức số 2 của chúng ta đó là đoán xem cái nhiễu tại một thời điểm t so với lại cái nhiễu đúng là bao nhiêu thì chúng ta sẽ có mi của qi xt phải x0 là bằng công thức này và mi của theta xt t thì nó sẽ là bằng công thức này trong công thức này thì chúng ta thấy nó có tính chất gọi là Markov tức là phải tính xt cũ trước rồi mới tính xt tuy nhiên có một bài báo khác đó là DDIM tức là denoising diffusion implicit model thì đã bỏ đi cái yếu tố gọi là chuỗi Markov tức là chúng ta sẽ không có yêu cầu quý xt, xt trừ 1 phải là một chuỗi Markov, tức là phải tính được xt trừ 1 xong rồi chúng ta mới tính được cái xt này thì ở đây chúng ta sẽ dùng cái sơ đồ này để dễ hình dung đó là từ xt chúng ta có thể tính trực tiếp lên x1 xin lỗi từ x0 chúng ta có thể tính trực tiếp lên x1 từ x0 chúng ta có thể tính trực tiếp đến x2 mà không cần thông qua không cần thông qua cái bước tính x1 này thì công thức của mình sẽ là qi của xt khi chúng ta biết trước xt trừ 1 x0 thì lúc này chúng ta sẽ tính trực tiếp từ x0 mà không cần qua xt trừ 1 vậy thì ở trên công thức này chúng ta thấy bản chất của các công thức nó chỉ là một sự tính toán với các hệ số a, b và b a và b hàm mi của quý xt, xt0, xt0 là bằng a, b, axt, bε tư tưởng như vậy mi theta của xt, t là bằng axt, bε, theta xt Thế thì chúng ta chỉ cần tìm a và b sao cho miễn là cái xt nó thỏa mãn xt là bằng căn của alpha t x0 cộng cho 1 trừ căn alpha 1 trừ... cộng cho căn của 1 trừ alpha epsilon thì như vậy là đã đúng được Thì cái mô hình DDIM ý tưởng của nó đó là thay vì chúng ta đi từng bước phụ thuộc bước thứ t chúng ta tính xong thì chúng ta mới đến được bước thứ T cộng 1 thì nó sẽ dùng một cái công thức trực tiếp từ x0 cho đến cái vị trí thứ T luôn và ngược lại cũng vậy thế thì nó sẽ nhảy cóc, nói một cách nôm na đó là nó sẽ tính toán nhảy cóc cái bước mà encoding và decoding và như vậy thì cái tốc độ của DDIM có thể nhanh hơn gấp 10 hoặc thậm chí là gấp 100 lần so với lại DDPM DDPM Đây là mô hình probabilistic tức là mô hình có xác suất Còn ở đây là implicit Tức là một mô hình mà nó có thể tính một cách đơn định không có kiểu yếu tố nhiễu trong đó không có yếu tố nhiễu Thế thì xét về tốc độ thì DDPM nó hơn Còn xét về độ chính xác thì nó gần như tương đương và thậm chí là tốt hơn ở một số tình huống ví dụ với số Step 10, FID là 10, DDPM là 13, DDPM là 300 khi thực hiện với 1000 step, DDPM cho độ chính xác cho FID là tốt nhất DDPM cũng gần như tương đương, 4.0 nhưng từ 100 trở về trước, ở đây là 4,0, còn ở đây là gần 10,4,0, rất tốt hơn 10 nhiều Với DDIM, số step của mình mà nhỏ hơn 100, độ chính xác FID của mình tốt hơn hẳn so với DDPM. Tương tự như vậy cho bộ CelebA-64, kết quả cũng hoàn toàn tương tự như vậy. DDIM có thể nói là một trong những cải tiến đột phá trong việc đó là cải tiến về tốc độ của một mô hình diffusion chuyển từ dạng probabilistic sang dạng deterministic để mà mình có thể lấy mẫu nhanh. Và một kỹ thuật khác đó là progressive distillation khi nói đến mô hình học máy thì chúng ta sẽ có kỹ thuật tức là huấn luyện một mô hình teacher có một số tham số rất là lớn và mô hình student có số lượng tham số ít hơn trong trường hợp này thì chúng ta sẽ huấn luyện mô hình teacher và student phối hợp với nhau để sao cho chúng ta, thay vì chúng ta phải đi từng bước như thế này thì chúng ta có thể đi những cái đường tắt mà vẫn có thể đến được đích progressive distillation ở đây chúng ta sẽ huấn luyện teacher trước và sau đó chúng ta sẽ distill vào knowledge của student theo đường màu vàng này thì student của mình là đi theo các đường tắt, tức là nó bỏ qua các bước trung gian ở đây sau đó, nếu là progressive có nghĩa là gì? nó lấy chính cái đường tắt này, tức là cái mô hình mà đi denoise theo cái kiểu đường tắt này để làm teacher để làm teacher, là cái đường màu vàng này là teacher thì chúng ta sẽ đi một cái đường tắt hơn nữa, đó là student chúng ta sẽ bỏ qua cái node này bỏ qua cái node của teacher cũ để tạo ra một student mới có bước nhảy cóc nhanh hơn thì đây chính là Progressive Length Distillation chúng ta từng bước giảm số bước của mình xuống để tăng tốc độ denoise Mô hình Guided Distillation ý tưởng cũng là dùng Distillation nhưng mà kết hợp với Latent Diffusion Đây là một mô hình cho chúng ta vừa đạt được tốc độ huấn luyện và tốc độ inference của mình. Đây là mô hình có Condition là Y, cho phép chúng ta điều hướng mô hình của mình. Vì vậy, ở đây là một mô hình Guided Distillation là giao thoa hoặc là kết hợp của Progressive tức là chúng ta sẽ đi các đường đi tắt thay vì chúng ta đi từng bước, từng bước, từng bước thì chúng ta sẽ đi tắt hoặc thậm chí là tắt hơn, tức là chúng ta có thể đi trực tiếp từ đây sang đây thông qua cái việc là chưng cất tuần tự sau đó chúng ta kết hợp với mô hình Latent Diffusion, tức là chúng ta chỉ làm bước encode và decode ở trên không gian latent thôi, tức là chúng ta không làm trong không gian ảnh mà làm trên không gian latent và kết quả của Guided Distillation thì chúng ta thấy là rất là đẹp và Các bước từ 2 bước, 4 bước và 8 bước thì kết quả gần như tương đương nhau, không có sự phân biệt gì nhiều Với chỉ 2 bước mà kết quả của chúng ta rất là tốt So với đương nhiên là 8 bước nhiều bước hơn thì nó sẽ đẹp hơn, chi tiết hơn nhưng mà 2 bước thì kết quả cũng rất là tốt và khi chúng ta denoise mà chỉ có hai bước thì rõ ràng tốc độ mình nhanh hơn rất là nhiều so với lại denoise cả t bước thì đây là cái kết quả vào năm 2023 và chúng ta sẽ có cái mô hình consistency model tức là chúng ta sẽ kết hợp các cái loss lại với nhau là bằng min của EMA của XT và T Rồi F của theta x t phải thì đây là một cái target network hay còn gọi là mô hình của teacher Còn online network sẽ là mô hình student Tóm lại là đối với những cái giải pháp mà giảm cái tốc độ thì chúng ta sẽ dùng cái mô hình đó là teacher và student Kết hợp hai cái network này lại để chúng ta có thể tạo ra cái mô hình mà tốt hơn, đi tắt hơn và multi-step hơn ví dụ như ở đây chúng ta thấy là cái đường này nè là đi 1 phát 1 đến đích thì nó đã tiết giảm cho chúng ta rất là nhiều các bước denoise như vậy thì chúng ta có thể là single step generation là một bước nhảy từ xt lớn về x0 Và kết quả của Latent Consistency Model thì cũng hoàn toàn tương tự như các mô hình trước Với 4 Step Inference, 4 Step Denoise thì kết quả của mình vẫn cho chất lượng rất tốt Ngoài ra thì chúng ta sẽ có các kỹ thuật liên quan đến vấn đề về Fine-tune lại mô hình Fine-tune mô hình diffusion Khi nói về mô hình diffusion thì tham số thường rất lớn Lý do đó là nó phải encode cả văn bản Cộng với lại encode cả thông tin về mặt hình ảnh Do đó số lượng tham số của mình của các mô hình diffusion thường rất là lớn có những mô hình lên đến gần 1 tỷ tham số có những mô hình hiện đại hơn thì có thể lên đến 3 tỷ, 4 tỷ tham số để tạo được những kỹ ảnh chất lượng tốt và hiểu được văn bản, hiểu được yêu cầu đầu vào của mình thì số tham số là lớn và chúng ta muốn fine-tune mô hình diffusion này với data set của mình Thì khi đó nó rất dễ bị hiện tượng overfitting. Tại vì trong các cái bài trước chúng ta đã nói rồi, hiện tượng overfitting xảy ra khi số lượng tham số lớn và khi dữ liệu của mình ít.'), Document(metadata={'filename': 'NJVpvCzceRk', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'start_timestamp': '0:13:08'}, page_content='Như vậy thì làm sao chúng ta có thể khử nhiễu được? Vì dựa trên cái công thức của cái ELBO mà chúng ta đã có ở những slide trước. Qua một số cái phép biến đổi, thì ở đây là do số lượng phép biến đổi quá nhiều. Nên chúng ta chỉ ghi cái kết quả cuối cùng ở đây thôi. Thì nó sẽ có ba cái thành phần số hạng. Số hạng đầu tiên đó là cái kỳ vọng của phân bố xác suất của x1 cho trước x0. X0 của mình chính là cái ảnh gốc ban đầu. Nó sau đó thêm một ít nhiễu để tạo ra thành x1. Thì chúng ta sẽ lấy kỳ vọng trên toàn bộ cái phân bố của x1. Và log của Ptheta x0 cho trước x1. Thì cái ý nghĩa của cái công thức này đó là gì? Ý nghĩa của cái công thức này đó là từ x1 cho trước x1. Chúng ta khôi phục được trở lại x0. Và phân bố xác suất của Ptheta x0 này là phải cực đại. Tại vì trong công thức của diffusion model là chúng ta cực đại cái kỳ vọng này.'), Document(metadata={'filename': 'NJVpvCzceRk', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'start_timestamp': '0:16:35'}, page_content='Đây chính là cái sự đặc thù riêng của cái diffusion model. Như vậy thì làm sao để có thể huấn luyện được cái hàm P này. Sao cho nó khớp với lại cái q. Thì ở trong cái hình này, nó minh họa một cái trực quan. Đó là cái quá trình, cái màu tím ở đây, tương ứng là cái màu hồng ở đây. Là cái phân bố của cái XT. Phân bố của XT khi chúng ta được encode từ XT-1, được encode từ XT-1. Tức là chúng ta phun nhiễu và thêm nhiễu từ XT-1. Thì cái phân bố này nó phải khớp với lại cái phân bố của cái Pθ, tức là cái màu xanh của XT, cho trước XT-1. Tức là chúng ta khử nhiễu từ XT-1 để về cái XT.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:07:03'}, page_content='Và huấn luyện nó cũng sẽ ổn định hơn. Thì đó chính là cái điều khiến cho latent diffusion model là một trong những cái mô hình tạo sinh hình ảnh mà được rất nhiều cái trích dẫn và được rất nhiều các cái bài báo cũng như là các cái nghiên cứu gần đây họ sử dụng để phát triển.'), Document(metadata={'filename': 'SCNZncN1Hvk', 'video_url': 'https://youtube.com/watch?v=SCNZncN1Hvk', 'start_timestamp': '0:00:14'}, page_content='Chúng ta sẽ cùng đến với các mô hình tạo sinh học sau Deep Generated Model phần 2, mô hình Diffusion. Các mô hình tạo sinh hình ảnh đều có gốc gác sử dụng mô hình phát tán, mô hình Diffusion Model. Đây có thể nói là một trong những mô hình có tính ứng dụng rất cao do tạo ra những ảnh có độ phân giải cao, đồng thời có thể cho chúng ta can thiệp và điều hướng nội dung của tấm ảnh. Vậy thì ý tưởng của Diffusion là gì và cách thức huấn luyện ra sao, chúng ta sẽ cùng tìm hiểu trong bài ngày hôm nay. Các vấn đề chính khi chúng ta tìm hiểu một mô hình Diffusion Model, mô hình phát tán, đó là chúng ta sẽ tìm hiểu về mô hình tạo sinh tổng quát. Mô hình tạo sinh tổng quát này sẽ dựa trên lý thuyết về xác suất thống kê.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:00:52'}, page_content='Và cái này nó sẽ được thực hiện đi, thực hiện lại là T, 1 bước. Và khi sang cái mô hình cascade diffusion mode thì chúng ta không chỉ text-to-image diffusion, tức là đây là cái mô hình gốc ban đầu nè. Nó sẽ có kết hợp với các mô hình để thực hiện việc super resolution, tức là tăng kích độ phân giải lên. Và ở trong hình bên dưới chúng ta thấy đó là ban đầu cái ảnh của mình nó sẽ có kích thước là 64 x 64. Và đây là cái mô hình diffusion gốc. Sau khi chúng ta kết thúc text-to-image diffusion, nó sẽ tạo ra tấm hình giống như thế này. Thì chúng ta sẽ train một cái mô hình super resolution thứ 2 để tăng kích thước của tấm ảnh lên. Và nó đã tăng lên 256 x 256. Rồi sau đó chúng ta lại tiếp tục chạy qua một cái mô hình super resolution diffusion mode để tăng lên là 1024 x 1024. Như vậy thì với cái mô hình cascade diffusion này chúng ta thấy, đó là cái quá trình huấn luyện này là nó độc lập nhau. Text-to-image và super resolution diffusion 1 và 2 thì không có, nói chung là huấn luyện độc lập với nhau. Và nó không có end to end, tức là không có huấn luyện từ đầu đến cuối.'), Document(metadata={'filename': 'qCEs0PIGwek', 'video_url': 'https://youtube.com/watch?v=qCEs0PIGwek', 'start_timestamp': '0:00:14'}, page_content='Chúng ta sẽ cùng tìm hiểu về mô hình khuếch tán diffusion model và sự khác biệt giữa diffusion model so với mô hình variational autoencoder ra sao, quá trình khuếch tán được thực hiện như thế nào. Chúng ta sẽ nhắc lại công thức của mô hình xác suất đằng trước, đó là log P của x sẽ là bằng tổng của hai kỳ vọng này.'), Document(metadata={'start_timestamp': '0:00:14', 'chunk_id': 0, 'end_timestamp': '0:01:08', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'filename': 'NJVpvCzceRk', 'title': '[CS315 - Chương 3] Deep Generative Models (2) - Part 4'}, page_content='Rồi trong những phần trước thì chúng ta đã cùng tìm hiểu về sự khác nhau giữa VAE, Variational Autoencoder và Diffusion Cả hai mô hình VAE và Diffusion đều dựa trên lý thuyết đó là chúng ta sẽ cực đại hóa log của PX này, tức là làm sao cho kỳ ảnh X của mình giống thật nhất. Thay vì chúng ta cực đại hóa log PX này, chúng ta sẽ cực đại hóa chặn dưới, tức là evidence lower bound ELBO của kỳ vọng này. Nếu như trong công thức của VAE, thì cái Z này là một vector ẩn, thì ở đây chúng ta sẽ có nhiều vector ẩn, tại vì mô hình Diffusion của mình sẽ thực hiện nhiều bước để encoding. Nguyên lý của nó đó là chia thành những bước nhỏ, thì nó sẽ giúp chúng ta đơn giản hóa bài toán của mình.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:00:14'}, page_content='Vấn đề tiếp theo thì chúng ta sẽ bàn về độ phân giải. Do sao thì các mô hình tạo sinh ảnh nếu mà muốn có ứng dụng được thì nó phải có thể tạo ra được những cái ảnh mà có kích thước lớn. Vậy thì với mô hình cascade diffusion thì chúng ta sẽ denoise, chúng ta thêm nhiễu rồi sau đó chúng ta sẽ khử nhiễu ở trên cùng một độ phân giải khác nhau. Ví dụ như ở đây chúng ta thấy là đây là mô hình diffusion gốc, thì kích thước của noise của mình đúng bằng kích thước của ảnh mà chúng ta sẽ decode. Và cái quá trình mà chúng ta huấn luyện mô hình thì đây là một cái mô hình để mà tạo ra một cái ảnh với điều kiện cho trước là cái Y.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:03:18'}, page_content='Cái thứ hai đó là cái sự cồng kềnh. Mình mong muốn khi setup thì nó sẽ chỉ có duy nhất một mô hình thôi, còn ở đây nó có đến 3 cái mô hình thực hiện cùng một lúc. Như vậy thì chúng ta sẽ sang một cái phiên bản tiếp theo để có thể giải quyết được cái mô hình, cái điểm yếu của mô hình cascade diffusion này. Đó chính là cái mô hình latent diffusion. Thì latent diffusion là chúng ta sẽ thực hiện cái diffusion, chúng ta thực hiện cái bước là denoise và add noise ở trên cái không gian latent. Thì đầu tiên chúng ta train một cái mô hình VAE để ánh xạ từ cái ảnh có độ phân giải cao ví dụ như là 1024 về cái không gian latent z của mình, ví dụ như là 64 x 64. Rồi, sau đó với cái độ phân giải thấp này, cái ảnh độ phân giải thấp này chúng ta sẽ decode ra để tạo ra cái ảnh gốc. Và chúng ta sẽ có một cái reconstruction loss, tức là cái loss để kiểm tra xem cái ảnh chúng ta tái tạo có giống với ảnh ban đầu hay không. Rồi sau đó chúng ta cũng sẽ có cái phần regularization loss để cho cái latent z này nó tuân theo một cái phân bố là, tuân theo một cái prior distribution mong muốn, ví dụ như là phân bố Gauss. Ngoài ra thì còn có thêm cái adversarial loss của gan để giúp cho chúng ta có thể tạo ra những cái tấm ảnh có chất lượng cao với độ sắc nét chi tiết. Và chúng ta sẽ sử dụng cái mô hình VAE này để là cái bước đầu tiên để nén, chúng ta sẽ nén cái ảnh x này qua VAE encoder. Chúng ta sẽ tạo ra cái vector latent z, sau đó chúng ta sẽ áp dụng cái mô hình diffusion trên chính cái không gian latent này, thay vì trên không gian gốc chúng ta sẽ tạo ra d, đây là d, d1 hoặc là d0 đi ha, d2, rồi cho đến dt, thì đây là cái quá trình encode. Sau đó chúng ta sẽ tiến hành là decode là từ dt, denoise ra dt trừ 1 v.v. về d0 mũ, và với d0 mũ này sau đó chúng ta áp dụng cái decoder của VAE, thì nó đã tạo ra một cái tấm hình, giống như ở đây, thì đây là cái cách thức để chúng ta huấn luyện một cái mô hình latent diffusion. Cái ý tưởng lớn nhất của cái latent diffusion này, thứ nhất đó là một cái end-to-end model. Và cái thứ hai, đó là thay vì chúng ta diffusion, chúng ta encode và decode hoặc là chúng ta add noise hoặc denoise ha, encode và decode. Nhưng chúng ta không làm trên không gian ảnh mà chúng ta làm trên không gian latent.'), Document(metadata={'end_timestamp': '0:02:11', 'start_timestamp': '0:01:28', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'filename': 'NJVpvCzceRk', 'title': '[CS315 - Chương 3] Deep Generative Models (2) - Part 4', 'chunk_id': 2}, page_content='X0 sẽ là ảnh đầu vào được sampling theo phân bố của data X. Vậy thì công thức ở trên sẽ được đưa về và bài toán mô hình Diffusion model sẽ đưa về việc cực đại hóa kỳ vọng của x1 cho đến XT cho trước X0. Thì đây chính là latent của mình. Và xT sẽ là gồm x0 cho đến XT, nó mở, trộn lại với nhau. Còn công thức ở đây thì nó đem qua từ đây.'), Document(metadata={'filename': '--6FInuIyys', 'video_url': 'https://youtube.com/watch?v=--6FInuIyys', 'start_timestamp': '0:00:58'}, page_content='Đẩy cái ELBO này lên, maximum ELBO này lên. Và khi chúng ta maximum ELBO này lên thì chúng ta sẽ có hai cái mô hình, đó là VAE và mô hình diffusion. Và đối với cái mô hình diffusion thì chúng ta sẽ có cái bước gọi là khuếch tán thuận. Và trong cái khuếch tán thuận này thì chúng ta sẽ thêm nhiễu vào cái ảnh của mình. Và ở đây là chúng ta không có tham số để học, không có tham số huấn luyện. Cái điều này nó giúp cho chúng ta đơn giản hóa cái việc huấn luyện của cái mô hình diffusion mà chỉ dành cái dư địa để huấn luyện cho cái phần denoising, phần khử nhiễu. Chúng ta chỉ học khử nhiễu và học bằng cả ba cách. Cách đầu tiên đó là chúng ta sẽ tối ưu để sao cho cái x mũ theta xấp xỉ với lại x0. Cách thứ hai đó là chúng ta tối ưu cái epsilon theta sao cho xấp xỉ với lại cái epsilon. Và cách số ba đó là chúng ta sẽ tối ưu để cho cái x mũ theta xấp xỉ với lại cái gradient của log p theta. Thì đây giống như là cái hướng để khử nhiễu của mình.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=nZc5vWo2Rrg', 'title': '[CS315 - Chương 3] Deep Generative Models (2) - Part 8', 'chunk_id': 0, 'end_timestamp': '0:01:10', 'filename': 'nZc5vWo2Rrg', 'start_timestamp': '0:00:14'}, page_content='Tiếp theo chúng ta sẽ bàn về tốc độ của mô hình Diffusion Đối với mô hình Diffusion thì vấn đề lớn nhất là nó phải sampling rất nhiều bước trung gian để có thể encode và decode Như vậy thì làm sao để có thể sinh ra ảnh với tốc độ nhanh hơn Nguyên nhân là trong quá trình thêm nhiễu vào, nhiễu sau sẽ phụ thuộc vào nhiễu trước Tức là để denoise được xt-2 thì phải có xt-1 Mà muốn tính được xt-1 thì phải có xt Chính sự tuần tự này sẽ khiến chúng ta chậm Nguyên nhân của tuần tự này là nó giả định theo chuỗi Markov, tức là phải có x thứ t trừ 1 xong chúng ta mới có thể tính được xt. Đó chính là nguyên nhân.'), Document(metadata={'end_timestamp': '0:05:48', 'chunk_id': 3, 'title': '[CS315 - Chương 0] Giới thiệu môn học (Phần 1)', 'video_url': 'https://youtube.com/watch?v=RU8d6QAuX0k', 'filename': 'RU8d6QAuX0k', 'start_timestamp': '0:04:07'}, page_content='Đó chính là mô hình dựa trên xác suất và cụ thể của một mô hình dựa trên xác suất đó chính là mô hình khuếch tán là Diffusion Model. Sau đó sang tuần thứ 11 thì chúng ta sẽ cùng tìm hiểu về những mô hình học sâu nhưng mà có sự tham gia của ngôn ngữ và thị giác hay còn gọi là Vision Language Model. Đối với tiếng Anh thì chúng ta để là Vision Language Model nhưng mà khi chúng ta dịch sang tiếng Việt thì nó sẽ đảo lại, đó là ngôn ngữ thị giác. Và 3 mô hình đầu tiên chúng ta sẽ cùng tìm hiểu trong tuần thứ 11 đó chính là mô hình clip, mô hình clip và mô hình clip. Sau đó thì chúng ta sẽ tìm hiểu về những mô hình ngôn ngữ thị giác mà ở cấp độ có sự tương tác về ngữ nghĩa cao hơn, đó là mô hình Visual Programming và GPT for Vision. Rồi cuối cùng trong mô hình ngôn ngữ thị giác thì chúng ta có các mô hình sử dụng mô hình ngôn ngữ thị giác để giải quyết bài toán từ kinh điển cho đến hiện đại của thị giác máy tính. Ví dụ như là Grounding Dino để phục vụ cho bài toán phát hiện vật thể hoặc là phân đoạn ngữ nghĩa giác. Đầu tiên là để phát hiện, sau đó là kết hợp với thuật toán SAM để phân đoạn ngữ nghĩa đối tượng.'), Document(metadata={'filename': 'iQqNUKgIZpc', 'video_url': 'https://youtube.com/watch?v=iQqNUKgIZpc', 'start_timestamp': '0:13:11'}, page_content='Và đã có là hơn 200.000 và gần xấp xỉ 300.000 citation, là 300.000 cái trích dẫn. Thì cách đây là hơn một năm thì mới chỉ khoảng là 210.000 nhưng mà sau một năm là nó nhảy lên 90.000. Thì thế thì chúng ta thấy đó là cái tốc độ tăng citation rất là nhanh và chưa thấy có một cái dấu hiệu gì là dừng lại. Thì điều đó chứng tỏ là cái kỹ thuật mà Skip Connection này rất là hiệu quả và được rất nhiều những cái nghiên cứu họ sử dụng gần đây. Và với cái kết nối tắt này thì không chỉ ResNet mà những cái kiến trúc khác ví dụ như là DenseNet cũng sẽ có các cái kết nối tắt. Đây là các kết nối tắt. Rồi Transformer cũng vậy. Chúng ta thấy là Transformer là Attention Is All You Need. Tức là là tất cả những gì bạn cần.'), Document(metadata={'end_timestamp': '0:08:49', 'filename': 'Hrmm1B6sR8g', 'title': '[CS315 - Chương 3] Deep Generative Models (2) - Part 2', 'chunk_id': 8, 'start_timestamp': '0:08:10', 'video_url': 'https://youtube.com/watch?v=Hrmm1B6sR8g'}, page_content='Khi đưa về min chúng ta đảo thứ tự cho nhau. Và chúng ta đã đưa nó về cái công thức của KL diversion. Thì đây là một cái công thức rất là nổi tiếng. Rồi, cái ý nghĩa của cái công thức này đó là gì? Đó là chúng ta sẽ tìm cách để cho cái P theta này tiến về với P data. Hay là cái phân bố màu cam này nè.'), Document(metadata={'filename': 'peYaH97QeEw', 'video_url': 'https://youtube.com/watch?v=peYaH97QeEw', 'start_timestamp': '0:00:14'}, page_content='Chắc hồi trước thì chúng ta đã cùng tìm hiểu về kiến trúc autoencoder Bây giờ thì chúng ta sẽ cùng tìm hiểu về một biến thể rất là quan trọng, đó chính là Variational Autoencoder Trước hết thì chúng ta sẽ nhắc lại autoencoder là gì và chúng ta sẽ xem có những điểm gì cần phải cải tiến trong kiến trúc này Đầu tiên đó là autoencoder thì sẽ bao gồm hai thành phần, đó là một encoder và một decoder Trong đó, encoder, nhiệm vụ của nó là chúng ta sẽ nén dữ liệu và biểu diễn dữ liệu ở số chiều cao về một vector biểu diễn thấp chiều hơn Nếu chỉ như vậy thì không được, chúng ta sẽ phải tái tạo lại được so với dữ liệu gốc ban đầu là x, chúng ta sẽ phải có một decoder Với decoder này thì nó sẽ giúp chúng ta liên kết về mặt ý nghĩa giữa vector z và dữ liệu gốc ban đầu x Chúng ta tưởng tượng là trong một không gian latent, giống như ở đây thì ảnh của mình sẽ được map vào một không gian và ở đây sẽ là vector z Vector z này qua decoder sẽ khôi phục ngược lại về ảnh gốc ban đầu Câu hỏi đặt ra đó là bây giờ chúng ta sẽ dùng autoencoder này để làm gì? Rõ ràng các mô hình tạo sinh được sử dụng để sinh hình ảnh, do đó chúng ta sẽ tiến hành sinh hình ảnh Ví dụ chúng ta có một vector ở đây và chúng ta sẽ qua hàm decoder, viết tắt chữ D, thì nó sẽ tạo ra thành một tấm hình Với kiến trúc encoder thì nó không có gì đảm bảo rằng ảnh sau khi chúng ta tái tạo lại có thể là một ảnh có ý nghĩa Đó là ý thứ nhất.'), Document(metadata={'end_timestamp': '0:05:30', 'video_url': 'https://youtube.com/watch?v=NEK5lIyST0M', 'chunk_id': 3, 'start_timestamp': '0:03:19', 'title': '[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)', 'filename': 'NEK5lIyST0M'}, page_content='Mèo sẽ khác chó chứ không thể nào mà mèo nhỏ hơn chó hoặc là mèo lớn hơn chó. Thì đó là cái cách để chúng ta có thể biết đó là bài toán hồi quy hay bài toán tuyến tính. Thì đối với cái bài toán hồi quy thì chúng ta sẽ có cái mô hình là hồi quy tuyến tính hay còn gọi là linear regression. Và đối với cái bài toán phân loại thì chúng ta sẽ có hai tình huống. Tình huống đầu tiên đó là phân loại nhị phân, tức là cái số phân lớp ca của mình là có hai phân lớp. Và chúng ta sẽ có cái mô hình đó là hồi quy logistic hay là logistic regression. Đối với trường hợp mà ca lớn hơn 2 thì đó sẽ là chúng ta sẽ có cái mô hình đó là hồi quy softmax hay còn gọi là softmax regression. Còn trong cái trường hợp mà cái mô hình của mình phi tuyến tính thì chúng ta sẽ có rất nhiều những cái mô hình hiện đại tập trung vào giải quyết cái bài toán mà y của mình phụ thuộc một cách phi tuyến tính với là x đầu vào. Và một trong những cái mô hình đầu tiên mà giải quyết cái bài toán mà có tính chất phi tuyến tính đó là mô hình Neural Network. Neural Network hay còn gọi là mạng Neural Nhân tạo, ANN. Thì đây có thể nói là một trong những cái mô hình đầu tiên để đặt nền móng cho học sâu. Và các cái mô hình về sau thì chúng ta thấy nó có cái chữ A, có cái chữ NN, ví dụ như là CNN. Thì cái chữ NN ở đây nó cũng chính là Neural Network. Và còn ANN thì nó cũng có cái chữ NN là Neural Network. Và thậm chí là Transformer thì rất nhiều những cái, kể cả Transformer thì rất nhiều những cái module ở trong Transformer nó cũng dựa trên cái kiến trúc của Neural Network. Do đó thì chúng ta mới gọi Neural Network là một trong những cái mô hình nền tảng đầu tiên về học sâu. Và chúng ta sẽ đến với cái mô hình đầu tiên.'), Document(metadata={'filename': 'qCEs0PIGwek', 'video_url': 'https://youtube.com/watch?v=qCEs0PIGwek', 'start_timestamp': '0:11:23'}, page_content='Cái vế thứ hai đó là cái thành phần chính quy hóa là cái nhiễu này, thì nó sẽ tuân theo cái phân bố 0.1. Còn đối với cái mô hình diffusion ở dưới đây thì thay vì một bước, Thứ nhất, cái sự khác biệt thứ nhất đó là thay vì một bước thì ở đây chúng ta sẽ có nhiều bước encoding, nhiều bước nhỏ encoding. Và cuối cùng chúng ta cũng đến được cái random noise như thế này theo cái phân bố normal distribution. Nhưng cái sự khác biệt thứ hai đó là trong mô hình VAE thì nó sẽ có tham số, có cái tham số phi. Còn ở đây là không có tham số, các encoding này là không có tham số. Thì đó chính là cái sự khác biệt lớn nhất mà chúng ta thấy được giữa hai cái mô hình VAE và AE. VAE thì sẽ có tham số và chỉ có một bước, một bước nhảy là đến được cái random noise. Thế thì chúng ta thấy là cái việc mà chúng ta ánh xạ trực tiếp từ ảnh thế giới thực sang cái random noise này mà chỉ qua một bước, thì đây là một cái bài toán khó. Và chưa kể khi chúng ta decode ngược trở lại từ cái random noise này thì đây cũng là một cái bài toán khó. Tuy nhiên khi thay vì chúng ta giải một cái bài toán khó với một cái encoder thì chúng ta sẽ chia nhỏ nó ra thành nhiều bước. Thì những cái bước encoding này nó sẽ là một cái mô hình dễ hơn, dễ hơn rất là nhiều. Chúng ta phun một ít nhiễu lên trên cái X0 để được cái X1, rồi sau đó phun một ít nhiễu lên để thành X2.'), Document(metadata={'chunk_id': 11, 'title': '[CS315 - Chương 3] Deep Generative Models (2) - Part 2', 'filename': 'Hrmm1B6sR8g', 'video_url': 'https://youtube.com/watch?v=Hrmm1B6sR8g', 'end_timestamp': '0:17:51', 'start_timestamp': '0:12:36'}, page_content='Tức là làm sao chúng ta có thể biết được cái P của z khi cho trước x. Thì để làm được cái chuyện đó thì chúng ta sẽ sử dụng một cái hàm, đó là encoder. Tức là trong công thức này là cho trước x, cho trước x, làm sao chúng ta xác định được cái P của z cho trước x thì đây là một cái hàm phân bố. Vậy làm sao biết được cái P này? Thì chúng ta sẽ thêm vô một cái module là encoder để từ cái dữ liệu x mà chúng ta sampling trong thế giới thật P data. Qua cái hàm encoder này thì chúng ta sẽ xác định được cái Quy zx, tức là phân bố của z khi biết trước x. Tức là cho trước mẫu dữ liệu đầu vào và chúng ta xác định cái phân bố của z, của cái vector trong không gian tìm ẩn. Thế thì chúng ta có cái công thức đó là P của x là bằng log của Px. Thì nhân với lại cái tích phân của Quy z cho trước x nhân với dz thì cái công thức này nó sẽ có cái giá trị là bằng một. Tại vì khi chúng ta cho z dựa trên toàn bộ cái không gian xác suất của nó thì Quy của z cho trước x thì tổng xác suất này là cái tích phân xác suất này là luôn là bằng một. Tại vì dz nó đã chạy, cái dz này nó chạy trên hết trong cái không gian xác suất của nó. Vậy thì chúng ta sẽ triển khai cái công thức này, đem cái tích phân ra ngoài. Thì sẽ có là Quy của zx cho trước x nhân với lại log của Px dz. Chúng ta đưa cái tích phân ra ngoài. Thì cái công thức này nó sẽ tương đương với cái việc là chúng ta tính cái kỳ vọng của z, lấy mẫu trong cái z cho trước x. Rồi, như vậy thì chúng ta sẽ lấy hết cái phân bố này, sau đó chúng ta sẽ lấy cái xác suất đó, chúng ta nhân với lại log của Px. Thì cái công thức này nó sẽ tương đương với lại cái kỳ vọng ở đây. Và chúng ta sẽ cùng nhân sử dụng cái công thức Bayes thì Px, hồi nãy chúng ta đã ghi cái công thức này rồi. Px là bằng Px và z chia cho Pzx dựa trên cái luật Bayes. Và khi chúng ta áp dụng cái công thức này vào thì chúng ta cùng nhân cho tử và mẫu là Quy của z cho trước x. Rồi, sau đó chúng ta đảo thứ tự lại, chúng ta đem cái Quy qua và đem cái P qua đây. Thì khi đó chúng ta sẽ có là Px, nhân cho Quy của zx. Rồi, và từ cái công thức ở trên thì chúng ta sẽ có là log của tích, ở đây chúng ta có cái phép là phép nhân. Chúng ta có cái phép nhân, thì log của tích sẽ là bằng tổng 2 log. Rồi, thì là Px chia cho Quy của zx, còn ở đây sẽ là Quy của zx chia cho Px. Và chúng ta sẽ thấy đây chính là cái công thức để mà chúng ta có thể ước lượng được cái Px này. Và làm sao cho cái Px này nó tiến về cái P của data.x thì chúng ta sẽ dựa trên cái công thức này để chúng ta xây dựng cái mô hình. Và ở trong cái công thức này thì kỳ vọng của Quy zx, của cái công thức là log của Quy zx chia cho P của zx, thì đây chính là cái công thức của KL diversion. Đây chính là cái công thức của KL diversion. Ở trên đây là Quy zx, thì nó sẽ là KL diversion của Quy zx và Pzx, tức là cái khoảng cách giữa 2 cái phân bố này. Mà khoảng cách của 2 cái phân bố này thì đó là con số lớn hơn không. Tuy nhiên làm sao chúng ta có được cái này, làm sao chúng ta có được cái P của zx thì cái chuyện đó là rất là khó. Rất khó để chúng ta có thể xác định được cái phân bố thực tế của z cho trước x.'), Document(metadata={'filename': 't5t5G61ZtAg', 'video_url': 'https://youtube.com/watch?v=t5t5G61ZtAg', 'start_timestamp': '0:04:27'}, page_content='thì cách mà chúng ta sẽ thực nghiệm đó chính là chúng ta sẽ làm cái lưới từ trừ 5 cho đến 10 và từ trừ 10 cho đến 5 rồi, thì chúng ta sẽ thử ha chúng ta sẽ vẽ cái lưới này rồi, trừ 5 là ở đây rồi chúng ta sẽ lấy cái lưới chụp cái màn hình này thì trừ 5 sẽ là ở đây rồi 10 sẽ là ở đây trừ 5 cho đến 10 trừ 5 cho đến 10 thì 10 sẽ là ở đây rồi và trục tung thì là sẽ từ trừ 10 cho đến 5 trừ 10 cho đến 5 là ở đây trừ 10 cho đến 5 là ở đây rồi, như vậy cái lưới mà dự định chúng ta sẽ vẽ là ở khu vực này trục hoành là từ trừ 5 cho đến 10 và trục tung là từ trừ 10 cho đến 5 như vậy thì chúng ta sẽ có một cái khung vuông rồi, sau đó chiến thuật của chúng ta là gì? chúng ta sẽ chia lưới nó ra ví dụ như trong trường hợp này chúng ta sẽ chia ra làm 12 khoảng cách đều nhau rồi, sau đó chúng ta cũng sẽ chia lưới theo chiều dọc như vậy rồi, thì với mỗi một cái điểm trên cái mắt lưới này lấy ví dụ như cái điểm ở đây chúng ta sẽ dùng một điểm đen ví dụ như một cái điểm trên cái mắt lưới này thì nó sẽ là một cái vector z mà chúng ta lấy ra, chấm lên trên cái lưới và chúng ta sẽ qua cái hàm decoder để xem nó ra một cái tấm ảnh gì nó như thế nào sau đó chúng ta lấy cái ảnh này chúng ta sẽ vẽ lên trên thành một cái ma trận với cái ảnh này chúng ta sẽ vẽ ra một ảnh với một cái điểm z ở đây chúng ta sẽ decode ra và vẽ ảnh lên với cái điểm này, điểm này chúng ta decode ra và vẽ ảnh lên thì chúng ta sẽ ra một cái ma trận các điểm ảnh và chúng ta sẽ quan sát xem nó có cái tính chất gì đặc biệt phải không Rồi, thì đó chính là cái ý tưởng của cái hàm Plot Reconstructed chúng ta sẽ chia ra thành các latent space với n ở đây là bằng 12, chúng ta sẽ chia ra làm 12 khoảng rồi lấy cái x và cái y này chúng ta sẽ có được cái latent z là cái điểm màu đen mà chúng ta đã vẽ rồi qua cái hàm decoder chúng ta sẽ ra được x hat tức là cái ảnh được tạo sinh ra và ảnh này sẽ được reset về cái kích thước là 28 x 28 và sau đó vẽ lên cái ma trận ảnh rồi, thì chúng ta sẽ chạy cái đoạn code này đó thì với cái ví dụ này chúng ta có thể thấy đó là ở những cái khu vực phía trên đó sẽ ra một cái hình thù gì đấy và chúng ta không cảm nhận được đó là một cái con số khu vực ở giữa ở đây cũng vậy nó sẽ có lẫn lộn rất nhiều những cái hình ảnh ở trong đó có thể có chứa nhiều con số dẫn đến là mình nhìn mình không cảm nhận được đó là số gì khu vực này cũng vậy thế thì chiếu lên trên cái hình ảnh của cái không gian của mình thì những ảnh ở góc phía trên bên đây là ở khu vực trừ 5 cho đến 5 trừ 5 cho đến 5 tức là nó nằm ở cái khu vực màu trắng và cái khu vực màu trắng này khi chúng ta decode ra thì nó sẽ tạo ra một cái ảnh không có ý nghĩa không giống cái con số nào hết đó thì đây chính là cái điểm yếu của mô hình auto encoder'), Document(metadata={'video_url': 'https://youtube.com/watch?v=ZMtZ2jeujIU', 'end_timestamp': '0:12:26', 'filename': 'ZMtZ2jeujIU', 'chunk_id': 0, 'title': '[CS315 - Chương 3] Deep Generative Models (1) - Part 3 (Phần 2)', 'start_timestamp': '0:00:14'}, page_content='Chúng ta sẽ lựa chọn một phân bố xác suất prior tức là tiền nghiệm, là Normal Gaussian Tức là chúng ta có rất nhiều những dạng phân bố khác nhau, tuy nhiên một trong những phân bố rất phổ biến đó là phân bố chuẩn là Normal Gaussian Chúng ta mong muốn phân bố không gian ẩn của mình sẽ là một phân bố giống với phân bố Gauss Và cụ thể luôn là Normal Gaussian, tức là với mu là bằng 0 và sigma bình phương là bằng 1, thì đây là phân bố ẩn tiền nghiệm Và mình sẽ huấn luyện mô hình để cho Q của z cho trước x với tham số phi là tuân theo phân bố Gauss Vì vậy, phân bố đồng đều sẽ xoay xung quanh tâm của không gian ẩn, ví dụ như chúng ta có một không gian ẩn thì mình sẽ tìm cách đưa nó về cùng một tâm với nhau Vì vậy, phân bố của mình sẽ xoay xung quanh tâm không gian ẩn, tức là mu bằng 0, khuyến khích cho đặc trưng phân bố đồng đều xoay xung quanh tâm không gian ẩn Vì vậy, phân bố đều sẽ xoay xung quanh tâm không gian ẩn, tức là nếu như ở trong mô hình autoencoder không có hình thông thường, thì mình sẽ tìm cách đưa nó về cùng một tâm Vì vậy, phân bố của mình sẽ xoay xung quanh tâm không gian ẩn, tức là nếu như ở trong mô hình autoencoder không có hình thông thường, thì mình sẽ tìm cách đưa nó về cùng một tâm Vì vậy, phân bố của mình sẽ xoay xung quanh tâm không gian ẩn, tức là mu bằng 0, khuyến khích cho đặc trưng phân bố đồng đều xoay xung quanh tâm không gian ẩn Vì vậy, phân bố của mình sẽ tìm cách đưa nó về cùng một tâm Cái công thức khoảng cách độ lỗi giữa qi và p thì nó được tính như thế nào? Nó sẽ được tính dựa trên công thức KL divergence giữa hai phân phối Và khi chúng ta triển khai với p là bằng phân bố Normal Gauss là mu bằng 0 và sigma bình bằng 1, thì chúng ta sẽ có công thức đó là bằng một phần tổng của g chạy từ 0 cho đến k trừ 1 của sigma z cộng cho mu z bình phương trừ 1 Trừ cho log của sigma z, trong đó k chính là số chiều của vector của mình K chính là số chiều của không gian ẩn Và khi đó nó cũng chính là số chiều của mu, nó cũng chính là số chiều của sigma luôn Rồi, khi chúng ta huấn luyện một mô hình VAE, thành phần chính quy hóa này nó khuyến khích cái chuyện gì? Đó là khi chúng ta cho cái loss này càng tiến về 0, tức là càng giảm Rõ ràng là với công thức này chúng ta sẽ thấy sigma z sẽ có xu hướng tiến về 0 Ngược lại, ở đây chúng ta thấy có cái dấu trừ log của sigma z, thì nó lại khuyến khích cái sigma này là không quá nhỏ Nó sẽ khuyến khích Cái sigma z không quá nhỏ Còn cái mu tiến về 0, tức là cái phân bố của mình, nó sẽ kéo từ một cái khu vực rất là xa, nó sẽ kéo về tiến về cái góc tọa độ 00 này Đây là một cái mu ban đầu, nó sẽ kéo cái mu này về góc tọa độ Rồi, đồng thời sigma z nếu như cái phân bố của mình nó quá lớn, thì nó sẽ kéo cho cái sigma này tiến về đủ nhỏ Nhưng nhờ có cái log của sigma z này thì nó sẽ khiến cho cái sigma của mình không quá nhỏ Chứ còn nếu mà nó nhỏ quá thì có phải là thay vì chúng ta đưa về một phân bố thì cuối cùng nó sẽ đưa về một điểm không? Phân bố của mình nó sẽ tiến về một điểm, như vậy là nó tương tự như autoencoder rồi Như vậy thì cái sigma nó sẽ kéo về, đừng có quá lớn nhưng mà cũng đừng có quá nhỏ để hy vọng rằng là cái phân bố của mình nó thực sự là một cái phân bố có yếu tố ngẫu nhiên Chứ còn nếu mà sigma mà tiến về bằng 0, tức là nó sẽ co về một điểm, tức là nó sẽ đưa về một cái mô hình deterministic, tức là một cái mô hình tất định Chứ không có yếu tố xác suất như trong cái mô hình VAE Thì với cái công thức này nó sẽ khuyến khích hai cái chuyện đấy, một đó là cái phân bố Q này sẽ tiến về 0, tiến về cái gốc tọa độ Cái thứ hai đó là mu z, nó sẽ tiến về một cái phân bố mà có cái độ lệch vừa đủ, chứ nó không có quá nhỏ nhưng nó cũng không quá to Thì đây là cái công thức chính quy hóa Và chúng ta có những cái tính chất gì từ cái việc chính quy hóa này, nó sẽ có những tính chất gì Đầu tiên đó là cái tính liên tục, tức là những cái điểm gần nhau trong không gian thì nội dung hoàn toàn tương tự nhau khi giải mã Chúng ta đang nói đến cái ý này Thì ở bên trái là một cái mô hình không có được chính quy, tức là chúng ta chỉ có cái sai số giữa x trừ cho x mũ thôi Sai số tái tạo thôi, chỉ có sai số tái tạo Thì nếu không có thành phần chính quy hóa thì nó sẽ không đảm bảo được Thứ nhất đó là hai điểm gần nhau trong không gian ẩn, là cái điểm màu xanh lá mạ và màu đỏ ở đây thì nó gần nhau trong không gian tiền ẩn Nhưng khi mà giải mã thì nó không có tương tự nhau, ví dụ cái điểm màu xanh lá này, xanh lá mạ này thì nó sẽ ra hình vuông Trong khi cái điểm màu đỏ thì lại tạo ra một cái hình giống hình tam giác, thì hai cái hình này nó không có tương tự nhau, mặc dù hai cái điểm này nó gần nhau Cái thứ hai đó là đối với cái việc mà không chính quy hóa, nó sẽ có thể khiến cho cái điểm của cái không gian ẩn được giải mã nhưng mà không có ý nghĩa Ví dụ như ở đây chúng ta chỉ có hình tam giác, hình tròn, hình vuông, nhưng mà có một cái điểm ở đây là cái điểm mà nó không quá gần ba cái điểm này thì khi chúng ta giải mã nó ra một cái hình gì đấy mà nó không có ý nghĩa Ví dụ như trong cái chữ số viết tay thì khi chúng ta decode ra lẽ ra nó phải ra là số, chữ số thì 0 cho đến 9 nhưng cuối cùng nó sẽ ra một cái gì đấy, nó không phải là con số Tức là một cái dữ liệu không có ý nghĩa, thì nếu như không có chính quy hóa nó sẽ khiến cho chúng ta bị hai cái vấn đề này Ngoài ra thì nhờ có chính quy hóa nó sẽ giúp cho chúng ta giải quyết được cái vấn đề đó, đó là cái tính liên tục của dữ liệu của cái điểm biểu diễn trong không gian ẩn Thì hai cái vector z và z phải nằm trong không gian ẩn mà giống nhau, gần nhau thì khi decode ra nó cũng phải giống nhau Tính chất thứ hai, đó là tính đầy đủ là lấy mẫu từ không gian ẩn thì cái nội dung của mình nó sẽ phải có ý nghĩa, thì đây là một cái ví dụ này không có ý nghĩa Còn nếu như chúng ta sử dụng một cái mô hình chính quy hóa, tức là bên cạnh cái sai số tái tạo nó có thêm cái thành phần chính quy hóa là được biểu diễn bởi cái công thức là d của kl, đó là KL divergence của qi và p Cái này là viết tắt nha, thì các cái điểm gần nhau thì được giải mã tương tự và có ý nghĩa, ví dụ chúng ta thấy cái điểm màu cam và cái điểm màu tím thì hai cái hình này khi chúng ta giải mã thì chúng ta thấy cái dáng dấp nó cũng giống nhau Mặc dù cái điểm màu tím thì nó sẽ hơi bo ở đây một chút, hơi bo tròn, nhưng nếu xét về hình thù thì nó cũng gần giống với hình tam giác, do đó thì hai cái điểm này khi chúng ta dạy nó sẽ có cái tính tương tự nhau và nó hoàn toàn là có ý nghĩa của nó, nó có cái lý do của nó Rồi, thì đây chính là cái sự khác biệt của việc có chính quy hóa và không có chính quy hóa khi chúng ta huấn luyện với cái mô hình VAE Thế thì một cái biểu diễn khác là sau khi chúng ta đã huấn luyện xong mô hình VAE, thì cái phân bố chuẩn tiền nghiệm sẽ đảm bảo được cái yếu tố về tính liên tục và tính đầy đủ Cái tính liên tục nó thể hiện ở chỗ đó là những cái điểm nào mà gần nhau thì khi decode nó sẽ giống nhau và cái tính đầy đủ đó là mọi điểm của mình Trong cái không gian thì khi chúng ta decode ra nó đều có cái ý nghĩa của nó chứ không phải là một cái nội dung vô nghĩa Thì sau đây chúng ta sẽ nói có một cái ví dụ rõ hơn về cái chuyện này Chúng ta thấy ở đây có 3 cái phân bố màu đỏ màu xanh và màu vàng Thì ở đây là cái tâm cụm màu đỏ thì khi chúng ta decode ra nó sẽ ra cái hình tam giác Còn đây là tâm cụm của bồ màu xanh decode ra là ra hình tròn Thế thì một cái điểm ở lưng chừng ngay chính giữa tròn và tam giác thì chúng ta thấy cái hình này nó đều có cái ý nghĩa khá là phù hợp Đúng không? là cái hình này nó sẽ có cái bo tròn giống như cái hình tròn Nhưng đồng thời nó sẽ có cái nét thẳng, 3 cái nét thẳng Giống như tam giác Đó, thì cái điểm trung điểm này nó sẽ giống giống, nó sẽ giúp chúng ta tạo ra cái tính gọi là cái tính liên tục Và đồng thời nó cũng có ý nghĩa, nó cũng có ý nghĩa chứ không phải là không Nếu mà cái ở giữa này mà nó ra một cái điểm nào đó mà chúng ta không thể giải thích được thì đó là không có ý nghĩa Rồi khi chúng ta tiến càng gần hơn về cái tâm thì chúng ta thấy là cái tam giác nó bớt bo tròn đi Đúng không?'), Document(metadata={'filename': 'Ds8mbsbarxs', 'video_url': 'https://youtube.com/watch?v=Ds8mbsbarxs', 'start_timestamp': '0:06:49'}, page_content='Và input của nó chính là cái hidden ở phía trước. Rồi, bây giờ chúng ta sẽ đóng gói cả cái này vào trong cái biến là model. Và chúng ta sẽ trả về cho cell.model. Ở đây thì chúng ta sẽ không cần phải return cái gì ra bên ngoài. Rồi, tương tự như vậy ở đây chúng ta sẽ có optimizer sẽ là bằng tf.keras.optimizer.stochastic gradient descent Với learning rate là bằng 0.1 để train cho nó nhanh. Và ở đây chúng ta sẽ có sử dụng momentum'), Document(metadata={'start_timestamp': '0:15:35', 'chunk_id': 15, 'title': '[CS315 - Chương 3] Deep Generative Models (2) - Part 4', 'end_timestamp': '0:16:16', 'filename': 'NJVpvCzceRk', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk'}, page_content='Thì đây chính là cái thành phần regularization. Rồi, và thành phần cuối cùng, đó chính là cái kỳ vọng này. Rồi, chạy t chạy từ 1 cho đến T lớn. Thì cái ý nghĩa của cái tổng kỳ vọng này đó là cái sự consistency. Là cái consistency, tức là cái sự nhất quán giữa cái kỳ vọng của cái hàm chúng ta denoise, giải mã, chúng ta khử nhiễu. Với lại cái phân bố của q XT, XT từ 1.'), Document(metadata={'filename': 'DSmR6JSwx5I', 'video_url': 'https://youtube.com/watch?v=DSmR6JSwx5I', 'start_timestamp': '0:06:26'}, page_content='Vậy thì với cái đạo hàm này mà bằng 0.25 thì điều gì xảy ra? Với cái công thức đạo hàm của G theo theta y, nó có đến sự xuất hiện của đạo hàm sigmoid đến 10 lần. Tức là ngoài các thành phần kia thì chúng ta sẽ thấy là thành phần đạo hàm sigmoid sẽ bé hơn hoặc bằng 0.25. Vậy là 0.25 là mũ 10. Rồi xong đó nhân với cái thành phần đạo hàm còn lại. Vậy thì bây giờ chúng ta sẽ xem xét cái 0.25 mũ 10 này nếu chúng ta lấy máy tính bấm thì nó sẽ xấp xỉ là bằng 0. Nó là 1 con số rất là bé.'), Document(metadata={'filename': 'CtOfKuiy_uc', 'title': '[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 3)', 'end_timestamp': '0:04:33', 'start_timestamp': '0:04:00', 'chunk_id': 4, 'video_url': 'https://youtube.com/watch?v=CtOfKuiy_uc'}, page_content='Một mẫu random. Cái biến thể tiếp theo đó chính là mini-batch gradient descent hay viết tắt là MGD. Thì chúng ta thay vì truyền vào một mẫu, thì chúng ta sẽ truyền vào một khối hay batch. Cái mẫu huấn luyện. Và cái batch size ở đây, cái kích thước của cái mẫu, kích thước của cái khối là viết tắt của chữ batch size. Đây là kích thước của khối.'), Document(metadata={'filename': 'peYaH97QeEw', 'video_url': 'https://youtube.com/watch?v=peYaH97QeEw', 'start_timestamp': '0:02:23'}, page_content='Ý thứ hai là một điều rất quan trọng, một vector z phải nằm ở gần z trong không gian latent space Khi chúng ta decoder ra thì liệu có gì đảm bảo rằng ảnh mà chúng ta qua decoder phải có tính chất gì đó giống với vector z ở đây không? Tại vì hai vector biểu diễn z và z phải ở trong không gian của mình nằm gần nhau, chúng ta kỳ vọng cái số giải mã ra được là giống như số 3 Chứ không thể nào nếu vector z phải gần z, nhưng nếu chúng ta decode mà nó ra số 7 chẳng hạn Thì đây là điều mà chúng ta không mong muốn. Chúng ta mong muốn là z phải gần z, thì khi decode nó phải ra con số giống với con số z này Thì đó mới đúng là một cái không gian latent. Với autoencoder nó không có đảm bảo được cái chuyện đó Nếu như vector z sau khi tôi đã encode, thì khi tôi decode nó sẽ ra lại đúng ảnh ban đầu Nó thiếu đi một tính chất chắn và tính liên quan trong không gian của mình. Đó là những điểm gần nhau sẽ có cùng một ý nghĩa giống nhau Và đó chính là điểm yếu của autoencoder và variational autoencoder sẽ tìm cách giải quyết cái vấn đề này Đó là thay vì với mỗi một cái ảnh khi chúng ta encode thì cũng có một cái module là encode Đó là trong không gian latent. Tuy nhiên thay vì chúng ta ánh xạ sang một điểm cố định giống như trong autoencoder Thì ở đây cái mà chúng ta sẽ ánh xạ sang đó chính là một distribution, một cái phân bố Thế thì tại sao lại là phân bố mà không phải là một điểm cố định? Tại vì nếu chúng ta ánh xạ sang một điểm cố định Thì nó sẽ dễ khiến cái mô hình của mình là học thuộc cái vị trí, tức là cứ ảnh đó thì vị trí đó, ảnh đó thì vị trí đó Mà nó không có cái tính chất tổng quát.'), Document(metadata={'end_timestamp': '0:06:52', 'title': '[CS315 - Chương 1] Gradient based model - Phần 10 - Part 3 (New)', 'filename': 'm19884tczqs', 'video_url': 'https://youtube.com/watch?v=m19884tczqs', 'start_timestamp': '0:06:27', 'chunk_id': 6}, page_content='Do đó nó sẽ chia cái không gian của mình ra. Chia cái không gian của mình ra. Ví dụ vậy thành 4 phần và với mỗi một cái điểm thì nó sẽ thuộc vào một phần chứ nó không có thuộc vào hai cái phần. Gây ra cái sự nhập nhằng giống như trong cái mô hình logistic regression.'), Document(metadata={'filename': 'yPzXzbEhUW0', 'video_url': 'https://youtube.com/watch?v=yPzXzbEhUW0', 'start_timestamp': '0:03:53'}, page_content='Sau đó thì chúng ta sẽ cấu hình. Ví dụ như ở đây chúng ta sẽ chọn cái đường dẫn ảnh đến cái thư mục hiện tại. Thì cái thư mục hiện tại là, chúng ta xem cái thư mục gì ha? Thì là Content. Do đó cái DataDir chúng ta sẽ để là Content. Rồi, ở hiện giờ thì chưa có hình. Chúng ta sẽ tải các cái hình này về. Thì ở đây tôi có chuẩn bị sẵn 3 cái tấm hình. Ví dụ đây là cháo bún ha.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=HWWlm40wQ-s', 'end_timestamp': '0:08:43', 'chunk_id': 6, 'filename': 'HWWlm40wQ-s', 'title': '[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)', 'start_timestamp': '0:07:53'}, page_content='Nhưng tuy nhiên mặc dù là nó hội tụ chậm nhưng mà bù lại là nó sẽ ưu tiên hội tụ về những điểm cực tiểu tốt hay gọi là generalization minimum do yếu tố ngẫu nhiên. Tại sao lại như vậy? Thì chúng ta tham khảo một cái bài báo về On-Large Batch Training for Deep Learning. Ở đây sẽ xuất hiện hai khái niệm đó là flat minimum và sharp minimum. Flat minimum là chúng ta thấy là đây là một điểm cực tiểu. Tuy nhiên nó sẽ rộng. Cái khu vực này chúng ta thấy là nó sẽ rất rộng.'), Document(metadata={'filename': 'iQqNUKgIZpc', 'video_url': 'https://youtube.com/watch?v=iQqNUKgIZpc', 'start_timestamp': '0:04:33'}, page_content='Thì đây là cái thao tác biến đổi một cách tuần tự. Và chúng ta ký hiệu nó là hx. Thì nếu như chúng ta dùng một cái kiến trúc mạng bình thường như thế này, mà không có cái kết nối tắt, kết nối tắt là gì thì chúng ta sẽ nói trong slide tiếp theo. Nhưng mà với cái kiến trúc thông lệ này, thì khi tác giả của cái bài báo là Deep Residual Learning for Image Recognition, bài này là viết tắt của cái kiến trúc mạng là ResNet, là tác giả Kaming Hair, thì khi chúng ta tăng số layer lên từ 20 lên 32 lên 46 lên 56, thì cái giá trị loss của mình nó lại càng lúc càng cao. Khi mà tăng layer lên thì nó lại đi hội tụ chậm.'), Document(metadata={'chunk_id': 6, 'end_timestamp': '0:10:19', 'filename': 'HKbzvh4rDw0', 'start_timestamp': '0:08:55', 'title': '[CS315 - Chương 2] Xu hướng chung của CNN', 'video_url': 'https://youtube.com/watch?v=HKbzvh4rDw0'}, page_content='Vậy thì CNN thì sao? Với mỗi một cái lát cắt ở đây, với ảnh dữ liệu đầu vào, chúng ta thấy ở đây sẽ có 3 chiều. Trong đó chiều ngang và chiều dọc chính là chiều không gian là width và height. Đây là hai chiều không gian. Còn chiều này sẽ là chiều độ sâu d. Đây chính là chiều của đặc trưng. Rồi, tức là số lượng đặc trưng của mình. Ví dụ trong cái feature map ở đây, thì mỗi một cái lát cắt ở đây nó sẽ là một cái đặc trưng của cái input đầu vào. Trên hình chúng ta thấy là một cái vùng màu đen, thì đây sẽ là một cái feature. Và feature này là của một cái lát cắt đầu tiên. Chúng ta sẽ có rất nhiều những cái lát cắt. Và với mỗi cái lát cắt này, nó sẽ là một cái feature, một cái đặc trưng. Thì nhiều cái đặc trưng chúng ta tổng hợp lại, thì nó sẽ giúp cho chúng ta có cái góc nhìn đa chiều về đối tượng của mình.'), Document(metadata={'filename': '--6FInuIyys', 'video_url': 'https://youtube.com/watch?v=--6FInuIyys', 'start_timestamp': '0:05:27'}, page_content='Thì chúng ta sẽ đi tắt như thế này. Đi tắt đến đến mà không qua các cái bước trung gian. Và cái độ chính xác, cái chất lượng của hình ảnh vẫn rất là tốt, tương đương với những trạng thái ban đầu. Và tương tự như vậy cho cái mô hình consistency là có kết hợp với cả Latent Diffusion. Để mà cho cái chất lượng vừa tốt mà tốc độ vừa nhanh, thì trên đây đó là chúng ta đã tổng kết những cái gì đã học trong phần các mô hình tạo sinh học sâu. Tạm biệt.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=N6F7elExenE', 'filename': 'N6F7elExenE', 'end_timestamp': '0:09:55', 'chunk_id': 7, 'title': '[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 2)', 'start_timestamp': '0:08:47'}, page_content='Đây là phân phối dữ liệu mục tiêu. Và khi chúng ta sampling một cái điểm khác ở phía dưới đây, thì qua cái hàm G chúng ta có hình một cái con chim như thế này. Và nó nằm ở đây. Thế thì khi chúng ta di chuyển từ cái điểm ở trên xuống dưới cái điểm ở dưới, cứ lần lượt với mỗi điểm chúng ta lấy mẫu, thì chúng ta qua cái hàm G thì chúng ta cũng sẽ được các cái mẫu dữ liệu. Và khi chúng ta vẽ các cái mẫu dữ liệu này lên thì chúng ta thấy là có một cái sự dịch chuyển mượt mà từ cái ảnh con ngỗng màu đen sang cái con chim màu cam này. Thì chúng ta từ trái sang phải thì cũng giống như là chúng ta lấy mẫu từ trên xuống dưới với mỗi điểm trong cái không gian latent, chúng ta qua generator, chúng ta tạo ra một tấm ảnh. Thì chúng ta thấy là dần dần cái con ngỗng màu đen này, cái đầu của mình nó hướng về phía bên đây, thì nó dần dần là cái đầu nó sẽ không rõ hướng, rồi sau đó qua đây sẽ là hướng về bên tay trái.'), Document(metadata={'filename': 'Qj6HkeNtIuI', 'video_url': 'https://youtube.com/watch?v=Qj6HkeNtIuI', 'start_timestamp': '0:00:14'}, page_content='Chúng ta sẽ cùng đến với vấn đề đầu tiên mà chúng ta cần phải giải quyết, đó chính là vấn đề về overfitting. Thì overfitting không phải là một vấn đề riêng của lĩnh vực học sâu mà đó là một vấn đề chung của mọi mô hình máy học. Thế thì overfitting là gì, nguyên lý của nó ra sao, nguyên nhân là gì và giải pháp là gì thì chúng ta sẽ cùng tìm hiểu trong phần này. Đầu tiên khi nói về hiện tượng overfitting thì chúng ta sẽ phải nhắc đến cái vấn đề đó là cái mô hình của mình. Nó dự đoán rất là tốt trên tập Train nhưng nó lại rất là tệ trên tập Test. Thì cái này có một số biểu hiện mang tính chất định lượng, ví dụ như là trên tập Train chúng ta huấn luyện xong chúng ta dùng chính tập Train để chúng ta đánh giá, thì cái độ chính xác của mình nó có thể lên đến 80% ví dụ vậy. Nhưng khi chúng ta Test trên tập Dữ liệu Test thì độ chính xác của mình nó rớt xuống rất là đáng kể. Ví dụ nếu mà nó khoảng 75% thì ok là cái mô hình của mình tương đối tốt và nó sẽ không có quá bị hiện tượng Overfitting. Tuy nhiên nếu cái độ chính xác trên tập Test của mình mà chỉ còn có khoảng 60% thì nó đã có một sự giảm đáng kể từ 80% xuống 60%. Vì vậy cái tình huống này đó là hiện tượng Overfitting. Thì đây là một cái ví dụ mang tính chất định lượng để giúp chúng ta hình dung về cái hiện tượng này. Thế thì nếu xét về giải thích thì chúng ta có rất nhiều những cái cách thức để giải thích cho cái hiện tượng Overfitting. Thì đây là một cái mô hình nó rất là phức tạp và dữ liệu không đủ nhiều. Thì đây là một cái cách giải thích cho cái nguyên nhân của hiện tượng Overfitting mà các bạn thấy phổ biến nhất khi chúng ta đọc các tài liệu trên các bài báo khoa học hoặc là trên nguồn internet. Hoặc là một cái cách giải thích khác đó là hiện tượng Overfitting là cái hiện tượng mà mô hình của mình nó sẽ tìm cách để mà học thuộc các mẫu dữ liệu Train thay vì là chúng ta tổng quát hóa lên. Để sao cho sau này khi có một cái dữ liệu mới thì nhờ có tính chất tổng quát hóa này nó có thể dễ dàng xử lý được trên những cái dữ liệu mới.'), Document(metadata={'chunk_id': 4, 'title': '[CS315 - Chương 3] Deep Generative Models (1) - Part 4', 'filename': '-2bJ_8EO9ZE', 'video_url': 'https://youtube.com/watch?v=-2bJ_8EO9ZE', 'end_timestamp': '0:06:35', 'start_timestamp': '0:04:31'}, page_content='Rồi đó, tức là chúng ta sẽ tích từng phần tử. Thì tại sao chúng ta lại dùng element y? Tại vì mi và sigma đó là những cái vector, ví dụ như là vector d chiều. Sigma cũng là một cái vector d chiều. Thì epsilon của mình nó cũng sẽ thuộc một cái vector d chiều. Đó là một cái vector nhiễu d chiều. Trong đó từng cái chiều của sigma, xe gọi từng cái chiều của epsilon, thì sẽ là một cái vector, là một cái giá trị được sampling theo phân bố chuẩn 0,1. Thì khi chúng ta dùng cái công thức này là z bằng mi cộng cho sigma nhân tích từng phần tử với epsilon, thì khi đó expectation của z của chúng ta nó đúng là bằng mi luôn. Và variance của z cũng đúng là bằng sigma. Thì đây chính là cái tính chất mà tái tham số hóa, tức là thay vì chúng ta sử dụng một cái lớp sampling layer là lấy mẫu z theo cái biến, theo cái phân bố Gaussian mi sigma bình, thì chúng ta đi lấy mẫu, đi sampling cái này. Chúng ta sẽ đi sampling epsilon. Còn các giá trị mi và sigma này là cố định, là tất định, được tính toán từ encoder. Thì khi đó là chúng ta sẽ không có bị cái hiện tượng gọi là lan truyền ngược, nó không có đi được.'), Document(metadata={'filename': 'FMhXMbROI-o', 'video_url': 'https://youtube.com/watch?v=FMhXMbROI-o', 'start_timestamp': '0:00:14'}, page_content='Chúng ta sẽ cùng đến với vấn đề thứ 2 khi huấn luyện với một mô hình học sâu đó chính là Vanishing-Gradient. Nếu như cái vấn đề về overfitting hay là quá khớp với dữ liệu thì nó rất tổng quát cho các mô hình máy học. Mọi mô hình máy học đều sẽ gặp những vấn đề về overfitting. Còn vấn đề về Vanishing-Gradient thì thường chỉ dành cho các mô hình học sâu. Vậy thì cơ chế của cái hiện tượng Vanishing-Gradient là gì và làm sao để khắc phục được vấn đề này? Chúng ta sẽ cùng đến trong những phần tiếp theo.'), Document(metadata={'start_timestamp': '0:16:42', 'chunk_id': 10, 'end_timestamp': '0:17:20', 'filename': 'NEK5lIyST0M', 'video_url': 'https://youtube.com/watch?v=NEK5lIyST0M', 'title': '[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 10)'}, page_content='Cái đường như thế này nó sẽ tách ra làm 4 phần thì nó sẽ không có tình trạng 1 điểm thì nó sẽ không thuộc về cái phần nào. Ví dụ như với 1 điểm ở đây thì chúng ta dựa trên cái đường phân biên này chúng ta sẽ biết nó sẽ thuộc về cái lớp xanh lá. Rồi cái điểm ở đây thì nó sẽ thuộc về cái lớp màu vàng. Thì đó chính là hồi quy softmax.'), Document(metadata={'filename': '5Wpw2EsSz40', 'video_url': 'https://youtube.com/watch?v=5Wpw2EsSz40', 'start_timestamp': '0:12:16'}, page_content='Đây là một kỹ thuật rất là nổi tiếng và nó đơn giản. Nó rất là đơn giản. Tại vì nó dễ thực hiện. Nhưng mà cái gì đơn giản thì nó sẽ có cái mặt hạn chế của nó, đó là cái chi phí cao. Cái chi phí nó cao. Nếu chúng ta thu thập bằng tay thì có thể chúng ta sẽ phải tốn cái chi phí để thuê người gán nhãn. Trong hai cái lĩnh vực xử lý hình ảnh và văn bản, chúng ta có hai cái kỹ thuật tăng cường dữ liệu. Một đó là đối với hình ảnh thì chúng ta có thể sử dụng các phép biến đổi. Ví dụ như là thay đổi cái texture, giảm bớt cái texture của đối tượng đi, loại bỏ đi cái yếu tố màu sắc để ra cái ảnh mức xám. Rồi chúng ta tăng cường cái biên cạnh lên.'), Document(metadata={'chunk_id': 9, 'video_url': 'https://youtube.com/watch?v=fiDM76zR6UY', 'title': '[CS315 - Chương 3] Tutorial - GAN', 'end_timestamp': '0:09:38', 'filename': 'fiDM76zR6UY', 'start_timestamp': '0:08:13'}, page_content='Label real thì sẽ có nhãn là 1 và label fake thì sẽ có nhãn là 0. Sau đó thì chúng ta sẽ fix cái noise của mình. Là cái random noise là từ... là 64 và kích thước đó là 100. Epoch là 10. Thì ở đây chúng ta sẽ lần lượt huấn luyện. Step số 1 là chúng ta sẽ đi tối ưu Discriminator trước. Tức là huấn luyện cho bộ phân loại này có khả năng phân loại được ảnh thật và ảnh giả trước. Sau đó chúng ta mới sang Step số 2 để đi huấn luyện cho Generator. Rồi, thì ở đây chúng ta sẽ lấy ra cái Xreel và truyền vào GPU. Rồi sau đó chúng ta sẽ khởi tạo cái optimizer D. Và chúng ta sẽ truyền cái Xreel này vào cái Discriminator. Thì đây chính là cái xác suất. Đây chính là cái xác suất thuộc về lớp Reel. Và lossD của Reel tức là cái giá trị loss cho cái Discriminator. Đối với cái phần dữ liệu Reel là dữ liệu thật thì chúng ta sẽ truyền vào cái giá trị dự đoán và cái nhãn của mình là label Reel. Thì mục tiêu là làm sao cho cái giá trị này là nhỏ nhất.'), Document(metadata={'filename': '-2bJ_8EO9ZE', 'video_url': 'https://youtube.com/watch?v=-2bJ_8EO9ZE', 'start_timestamp': '0:08:07'}, page_content='Nên nó sẽ không ảnh hưởng gì đến cái quá trình huấn luyện của mình. Cái quá trình huấn luyện của mình đó là khi chúng ta tính được cái loss ở phía trên, chúng ta lan truyền xuống, và đến đây thì chúng ta gặp cái z. Và z này thì hoàn toàn là một cái node deterministic, tức là một cái node tất định, tức là không có yếu tố ngẫu nhiên. Nó sẽ được tính từ mi và sigma, được tính toán từ phi và x. Qua cái bước encode, chúng ta sẽ có được một cái cặp mi và sigma cố định. Còn epsilon ở đây là một cái giá trị chúng ta truyền vào z. Thì có cái giá trị này, chúng ta nhân với mi, chúng ta nhân với sigma, và sau đó cộng với mi thì nó sẽ ra một node tương đương. Với cái việc là z của mình tuân theo một cái phân bố là Gaussian.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=_HLKpylxwMw', 'end_timestamp': '0:12:25', 'title': '[CS315 - Chương 0] Giới thiệu môn học (Phần 2)', 'filename': '_HLKpylxwMw', 'chunk_id': 12, 'start_timestamp': '0:11:09'}, page_content='Chuyển không gian. Ví dụ như chúng ta có một cái không gian là như thế này. Và một cái điểm trong cái không gian thì khi chúng ta chiếu xuống dưới một cái mặt phẳng nào đó, ví dụ vậy. Rồi, thì khi chúng ta chiếu xuống, để đại diện cho cái mặt phẳng này, đại diện cho cái mặt phẳng này, mặt phẳng P đi, thì nó sẽ có cái tham số và tham số đó chính là cái ma trận A của mình. Và khi chiếu, khi chiếu xuống cái không gian của A thì chúng ta sẽ chuyển từ một cái vector là 3 chiều, Ví dụ vậy, thuộc R3, chuyển xuống một cái không gian 2 chiều thì lúc đó là chúng ta chỉ còn là một cái điểm kích sởi, nhưng mà nằm trong cái không gian chỉ có 2 chiều, chứ không gian mặt phẳng. Ở đây là một cái phép chiếu từ một cái không gian lớn chiều là 3 chiều xuống một cái không gian mặt phẳng là 2 chiều. Và ngược lại, chúng ta cũng sẽ có cái phép chiếu từ không gian thấp chiều lên không gian cao chiều.'), Document(metadata={'filename': 'iQqNUKgIZpc', 'video_url': 'https://youtube.com/watch?v=iQqNUKgIZpc', 'start_timestamp': '0:01:39'}, page_content='Hoặc là có thể lúc nó sẽ là số rất bé nhưng mà cũng có thể là số lớn, nó sẽ phải dao động xung quanh con số một. Còn với hàm sigmoid thì cho dù là hàm kích hoạt có đạo hàm nhỏ, cho dù là hàm của mình nó có kiến trúc gì đi chăng nữa, thì sigmoid của x luôn luôn là con số bé hơn một. Trong khi đó chúng ta không có dùng cái hàm này, không dùng hàm sigmoid nữa, mà chúng ta dùng hàm relu. Thì đạo hàm của hàm relu này thì nó sẽ là bằng 0. Nếu z bé hơn 0 và bằng 1 nếu z lớn hơn 0, thì cái việc này nó sẽ giúp chúng ta cân bằng. Và chúng ta lưu ý đó là không phải lúc nào z khi chúng ta gọi hàm activation function, thì cái giá trị chúng ta truyền vô là đều bé hơn 0, nó sẽ có lúc bé hơn 0, có lúc lớn hơn 0, do đó nó tạo ra sự hài hòa và sự cân bằng cho mình. Đó là cái biểu hiện của tính cân bằng, là thể hiện cho đó.'), Document(metadata={'chunk_id': 4, 'video_url': 'https://youtube.com/watch?v=NqnUZDkYvM0', 'title': '[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 11)', 'filename': 'NqnUZDkYvM0', 'start_timestamp': '0:04:17', 'end_timestamp': '0:04:59'}, page_content='Làm 2 phần. Đó là cái vùng màu tam giác và hình tròn. Thì đây chính là cái ý tưởng tại sao một cái mạng Neural Network có thể giải quyết được một cái bài toán phi tuyến tính. Là nhờ các cái đặc trưng, các cái bộ phân lớp yếu ở các lớp đầu tiên tổ hợp lại với nhau để tạo ra các cái đặc trưng cấp giữa, tức là đặc trưng cấp vừa.'), Document(metadata={'filename': 'FMhXMbROI-o', 'video_url': 'https://youtube.com/watch?v=FMhXMbROI-o', 'start_timestamp': '0:09:35'}, page_content='Do đó thì các cái tham số càng xa thì nó càng dễ bị tiêu biến. Và thế thì nếu mà cái đạo hàm của G theo thetaG mà nó tiêu biến, tức là nó sẽ tiến về 0, thì vấn đề gì xảy ra? Chúng ta phải quay trở lại cái công thức cập nhật tham số của thuật toán Gradient Descent, đó là thetaG, thì sẽ là bằng thetaG trừ cho alpha nhân cho đạo hàm của G theo thetaG. Vì cái đại lượng mà đạo hàm ở đây xấp xỉ 0 nên alpha nhân với nó sẽ xấp xỉ 0, alpha là một con số còn nhỏ hơn 1 nữa, nó có thể là 0.001 nữa, và càng nhỏ hơn. Thế thì cái con số này sẽ càng tiến về 0, thế thì thetaI bằng thetaI trừ 0, tức là xấp xỉ với lại con số thetaI hay nói cái khác thetaI không cập nhật, tức là gần như không cập nhật. Thì nó giải thích cho cái hiện tượng đó là hội tụ chậm, tại vì nó không có cập nhật tham số thì lấy đâu mà nó hội tụ?'), Document(metadata={'chunk_id': 1, 'end_timestamp': '0:17:32', 'title': '[CS315 - Chương 1] Gradient based model - Phần 1 (New)', 'start_timestamp': '0:07:45', 'filename': 'QZrUqMbEY8Q', 'video_url': 'https://youtube.com/watch?v=QZrUqMbEY8Q'}, page_content='Thì lỗi mà nhỏ nhất là cái dự đoán càng chính xác Tiếp theo thì chúng ta sẽ cùng so sánh với các cái mô hình khác, thì một số mô hình mà không có dựa trên Gradient, ví dụ như chúng ta có K-Nearest Neighbor Mặc dù đây là một cái thuật toán máy học nhưng mà nó không thực sự là huấn luyện và bản chất của nó chỉ là truy vấn để tìm ra k cái láng giềng gần nhất Và sau đó sẽ dựa trên nhãn của k cái láng giềng đó để từ đó nó dùng cái cơ chế đó gọi là voting để mà lấy ra những cái tập nhãn mà có xuất hiện nhiều nhất để từ đó gắn cái nhãn nhiều nhất đó vào cho cái đặc trưng của mình Thì đây chính là cái ý tưởng của K-Nearest Neighbor. Hướng tiếp cận thứ 2 đó chính là Naive Bayes, thì đây là dựa trên các cái mô hình xác suất mà cụ thể đó là chúng ta dựa trên công thức xác suất có điều kiện như là công thức Bayes Thì ước lượng cái phương pháp này thì nó sẽ ước lượng các cái tham số một cách tường minh Cách tiếp cận thứ 3 đó chính là Decision Tree với các thuật toán ví dụ như là CART, ID3, C4.5 thì nó dựa trên luật để phân chia thành các cái nhánh quyết định Ví dụ như ở đây chúng ta sẽ có một cái node, nó sẽ chia ra làm 2, 2 nhánh ví dụ vậy rồi sau đó chúng ta lại tiếp tục có những cái luật, nó sẽ có những cái luật lại tiếp tục chia xuống Ví dụ như ở trên đây, cái luật của mình sẽ là trời có mây hay không, thì nếu có thì nó sẽ tiếp tục hỏi là cái độ ẩm của mình là cao hay thấp Nếu mà độ ẩm cao thì nó sẽ kết luận là mưa, ví dụ vậy, thì đây là một cái mô hình khá là hiệu quả và dễ hiểu Và mở rộng cho cái mô hình Decision Tree đó chính là Random Forest thì như cái tên gọi của mình, Random Forest nó sẽ kết hợp nhiều cái cây thành phần Ví dụ như ở đây chúng ta có một cây thì Random Forest có thể kết hợp thêm nhiều cái cây khác để có thể tạo ra thành một cái khu rừng Và Random Forest là một trong những thuật toán, một cái mô hình mà có thể chống được cái Overfitting và có cái tính tổng quát khá là cao để chúng ta chọn được cái tham số phù hợp Thế thì cả 4 cái mô hình này đều là nằm trong cái nhóm đó là học có giám sát Và thuật toán không giám sát thì chúng ta sẽ có các thuật toán liên quan đến cái Clustering Ví dụ như là có K-Means, DBscan, Hierarchical Clustering, thì ý tưởng của các thuật toán này cũng là những thuật toán lặp việc cập nhật tâm cụm Tức là chúng ta sẽ lặp đi lặp lại việc cập nhật tâm cụm Và khác biệt so với các mô hình dựa trên Gradient đó là chúng ta không tính cái Vector đạo hàm, không dựa trên Gradient Và trong cái bảng sau thì chúng ta sẽ so sánh các mô hình trên các khía cạnh khác nhau Khía cạnh đầu tiên đó là cái cơ chế để tối ưu hóa mô hình của mình Thì các thuật toán dựa trên Gradient thì đều dựa trên thuật toán Gradient Ascent Và các biến thể của nó, ví dụ như Stochastic Gradient Ascent, Adam, Root Mean Square Propagation thì đây đều là những cái thuật toán tối ưu hóa Và các mô hình dựa trên Gradient thì đều dựa trên các thuật toán này Trong khi đó các mô hình không dựa trên Gradient, thì cơ chế để tối ưu hóa dựa trên một công thức tường minh hoặc dựa trên các chiến thuật tham lam, heuristic, ví dụ như là Naive Bayes, Decision Tree, K-Nearest Neighbor Xét trên khía cạnh về khả năng diễn giải mô hình thì các mô hình dựa trên Gradient thì thường có tính diễn giải khá là thấp hay một cái cách gọi khác đó là thường có dạng Black Box, hộp đen thì khả năng diễn giải của mình là sẽ thấp Tuy nhiên các nghiên cứu gần đây thì họ cũng đã tìm cách trực quan hóa mô hình dựa trên Gradient nó vận hành như thế nào, rồi giải thích cơ chế của nó để làm sao cho mô hình có thể tối ưu hóa được việc mà dự đoán thì các nghiên cứu đó gần đây cũng được chú tâm rất nhiều Trong khi đó thì mô hình không dựa trên Gradient thì nó có tính giải thích dễ dàng hơn và đặc biệt là những mô hình như là Decision Tree, Random Forest chúng ta nhìn vô cái cấu trúc cây thôi là chúng ta có thể hiểu được mô hình vận hành như thế nào Xét trên cái hiệu quả của các tác vụ phức tạp thì thuật toán các mô hình dựa trên Gradient thì nó sẽ cho kết quả rất tốt trên những lĩnh vực như là thị giác máy tính hoặc là xử lý ngôn ngữ tự nhiên trong đó là trên những dữ liệu là Unstructured Data ví dụ như là dữ liệu hình ảnh, dữ liệu văn bản, rồi dữ liệu âm thanh và thì đây là những dữ liệu mô hình dựa trên Gradient làm việc rất tốt trong khi đó mô hình không dựa trên Gradient thì thường tốt trên dữ liệu bảng và có quy mô nhỏ ví dụ như là dữ liệu bảng thì nó bao gồm các cột ABC và từng cái cột này thì nó sẽ có kiểu dữ liệu cố định và ý nghĩa của nó là cố định các mô hình không dựa trên Gradient thì làm việc rất tốt trên dữ liệu này đó là những dữ liệu Structured Data và cuối cùng đó là xét trên khía cạnh chi phí huấn luyện các mô hình dựa trên Gradient thì thường có chi phí huấn luyện rất cao do nó cần rất nhiều tài nguyên tính toán, bộ nhớ, GPU, TPU do các mô hình dựa trên Gradient có số lượng tham số rất lớn ngược lại thì chi phí huấn luyện của các mô hình không dựa trên Gradient thì ít tốn kém hơn như vậy chúng ta đã lượt qua những khía cạnh và chúng ta thấy mô hình dựa trên Gradient nó có những điểm yếu cố hữu ví dụ như là mô hình của mình khả năng diễn giải sẽ thấp hơn so với những mô hình như là Decision Tree và chi phí huấn luyện của nó sẽ cao hơn tuy nhiên gần đây thì tại sao mô hình dựa trên Gradient lại càng trở nên phổ biến nó có nhiều lý do, lý do đầu tiên đó là dưới sự phát triển của các mạng xã hội thì các dữ liệu của mình sẽ ngày càng phong phú hơn và được lưu trữ công khai thì ở giai đoạn đầu, ví dụ như là vào những năm 2010, thì cái quy mô dữ liệu của chúng ta đâu đó chỉ khoảng là 1-2 triệu ảnh nhưng mà sau đó đến vào những năm 2020, cụ thể đó là công ty OpenAI được đầu tư thì họ xây dựng những mô hình ví dụ như mô hình clip được huấn luyện trên tập dữ liệu rất lớn lên đến hàng trăm triệu mẫu dữ liệu và gần đây hơn nữa thì vào những năm 2020, thì có tập dữ liệu LAION lên đến 5 tỷ ảnh thì có thể nói là để huấn luyện được trên những quy mô dữ liệu lên hàng tỷ ảnh thì chỉ có thể có tập đoàn công nghệ lớn họ mới có thể làm được mà thôi và một trong những lý do nữa để khiến mô hình dựa trên Gradient càng trở nên phổ biến đó là tài nguyên của mình tài nguyên cụ thể là tài nguyên tính toán, nó ngày càng mạnh và đồng thời nó sẽ ngày càng rẻ thì nói về phần cứng thì nó sẽ càng càng rẻ và nhờ có tài nguyên tính toán sắp sau này, nó sẽ giúp chúng ta huấn luyện các mô hình nhanh chóng hơn cuối cùng đó là sự hoàn thiện của các mô hình chúng ta thấy đó là trước đây thì chúng ta có cái mạng Neural Network thì nó không có hiệu quả trong việc huấn luyện với các dữ liệu lớn và các bài toán phức tạp nhưng mà gần đây thì chúng ta thấy là có cái kiến trúc như là CNN, RNN, Convolutional Neural Network, Recurrent Neural Network và gần đây nhất chính là Transformer, đó là những cái kiến trúc đã hoàn thiện hơn giúp chúng ta có thể hấp thụ được lượng dữ liệu tốt hơn và có thể khai thác được hiệu quả tài nguyên của GPU do đó thì các mô hình dựa trên Gradient đang ngày càng trở nên phổ biến và không chỉ như vậy mà các thành tựu mới nhất của trí tuệ nhân tạo gần đây ví dụ như là ChatGPT, Gemini, chúng ta thấy đó là đều có kiến trúc dựa trên Transformer và cái kiến trúc dựa trên Transformer này, đó là dựa trên, đã đều được huấn luyện dựa trên thuật toán, đó là Gradient Descent thì đây chính là một cái ví dụ minh chứng cho cái thành tựu của các mô hình dựa trên Gradient Cảm ơn các bạn đã xem video hấp dẫn'), Document(metadata={'filename': '2NThga7SQ-I', 'video_url': 'https://youtube.com/watch?v=2NThga7SQ-I', 'start_timestamp': '0:05:36'}, page_content='Và tất cả các phần tử còn lại sẽ để là số 0. Và tương tự như vậy cho số 2 đi, thì nó sẽ bật lên là 0, ở đây là 0, ở đây là 0 và nó sẽ bật lên ở đây. Và tất cả các phần tử còn lại sẽ để là số 0. Thì đây là cái dạng One Hot Encoding. Rồi bước tiếp theo, đó là chúng ta sẽ tiến hành cài đặt cái thuật toán huấn luyện hay cụ thể đó là cài đặt cái mô hình. Thì cái mạng CNN, ở đây chúng ta sẽ có các phương thức như là Build, Train, Constructor, Load, Get Weights. Ở đây có các phương thức Get Weights là chúng ta sẽ chưa cài đặt, chúng ta sẽ cài đặt để đưa lên Train song hành cùng với lại hàm Train để kẻo chúng ta quên. Xin lỗi, chúng ta sẽ đưa lên Train ngang với lại phương thức là Build để không một chút nữa chúng ta sẽ quên. Cái quá trình Train của mạng CNN rất là lâu, nếu mà chúng ta quên thực hiện cái gì đấy và chúng ta thực hiện lại thì nó sẽ tốn thời gian rất là nhiều. Thì ở đây chúng ta sẽ phải cho cái model nó biết đó là Input Dimension. Rồi, đồng thời là các cấu hình, ví dụ như số lượng filter là 6, số lượng filter là 16, rồi số các output của các lớp Fully Connected là 120, 84. Thì chúng ta sẽ phải tham số hóa 4 cái bộ số này.'), Document(metadata={'start_timestamp': '0:00:14', 'end_timestamp': '0:01:01', 'chunk_id': 0, 'title': '[CS315 - Chương 2] Xu hướng chung của CNN', 'video_url': 'https://youtube.com/watch?v=HKbzvh4rDw0', 'filename': 'HKbzvh4rDw0'}, page_content='Chúng ta sẽ cùng vận dụng những lý thuyết về balancing gradient và overfitting đã được tìm hiểu ở những phần trước để lý giải cho sự tiến hóa của các mạng CNN. Các mạng CNN ở đây sẽ được khảo sát từ giai đoạn mới bắt đầu có ý tưởng của mạng CNN cho đến những mạng CNN hiện đại hơn. Đầu tiên đó chính là mô hình Logistic Regression hay là một cái Perceptron đơn giản. Ở đây chúng ta thấy mạng của chúng ta chỉ có duy nhất một node, duy nhất một neuron. Và ý nghĩa của mô hình này là nó sẽ phân chia không gian đặc trưng ra, làm thành một mặt phẳng.'), Document(metadata={'filename': 'HWWlm40wQ-s', 'video_url': 'https://youtube.com/watch?v=HWWlm40wQ-s', 'start_timestamp': '0:01:33'}, page_content='Thì những cái chướng ngại đó là gì và tại sao những cái điểm đó nó lại gây ra cái việc huấn luyện khó khăn, thì chúng ta sẽ cùng lấy một số ví dụ. Cái chướng ngại đầu tiên đó là những cái điểm cực tiểu cục bộ hay còn gọi là local minimum. Vì vậy, giả sử như chúng ta bắt đầu tại cái điểm ở đây, thì trong cái quá trình di chuyển, nếu như hoàn hảo, thì chúng ta sẽ đạt được cái điểm này, đó là cái điểm global minimum. Nhưng mà thực tế thì không phải vậy. Nó hoàn toàn có khả năng là trong quá trình di chuyển, nó có thể rớt vào một cái điểm ở cái điểm ở đây, tức là tương ứng ở đây. Vì đây chính là một cái điểm local minimum. Và khi chúng ta rớt vào cái điểm ở đây, thì nó sẽ bị bắt kẹt và nó sẽ không thoát ra được, để mà có thể đến được cái điểm tối ưu toàn cục. Cái tình huống thứ hai đó là cái điểm yên ngựa. Thì điểm yên ngựa là những cái điểm đặc biệt. Lấy ví dụ ở đây. Điểm yên ngựa thì nó sẽ có cái đạo hàm bằng không tại cái vị trí đó, và nó sẽ đạo hàm bằng không tại nhiều hướng. Ví dụ như là theo cái hướng này, chúng ta thấy là nó đi xuống rồi đi lên, thì tại cái vị trí này là đạo hàm bằng không.'), Document(metadata={'filename': 'NJVpvCzceRk', 'chunk_id': 10, 'title': '[CS315 - Chương 3] Deep Generative Models (2) - Part 4', 'end_timestamp': '0:12:37', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'start_timestamp': '0:11:16'}, page_content='Hay chúng ta biết gọi là triển khai. Đó là bằng epsilon của căn của cái vế bên tay trái là alpha 2 trừ cho alpha 1 alpha 2. Rồi cộng cho 1 trừ cho alpha 2. Thì đây là một cái công thức mà khá là kinh điển của cái việc mà chúng ta cộng 2 cái biến ngẫu nhiên theo phân bố chuẩn. Thế thì trừ alpha 2 cộng alpha 2 là mất do đó thì chúng ta sẽ còn là 1 trừ alpha 1 alpha 2 epsilon. Và một cách tương tự thì cái xt bất kỳ nó sẽ được tính dưới từ cái x0 và một cái biến epsilon theo phân bố chuẩn. Và công thức của nó sẽ là như đây. Thế thì alpha ở đây sẽ là alpha gạch ngang trên đầu. Đó công thức của cái alpha t gạch ngang trên đầu. Nếu mà viết triển khai ra thì alpha gạch ngang t sẽ bằng alpha 1 alpha 2... cho đến alpha t. Và epsilon ở đây thì vẫn là một cái biến ngẫu nhiên theo phân bố chuẩn. Thì cái công thức này chúng ta thấy khá là gọn.'), Document(metadata={'start_timestamp': '0:14:40', 'title': '[CS315 - Chương 3] Deep Generative Models (1) - Part 1', 'video_url': 'https://youtube.com/watch?v=hrxNKadDpw4', 'filename': 'hrxNKadDpw4', 'chunk_id': 15, 'end_timestamp': '0:15:14'}, page_content='Thì ở đây chúng ta sẽ dẫn nhập, giải thích cái ý này. Các cái mô hình của mình khi được huấn luyện thì lấy dữ liệu ở trong thực tế mà dữ liệu chúng ta sampling trong thực tế thì 95% Chúng ta lấy một cái ví dụ đó là dữ liệu mà lái xe trên đường. 95% dữ liệu mà chúng ta lái xe, tức là nó nằm ở trong cái khu vực này. Là trong cái khu vực này.'), Document(metadata={'start_timestamp': '0:14:38', 'end_timestamp': '0:15:06', 'filename': 'HWWlm40wQ-s', 'chunk_id': 10, 'video_url': 'https://youtube.com/watch?v=HWWlm40wQ-s', 'title': '[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 4)'}, page_content='Thì ở đây đó chính là cái hiện tượng có cái độ dốc bất thường. Ở đây chúng ta thấy là có cái độ dốc đi xuống nè, nhưng ngay lập tức nó lại đi lên. Ngay lập tức nó lại đi lên thì đó chính là cái sự bất thường. Thì những cái, đây chính là những cái vùng mà có cái sự thay đổi lớn về độ dốc theo các cái chiều, theo các cái chiều.'), Document(metadata={'chunk_id': 17, 'video_url': 'https://youtube.com/watch?v=-7JWQptLoMQ', 'start_timestamp': '0:19:31', 'title': '[CS315 - Chương 2] Sự tiến hóa của các mô hình chuỗi (Phần 1)', 'end_timestamp': '0:20:56', 'filename': '-7JWQptLoMQ'}, page_content='Còn chưa có nhiều tài liệu nói là khi chúng ta dùng thêm nhiều hơn nữa, ví dụ như là hàng chục hoặc hàng trăm lớp. Thường là từ 2 cho đến 4 lớp. Riêng trong Transformer thì có thể là với dữ liệu phức tạp hơn, bài toán thách thức hơn, thì có thể là số lớp của mình sẽ cao hơn. Thế thì chúng ta đã học về Bi-directional và DeepStack, do đó chúng ta cũng sẽ có một hỗn hợp của hai biến thể này. Đó là vừa Bi-directional, tức là đi theo chiều từ trái sang phải, nhưng đồng thời cũng sẽ có chiều đi từ phải sang trái, thông qua dấu mũi tên nét đứt này. Và nó sẽ stack lên nhiều tầng, thì đây sẽ là layer 1, đây là layer 2 và đây là layer 3. Nó sẽ kết hợp vừa 2 chiều và vừa DeepStack để tận dụng được thế mạnh của từng cái biến thể của mình. Đó là thứ nhất, đọc được nhiều chiều, cái thứ 2, đặc trưng của mình sẽ phân cấp tốt hơn, có nhiều thông tin hơn. Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn.'), Document(metadata={'end_timestamp': '0:17:35', 'chunk_id': 1, 'start_timestamp': '0:07:45', 'video_url': 'https://youtube.com/watch?v=0PqzYo2Z-20', 'filename': '0PqzYo2Z-20', 'title': '[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 8)'}, page_content='Chúng ta sẽ còn lại là dfn-dx, tức là đạo hàm của f theo x Thì đây là một cái quy tắc để nhớ thôi Đó là dfn-1, sau đó là n-1, n-2, n-2, n-3, rồi v.v.v cho đến f2 theo f1 và f1 theo x Thì x sẽ là cái biến số của mình, nó sẽ nằm ở cuối cùng ở đây Thì chúng ta sẽ xét một cái ví dụ cho đơn giản và trực quan Ví dụ như fx, iz là bằng x cộng i, tất cả nhân với z Thì ở đây giả sử như chúng ta xem xét là, chúng ta tại một thời điểm thì chúng ta chỉ xét với một biến x Tức là tất cả những cái hàm ở trên đây sẽ được đưa về cái hàm chỉ có một biến thôi Thì đặt cái công việc đầu tiên chúng ta phải tính toán, đó là cái việc tính x cộng i Đây là cái thao tác đầu tiên chúng ta tính, thì đây sẽ là biểu diễn bởi hàm f1 Sau khi chúng ta tính cái f1 là x cộng i xong, thì chúng ta sẽ lại nhân với z, thì đây sẽ là hàm f2 Nhưng ở đây chúng ta sẽ xét trên một biến x trước, thì f1x sẽ là bằng x cộng i Sau đó chúng ta lại lấy f1 nhân với z để ra f2 Như vậy công thức của f2 mà theo cái biến x thì nó sẽ là bằng f1 nhân với z Nhưng mà trong trường hợp này, f1 của chúng ta chính là cái biến số của mình Thì khi đó, fx của mình, cái công thức fx ban đầu của mình sẽ là bằng f2 của f1x Khi chúng ta thế vào, thì f2 chính là z nhân x Do đó, f2 của f1x sẽ là bằng z nhân cho xx, trong trường hợp này chính là f1 F1 chúng ta sẽ thế vào bằng công thức này, đó là x cộng i Rồi, khi đó thì đạo hàm của f1 theo x, lưu ý là ở đây chúng ta chỉ đang xét với một biến x thôi Chúng ta sẽ làm cái việc tương tự, cái việc này tương tự cho biến i, chúng ta sẽ làm sao Đạo hàm của f1 theo x, thì đạo hàm của f1 theo x chính là trong công mắc của x, thì i chính là hằng số Do đó đạo hàm của f1 theo x chính là 1 Rồi, đạo hàm của f2 theo f1 là bao nhiêu? Đạo hàm của f2 theo f1, tức là chúng ta sẽ tính đạo hàm của cái này theo x Chúng ta sẽ tính đạo hàm của cái này theo x, thì trong biến x, thì z chính là hằng số do đó đạo hàm của cái này sẽ là bằng z Đạo hàm của f2 theo f1 chính là z Rồi, như vậy thì chúng ta sẽ sử dụng, áp dụng cái công thức chain rule là d của f theo x sẽ là bằng df2 theo f1 Sau đó df1 theo x, thì df2 theo f1 chính là z, nguyên cái cọp này sẽ là z Và df1 theo x chính là 1 Như vậy z nhân 1 chính là bằng z, như vậy đạo hàm của f theo x sẽ là bằng z Hoàn toàn tương tự cho i và z, chúng ta sẽ làm cái công việc này cho đạo hàm của f theo i và đạo hàm của f theo z Thì đối với biến i Vì chúng ta có nhiều biến nên tại một thời điểm chúng ta chỉ xem xét một biến thôi Thì công việc đầu tiên chúng ta sẽ tính toán, đó là phép cộng ở đây Thì f1 của ta, bây giờ nó không phải là biến x nữa mà sẽ là biến theo i, thì nó vẫn sẽ là bằng x cộng i Và f2 của mình theo biến i thì nó cũng sẽ là bằng giá trị f1 nhân với z Và f1 theo nhân với z như vậy sẽ là z nhân với i Tại vì trong trường hợp này f1 của mình sẽ là biến số, f1 của mình sẽ là biến số Như vậy thì f2 i là bằng z i Và khi đó thì công thức f của i sẽ là bằng f2 của f1 của i Thì x cộng i là x cộng i Rồi, f2 của f1 là z nhân với i Thay là z nhân với lại cái f1 này Mà f1 của mình là x cộng i Tức là khi chúng ta triển khai ở đây thì f1 i chính là chúng ta xem nó như là một cái biến Rồi chúng ta triển khai vô thì nó sẽ là z nhân với lại cái biến Tức là z nhân với f1, mà f1 thì nó lại là bằng x cộng i Rồi, khi đó chúng ta sẽ tính đạo hàm Đạo hàm là d của f1 theo i D của f1 theo i thì nó sẽ là bằng 1 Tại trong có mắt của i thì x là bằng hằng số D của f2 theo f1 Tức là đạo hàm của công thức này Và đạo hàm của công thức này là bằng z Rồi, như vậy thì chúng ta sẽ có đạo hàm của f theo biến i Chính là bằng đạo hàm của f2 theo f1 Nhân cho đạo hàm của f1 theo i Vì f2 theo f1 chính là bằng z Và df1 theo i chính là bằng 1, không bằng z Tương tự như vậy chúng ta sẽ tính cho đạo hàm của f theo z Thì chúng ta thấy là cái cách làm này, Chain Rule này thì nó sẽ rất là bài bảng và có thể tổng quát hóa được Và bây giờ chúng ta sẽ tìm cách biểu diễn cái công thức của cái fx, iz này dưới dạng là biểu đồ, đồ thị tính toán Như sau, đầu vào chúng ta sẽ có x, y và z Bước đầu tiên chúng ta sẽ thực hiện là lấy x, y, đây là toán tử cộng Và đầu ra của mình sẽ là hàm f1 Sau đó chúng ta lấy cái z này đem nhân với cái f1 để ra cái f2, thì đây chính là cái hàm f của mình Rồi, thì đây là cái cách biểu diễn dưới dạng đồ thị tính toán Trong đó mỗi một cái node tính toán sẽ là một toán tử và đầu vào nó sẽ nhận các cái biến số Thế thì chúng ta sẽ đến với một trong những thuật toán đầu tiên, đó chính là thuật toán Feed Forward Tức là trước khi thực hiện Backpropagation, Backpropagation là lan truyền nghịch Thì chúng ta sẽ phải làm cái thuật toán lan truyền thuận, tức là chúng ta sẽ đi tính cái giá trị của hàm f trước Dựa trên cái đồ thị tính toán, thì giả sử ở đây chúng ta vẫn sử dụng các cái hàm như đã nêu ở trên Thì x, x nó sẽ là bằng f2 của f1, x thì đầu tiên ta sẽ xây dựng cái đồ thị tính toán Rồi sau đó chúng ta sẽ tính giá trị tại các cái node, biết rằng là chúng ta sẽ chọn ra một cái bộ giá trị x, y, z khởi tạo ban đầu Đây chính là cái giá trị khởi tạo Và chúng ta sẽ đi tính đạo hàm tại cái giá trị x bằng 3, y bằng trừ 4 và z bằng 5 Đầu tiên đó là chúng ta sẽ xây dựng cái đồ thị tính toán, giống như ở trong slide trước, thì đây chính là đồ thị tính toán Và chúng ta sẽ có các cái node là node cộng, rồi node nhân Sau đó chúng ta sẽ lần lượt thay các cái giá trị này vào các cái node, thì x là bằng 3, y là bằng trừ 4 và z là bằng 5 Sau đó chúng ta cứ lần lượt lan truyền thuận lên, lan truyền thuận về phía trước Đầu tiên đó là thực hiện phép cộng, thì f1 bước này nó sẽ là bằng 3 cộng cho trừ 4, thì nó sẽ là bằng trừ 1 Sau khi chúng ta đã tính f1 xong, thì chúng ta sẽ thực hiện cái node phép nhân Thì f2 nó sẽ là bằng f1 nhân với trừ 5, tức là f1 nhân với 5, tức là bằng trừ 1 nhân với 5 là bằng trừ 5 Như vậy thì cái thuật toán lan truyền thuận đó là một cái thuật toán quan trọng để giúp chúng ta xây dựng cái đồ thị tính toán Cái bước quan trọng đầu tiên đó là xây dựng được cái đồ thị tính toán Là một cái bước tiền đề quan trọng trước khi chúng ta có thể tính được cái đạo hàm của hàm f theo các cái biến x này, các cái biến x, x, y, z này'), Document(metadata={'chunk_id': 3, 'filename': 'hrxNKadDpw4', 'end_timestamp': '0:06:22', 'start_timestamp': '0:03:12', 'video_url': 'https://youtube.com/watch?v=hrxNKadDpw4', 'title': '[CS315 - Chương 3] Deep Generative Models (1) - Part 1'}, page_content='Chúng ta có thể dùng trong lĩnh vực về phân loại một cái đối tượng nào đó, bài toán hồi quy, dự đoán một cái giá trị có tính thứ tự nào đó. Rồi phát hiện đối tượng, phân đoạn ngữ nghĩa đối tượng v.v. thì học có giám sát nó đã đạt được những thành tựu hiện nay và có thể ứng dụng được rất là rộng rãi. Thế thì còn một cái mảng nữa đó chính là học không có giám sát. Thì học không có giám sát đó là dữ liệu đầu vào chúng ta sẽ không có y mà chúng ta chỉ có duy nhất một biến x đầu vào. Chúng ta không có nhãn, thì đây chính là sự khác biệt lớn nhất giữa học không giám sát và học có giám sát. Mục tiêu của học không giám sát đó là chúng ta sẽ học từ cái cấu trúc ẩn của dữ liệu, hay là chúng ta sẽ đi học cái phân bố của dữ liệu. Phân bố của dữ liệu. Rồi, thì mình có thể lấy một cái ví dụ như sau để chúng ta hiểu thế nào là chúng ta đi học một cái cấu trúc ẩn và học một cái phân bố dữ liệu. Bằng cách đó là chúng ta sẽ trả lời cho cái câu hỏi sau. Một bạn học sinh có điểm trung bình là ví dụ như là 8,8 điểm. Thì theo các bạn đó là bạn này sẽ có cái học lực là giỏi, khá xuất sắc hay là dưới trung bình. Thì đa số đó là chúng ta sẽ không biết được cái điểm này là cao hay thấp khi chúng ta không đặt nó ở trong cái phân bố của những cái bạn còn lại trong lớp. Thì nếu như cái điểm của lớp mình mà có cái phân bố như sau, điểm 8,8 thì nằm ở cái khu vực này. Ví dụ như điểm 8,8 là nằm ở khu vực này. Thì bạn này là một bạn có học lực giỏi tại vì nhìn trong cái phân bố này bạn nằm ở cái top mà những người có điểm cao. Nhưng ngược lại nếu trong một cái phân bố khác, điểm 8,8 của bạn nó lại nằm ở đây. 8,8 thì khi đó là với cái phân bố này thì điểm của bạn là có học lực dưới trung bình. Như vậy để kết luận được tính chất của dữ liệu x thì chúng ta phải học được cái phân bố. Vì vậy, trong cái phân bố chúng ta sẽ xác định được cái phân bố của dữ liệu và từ đó chúng ta hình thành được cái cấu trúc ẩn của dữ liệu. Ví dụ chúng ta chia cái không gian của mình ra làm 3 phần. Ví dụ vậy thì đây là những cái bạn mà có học lực kém. Đây là những bạn có học lực trung bình và đây là những bạn có học lực giỏi. Ví dụ vậy thì đây là chúng ta đang cấu trúc hóa cái không gian ẩn của mình. Và những cái bài toán mà kinh điển liên quan đến cái học không giám sát đó chính là bài toán phân cụm, bài toán giảm chiều dữ liệu. Thì đó là chúng ta đã cùng ôn lại một vài cái khái niệm về học có giám sát và học không có giám sát.'), Document(metadata={'end_timestamp': '0:13:56', 'filename': '5Wpw2EsSz40', 'video_url': 'https://youtube.com/watch?v=5Wpw2EsSz40', 'title': '[CS315 - Chương 2] Overfitting (Phần 2)', 'chunk_id': 9, 'start_timestamp': '0:12:59'}, page_content='Hoặc là chúng ta lấy cái salient, tức là những cái biên cạnh mà nổi bật nhất. Hoặc là chúng ta làm các cái thao tác là transformation. Tức là cái thao tác biến đổi về mặt hình học, như flip, quay, tỷ lệ, tịnh tiến, v.v. Từ đó, từ một ảnh mức xám, thì từ một ảnh chúng ta sẽ tạo ra N ảnh và cái N ảnh này thì N ảnh phiên bản khác nhau. Còn đối với lĩnh vực về xử lý ngôn ngữ tự nhiên, thì chúng ta cũng có một số kỹ thuật. Trong đó đơn giản và dễ hiểu nhất đó chính là kỹ thuật Back Translation. Tức là với cái văn bản gốc, thì chúng ta chuyển nó dịch nó sang cái ngôn ngữ khác. Thí dụ như là tiếng Anh, sau đó chúng ta dịch ngược trở lại, sang trở lại tiếng Anh. Thì từ tiếng Anh sang tiếng Pháp, xong rồi từ tiếng Pháp dịch ngược lại tiếng Anh, thì chúng ta đã có một cái phiên bản mới.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'end_timestamp': '0:06:23', 'start_timestamp': '0:05:49', 'filename': 'NJVpvCzceRk', 'chunk_id': 5, 'title': '[CS315 - Chương 3] Deep Generative Models (2) - Part 4'}, page_content='Rồi thêm vô một cái thành phần nhiễu là 1 trừ alphaT. Thì đây chính là cái công thức của khuếch tán thuận. Thế thì chúng ta sẽ đến với một cái kỹ thuật. Đó là kỹ thuật Reparameterization hay gọi là tái tham số hóa. Thì cái này cũng tương tương tương tự như là cái VAE. Nếu như cái thao tác x mà chúng ta sampling, cái ký hiệu này là sampling. Thì cái thao tác sampling này là một cái thao tác không tính đạo hàm được.'), Document(metadata={'end_timestamp': '0:04:18', 'filename': 'RVj2LTBd7IU', 'start_timestamp': '0:00:14', 'video_url': 'https://youtube.com/watch?v=RVj2LTBd7IU', 'chunk_id': 0, 'title': '[CS315 - Chương 3] Deep Generative Models (1) - Part 5 (Phần 3)'}, page_content='Chúng ta sẽ cùng tìm hiểu về một số biến thể của mạng GAN và ứng dụng của nó. GAN sẽ bao gồm hai generator và discriminator. Tuy nhiên, khi chúng ta sinh ảnh với độ phân giải rất cao, cụ thể là độ phân giải HD, thì nó sẽ gặp một số vấn đề thách thức, ví dụ như tốc độ huấn luyện, khó hội tụ, hoặc bị overfitting. Thế thì, cái giải pháp của chúng ta đó là thay vì chúng ta sử dụng một cái kiến trúc phức tạp từ độ phân giải thấp lên độ phân giải cao, tức là một cái random noise, từ độ phân giải thấp lên độ phân giải cao, sau đó từ cao xuống thấp, chúng ta chỉ huấn luyện với một cái mạng như thế này, thì chúng ta sẽ huấn luyện từ từ. Thì cái quá trình training process chúng ta thấy là từ trái sang phải, là chúng ta đang đi từ độ phân giải thấp, đi tiến đến cái độ phân giải cao. Với cái độ phân giải thấp, thì chúng ta sẽ học về những cái concept chung của tấm hình. Ví dụ như ở đây chúng ta có cái vector latent, được random sampling theo nhiễu normal 01, thì chúng ta sẽ biến đổi nó thành một cái tấm ảnh có độ phân giải, đó là 4x4. Cái module này thì giúp chúng ta tạo ra tấm ảnh có độ phân giải là 4x4. Và kết hợp với lại cái ảnh thật, thì chúng ta sẽ qua cái discriminator, và dành cho cái ảnh có kích thước là 4x4. Thì chúng ta thấy là với cái mô hình tạo sinh và phân biệt, phân loại, ảnh thật, ảnh giả, mà với độ phân giải thấp, thì cái số lượng tham số nó sẽ rất là ít, do đó cái hội tụ, tốc độ hội tụ nó sẽ nhanh hơn, nó dễ hội tụ hơn. Khi chúng ta lên cái độ phân giải cao hơn, chúng ta sẽ chồng thêm các lớp biến đổi để từ ảnh có độ phân giải 4x4 lên 8x8. Và với ảnh này thì chúng ta thấy nó đã mượt hơn một chút, nó đã mượt hơn, so với lại ảnh ở phía trước là 4x4. Tương tự như vậy, kết hợp với ảnh thật, thì chúng ta sẽ đi qua một bộ phân loại, ảnh thật, ảnh giả, từ 8x8 về lại 4x4. Và cứ như vậy, thì chúng ta nâng dần cái độ phân giải của ảnh lên, từ 4x4 lên 1024 x 1024, thì tạo ra một ảnh có độ phân giải rất là cao. Độ phân giải cao. Và từ cái độ phân giải cao này, chúng ta đưa qua cái mô hình phân loại, thì chúng ta sẽ ra được cái mô hình có khả năng phân biệt được ảnh hay là ảnh thật, hay ảnh giả, thì ở bên tay phải, chúng ta thấy đó là cái kết quả là ảnh có độ phân giải rất là cao. Và khi chúng ta tạo sinh hình ảnh, thì chúng ta sẽ sử dụng cái mô hình G này, chúng ta sẽ sử dụng cái mô hình G có cái độ phân giải cao này. Và ứng dụng của nó thì chúng ta biết rằng là ở trong cái StyleGAN, StyleGAN 2, thì có công bố một cái trang web đó là This Person Does Not Exist, thì mục tiêu đó là nó tạo ra ngẫu nhiên một cái ảnh người nhưng mà không có thật. Và chúng ta có thể sử dụng cái ảnh này để phục vụ cho cái việc là làm những cái ví dụ nâng cao mà không vi phạm các cái vấn đề về quyền riêng tư. Một cái biến thể khác cũng rất là nổi tiếng của GAN, đó chính là Conditional GAN hay là GAN có điều kiện. Trước đây thì chúng ta từ một cái vector nhiễu Z, chúng ta tạo ra một cái tấm ảnh, nhưng mà cái ảnh này là chúng ta không thể đoán trước được, hoặc là chúng ta không thể kiểm soát được, không thể kiểm soát được cái đầu ra của mình, đó là cái ảnh như thế nào.'), Document(metadata={'chunk_id': 10, 'start_timestamp': '0:14:16', 'video_url': 'https://youtube.com/watch?v=iQqNUKgIZpc', 'end_timestamp': '0:15:28', 'title': '[CS315 - Chương 2] Vanishing Gradient (Phần 3)', 'filename': 'iQqNUKgIZpc'}, page_content='Nhưng mà các bạn nhìn vô đây thì chúng ta thấy cái kết nối tắt mới chính là những cái thao tác mà nhiều nhất. Đây là một cái nối tắt. Một kết nối tắt. Rồi lại tiếp tục kết nối. Kết nối tắt. Đó thì không biết là Attention Is All You Need hay là Skip Connection Is All You Need. Cái này là một cái nói vui. Và tương tự như vậy thì cũng sẽ có Deep Supervision là một cái kiến trúc mạng mà có các cái kết nối tắt. Thì cái kết nối tắt này nó không có theo kiểu của DenseNet mà là nó sẽ tắt ra thành từng nhánh. Và với mỗi nhánh thì chúng ta thấy nếu đi theo đúng cái đường ban đầu là cái đường kiến trúc ở giữa thì sẽ biến đổi rất là nhiều. Nhưng mà nhờ có cái nhánh nó tắt ra, tắt ra, tắt ra, tắt ra ở đây. Thì chúng ta sẽ tính các cái loss ở những cái lớp mà có ít biến đổi hơn. Thì những cái loss ở các lớp ít biến đổi này thì khi chúng ta lan truyền về thì chúng ta sẽ giúp cập nhật được trọng số của những lớp đầu tiên dễ dàng hơn. Tại vì khoảng cách từ lớp đầu tiên này cho đến những cái...'), Document(metadata={'chunk_id': 7, 'title': '[CS315 - Chương 1] Mô hình học máy dựa trên Gradient (Phần 7)', 'filename': '3TT7y2Nz-vc', 'start_timestamp': '0:08:35', 'video_url': 'https://youtube.com/watch?v=3TT7y2Nz-vc', 'end_timestamp': '0:10:14'}, page_content='Nó bị sai lệch so với lại cái đạo hàm tại cái thời điểm đó. Và trong cái sơ đồ này thì chúng ta sẽ có cái trực quan hóa để cho thấy cái tốc độ hội tụ của từng thuật toán. Thì ở đây AdaDelta, đó chính là cái Adam của mình. Đó là cái đường màu vàng. Đó là cái đường màu vàng này. Rồi, và chúng ta thấy là cái đường màu vàng thì nó sẽ rớt xuống rất là nhanh, nó sẽ hội tụ rất là nhanh. Khi đến cái khu vực mà gọi là Saddle Point và đồng thời là có cái valley, là cái thung lũng chúng ta thấy là có hai cái thành, giảm độ dốc, đi ngang, xong rồi lại đi lên, đó gọi là valley thì cái Adam của chúng ta rớt xuống nhanh nhất, nó rớt xuống rất là nhanh. Còn cái thuật toán mà Root Mean Square Propagation là cái đường màu đen thì chúng ta thấy là nó sẽ rớt chậm hơn. Còn Stochastic Gradient Descent thì đối với Stochastic Gradient Descent là cái chấm màu đỏ nè là chúng ta thấy nó bị dao động qua lại và nó đứng yên luôn, nó không thoát ra được cái chỗ này luôn. Momentum thì khá hơn một chút xíu là cái đường, cái điểm màu xanh lá. Chúng ta thấy là khi Momentum nó rớt xuống nó cũng sẽ chao đảo qua lại. Nhưng mà vì có một số kiểu tối ưu nên nó sẽ dần dần dần dần nó thoát ra được và nó đến được cái rảnh này nó di chuyển. Trong khi các cái phương pháp cải tiến khác thì nó cũng bị cái hiện tượng là dao động qua lại rất là nhiều.'), Document(metadata={'filename': 'zbR5lDFTKTM', 'chunk_id': 2, 'start_timestamp': '0:03:47', 'end_timestamp': '0:21:54', 'video_url': 'https://youtube.com/watch?v=zbR5lDFTKTM', 'title': '[CS315 - Chương 4] Vision - Language Model (1): Part 6'}, page_content='Để mà từ đó là nó... Ví dụ đây, nó tìm ra được cái Magna nằm ở đây chẳng hạn Thì nó sẽ trả lời là 6 đô la Và sau đó nó còn lập luận và thực hiện cái thao tác đếm Là trong cái đây có hai chai bia, do đó nó sẽ lấy 6 nhân cho 2 là bằng 12 Như vậy thì ở đây chúng ta thấy cái mô hình này nó còn có cái sự gọi là reasoning Tức là cái sự suy luận Chứ nó không chỉ đơn giản là information extraction, tức là rút trích thông tin ra từ tấm ảnh Mà nó có cái sự reasoning ở đây Thì để đạt được cái reasoning này thì nó sẽ phải nhờ đến cái kết quả hoặc là những thành tựu của GPT Là cái mô hình mà pre-train dành cho cả decoder để phục vụ cho việc là xử lý cái văn bản Hoặc là generate tạo sinh ra văn bản Vậy thì GPT-4V là một cái mô hình cho phép xử lý đa dạng các dữ liệu đầu vào hay còn gọi là multimodality là đa thể thức Và nó có thể xử lý dữ liệu đầu vào là dạng văn bản thông thường Nó có thể gồm một hoặc là nhiều ảnh Ví dụ như trong cái ví dụ này ta thấy là có thể lên đến vài ảnh, ba ảnh Rồi văn bản trong ảnh, tức là trong tấm ảnh nó lại có văn bản Bình thường là mình sẽ có văn bản riêng và ảnh riêng Bây giờ trong ảnh nó lại có văn bản Đó, thì đây là một cái ví dụ trong ảnh là có văn bản Là trong tấm hình menu nó sẽ có các cái tên của các loại đồ uống và giá tiền Rồi visual pointer tức là một cái dạng thức để cho chúng ta tương tác Đối với là một cái dạng prompt, nó là một cái dạng prompt mới Bình thường mình có prompt là dạng text và ảnh Bây giờ cái prompt của mình có thể là dấu mũi tên giống như chúng ta đang vẽ ở đây Cái mũi tên này nó cũng được gọi là một cái prompt Nếu như cái mô hình này giả sử như nó giải không được thì chúng ta có thể chỉ vô đây Giá của cái beer Magna nó là nằm ở đây, mình chỉ vô Mô hình của mình sẽ hiểu được cái visual pointer này như là một cái loại prompt Vậy thì GPT-4V nó có một vài đặc trưng chính, đó là gì Đây là một cái bài toán có thể được thực hiện với GPT-4V Đây là những cái bài toán mà GPT thực hiện được bao gồm những task rất là đơn giản Ví dụ như là mô tả hình ảnh, image description, image captioning, rồi nhận dạng ảnh, recognition on different domains Rồi kết hợp kiến thức đa thể thức, multimodal knowledge Trong cái ví dụ ở trên chúng ta thấy là nó có sử dụng cái knowledge của văn bản là text Đồng thời nó cũng có sử dụng cái knowledge của tấm ảnh Rồi nó có sử dụng cái text trong ảnh Thì đó là multimodality Và có thể tương tác với các kiến thức tổng quát Ví dụ như nó có thể hiểu về những người nổi tiếng như là David Beckham Người nổi tiếng này Rồi các cái địa danh như là Paris, Hà Nội v.v. Địa danh nổi tiếng thì đó là những cái kiến thức tổng quát Rồi và đồng thời nó có khả năng quan trọng là hiểu và suy luận hay gọi là reasoning trên cái văn bản đơn thuần hoặc là văn bản trong ảnh syntax understanding hoặc document reasoning Thì đây chính là những cái khả năng nổi trội của GPT-4V so với những mô hình ngôn ngữ thị giác mà chúng ta đã tìm hiểu ở phía trước Tiếp theo thì chúng ta sẽ cùng tìm hiểu về khái niệm visual pointer Ở bên tay phải là một hình ảnh ví dụ về visual pointer Bên cạnh câu mô tả là display the pointed region in the image Và chúng ta sẽ có một tấm ảnh Trong tấm ảnh này, nó sẽ có một đường màu đỏ Đây chính là một ví dụ của visual pointer Với visual pointer sẽ hướng dẫn cho mô hình tập trung vào những phần quan trọng của tấm ảnh Thay vì chúng ta nhìn vô, tấm ảnh này sẽ có cả rừng chữ và số Với đường khoanh màu đỏ này, mô hình của mình biết là sẽ tập trung vào đây để phân tích số liệu của mình Với đường màu đỏ này, mô hình GPT-4V đã nêu được Và chúng ta đã đưa ra các phân tích tương ứng của tấm ảnh Và chúng ta đã đưa ra các phân tích tương ứng của tấm ảnh Vậy thì ngoài đường khoanh màu đỏ, nó sẽ còn những dạng visual pointer nào Ví dụ như chúng ta có thể đưa vào tọa độ dạng số, hoặc là coordinate Hoặc chúng ta có thể đưa vào blackbox, trong đó chúng ta loại bỏ hết tất cả những phần ảnh không liên quan Và chỉ chừa cái vùng ảnh có liên quan đến việc suy luận hoặc là cái việc trả lời câu hỏi của chúng ta Hoặc là nó có thể ở dạng là một cái mũi tên, chỉ vào những đối tượng mà chúng ta đang muốn quan tâm Thì đây có thể là một trong những dạng khá là thú vị và gần với cách thức người tương tác khi mà trao đổi với nhau trên hình ảnh Rồi cái dạng nữa đó là chúng ta có thể dùng một cái box, một cái khung kèm cái ảnh gốc thì nó sẽ có thêm một cái đường màu đỏ để khoanh vùng cái đối tượng chúng ta quan tâm Và có những cái dạng mà freestyle hơn, ví dụ như là hình oval, hoặc là hand drawing, tức là một cái đường nét tự do Với cái visual pointer, nó đã giúp cho cái việc tương tác giữa người và máy tính trở nên thuận tiện hơn Và đây có lẽ là một trong những cái thể thức quan trọng đặc biệt mà GPT-4V nó khác biệt so với lại những cái mô hình vision language, cái mô hình thị giác ngôn ngữ trước đây Vậy thì một vài cái ví dụ nữa để cho chúng ta thấy cái tính hiệu quả của GPT-4V liên quan đến cái việc là reasoning Nếu như chúng ta đưa vào một cái câu prompt đó là count number of apples in the image thì nó sẽ đếm sai là có 12 quả táo Nâng cấp hơn một chút xíu thì mình sẽ chỉ dẫn cho nó, đó là thêm một cái câu viết đằng sau đó là suy nghĩ step by step Thì nó sẽ đưa ra là có 4 step, rồi step 1 là tính như thế nào, step 2 là làm gì, step 3 là làm thế nào, step 4 thậm chí đã kiểm tra lại Nhưng cuối cùng nó vẫn ra sai và chỉ đến khi chúng ta đưa ra một cái chỉ dẫn đầy đủ và các cái bước đủ đơn giản Thì nó mới có thể làm đúng ví dụ, câu đầu giống như nó khen You are an expert in counting things in the image Rồi, hãy đếm những số lượng apple trong tấm ảnh này row by row và đảm bảo rằng là nó ra được cái kết quả chính xác Thế thì nó sẽ xét trong tấm hình này thì nó sẽ có 4 dòng và với mỗi dòng nó sẽ lần lượt liệt kê ra, nó sẽ đưa ra cái con số đếm Ví dụ như là 4 apple, dòng số 2 là có 4 apple, dòng số 3 là có 3 apple và cuối cùng nó sẽ ra được con số đúng là 11 apple Rồi, thì như vậy, GPT-4V ở đây là một cái ví dụ cho chúng ta thấy là nó có thể đưa ra, chúng ta có thể đưa vào các cái chỉ dẫn cộng với cái tấm ảnh Và cái chỉ dẫn này thì biết nó giống như là một cái câu prompt mà chúng ta trò chuyện với chatbot, chỉ dẫn cho nó biết là phải làm như thế nào để mà suy luận Thì đây chính là một cái ví dụ khi sử dụng GPT-4V giống như là chúng ta sử dụng với cái mô hình GPT-4o hoặc GPT-4 của nền tảng ChatGPT Rồi, cái In-context Few-Shot Learning thì ở đây là một cái ví dụ Zero-Shot Đại đa số mọi người khi mà làm việc thì đều hay sử dụng Zero-Shot, tại vì thứ nhất là họ nghĩ rằng cái mô hình của mình là tốt, cái mô hình của mình là xịn Giờ đến đây là cái gì cũng biết, cái gì cũng biết Cái thứ hai là bản thân mình là cái người sử dụng thì mình cũng lười, mình lười hướng dẫn cho nó nhiều Thì đó là hai cái yếu tố khiến cho Zero-Shot là một trong những cái kỹ thuật được sử dụng rất là phổ biến Ví dụ trong ví dụ này là chúng ta đưa vào cái prompt là In which year had the highest average gas price ở trong tháng 6 Thì ở đây là mô hình trả lời sai là 3,3 đô Nếu mà chúng ta dùng là Zero-Shot nhưng mà chúng ta kêu nó là think step by step thì kết quả của mình cũng sai Chỉ khi chúng ta đưa vào cái In-context Few-Shot, cụ thể ở đây là hai shot Thì cái In-context Few-Shot này có nghĩa là gì? Chúng ta sẽ cho nó một cái cặp câu hỏi Và ví dụ, câu hỏi ví dụ, cái đáp án thì nó sẽ bám theo cái cặp suy luận đó để mà nó trả lời cho những câu hỏi mới Ví dụ như ở đây là chúng ta hỏi, ở đây chúng ta sẽ đưa cho nó là chỉ dẫn thêm là cái đồ thị này Plot the National Gas Price, tức là plot giá gas ở trong nước là từ 2016 cho đến 2019 Rồi nó mô tả ra chi tiết là màu đỏ là gì, màu xanh là gì, màu xanh lá là gì, v.v. Rồi sau đó thì nó sẽ đưa ra tính toán là năm mà có cái High Gas Price là vào tháng 6 năm 2018 Thì ở đây là nó đưa ra những cái Few-Shot, tức là cái kết quả Vậy thì GPT nó đã dựa trên cái lập luận tương tự ở phía trên là với hai shot, đây là shot số 1 Đây là shot số 2 ở phía bên dưới, nó sẽ còn một cái câu nữa Ví dụ thì khi chúng ta đưa vào một số liệu mới, ở trên là chúng ta cho ví dụ 2019, 2018 Và với số liệu mới này là 2023 thì nó sẽ tự động lập luận y chang như thế này để tìm ra được giá gas mà cao nhất là bao nhiêu Thì nó bắt chước hai cái shot ở phía trên cho một cái loại dữ liệu mới Và cái kết quả nó ra được đó là tháng 6 năm 2020, thì đó chính là cái hướng dẫn cho cái mô hình, cái cách thức để mà nó lập luận Và với Few-Shot hay còn gọi là In-context learning Như vậy tổng kết lại chúng ta đã cùng tìm hiểu qua các cái mô hình, mô hình ban đầu như là CLIP Và cho đến bây giờ thì vẫn được dùng nhiều, CLIP thì dùng nhiều cho bài toán là Zero-Shot Image Classification Sau đó chúng ta có phiên bản là GLIP, với cái sự cũng là Zero-Shot nhưng mà cho bài toán Detection Rồi nâng lên là có mô hình CLIP, sau đó là sẽ có Visual Programming Rồi cái mô hình mà chúng ta vừa mới tìm hiểu đó chính là GPT-4V Vậy thì cái việc mà chúng ta sẽ có cái nhận định gì khi chúng ta đã tìm hiểu qua các cái mô hình này Đó là cái việc mà chúng ta huấn luyện một cái mô hình từ đầu cho cái mô hình thị giác thì nó cần rất nhiều tài nguyên tính toán Cũng như là cái dữ liệu của chúng ta rất là lớn Nói vui đó là nhiều khi cái dữ liệu của mình nó lớn đến nỗi mà chúng ta không đủ dung lượng để chứa chứ đừng nói đến cái chuyện là chúng ta huấn luyện mô hình Tại vì quy mô nó lên đến Internet Scale Internet Scale Dataset Và do đó thì thông thường chúng ta sẽ sử dụng cái mô hình đã huấn luyện sẵn Nhưng mà quan trọng là chúng ta sẽ phải biết được cái công năng của từng mô hình, của từng phần trong mô hình là gì Ví dụ như khi chúng ta nhìn vào cái mô hình CLIP thì chúng ta biết cái mô hình nào là mô hình chúng ta sẽ sử dụng để cho cái công việc gọi là Unimodal encoding Và khi nào thì chúng ta sẽ sử dụng cái mô hình, mà cross-modal hay là image-text, image-text là text matching Và khi nào thì chúng ta sẽ sử dụng cái language model ở phía sau để cho cái tác vụ là text generation Thì chúng ta biết được cái công năng của từng mô hình và dùng mô hình nào là phù hợp cho cái bài toán của chúng ta Cái thứ hai đó là phối hợp các cái thành phần huấn luyện sẵn đó cho cái bài toán của mình Ví dụ như chúng ta khai thác cái module để mã hóa hình ảnh hoặc module mã hóa văn bản Tại vì cái việc mà chúng ta cho hình ảnh và văn bản tương tác với nhau để học ra được encoding thì nó sẽ giúp cho chúng ta có cái tính tổng quát, có cái tính tương tác và phân biệt được ngữ nghĩa một cách rõ ràng hơn so với việc chúng ta chỉ học dựa trên văn bản không hoặc chỉ học dựa trên hình ảnh không Và sử dụng các kỹ thuật Prompt Engineering một cách hiệu quả Ví dụ như chúng ta sử dụng cái In-context learning với kỹ thuật Few-Shot Prompting Chúng ta sẽ cho nó khoảng hai, ba ví dụ về cái instruction và cái instruction và cái kết quả của mình Thì kết quả, cái Result thì nó sẽ bắt chước cái instruction và cái Result này Khi chúng ta có một cái new instruction thì nó sẽ giúp cho chúng ta dự đoán ra được cái kết quả Nó sẽ đưa ra một cái kết quả dự đoán Thì đó là ý tưởng của In-context learning và đây là một trong những kỹ thuật dùng cũng rất là phổ biến Rồi hướng dẫn mô hình suy luận một cách có hệ thống, chúng ta sẽ cho nó suy nghĩ theo kiểu step by step Rồi có thể chỉ dẫn cho nó chi tiết hơn là chúng ta sẽ chia nó ra thành bước 1, bước 2, bước 3 như thế nào Bước 1 chi tiết là sao? Càng đơn giản thì mô hình sẽ dễ thực hiện theo Rồi hướng dẫn cho nó cách suy luận Và cuối cùng đó là sử dụng Visual Pointer thì đây là một kỹ thuật để giúp cho chúng ta có thể hỗ trợ cho người dùng Tạo ra một cái prompt một cách đơn giản và tự nhiên Chúng ta có thể tạo ra một cái visual pointer là dạng mũi tên, nó có thể là một cái box hoặc là một cái scribble như thế này Một cái đường mà zigzag Vậy thì trên đây đó là một vài cái mô hình đầu tiên khi nói về mô hình ngôn ngữ thị giác Trong những phần tiếp theo thì chúng ta sẽ nói về những cái mô hình hiện đại hơn, được train trên những dữ liệu lớn hơn Và phục vụ cho các cái bài toán mà chúng ta đã đề cập trước đây, ví dụ như bài toán segmentation Và bài toán sinh ngôn ngữ text generation Cụ thể đó là cái mô hình là LLaVA Còn đối với cái segmentation thì chúng ta có thể sử dụng hai cái mô hình, đó là SAM Grounding DINO Đây là hai cái mô hình Zero-Shot Segmentation Và mô hình SEEM là một cái mô hình tương tác đa thể thức Trong những phần tiếp theo chúng ta sẽ tìm hiểu về các cái mô hình này')]\n"
     ]
    }
   ],
   "source": [
    "result = hybrid_retriever.get_relevant_documents(\"diffusion là gì\") if bm25_retriever else []\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925223f5",
   "metadata": {},
   "source": [
    "## generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af4a97",
   "metadata": {},
   "source": [
    "### Chọn mô hình (qwen 0.5b hoặc api gemini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8aa5a1",
   "metadata": {},
   "source": [
    "## Generation với Qwen 0.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7569d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float32,  # CPU thường dùng float32\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2-0.5B\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.1,\n",
    "    device=0  \n",
    ")\n",
    "# HuggingFacePipeline LangChain\n",
    "llm = HuggingFacePipeline(pipeline=model_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b29605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "allocated: 3.089437184 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(\"allocated:\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257647e",
   "metadata": {},
   "source": [
    "## generation ( chỉ dùng cho qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c89ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3550: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 79\u001b[0m\n\u001b[0;32m     69\u001b[0m     reranked \u001b[38;5;241m=\u001b[39m crossencoder_rerank(docs, query, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m format_doc(reranked)\n\u001b[0;32m     72\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     73\u001b[0m     {\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough(),\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnableLambda(get_context),\n\u001b[0;32m     76\u001b[0m     }\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m#| prompt.partial(format_instructions=parser.get_format_instructions())\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\u001b[38;5;241m.\u001b[39mpartial()\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;241m|\u001b[39m \u001b[43mllm\u001b[49m\n\u001b[0;32m     80\u001b[0m    \u001b[38;5;66;03m#| RunnableLambda(lambda x: extract_json_from_output(x))\u001b[39;00m\n\u001b[0;32m     81\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableMap,RunnableLambda\n",
    "\n",
    "\n",
    "class VideoAnswer(BaseModel):\n",
    "    text: str = Field(description=\"Câu trả lời tóm tắt trong 3 câu\")\n",
    "    filename: str = Field(description=\"Tên file transcript gốc\")\n",
    "    video_url: str = Field(description=\"URL của video gốc\")\n",
    "    start_timestamp: str = Field(description=\"Thời điểm bắt đầu (format: HH:MM:SS)\")\n",
    "    end_timestamp: str = Field(description=\"Thời điểm kết thúc (format: HH:MM:SS)\")\n",
    "    confidence: str = Field(description=\"Độ tin cậy: zero/low/medium/high\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=VideoAnswer)\n",
    "\n",
    "# ===== Prompt =====\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Câu hỏi: {question}\n",
    "\n",
    "Trả lời bằng JSON với các yêu cầu:\n",
    "- \"text\": tóm tắt **chỉ 3 câu ngắn gọn**.\n",
    "- \"filename\", \"video_url\", \"start_timestamp\", \"end_timestamp\": giữ nguyên thông tin.\n",
    "- \"confidence\": chọn một trong các giá trị \"zero\", \"low\", \"medium\", \"high\" dựa trên độ chắc chắn của câu trả lời.\n",
    "\n",
    "Cấu trúc JSON:\n",
    "{{\n",
    "  \"text\": \"<tóm tắt trong 3 câu ngắn gọn>\",\n",
    "  \"filename\": \"<tên file transcript>\",\n",
    "  \"video_url\": \"<URL video>\",\n",
    "  \"start_timestamp\": \"<HH:MM:SS>\",\n",
    "  \"end_timestamp\": \"<HH:MM:SS>\",\n",
    "  \"confidence\": \"<zero/low/medium/high>\"\n",
    "}}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def extract_json_from_output(output: str) -> str:\n",
    "    return output.split('Answer:')[1].strip()\n",
    "\n",
    "\n",
    "def format_doc(docs):\n",
    "    formatted = []\n",
    "    for doc in docs:\n",
    "        url = doc.metadata.get(\"video_url\", \"\")\n",
    "        filename = doc.metadata.get(\"filename\", \"\")\n",
    "        start = doc.metadata.get(\"start_timestamp\", \"\")\n",
    "        end = doc.metadata.get(\"end_timestamp\", \"\")\n",
    "        content = doc.page_content\n",
    "        formatted.append(f\"\"\"[Video URL]: {url}\n",
    "[Filename]: {filename}\n",
    "[Start]: {start}\n",
    "[End]: {end}\n",
    "[Content]: {content}\"\"\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "def rerank_with_query(docs_and_query) -> List:\n",
    "    docs, query = docs_and_query\n",
    "    return crossencoder_rerank(docs, query, top_k=3)\n",
    "\n",
    "def get_context(query: str):\n",
    "    docs = vector_retriever.get_relevant_documents(query)\n",
    "    reranked = crossencoder_rerank(docs, query, top_k=3)\n",
    "    return format_doc(reranked)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": RunnableLambda(get_context),\n",
    "    }\n",
    "    #| prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | prompt.partial()\n",
    "    | llm\n",
    "   #| RunnableLambda(lambda x: extract_json_from_output(x))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b0cd3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Transcript:\n",
      "[Video URL]: https://youtube.com/watch?v=HKbzvh4rDw0\n",
      "[Filename]: HKbzvh4rDw0\n",
      "[Start]: 0:07:31\n",
      "[End]: 0:08:33\n",
      "[Content]: Cái quy mô nó quá lớn. Vậy thì từ đó nó sẽ cho ra đời là cái mạng CNN. Mạng CNN thì bản chất là nó có một cái phần rút trích đặc trưng riêng, riêng đó là dùng cái phép biến đổi convolution. Thì các lớp convolution và relu hoặc là sigmoid, hoặc một hàm kích hoạt là sigmoid, thì mục đích của nó đó là để rút trích ra đặc trưng ảnh. Và đặc trưng này nó sẽ được sắp xếp từ đơn giản cho đến phức tạp. Và các lớp MLP phía sau thì mục đích của nó là để phân lớp đặc trưng. Còn ở cái lớp phía trước mục tiêu của nó đó là chúng ta sẽ rút trích đặc trưng.\n",
      "\n",
      "[Video URL]: https://youtube.com/watch?v=t5t5G61ZtAg\n",
      "[Filename]: t5t5G61ZtAg\n",
      "[Start]: 0:04:27\n",
      "[End]: 0:09:02\n",
      "[Content]: thì cách mà chúng ta sẽ thực nghiệm đó chính là chúng ta sẽ làm cái lưới từ trừ 5 cho đến 10 và từ trừ 10 cho đến 5 rồi, thì chúng ta sẽ thử ha chúng ta sẽ vẽ cái lưới này rồi, trừ 5 là ở đây rồi chúng ta sẽ lấy cái lưới chụp cái màn hình này thì trừ 5 sẽ là ở đây rồi 10 sẽ là ở đây trừ 5 cho đến 10 trừ 5 cho đến 10 thì 10 sẽ là ở đây rồi và trục tung thì là sẽ từ trừ 10 cho đến 5 trừ 10 cho đến 5 là ở đây trừ 10 cho đến 5 là ở đây rồi, như vậy cái lưới mà dự định chúng ta sẽ vẽ là ở khu vực này trục hoành là từ trừ 5 cho đến 10 và trục tung là từ trừ 10 cho đến 5 như vậy thì chúng ta sẽ có một cái khung vuông rồi, sau đó chiến thuật của chúng ta là gì? chúng ta sẽ chia lưới nó ra ví dụ như trong trường hợp này chúng ta sẽ chia ra làm 12 khoảng cách đều nhau rồi, sau đó chúng ta cũng sẽ chia lưới theo chiều dọc như vậy rồi, thì với mỗi một cái điểm trên cái mắt lưới này lấy ví dụ như cái điểm ở đây chúng ta sẽ dùng một điểm đen ví dụ như một cái điểm trên cái mắt lưới này thì nó sẽ là một cái vector z mà chúng ta lấy ra, chấm lên trên cái lưới và chúng ta sẽ qua cái hàm decoder để xem nó ra một cái tấm ảnh gì nó như thế nào sau đó chúng ta lấy cái ảnh này chúng ta sẽ vẽ lên trên thành một cái ma trận với cái ảnh này chúng ta sẽ vẽ ra một ảnh với một cái điểm z ở đây chúng ta sẽ decode ra và vẽ ảnh lên với cái điểm này, điểm này chúng ta decode ra và vẽ ảnh lên thì chúng ta sẽ ra một cái ma trận các điểm ảnh và chúng ta sẽ quan sát xem nó có cái tính chất gì đặc biệt phải không Rồi, thì đó chính là cái ý tưởng của cái hàm Plot Reconstructed chúng ta sẽ chia ra thành các latent space với n ở đây là bằng 12, chúng ta sẽ chia ra làm 12 khoảng rồi lấy cái x và cái y này chúng ta sẽ có được cái latent z là cái điểm màu đen mà chúng ta đã vẽ rồi qua cái hàm decoder chúng ta sẽ ra được x hat tức là cái ảnh được tạo sinh ra và ảnh này sẽ được reset về cái kích thước là 28 x 28 và sau đó vẽ lên cái ma trận ảnh rồi, thì chúng ta sẽ chạy cái đoạn code này đó thì với cái ví dụ này chúng ta có thể thấy đó là ở những cái khu vực phía trên đó sẽ ra một cái hình thù gì đấy và chúng ta không cảm nhận được đó là một cái con số khu vực ở giữa ở đây cũng vậy nó sẽ có lẫn lộn rất nhiều những cái hình ảnh ở trong đó có thể có chứa nhiều con số dẫn đến là mình nhìn mình không cảm nhận được đó là số gì khu vực này cũng vậy thế thì chiếu lên trên cái hình ảnh của cái không gian của mình thì những ảnh ở góc phía trên bên đây là ở khu vực trừ 5 cho đến 5 trừ 5 cho đến 5 tức là nó nằm ở cái khu vực màu trắng và cái khu vực màu trắng này khi chúng ta decode ra thì nó sẽ tạo ra một cái ảnh không có ý nghĩa không giống cái con số nào hết đó thì đây chính là cái điểm yếu của mô hình auto encoder\n",
      "\n",
      "[Video URL]: https://youtube.com/watch?v=ZS8Ny8QSPQQ\n",
      "[Filename]: ZS8Ny8QSPQQ\n",
      "[Start]: 0:02:22\n",
      "[End]: 0:13:35\n",
      "[Content]: Ở đây là công thức của sinh ảnh không có điều kiện. Đối với sinh ảnh mà có điều kiện, chúng ta sẽ thêm vô một biến nữa là biến y. Đây chính là conditional signal. Đây là conditional signal. Sau này khi tổng quát lên, y này không nhất thiết phải là văn bản. nó có thể là một cái mask, nó có thể là một cái điểm v.v. thì công thức của chúng ta thay vì là S theta của Xt, t thì chúng ta sẽ thêm cái thành phần là y vào đây và khi đó thì cái St này sẽ xấp xỉ với lại cái gradient của log p Xt cho trước y Đây là conditional score Công thức trước là unconditional score Bây giờ chúng ta sẽ chuyển sang conditional score chúng ta sẽ đưa vô một xác suất có điều kiện là i Chứ cho trước i, thì xác suất để tìm ra xt khi cho trước i là bao nhiêu? Chúng ta sẽ triển khai Và dựa trên định lý Bayes thì công thức này xuất phát từ triển khai như sau đó là cái log của Px t cho trước y thì nó sẽ là bằng log của Pxt cho trước y thì nó sẽ là bằng Pxt nhân với lại Pi cho trước xt tất cả chia cho Pi Với công thức này, chúng ta sẽ triển khai ra và có được là bằng đạo hàm của log của PxT Nhân thì chúng ta sẽ đưa về dấu cộng, đó là cộng cho log của Py cho trước xT Chia thì chúng ta sẽ chuyển thành là dấu trừ cho log của Pi Với công thức này, chúng ta thấy là vì chúng ta đang muốn tính đạo hàm theo XT chúng ta đang tính đạo hàm theo XT Đây là đạo hàm theo XT Trong con mắt của XT, thì y của mình là hằng số Do đó chúng ta sẽ loại bỏ đi thành phần này đi Tại vì đạo hàm của một cái hằng số đối với xt thì nó sẽ là bằng 0 Do đó thì công thức này sẽ đưa về công thức ở trên Đó là log của pxt cộng cho log của pi cho trước xt Và với cái công thức này thì chúng ta sẽ thấy là cái xt của mình Khi chúng ta khôi phục, chúng ta decode Bình thường nó sẽ đi theo con đường này là Unconditioned là màu xanh lá Màu xanh lá tương ứng cho Unconditioned Bình thường nó sẽ đi theo đường màu xanh dương Và qua màu xanh lá thì chúng ta sẽ điều hướng đi qua mũi tên màu xanh và cộng 2 cái đó lại thì nó sẽ ra cái mũi tên màu cam. Thế thì bình thường là chúng ta sẽ đi theo cái con đường này. Nhờ có cái vector gradient của log y cho trước xt, nó bẻ lái để biến thành cái vector màu cam này. Chúng ta lưu ý ở đây nó sẽ có thêm một cái hệ số nữa, nó gọi là classifier guidance. Nếu như trong công thức chúng ta biến đổi ở phía trước là chúng ta không có cái gamma ở đây thì hàm ý đó là một cái Unconditional Score nó sẽ kết hợp với một cái Adversarial Gradient tức là cái vector điều hướng theo tỷ lệ đó là 1,1 nhưng mà chúng ta muốn nó nhanh điều hướng thì chúng ta sẽ tăng cái hệ số tỷ lệ đó lên hoặc là chúng ta muốn chậm lại thì chúng ta sẽ giảm cái hệ số tỷ lệ đó xuống Như vậy trong công thức này, gamma sẽ là hệ số để giảm tốc độ điều hướng của mình Vector màu cam sẽ là tổng hợp của vector màu đỏ trong điều kiện là Unconditional Kết hợp với adversarial thì nó sẽ đưa ra, bẻ cái hướng, thay vì chúng ta đi theo hướng này để mà tìm được đến đây thì bây giờ nó bẻ hướng lại, nó sẽ đi theo cái hướng này để đến cái ảnh mà có cái điều kiện giống với lại cái Y của mình thì đó chính là cái Classifier Guidance thế thì cái mô hình này sẽ được thực hiện như thế nào Trước tiên chúng ta sẽ nói về vai trò của Classifier Guidance, tức là gamma hồi nãy của mình Nếu chúng ta chọn gamma là bằng một, tức là dùng công thức gốc ban đầu Thì kết quả của mình sẽ không được điều hướng đủ tốt và đủ nhanh Dẫn đến là nó sẽ tạo ra những hình thù không có thật Tại sao không có thật? Tại vì nó vừa pha trộn của một cái ảnh, của một đối tượng có một đối tượng thật mà lẽ ra với vector Z tạo ra tạo ra cái x0 khi có sự tham gia của gamma vào thì gamma này nó bẻ lái nhưng nó bẻ chưa đủ nhanh dẫn đến đó là kết quả của mình nó tạo ra đối tượng lai lai ở giữa đây là cái x0 còn đây là cái x0 mới thì lẽ ra là chúng ta hướng đến chỗ này nhưng mà cái gamma của chúng ta chưa đủ nên thay vì là nó bẻ lái bình thường là đến đây đúng không thì nó sẽ bẻ lái đến giữa chừng và ở cái khúc giữa chừng này thì nó tạo ra những tấm ảnh như thế này trong khi đó nếu chúng ta cho classifier guidance tức là cái gamma lớn hơn ví dụ như gamma trong trường hợp này bằng 10 thì nó sẽ bẻ lái mạnh hơn để mà nó đến được đến cái xnew giống với lại cái nội dung mà chúng ta mong muốn đó là Pembroke Welsh Corgi Đây là một cái giống chó rất là hiếm Vậy thì quá trình sinh ở trên là quá trình sinh có điều kiện và nó có một cái Classifier Guidance Vậy thì chúng ta sẽ huấn luyện cái mô hình này như thế nào Thì cái cách thức huấn luyện đó là chúng ta sẽ có thêm một cái module chúng ta sẽ có thêm một cái mạng nữa, nó gọi là một cái Classifier hay còn gọi là Off-the-shelf Classifier Và cứ với mỗi cái i mà chúng ta đưa vào thì chúng ta sẽ đi huấn luyện cho một cái classifier như vậy là một cái i sẽ có một cái classifier riêng Và như vậy thì nó sẽ khiến cho cái mô hình của mình nó không có tính linh động Nó không có tính linh động vì khi chúng ta muốn tạo ra một cái đối tượng mới Bình thường chúng ta tạo ra 2 con mèo đeo kính, bây giờ chúng ta muốn tạo ra 1 con chó Welsh Corgi đeo kính chẳng hạn thì lúc đó chúng ta sẽ phải train 1 cái classifier mới cho cái y đó thì nó sẽ khiến cho cái mô hình của mình nó chạy không có tính thực tiễn cao do đó thì chúng ta sẽ chuyển sang 1 cái mô hình, nó gọi là cái mô hình mà sinh có điều kiện nhưng mà với Classifier Free Guidance, tức là không có classifier Vậy thì công thức của mình sẽ được sửa lại đó là bằng 1 trừ gamma nhân cho log của PXT thì đây là cái Unconditional Score kết hợp với Conditional Score và ở đây chúng ta sẽ huấn luyện trên chính mô hình Diffusion của mình luôn Đây chính là U-Net trong diffusion. U-Net trong diffusion này chúng ta sẽ huấn luyện bằng cách đưa 2 tình huống. Tình huống thứ nhất là chúng ta sẽ đưa một vector rỗng vào. Mục tiêu của mình tương đương như một mô hình sinh ảnh nhưng mà không có điều hướng. và chúng ta sẽ đưa y vào, thì y này sẽ là mẫu dữ liệu huấn luyện của chúng ta và y này sẽ cho trước một số mẫu condition mà chúng ta muốn huấn luyện để từ đó nó sẽ estimate ra cái x, xt, t, y Thứ nhất là chúng ta sẽ không có thêm, không có classifier mà chúng ta sẽ huấn luyện trên chính cái mô hình của diffusion của mình luôn trên chính cái decoder của mình luôn và khi chúng ta huấn luyện trên cái decoder này thì chúng ta sẽ có hai tình huống một đó là chúng ta sẽ truyền vô một cái condition là rỗng đây là một cái condition rỗng Mục tiêu của nó là tạo ra tấm ảnh không có cần điều hướng và đưa vào 1 condition trong data set của mình để chuẩn bị trước, đó chính là y. Mục tiêu của mình là điều hướng đến cái này là không điều hướng, còn cái này là có điều hướng. sau khi chúng ta huấn luyện xong, chúng ta cứ sử dụng decoder này để đưa y vào và nó sẽ tạo sinh ra mô hình của mình thì cái sơ đồ này sẽ tương tự như nó sẽ lấy từ mô hình mà chúng ta đã học trong những slide trước bình thường là chúng ta chỉ đưa vào xt và t, bây giờ chúng ta sẽ đưa vào thêm y nữa để làm được việc này thì chúng ta có thể sử dụng các mô hình của Transformer với attention sử dụng key-value của attention để điều hướng thì cái i này có thể là query\n",
      "\n",
      "Câu hỏi: ý tưởng của mô hình xác xuất trong tạo sinh ảnh\n",
      "\n",
      "Trả lời bằng JSON với các yêu cầu:\n",
      "- \"text\": tóm tắt **chỉ 3 câu ngắn gọn**.\n",
      "- \"filename\", \"video_url\", \"start_timestamp\", \"end_timestamp\": giữ nguyên thông tin.\n",
      "- \"confidence\": chọn một trong các giá trị \"zero\", \"low\", \"medium\", \"high\" dựa trên độ chắc chắn của câu trả lời.\n",
      "\n",
      "Cấu trúc JSON:\n",
      "{\n",
      "  \"text\": \"<tóm tắt trong 3 câu ngắn gọn>\",\n",
      "  \"filename\": \"<tên file transcript>\",\n",
      "  \"video_url\": \"<URL video>\",\n",
      "  \"start_timestamp\": \"<HH:MM:SS>\",\n",
      "  \"end_timestamp\": \"<HH:MM:SS>\",\n",
      "  \"confidence\": \"<zero/low/medium/high>\"\n",
      "}\n",
      "\n",
      "Answer:\n",
      "{\n",
      "  \"text\": \"Tìm hiểu về mô hình xác xuất trong tạo sinh ảnh\",\n",
      "  \"filename\": \"tên file transcript\",\n",
      "  \"video_url\": \"URL video\",\n",
      "  \"start_timestamp\": \"HH:MM:SS\",\n",
      "  \"end_timestamp\": \"HH:MM:SS\",\n",
      "  \"confidence\": \"zero\"\n",
      "}\n",
      "\n",
      "Assistant: 1. Câu hỏi: Tóm tắt nội dung của mô hình xác xuất trong tạo sinh ảnh.\n",
      "2. Tên file transcript: Tên file transcript của mô hình xác xuất trong tạo sinh ảnh.\n",
      "3. URL video: URL video của mô hình xác xuất trong\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain.invoke(\"ý tưởng của mô hình xác xuất trong tạo sinh ảnh\")\n",
    "# 3 thành phần loss của diffusion \n",
    "#vae loss có bao nhiêu thành phần\n",
    "#diffusion bị gì để có latent diffusion\n",
    "#VAE bị gì để có diffusion\n",
    "#diffuion bị gì để có laten diffusion\n",
    "#Auto encoder bị gì để tạo ra VAE\n",
    "#Tại sao tạo sinh cần encode xong lại decode ra\n",
    "#Ý tưởng của mô hình xác xuất trong việc tạo sinh hình ảnh\n",
    "## ý tưởng naive bayes trong tạo sinh\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d44befaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vram đã dùng 1.120776704 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"vram đã dùng\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4208c76",
   "metadata": {},
   "source": [
    "## gemini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf300fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",   # hoặc gemini-1.5-pro, gemini-2.0-flash\n",
    "    temperature=0.0,\n",
    "    google_api_key=googleAPIKey,  # 👈 thêm dòng này,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea8d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableMap,RunnableLambda\n",
    "\n",
    "\n",
    "class VideoAnswer(BaseModel):\n",
    "    text: str = Field(description=\"Câu trả lời tóm tắt trong 3 câu\")\n",
    "    filename: List[str] = Field(description=\"Tên file transcript gốc\")\n",
    "    video_url: List[str] = Field(description=\"URL của video gốc\")\n",
    "    start_timestamp: List[str] = Field(description=\"Thời điểm bắt đầu (format: HH:MM:SS)\")\n",
    "    end_timestamp: List[str] = Field(description=\"Thời điểm kết thúc (format: HH:MM:SS)\")\n",
    "    #confidence: List[str] = Field(description=\"Độ tin cậy: zero/low/medium/high\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=VideoAnswer)\n",
    "\n",
    "# ===== Prompt =====\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Dựa vào transcript sau, trả lời câu hỏi của người dùng bằng tiếng Việt.Phần tóm tắt nội dung thì nên tóm tắt trong 3 câu, \n",
    "dựa vào các đoạn transcript được cung cấp và chỉ ra đoạn video chứa thông tin đó và các đoạn video liên quan khác (nếu có) (nhưng vẫn chung 1 text tóm tắt) (video url, thời điểm bắt đầu và kết thúc).\n",
    "Đồng thời làm mượt lại nội dung tóm tắt đó\n",
    "Khi trích dẫn thông tin, **luôn sử dụng đúng [Video URL] và [Start] từ doc chứa nội dung đó**.\n",
    "Nếu không biết câu trả lời thì cứ trả lời là tôi không biết và độ tin cậy là zero\n",
    "Nếu câu hỏi không liên quan đến nội dung video thì trả lời tôi chỉ được huấn luyện trả lời các câu hỏi liên quan đến nội dung video và độ tin cậy là zero\n",
    "Không bịa ra thông tin không có căn cứ, không trả lời sai format\n",
    "Nếu bạn cực kỳ chắc chắn về câu trả lời, hãy đặt độ tin cậy là high. Nếu bạn khá chắc chắn, hãy đặt độ tin cậy là medium. Nếu bạn không chắc chắn về câu trả lời, hãy đặt độ tin cậy là low.\n",
    "Định dạng đầu ra phải tuân theo JSON schema sau:\n",
    "{format_instructions}\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Câu hỏi: {question}\n",
    "\\nAnswer:                                          \n",
    "\"\"\")\n",
    "\n",
    "def format_doc(docs):\n",
    "    formatted = []\n",
    "    for doc in docs:\n",
    "        url = doc.metadata.get(\"video_url\", \"\")\n",
    "        filename = doc.metadata.get(\"filename\", \"\")\n",
    "        start = doc.metadata.get(\"start_timestamp\", \"\")\n",
    "        end = doc.metadata.get(\"end_timestamp\", \"\")\n",
    "        content = doc.page_content\n",
    "        formatted.append(f\"\"\"[Video URL]: {url}\n",
    "[Filename]: {filename}\n",
    "[Start]: {start}\n",
    "[End]: {end}\n",
    "[Content]: {content}\"\"\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "def extract_json_from_output(output: str) -> str:\n",
    "    return output.split('Answer')[1].strip()\n",
    "    \n",
    "    # Hàm rerank lấy docs và query\n",
    "def rerank_with_query(docs_and_query) -> List:\n",
    "    docs, query = docs_and_query\n",
    "    reranked = crossencoder_rerank(docs, query, top_k=10)\n",
    "    return reranked\n",
    "\n",
    "# Hàm lấy context để đưa vào prompt \n",
    "def get_context(query: str):\n",
    "    docs = vector_retriever.get_relevant_documents(query)\n",
    "    reranked = crossencoder_rerank(docs, query, top_k=10)\n",
    "    return format_doc(reranked)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": RunnableLambda(get_context),\n",
    "    }\n",
    "    | prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c60c898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"text\": \"Việc tự huấn luyện mô hình CLIP từ đầu là không khả thi vì nó đòi hỏi lượng dữ liệu cực kỳ lớn, tài nguyên tính toán mạnh mẽ, khả năng xử lý song song và GPU đắt tiền. Do đó, giải pháp khả thi nhất là sử dụng các mô hình CLIP đã được huấn luyện trước để giải quyết các tác vụ hiện có. Điều này giúp tận dụng kiến thức đã được học trên bộ dữ liệu lớn mà không cần đầu tư quá nhiều vào việc huấn luyện từ đầu.\", \"filename\": [\"yPzXzbEhUW0\"], \"video_url\": [\"https://youtube.com/watch?v=yPzXzbEhUW0\"], \"start_timestamp\": [\"0:00:14\"], \"end_timestamp\": [\"0:01:03\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain.invoke(\" tại sao huấn luyện clip từ đầu là khó khăn\")\n",
    "# 3 thành phần loss của diffusion \n",
    "#vae loss có bao nhiêu thành phần\n",
    "#diffusion bị gì để có latent diffusion\n",
    "#VAE bị gì để có diffusion\n",
    "#diffuion bị gì để có laten diffusion\n",
    "#Auto encoder bị gì để tạo ra VAE\n",
    "#Tại sao tạo sinh cần encode xong lại decode ra\n",
    "#Ý tưởng của mô hình xác xuất trong việc tạo sinh hình ảnh\n",
    "## ý tưởng naive bayes trong tạo sinh\n",
    "print(result.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd8b0c",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e8b3273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chuẩn bị chạy đánh giá...\n",
      "Bắt đầu quá trình đánh giá RAG...\n",
      "Đang lấy chunk từ Vector DB để tạo bộ test...\n",
      "Đang dùng LLM để tạo 5 mẫu test...\n",
      "Đã tạo xong 5 mẫu test.\n",
      "Đang chạy pipeline trên bộ test set...\n",
      "Đang xử lý mẫu 1/5: Định dạng cần chuẩn bị trước cho phần văn bản là g...\n",
      "Đang xử lý mẫu 2/5: Một ví dụ về bài toán phức tạp mà mạng Perceptron ...\n",
      "Đang xử lý mẫu 3/5: Mục tiêu của việc phát triển mô hình là gì?...\n",
      "Đang xử lý mẫu 4/5: Tại sao việc tự huấn luyện mô hình CLIP lại không ...\n",
      "Đang xử lý mẫu 5/5: Mô hình tạo sinh giúp ích gì trong việc huấn luyện...\n",
      "Đã thu thập xong dữ liệu. Chuẩn bị cho Ragas...\n",
      "Đã phát hiện ground_truth_context, sẽ đo context_recall.\n",
      "Đang chạy Ragas evaluate... (Sử dụng Gemini làm Judge, việc này có thể mất vài phút)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.496811783s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.496741869s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.496752115s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.496671122s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.49684834s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.496673368s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.496368037s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.202838703s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.156954674s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.132680147s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.112031383s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.083631652s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:   5%|▌         | 1/20 [00:11<03:42, 11.73s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 40.363242363s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 40.298957561s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 40.299245525s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 40.291730951s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 40.288960545s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 40.267363124s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 40.241085706s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Evaluating:  25%|██▌       | 5/20 [00:30<01:19,  5.33s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 21.757657617s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 21\n",
      "}\n",
      "].\n",
      "Evaluating:  30%|███       | 6/20 [00:36<01:18,  5.62s/it]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 15.349542967s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 15.295304813s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 15.290156002s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 15.274207362s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 15.260215631s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 15.135015424s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "Evaluating:  35%|███▌      | 7/20 [00:44<01:22,  6.34s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 7.135367741s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "].\n",
      "Evaluating:  50%|█████     | 10/20 [00:49<00:37,  3.77s/it]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 2.299320478s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 2.23468038s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 2.216258345s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 2.193732634s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 59.990770073s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 59\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 59.905463965s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 59\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 58.262602969s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 57.927056183s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 57.868565225s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 54.593105889s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 54.491272749s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.121522421s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.071466927s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.07085856s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.056624861s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.953949259s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.633699746s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.530712347s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 46.313158592s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 46.179472792s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 33.651442426s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 33.36726652s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 33.239645919s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 30.015442319s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 29.878776353s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "].\n",
      "Evaluating:  60%|██████    | 12/20 [01:40<01:29, 11.18s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  65%|██████▌   | 13/20 [01:45<01:09,  9.98s/it]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 56.732051613s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 56\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 53.966546065s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 52.533487422s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 52.504249696s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 52.497786518s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.061986998s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 51.048039749s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 50.502316957s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.074647266s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.069832593s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.050974767s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 48.769554798s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 46.77559295s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 46.209536339s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 44.780932888s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 44.778167159s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 44.771218715s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 44.494455828s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 37.902690556s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 36.503960033s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 36.483752872s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 36.471437857s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 36.172211163s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 31.984774368s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 29.688617535s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 57.176623615s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 57.162658238s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Evaluating:  75%|███████▌  | 15/20 [02:56<01:35, 19.06s/it]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 55.698921929s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 55.688094059s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 55.678552753s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 53.693089836s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 53.673515953s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 53.381191954s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 53.375164324s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 53.363435254s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Evaluating:  80%|████████  | 16/20 [03:00<01:03, 15.91s/it]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 49.056767403s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\n",
      "Please retry in 40.754633617s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 20/20 [03:23<00:00, 10.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- KẾT QUẢ ĐÁNH GIÁ RAGAS ---\n",
      "{'faithfulness': 0.8333, 'answer_relevancy': 0.9508, 'context_precision': nan, 'context_recall': 1.0000}\n",
      "\n",
      "--- Bảng kết quả chi tiết ---\n",
      "| user_input                                                                    | retrieved_contexts                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | response                                                                                                                                                                                                                                                                                                                                                                                                                           | reference                                                                                                                                                                                  |   faithfulness |   answer_relevancy |   context_precision |   context_recall |\n",
      "|:------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------:|-------------------:|--------------------:|-----------------:|\n",
      "| Định dạng cần chuẩn bị trước cho phần văn bản là gì?                          | ['Chúng ta sẽ sử dụng một cái hình khác. Ví dụ như ở đây là chúng ta... thử tải cái này về. Bằng cái link khác. Rồi, ở đây chúng ta sẽ tải về. Rồi, ở đây chúng ta sẽ tải về. Rồi, ở đây chúng ta sẽ tải về. Bằng cái link khác. À, cái link này chính là cái link ban đầu hồi nãy. Rồi, chúng ta sẽ name là Elephant. Rồi, ở đây là... lấy tấm hình này đi. Rồi, chúng ta sẽ lấy cái đường dẫn trên. Và đưa cái link ảnh vào. Rồi, chúng ta đã tải được. Và chúng ta sẽ sửa lại là Elephant. Rồi, như vậy chúng ta đã có 3 cái công cụ này. Bây giờ, đối với cái phần văn bản, thì chúng ta sẽ có cái định dạng... chúng ta chuẩn bị trước cái định dạng đó là... tên của cái file của mình. Và cái câu mô tả... tương ứng với cái nội dung đó.', 'Hoặc là về lĩnh vực, ví dụ như tóm tắt văn bản. Thì cái many to many dạng 1 có rất nhiều những cái ứng dụng hiện đại. Many to many dạng 2 tức là nó khác biệt so với dạng 1 đó là đối với dạng 1 chúng ta phải xem hết toàn bộ input xong đó chúng ta mới đi trả lời. Còn many to many dạng 2 thì chúng ta chỉ... chúng ta nhận được đến đâu thì chúng ta sẽ ra cái output trên đó.', 'Tức là chúng ta sẽ đi lấy mẫu. Đầu tiên đó là chúng ta lấy mẫu. Ví dụ chúng ta muốn tạo ra những cái ảnh mặt người giống với lại cái ảnh thật như vậy. Trong cái ví dụ ở slide đầu tiên thì chúng ta sẽ đi lấy mẫu. Và chúng ta sẽ lấy mẫu những cái người trong thế giới thực của mình. Đó là những cái ảnh thật.', 'Và đây là một trong những cái công cụ rất là hiệu quả. Nhưng mà thông thường trong lập trình thì thường chúng ta sẽ dùng đến 4D tensor. Thường chúng ta sẽ dùng đến một cấp độ là 4D tensor. Trong đó cái chiều đầu tiên có thể là cái chiều về số lượng cái mẫu dữ liệu của mình. Ví dụ như là batch size, tức là cái kích thước dữ liệu của mình. Sau đó là chúng ta sẽ đến cái chiều độ sâu, depth.', 'Hoặc là chúng ta lấy cái salient, tức là những cái biên cạnh mà nổi bật nhất. Hoặc là chúng ta làm các cái thao tác là transformation. Tức là cái thao tác biến đổi về mặt hình học, như flip, quay, tỷ lệ, tịnh tiến, v.v. Từ đó, từ một ảnh mức xám, thì từ một ảnh chúng ta sẽ tạo ra N ảnh và cái N ảnh này thì N ảnh phiên bản khác nhau. Còn đối với lĩnh vực về xử lý ngôn ngữ tự nhiên, thì chúng ta cũng có một số kỹ thuật. Trong đó đơn giản và dễ hiểu nhất đó chính là kỹ thuật Back Translation. Tức là với cái văn bản gốc, thì chúng ta chuyển nó dịch nó sang cái ngôn ngữ khác. Thí dụ như là tiếng Anh, sau đó chúng ta dịch ngược trở lại, sang trở lại tiếng Anh. Thì từ tiếng Anh sang tiếng Pháp, xong rồi từ tiếng Pháp dịch ngược lại tiếng Anh, thì chúng ta đã có một cái phiên bản mới.', 'Đầu tiên cái vế bên trong cùng đó là hàm max. Tức là chúng ta sẽ đi huấn luyện D trước. Tức là Discriminator trước. Discriminator nó phải có khả năng phân biệt đối tượng 1 cách chắc chắn. Thì khi đó nó mới có thể thách thức cái G. Sao cho nó khó được. Do đó thì ở đây chúng ta sẽ sử dụng, ở đây nhìn chung. Nhìn chung đó là chúng ta công thức tương tự như công thức của Binary Cross entropy. Là so sánh giữa cái giá trị dự đoán và giá trị thực tế.', 'Do đó cái công thức này nó là hoàn toàn tương đương. Và chúng ta sẽ chạy thuật toán Backpropagation và cập nhật lại cái tham số cho D. Sau đó chúng ta sẽ sang bước số 2 là khởi tạo optimizer cho G, generator. Bước đầu tiên đó là chúng ta sẽ tạo ra cái dữ liệu từ noise. Thì chúng ta sẽ bắt chước cái code ở trên. Chúng ta sẽ bắt chước cái code ở trên. Rồi, thì ở đây chúng ta sẽ có là xgen là bằng G của noise. Rồi, chấm detach.', 'Chúng ta sẽ nhân với lại cái... Chúng ta sẽ lấy để... Xin lỗi ở đây chúng ta không phải là nhân vô hướng và chúng ta sẽ dùng cái hàm cross entropy Chúng ta sẽ dùng cái hàm cross entropy để mà tính như vậy thì f.cross entropy Rồi chúng ta sẽ truyền vào cái logic và cái one-hot vector tức là cái label của mình Thì ở trong trường hợp này cái label của mình chính là cái nhãn mà chúng ta đã setup ở phía trên Đây, cái label này Thì được gán từ một, tức là ảnh thứ nhất, nhãn là một, ảnh thứ hai, nhãn là hai, và cái cặp ảnh thứ n, nhãn là n Rồi, chúng ta sẽ show... Chúng ta sẽ đi tính cái loss này bằng cách lấy logic nhân với lại cái label Rồi, bây giờ chúng ta sẽ tính cái hàm loss này là logic và label Rồi, sau đó chúng ta sẽ đi print nó ra Rồi, chúng ta sẽ tính tương tự như vậy cho cái loss của t, tức là theo text Với text tức là gì? Chúng ta sẽ đi cố định cái text, ví dụ text là t3 và chúng ta sẽ cho y chạy từ trên xuống Thế thì bản chất cái cách tính của t3 với trên theo hàng y3 và t3 thì chúng ta chỉ cần lật cái ma trận lại là xong Rồi, sau đó ở đây chúng ta sẽ sửa lại cái code Đó là chấm, chúng ta thêm một cái thành phần chuyển vị vào đây ha Thì chúng ta sẽ lấy logic này, chuyển vị, cross entropy Và loss tổng hợp thì sẽ là bằng trung bình cộng của hai loss này Đó là bằng loss của y cộng cho loss của t Rồi, thì bây giờ chúng ta sẽ lần lượt chạy cái code Đây là theo cột ha, đây là trực quan hóa theo cột Chúng ta lấy ra, thì nếu đúng cái cột này, nó sẽ phải hướng về cái vector này Và nó sẽ bật sáng lên tại cái hàng thứ 3 Rồi, bây giờ chúng ta sẽ tính thử Thì cái loss của mình đó là loss theo trực y, nó ra là 2,410 Và theo cái trực t, rất là văn bản, thì là 2,2406 Và trung bình cộng là 248', 'Tại vì sao? Nhãn của nó thật ra cũng chính là cái x. Nhãn của nó cũng chính là x. Chúng ta lấy x trừ cho x mũ rồi bình phương. Thì đây là mean squared error. Và với cái biểu diễn gọn gàng hơn, tức là thay vì chúng ta sẽ phải có nhiều lớp biến đổi như thế này, rồi nhiều lớp biến đổi như thế này. Thì từ nay về sau chúng ta chỉ cần dùng một cái ký hiệu hình thang. Hai ký hiệu hình thang đó là từ x chúng ta đưa về z và chúng ta dùng cái hình thang là phía bên trái là lớn, và phía bên phải đó là cái cạnh nhỏ, tức là ám chỉ từ một không gian nhiều chiều về không gian ít chiều. Sau đó decoder, đây là encoder. Còn decoder là chúng ta sẽ làm một cái hình thang ngược lại, là từ không gian ít chiều hơn về không gian nhiều chiều hơn. Nó sẽ tạo ra cái thằng x mũ.', 'Ở trên là và, ở dưới là hoặc. Và một số kỹ thuật cụ thể, ví dụ như là Dropout, Regularization, tăng cường. Sửa lỗi Regularization là chính quy hóa và tăng cường dữ liệu. Thì đối với kỹ thuật Regularization thì cái hàm lỗi của mình là bên cạnh cái sai số giữa giá trị dự đoán và cái giá trị ground truth thì chúng ta có thể bổ sung thêm thành phần chính quy hóa. Trong cái công thức hàm lỗi ở đây chúng ta thấy loss của y, ngã và y, đây chính là cái sai số giữa giá trị dự đoán và ground truth. Và thành phần chính quy hóa mà chúng ta đang muốn đề cập chính là ở đây.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Đối với phần văn bản, định dạng cần chuẩn bị trước bao gồm tên của file. Kèm theo đó là một câu mô tả tương ứng với nội dung của file. Việc này giúp đảm bảo văn bản được tổ chức rõ ràng và dễ hiểu.                                                                                                                                                                                                                              | Đối với cái phần văn bản, thì chúng ta sẽ có cái định dạng... chúng ta chuẩn bị trước cái định dạng đó là... tên của cái file của mình. Và cái câu mô tả... tương ứng với cái nội dung đó. |       0.5      |           0.955833 |                 nan |                1 |\n",
      "| Một ví dụ về bài toán phức tạp mà mạng Perceptron không thể giải quyết là gì? | ['Cụ thể ở đây, các tham số theta 0, theta 1, theta 2 và theta m, thì đây chính là các tham số của phương trình đường thẳng. Và chính xác hơn là của mặt phẳng tại vì chúng ta sẽ xét trong không gian nhiều chiều. Và cái mặt phẳng này nó sẽ chia không gian ra làm hai phần, một cách tuyến tính. Và ví dụ như chúng ta có tập hợp các cái điểm như thế này, thì nếu như các điểm mà có thể phân chia được bởi một cái siêu phẳng hay là một cái mặt phẳng, thì khi đó chúng ta có thể sử dụng cái mạng Logistic Regression hoặc là Perceptron. Tại vì với cái đường thẳng này thì nó sẽ tách ra làm hai, một cách dễ dàng đối với dữ liệu tuyến tính. Vấn đề xảy ra đó là mỗi một cái Perceptron thì nó chỉ có thể giải quyết được một cái bài toán tuyến tính. Trong khi đó sẽ có rất nhiều những cái bài toán phức tạp hơn và chúng ta không thể sử dụng một cái mạng Perceptron để có thể giải quyết được. Chúng ta lấy một cái tình huống ví dụ đó là hai cái tập điểm nằm trong và nằm ngoài vòng tròn.', 'Đó là hình tròn và dấu cộng, các điểm tròn và cộng như thế này. Thì chúng ta thấy là với một đường thẳng thì không thể nào tách ra làm hai phần được, mà chúng ta cần phải có một cái tổ hợp các cái đường thẳng. Cụ thể đó là chúng ta sẽ cần có cái tổ hợp này để mà chia ra làm hai. Thế thì để mà có thể phối hợp và tổng hợp được các cái thông tin của một loạt các cái đặc trưng như thế này, thì nó đòi hỏi chúng ta không phải chỉ tăng theo cái chiều dọc như thế này. Tại vì với mỗi một cái neuron này thì chúng ta sẽ có một cái bộ phân loại yếu, đó là một cái mạng phẳng. Nhưng các cái mạng phẳng này muốn mà có thể giải quyết được bài toán vi tuyến thì nó đòi hỏi phải có một cái thao tác để tổng hợp. Và thao tác tổng hợp đó thì nó sẽ được đặt ở cái layer tiếp theo. Còn nếu không có cái layer này thì các cái neuron nó sẽ là độc lập nhau. Neuron số 1, neuron số 2 và neuron số 3 là độc lập. Nó sẽ không thể phối hợp với nhau. Nhưng nhờ có cái neuron số 4 ở cái layer tiếp theo, nó tổng hợp lại để phối hợp và tạo ra một cái đặc trưng mạnh hơn. Đó là ý nghĩa của việc mà chúng ta tăng thêm một cái layer, nó sẽ giúp chúng ta tạo ra một cái đặc trưng mới. Vì vậy, với một neuron thì đặc trưng của chúng ta quá đơn giản nên không giải quyết được các bài toán phức tạp hoặc là bài toán vi tuyến. Vậy thì đến với cái mạng neural network, nhờ có các cái hidden layer, tức là các cái lớp ẩn. Các cái lớp ẩn này thì nó sẽ tổng hợp, ví dụ như một cái node ở đây, chúng ta thấy là kết nối với các cái node ở phía trước. Tức là nó đang tổng hợp đặc trưng. Các cái đặc trưng ở lớp trước, đó là những đặc trưng đơn giản. Nhưng mà qua cái quá trình tổng hợp ở đây thì nó sẽ tạo ra các cái đặc trưng mới phức tạp hơn và nó phi tuyến hơn. Rõ ràng các cái đặc trưng phi tuyến tính, nó sẽ giúp cho chúng ta giải quyết được những cái bài toán phức tạp. Các cái đặc trưng phức tạp sẽ giúp cho chúng ta giải quyết được các cái bài toán phi tuyến tính. Và MLP, tức là cái mạng neural network của mình, một cái tên gọi khác của mạng neural network, nó sẽ tổng hợp đặc trưng phức tạp hơn từ các cái đặc trưng đơn giản qua các cái lớp ẩn. Với lớp ẩn này, tổng hợp đặc trưng đơn giản để tạo ra thành các đặc trưng mới.', 'Hay nó cách khác đó là đặc trưng đơn giản. Nó không thể giúp chúng ta giải quyết được các bài toán phức tạp. Do đó chúng ta cần có một cái nhu cầu, đó là tăng cái độ sâu theo cái trục đứng như thế này. Thì để làm chuyện đó chúng ta sẽ dùng cái kiến trúc đó là DeepStack chúng ta sẽ trồng nhiều lớp lên với nhau. Ở đây là layer 1, layer 2 và layer 3, nó được trồng lên nhau. Và với mỗi cái layer thì chúng ta sẽ tổng hợp được cái thông tin đặc trưng ở một cái cấp độ. Ví dụ như ở đây sẽ là low level feature, đây là mid level feature, đây là low và đây sẽ là high level feature. Thì khi đến cái đặc trưng ở trên tầng số 3 thì nó cũng giống như cái mạng CNN của một xử lý ảnh. Đó là đặc trưng của mình đã có cái tính chất gọi là đặc trưng phức tạp hơn, phi tuyến tính hơn. Thì hy vọng là nó giúp chúng ta giải quyết được cái bài toán khó. Thì như vậy khi chúng ta trồng các layer lên thì chúng ta sẽ có cái trạng thái ẩn từ lớp thứ y. Thì SI sẽ là đầu vào cho cái layer thứ y cộng 1, như vậy cái trạng thái ẩn của layer thứ y chính là cái SI. Nó sẽ là cái input để đi tính cái SI cộng 1. Thì layer số 1 nó sẽ truyền lên layer số 2, rồi lên layer số 3. Thì đó là cái ý nghĩa. Và chúng ta sẽ có cái công thức ở layer số 1 là S1 là ở đây. Và ở đây, ví dụ như là S1 tại vị trí T, thì nó sẽ được tính toán giống như một cái ANN bình thường. Nó cũng sẽ nhận vào cái thông tin của quá khứ tại cái tầng thứ 1. Nó nhận thông tin từ đây sang. Rồi kết hợp với thông tin tại cái thời điểm XT hiện tại để tổng hợp ra cái S1T. Sau đó chúng ta sẽ đi tính S2T. Nó sẽ tổng hợp thông tin từ 2 phía. Thứ nhất là từ quá khứ. Nhưng mà quá khứ tại cái tầng thứ 2, tức là ST-1-2. Sau đó nó sẽ tổng hợp, nó sẽ nhận cái thông tin từ ST1, S1T từ dưới lên. Tức là layer số 2 sẽ được tính toán từ layer thứ 1. Đây chính là chúng ta đang tạo ra một đặc trưng mới. Một đặc trưng tổng hợp mới từ cái lớp phía trước đó. Tương tự như vậy, từ S2T, chúng ta sẽ đi tính S3T. Và đồng thời nó sẽ còn có kết hợp thông tin của S3T-1 ở phía trước là thông tin của quá khứ, ở tầng thứ 3. Như vậy thì đây chính là công thức và kiến trúc của DeepStack ANN. Trong một số tài liệu người ta luôn khuyến nghị, đó là chúng ta nên sử dụng DeepStack nhưng mà không nên dùng quá nhiều. Ví dụ như là chúng ta dùng từ 2 cho đến khoảng 4 lớp là vừa đủ.', 'Vậy thì bây giờ chúng ta sẽ có những cái giải pháp gì? Đó là chúng ta sẽ tái tham số lớp lấy mẫu. Thì cái lớp lấy mẫu của chúng ta chỉ là cái lớp này. Đây là cái lớp lấy mẫu. Hay là sampling layer. Rồi, nếu như chúng ta giữ nguyên cái công thức đó là z là xấp xỉ, z là sampling theo cái phân bố mi và sigma bình phương. Rồi, thì rõ ràng chúng ta sẽ không có thể tính toán được.', 'thì cách mà chúng ta sẽ thực nghiệm đó chính là chúng ta sẽ làm cái lưới từ trừ 5 cho đến 10 và từ trừ 10 cho đến 5 rồi, thì chúng ta sẽ thử ha chúng ta sẽ vẽ cái lưới này rồi, trừ 5 là ở đây rồi chúng ta sẽ lấy cái lưới chụp cái màn hình này thì trừ 5 sẽ là ở đây rồi 10 sẽ là ở đây trừ 5 cho đến 10 trừ 5 cho đến 10 thì 10 sẽ là ở đây rồi và trục tung thì là sẽ từ trừ 10 cho đến 5 trừ 10 cho đến 5 là ở đây trừ 10 cho đến 5 là ở đây rồi, như vậy cái lưới mà dự định chúng ta sẽ vẽ là ở khu vực này trục hoành là từ trừ 5 cho đến 10 và trục tung là từ trừ 10 cho đến 5 như vậy thì chúng ta sẽ có một cái khung vuông rồi, sau đó chiến thuật của chúng ta là gì? chúng ta sẽ chia lưới nó ra ví dụ như trong trường hợp này chúng ta sẽ chia ra làm 12 khoảng cách đều nhau rồi, sau đó chúng ta cũng sẽ chia lưới theo chiều dọc như vậy rồi, thì với mỗi một cái điểm trên cái mắt lưới này lấy ví dụ như cái điểm ở đây chúng ta sẽ dùng một điểm đen ví dụ như một cái điểm trên cái mắt lưới này thì nó sẽ là một cái vector z mà chúng ta lấy ra, chấm lên trên cái lưới và chúng ta sẽ qua cái hàm decoder để xem nó ra một cái tấm ảnh gì nó như thế nào sau đó chúng ta lấy cái ảnh này chúng ta sẽ vẽ lên trên thành một cái ma trận với cái ảnh này chúng ta sẽ vẽ ra một ảnh với một cái điểm z ở đây chúng ta sẽ decode ra và vẽ ảnh lên với cái điểm này, điểm này chúng ta decode ra và vẽ ảnh lên thì chúng ta sẽ ra một cái ma trận các điểm ảnh và chúng ta sẽ quan sát xem nó có cái tính chất gì đặc biệt phải không Rồi, thì đó chính là cái ý tưởng của cái hàm Plot Reconstructed chúng ta sẽ chia ra thành các latent space với n ở đây là bằng 12, chúng ta sẽ chia ra làm 12 khoảng rồi lấy cái x và cái y này chúng ta sẽ có được cái latent z là cái điểm màu đen mà chúng ta đã vẽ rồi qua cái hàm decoder chúng ta sẽ ra được x hat tức là cái ảnh được tạo sinh ra và ảnh này sẽ được reset về cái kích thước là 28 x 28 và sau đó vẽ lên cái ma trận ảnh rồi, thì chúng ta sẽ chạy cái đoạn code này đó thì với cái ví dụ này chúng ta có thể thấy đó là ở những cái khu vực phía trên đó sẽ ra một cái hình thù gì đấy và chúng ta không cảm nhận được đó là một cái con số khu vực ở giữa ở đây cũng vậy nó sẽ có lẫn lộn rất nhiều những cái hình ảnh ở trong đó có thể có chứa nhiều con số dẫn đến là mình nhìn mình không cảm nhận được đó là số gì khu vực này cũng vậy thế thì chiếu lên trên cái hình ảnh của cái không gian của mình thì những ảnh ở góc phía trên bên đây là ở khu vực trừ 5 cho đến 5 trừ 5 cho đến 5 tức là nó nằm ở cái khu vực màu trắng và cái khu vực màu trắng này khi chúng ta decode ra thì nó sẽ tạo ra một cái ảnh không có ý nghĩa không giống cái con số nào hết đó thì đây chính là cái điểm yếu của mô hình auto encoder', 'Tại vì nó phải nhớ hết các cái dữ liệu. Và nó có thể mắc kẹt ở những cái điểm cực tiểu cục bộ. Thì cái nguyên nhân đó là vì nó thiếu những cái bước nhảy vọt để thoát ra. Thì chút nữa chúng ta sẽ cùng phân tích là cái thiếu bước nhảy vọt này nó thể hiện như thế nào. Trong stochastic gradient descent thì nó có những cái ưu điểm vượt trội so với lại cái thuật toán Batch gradient descent. Tuy nhiên là cái điểm yếu của nó vẫn là nó phải tính toán nhiều lần.', 'Bean, tương ứng là cái hàm denoise Và ở đây chúng ta denoise khi chúng ta không biết trước cái đáp án, chúng ta chỉ có ảnh, trước đó là XT thôi Và chúng ta sẽ phải đi xác định XT trừ một Trong khi đó cái anh chàng này thì anh có cái đáp án là x0 nên anh có thể xác định được cái phân bố nhiễu của này một cách chính xác Thì anh này sẽ tìm cách để bắt chước cái anh này Và cái quá trình huấn luyện thì chúng ta sẽ tính toán trên cái Q của XT trừ một Và dựa trên cái công thức xác suất có điều kiện và Bayes Và cái kết quả thu được, cuối cùng thu được đó là một cái phân bố Gauss Q XT cho trước XT trừ một của mình, đó là một cái phân bố Gauss như thế này Đó là phân bố màu xanh lá như thế này Và đây là Routroot Và cái phân bố này thì nó sẽ được tham số hóa bởi cái công thức đó là Mu của Q, XT, X0 và Sigma của Q T Thế thì hai cái Mu và Sigma này đó là Mean và Variance được tạo ra từ cái X0, XT và T Trong đó cái thành phần variance ở đây là chỉ phụ thuộc vào T thôi Nó không phụ thuộc vào các cái X0 và XT Lý do đó là vì các cái bán kính này là giống nhau, không thay đổi Nó là những cái hình tròn giống nhau cùng một cái bán kính Bán kính của nó sẽ thay đổi theo T Nhưng mà nó sẽ là chỉ phụ thuộc vào biến T thôi, không phụ thuộc vào các cái biến X của mình Và công thức này thì nó có một cái ý nghĩa khác, đó là chúng ta sẽ tìm cách để tối thiểu hóa cái Mean của hai phân phối Lý do đó là vì hai cái phân phối này có độ lệch giống nhau Hai cái phân bố này nó có độ lệch giống nhau Tại vì nó chỉ phụ thuộc vào T Nó chỉ là một cái biến phụ thuộc vào T hoặc chính xác hơn là phụ thuộc vào các cái alpha T Do đó thì hai cái này là khớp rồi Cái độ rộng của cái phân bố này là khớp rồi Giờ chỉ là làm sao để cái tâm của hai cái hình cầu, tâm của hai cái phân bố này là về khớp lại với nhau thôi Do đó thì cái việc này nó tương đương với việc chúng ta tối thiểu hóa Mean của hai phân phối Một xanh là công thức này và một nâu là công thức này Trong đó, cái Mean của cái phân phối P theta thì đó là một cái hàm tham số hóa bởi Phi Tức là nói cách khác, chúng ta sẽ xây dựng một cái hàm để ước lượng cái mu này Ước lượng cái mu này từ XT trước đó và cái giá trị T Vậy thì cái mô hình này thì chúng ta sẽ có hai cách, xin lỗi, có ba cách tính và diễn giải khác nhau Cái công thức trước đó nó sẽ được đưa về cái công thức này, tức là nó sẽ tương đương với việc chúng ta đi minimize hai cái phân bố Đây chính là hai cái Mean của hai phân phối Mean của cái phân phối Và chúng ta mong muốn hai cái phân phối này khớp với nhau, giống như trong cái nhận xét trước Vậy thì cái công thức của Mu-Q là nó sẽ có công thức như thế này Chúng ta hoàn toàn có thể tính được, chứng minh được cái công thức này nhưng mà nó sẽ hơi mất thời gian Chúng ta chỉ ghi cái kết quả cuối cùng thôi ha Thì cái Mu-Q nó sẽ có cái công thức như trên Và chúng ta sẽ có ba cách để chúng ta thực hiện cái việc mà tối ưu cái công thức này Cách thứ nhất đó là chúng ta sẽ đưa về cái Mu-Q Mu của theta x t là bằng cái công thức này Và khi đó chúng ta lấy cái Mu-Q trừ cho Mu theta, hai cái công thức này trừ cho nhau Thì chúng ta thấy là cái thành phần này loại bỏ Và cái thành phần này ở trên thì chúng ta sẽ xem như là hằng số Do đó thì chúng ta chỉ việc tối ưu sao cho cái x theta mũ x t t xấp xỉ với x0 Thế thì cái công thức này nói một cách khác Đó là chúng ta đang làm sao mà cái mô hình của mình có khả năng khôi phục được ảnh gốc từ mỗi step Lưu ý là trong cái công thức này chúng ta được tính tổng trên nhiều step chứ không phải chỉ tại một thời điểm T sẽ chạy từ 2 cho đến t lớn Và ở đây chính là cái ảnh mà mình khôi phục được Ảnh gốc, ảnh ban đầu khôi phục được Tức là chúng ta luôn mong muốn khôi phục lại cái ảnh ban đầu Và cái x mũ theta này nó phải xấp xỉ với x0 Đây là route root nè Đây là route root để mà chúng ta phải huấn luyện để mà bắt chước cái x0 này Thì đây là cái cách số 1 và cái cách số 1 cũng tương đương với lại cái cách số 2 Tức là nó chỉ là cái cách cách để mà biểu diễn khác nhau thôi Thì cái công thức mu của Q nó cũng có thể biểu diễn dưới dạng là một phần alpha t x t Nhân cho cái công thức này Với cái đại lượng epsilon này là tuân theo cái phân bố Gaussian 0 1 Và xt thì trong những slide trước chúng ta đã có cái công thức tính xt từ x0 và epsilon rồi Do đó chúng ta sẽ tính từ cái công thức này chúng ta sẽ suy ra được công thức của epsilon Thì epsilon là bằng cái công thức này Thì từ đó chúng ta sẽ ra được mu của theta xtt là bằng cái công thức này Và khi chúng ta lấy 2 cái hiệu số này chúng ta trừ cho nhau thì nó khử Và cái thành phần này là hằng số do đó thì nó sẽ tương đương với cái việc epsilon theta xt t trừ cho epsilon Hay nói cách khác đó là cái mô hình này là chúng ta dự đoán cái nhiễu của từng step Chúng ta đi dự đoán nhiễu của từng step Với step chạy từ 2 cho đến t thì làm sao cho cái nhiễu này là nhỏ nhất Với step chạy từ 2 cho đến t thì làm sao cho cái nhiễu này là nhỏ nhất Và công thức cách thức làm số 3 đó là chúng ta đi dự đoán cái vector gradient của logpt Vector gradient của logpt này hình ảnh nói hiểu một cách nôm na đó chính là cái hướng Vector hướng gradient là thể hiện hướng mà Thì cái hướng để mà hướng đến cái phân bố của cái ảnh xt Hướng đến cái phân bố của cái xt của mình Rồi thì cái s theta t xt này nó sẽ tìm cách là cực tiểu hóa hay nói cách khác là dự đoán được cái hướng này Thì tương tự như vậy chúng ta có 2 cái công thức này và khi chúng ta trừ cho nhau Thì nó sẽ 2 cái thành phần này là hằng số thì nó sẽ đưa về cái công thức này Thì đây là cái cách làm số 3 và cái công thức này nó gọi là score function Rồi, vậy thì bản chất của 3 cái cách này đó là giống nhau và chúng ta thực hiện theo cái cách số 1 Hay là chúng ta làm theo cái cách số 2 thì cũng giống nhau Cách số 1 đó là chúng ta tìm cách để tính cái L2 Tức là cái sai số giữa cái hàm dự đoán cái ảnh so với lại cái x0 ban đầu Còn đối với cái công thức của, xin lỗi trong cái công thức này thì nó để nhầm Nó không phải là mu theta xt mà nó sẽ là x mũ theta xt 1 Rồi, thì chúng ta mong muốn là cái x mũ theta này là khớp với lại cái x0 ban đầu Còn trong cái công thức của cái cách số 2 đó là qua cái hàm, qua cái mô hình có cái theta ở đây Vậy thì các bạn có thể nhận ra cái nhiễu này, thì chúng ta sẽ dự đoán được cái nhiễu Và cái nhiễu này thì chúng ta tính cái sai số với lại cái nhiễu ban đầu này của mình Tức là yêu cầu cái mô hình dự đoán được cái nhiễu mà chúng ta đã thêm vào trước đó Và cách làm số 3 đó là chúng ta đi dự đoán cái hướng để cho cái mô hình của mình dịch chuyển vào Vậy để khái quát hóa các cái cách làm của khác nhau thì chúng ta sẽ dùng cái không gian latent như sau Một cái không gian này chính là cái phân bố Pdata của mình Và x0 đây chính là cái ảnh mà chúng ta đã lấy mẫu được Sau đó thì chúng ta nhân với lại căn của alpha t x0 thì đây chính là cái mean của cái xt Nhưng mà chưa có cái xt tại vì chúng ta sẽ phải xác định dựa trên cái variance nữa Và cái variance giả sử như cái epsilon của mình là sampling là ở đây theo phân bố Gauss Thế thì chúng ta sẽ nhân với lại căn của 1 trừ alpha t thì nó sẽ ra cái vector màu đỏ này Và sau đó chúng ta lấy cái vector màu đỏ này đem qua đây Thì chúng ta sẽ ra được cái xt của mình Đem ra, tính ra được cái xt của mình Như vậy thì cái xt nó sẽ là bằng căn của alpha t x0 cộng cho căn của 1 trừ alpha t epsilon thì nó là nằm ở đây Và bây giờ nhiệm vụ của chúng ta ở đây là cái quá trình encode Bây giờ chúng ta decode để làm sao cho từ cái xt này có thể đi được trở về cái xt x0 Vậy thì trong cái quá trình huấn luyện thì chúng ta sử dụng cái cách số 1 Cách số 1 của mình đó là gì? Là chúng ta sẽ đi ước lượng cái xtt hay cái khác đó là đang đi dự đoán ảnh gốc ban đầu x0 Và chúng ta thấy là cái điểm này nó mong muốn là làm sao cho 2 cái này là khoảng cách nhỏ nhất Với cái cách làm số 1 thì cái mu theta xtt nó sẽ có cái công thức này Trong đó cái thành phần x0 xtheta mũ này tức là cái giá trị mà chúng ta dự đoán Và khi chúng ta có được cái xt theta 0 này rồi thì chúng ta sẽ dịch chuyển Chúng ta sẽ dịch chuyển cái xt đi theo cái hướng này thì đây sẽ là cái xt trừ 1 Đi về cái phân bố của xt trừ 1 Đối với cái cách làm số 2 thì chúng ta sẽ đi dự đoán nhiễu dựa trên cái công thức này Thì chúng ta sẽ có cái nhiễu dự đoán và chúng ta kỳ vọng là cái nhiễu dự đoán của mình khớp với cái nhiễu thực tế Thì khi mà chúng ta xác định được cái nhiễu đó thì chúng ta cũng sẽ xác định được cái phân bố của mình là P của xt trừ 1 Và cái cách làm số 3 đó là chúng ta sẽ xác định dựa trên cái gradient Thế thì cái gradient của mình nó sẽ được ước lượng bởi cái công thức của xt theta Và chúng ta mong muốn là cái này nó sẽ xấp xỉ Cái xt theta này nó sẽ xấp xỉ với lại cái nabla của cái log của mình, p theta Mong muốn nó xấp xỉ Thế thì khi chúng ta tính ra được cái xt theta rồi thì xt của mình sẽ được dịch chuyển về hướng này Dịch chuyển đi về cái hướng này dựa trên cái công thức này Vậy thì tóm lại cho dù chúng ta làm theo cách nào đi chăng nữa thì nó cũng hoàn toàn tương đương nhau Đó là chúng ta đang dịch chuyển từ cái xt về cái xt trừ 1, sau đó từ xt trừ 1 về cái xt trừ 2 Cứ như vậy, kéo cho đến khi nào mà tiến về cái x0, sao cho nó khớp với lại cái x0 nhất Thì đó chính là cái cách thức mà cái mô hình của mình huấn luyện De-noise và mục tiêu của mình đó là làm sao tìm các cái tham số theta để cho 3 cái mục tiêu trên, đó là thỏa mãn Một đó là cái gradient để hướng đến cái phân bố là khớp nhất hoặc là dự đoán được cái nhiễu là chính xác nhất hoặc là chúng ta khôi phục lại được cái ảnh gốc giống với lại cái x0 nhất, thì đó là 3 cái cách khác nhau Thì trên đây chúng ta đã cùng tìm hiểu qua 3 cái cách thức tương đương để mà có thể huấn luyện được cái mô hình diffusion Hy vọng là các bạn có thể hình dung được cái cách thức mà mô hình nó vận hành qua cái bước gọi là encoding Và encoding thì chúng ta sẽ không có tham số nhưng mà decode, khi chúng ta decode ngược lại thì chúng ta sẽ đi tìm cái theta này Sao cho cái việc xấp xỉ, đó có 3 cái cách để xấp xỉ, cái cách đầu tiên đó là xấp xỉ nhân noise Cách thứ 2 đó là xấp xỉ theo cái x0 Cách đầu tiên là xấp xỉ theo nhân noise Cách thứ 2 đó là xấp xỉ theo x0 Cách thứ 3 đó là xấp xỉ theo cái log của cái p Theta, tức là cái hướng đi của mình, nó xấp xỉ Trong những phần tiếp theo thì chúng ta sẽ cùng tìm hiểu về những cái chủ đề mở rộng của cái mô hình diffusion liên quan đến cái việc là điều hướng liên quan đến việc tăng độ phân giải, tốc độ huấn luyện', 'Cho đến thời điểm này, mạng RNN, cho dù với các biến thể như Deep Stack, hay Bi-directional thì nó vẫn còn bị một cái điểm yếu rất là lớn đó chính là vấn đề về điểm nghẽn thông tin, hay còn gọi là Bottleneck Thì đây là cái hiện tượng gì? Chúng ta sẽ cùng xem một vài cái ví dụ để minh họa Trên đây, đó là một cái kiến trúc ANN được sử dụng để encode một cái câu văn bản nguồn Và decode ANN thì dùng để dịch sang một cái văn bản đích Ví dụ như đây là chúng ta dịch từ tiếng Anh sang tiếng Pháp Thế thì cái điểm nghẽn thông tin nó sẽ thể hiện ở cái bottleneck này Tại vị trí cuối cùng mà chúng ta encode câu văn bản nguồn thì mọi thông tin của văn bản nguồn đều được chứa trong duy nhất một vector này. Và đây chính là cái điểm nghẽn của mình, khiến cho mô hình của mình không đủ thông tin toàn cục và thông tin cần thiết tại một thời điểm để chúng ta dịch ra ví dụ tại cái vector này, chúng ta muốn dịch ra cái từ rơ thì có thể cái thông tin của cái từ i là cái từ quan trọng nhất để giúp chúng ta dịch cái từ rơ này nè thì cái hàm lượng thông tin của nó đã bị mai một rất là nhiều rồi vì từ i khi đến được cái điểm nghẽn này nè thì nó đã bị biến đổi một lần, hai lần, ba lần, bốn lần và năm lần và đây là một cái ví dụ rất là bé trong những cái bài toán phức tạp hơn ví dụ như là bài toán tóm tắt văn bản thì để kể từ lúc chúng ta đọc hết cái văn bản cho đến lúc chúng ta bắt đầu tóm tắt nó có thể lên đến hàng trăm hoặc thậm chí là hàng ngàn chữ hàng ngàn cái token thì dẫn đến là cái từ ở đầu tiên nó đến cái chỗ điểm nghẽn này nè nó đã bị quên từ ai đã bị quên nhiều mình nói nó quên hết thì cũng không đúng, tại vì có thể chúng ta sử dụng một số biến thể như LSTM để giúp chúng ta lưu được những thông tin quan trọng nhưng mà đâu đó nó vẫn sẽ bị quên quên đi, một phần, quên nhiều khi từ ai này bị quên nhiều, đến lúc chúng ta cần dịch ra từ r, chúng ta bắt đầu từ start là bắt đầu quá trình decode thì khả năng chúng ta ra từ r này là thấp trong khi đó nếu chúng ta bắt đầu dịch, mà sau khi chúng ta vừa đọc xong từ ai thì xác suất chúng ta dịch ra được từ r, từ r trong tiếng Pháp là từ ai của mình, thì nó sẽ cao hơn đó chính là mô tả cho hiện tượng là điểm nghẽn thông tin khi chúng ta dự đoán đến từ xua thì rõ ràng là thông tin của từ xua ban đầu ở đây khi chúng ta lan truyền đến từ xua này cũng hoàn toàn tương tự, nó đã bị mất thông tin rất nhiều rồi Do đó, điểm nghẽn thông tin này cần phải giải quyết. Cơ chế để giải quyết là cơ chế Attention.', 'Do đó nó sẽ chia cái không gian của mình ra. Chia cái không gian của mình ra. Ví dụ vậy thành 4 phần và với mỗi một cái điểm thì nó sẽ thuộc vào một phần chứ nó không có thuộc vào hai cái phần. Gây ra cái sự nhập nhằng giống như trong cái mô hình logistic regression.', 'Và vấn đề của momentum đó là gì? Đối với những khu vực có độ dốc bất thường thì ví dụ như chúng ta thấy trong sơ đồ này Cái phác thảo của HempLoss, chúng ta thấy là cái độ dốc của mình tăng lên, nó dốc xuống rất là cao, sau đó lập tức nó đi ngang, rồi sau đó nó lại lập tức đi lên Tức là nó thay đổi trạng thái, đi xuống, đi ngang và sau đó là đi lên một cách rất là ngắn như vậy, thì đó chính là cái độ dốc bất thường và nó sẽ khiến cho nó có rất nhiều những cái dao động mà bật qua bật lại, bật qua bật lại giữa hai cái thành dốc này. Cụ thể hơn, đó là chúng ta xét tại một cái điểm ở đây. Thì nếu như cái thành phần mà theo cái theta 1 của mình, mà đạo hàm của mình nó lớn, tức là cái giá trị độ lớn này, nó lớn hơn so với lại cái thành phần theo theta 2, khi chúng ta tổng hợp lại là cái vector tổng hợp thì nó sẽ bị thiên lệch về phía có thành phần radian lớn tức là cụ thể đây là theta 1 khi đó là nó sẽ không có cân bằng mà nó sẽ bật qua bên tay phải sau đó tại vị trí này chúng ta lại tiếp tục tính cái radian và chúng ta lại thấy cái hiện tượng mất cân bằng này lập lại thì khi chúng ta cập nhật thì nó cũng sẽ bị thiên lệch về cái phía mà có cái thành phần lớn hơn, đó chính là thành phần theta 1 tức là một khi cái đạo hàm của mình theo thành phần, một cái thành phần nào đó mà lớn thì nó sẽ gây ra cái hiện tượng là bật qua bật lại trong khi đó cái đường tối ưu, ideal path thì lẽ ra nó phải là đường đường màu xanh ở đây, nó sẽ phải đi theo cái trục này Nó phải đi theo cái trục này, hay là đi theo cái trục của theo cái hướng của theta, theta2 Thì ở đây nó lại cứ bật qua trái, bật qua phải Thì bây giờ chúng ta sẽ cải tiến cái momentum bằng cách nào Thì muốn cải tiến thì chúng ta sẽ phải xem cái nguyên nhân của nó là gì Nguyên nhân đó là vì khi chúng ta có hai cái thành phần radian theo theta1 và theta2 Nếu thành phần nào đó lớn thì lẽ ra chúng ta sẽ phải giảm learning rate của nó xuống Nguyên nhân đó là do chúng ta dùng chung learning rate alpha dùng cho g, g là đạo hàm của J theo theta 1 và đạo hàm của J theo theta 2 một cách tổng quát thì nó có thể là có theta 3 theta n thì alpha a đang dùng chung cho radian theo theta 1 và radian theo theta 2 Bây giờ chúng ta mong muốn mỗi thành phần này sẽ có 1 cái alpha riêng Và nó sẽ giúp chúng ta cân bằng lại, đó chính là ý tưởng của cải tiến adaptive learning rate Giảm dao động dựa trên độ lớn của radian cập nhật gần đây, chúng ta giảm sự dao động đó Ý tưởng chính đó là, giả sử chúng ta có vector g là bằng hai thành phần, là g1 và g2 Nếu như chúng ta lấy alpha nhân với g, thì alpha mà dùng chung Thì không, bây giờ chúng ta sẽ dùng riêng, mỗi cái thành phần này sẽ có một cái alpha riêng trong đó, ở đây là ý tưởng đầu tiên là tách riêng ha, tách learning rate cho từng tham số và cái ý tưởng tiếp theo, đó là cái radian mà lớn thì learning rate nó sẽ nhỏ tức là nếu cái thành phần theo G1 mà lớn, G2 mà nhỏ, ví dụ vậy thì chúng ta sẽ có cái hệ số alpha 1 cân bằng ngược trở lại nó cân bằng ngược trở lại và thành phần G2 mà nhỏ thì chúng ta sẽ có cái Alpha 2 và khi đó thì cái vector tổng hợp của mình nó sẽ đều hơn thay vì là nó bị thiên lệch như thế này Đường màu đỏ là đường mà nó bị thiên lệch. Nó bị lệch về phía theta, phía theta 1. Rồi, bằng ngược lại thì thành phần theta 2 nhờ có cái alpha 2 lớn, nó sẽ kéo ra để cho nó cân bằng cả hai hướng. Và chi tiết thuật toán Root Mean Square Propagation, đó là chúng ta sẽ khởi tạo với cái alpha là bằng 0.01 và beta thì đây là cái hệ số decay rate tức là cái hệ số mà để cập nhật cho cái momentum thì chúng ta nhìn một cái công thức của cái thuật toán root mean square là V tức là cái vận tốc cập nhật tham số của mình là cái thành phần ở phía trên mà chúng ta khoanh vùng ở đây Cách làm cũ của alpha là theta trừ alpha nhân cho nabla J Alpha là đây và đạo hàm radian là G Cách làm cũ là đạo hàm quá lớn, thành phần radian lớn sẽ lớn hơn những thành phần còn lại R là momentum để phục vụ chuẩn hóa learning rate Chuẩn hóa Learning Rate, tức là thành phần nào của radian này mà lớn thì cái alpha của nó sẽ nhỏ và thành phần nào mà của radian này mà nhỏ thì cái alpha của mình nó sẽ lớn Đó, thì cái cách làm của chúng ta là như vậy R này nó là một cái vector, chúng ta thấy là R được in đậm, nó là một cái vector thì khi alpha chia cho căn của một vector thì nó sẽ biến thành một vector thì chút nữa chúng ta sẽ ghi rõ hơn cái công thức của nó Đây là hệ số tỷ lệ tùy chỉnh, tức là Adaptive Scaling Factor Với mỗi thành phần của G, chúng ta sẽ có một cái alpha riêng Tại sao nó là như vậy? Tại sao alpha chỉ có một cái giá trị scalar là một giá trị? Tại sao khi chia cho căn R nó lại biến thành hệ số tùy chỉnh? Chút nữa chúng ta sẽ chứng minh chi tiết hơn Mỗi tham số sẽ có một cái hệ số tỷ lệ khác nhau và ở đây chúng ta sẽ thấy là nó có một cái thành phần hơi lạ đó là epsilon là bằng một cái con số rất là bé thì ở đây đó là để chống cho cái việc là có một cái thành phần r nào đó mà bằng 0 có một cái thành phần trong r nào đó mà bằng 0 thì khi đó chúng ta sẽ bị cái lỗi là division by zero chia cho xuống 0 thì chúng ta sẽ cộng thêm epsilon để chống cái hiện tượng đó Và phép toán mà r chia cho căn của epsilon cộng r được thực hiện trên từng phần tử Bây giờ chúng ta sẽ cùng xem xét Giả sử như g là bằng 2 thành phần là g1 và g2 Rồi, khi đó g-r là phép tích Hadamard trên từng phần tử d-r-g là g1 bình phương, g2 bình phương sau đó nó sẽ được cộng với thành phần chuẩn hóa ở phía quá khứ đây là beta của quá khứ, tức là 90% thành phần r chuẩn hóa R là thành phần để chúng ta chuẩn hóa learning rate theo kiểu đạo hàm thành phần nào mà càng nhỏ thì learning rate sẽ càng nhỏ Trong công thức thành phần chuẩn hóa này chúng ta sẽ chia cho cái căn, thế thì tại sao nó lại có cái căn Nếu chúng ta lại bỏ đi thành phần epsilon đây để cho nó dễ hình dung epsilon này chỉ mang tính chất đó là chống cái việc chia cho 0 thôi còn nó sẽ không có nhiều ý nghĩa lắm trong việc chuẩn hóa thì khi chúng ta lấy alpha mà chia cho căn của epsilon cộng cho r thì nó sẽ xấp xỉ tại vì có cái epsilon này nên mình mới để cái dấu xấp xỉ đó là alpha chia cho căn của vector g1 bình g2 bình cộng cho thành phần quá khứ nhưng tại thời điểm ban đầu chúng ta thấy là r bằng 0 nên xem như chúng ta tạm bỏ qua thành phần này để chúng ta dễ hình dung khái niệm của việc chuẩn hóa này là gì thì là g1 bình phương và g2 bình phương Thì ở đây là chúng ta thực hiện phép căn là phép căn trên ElementWise do đó nó sẽ là căn của các thành phần bên trong như vậy thì nó sẽ là trị tuyệt đối của G1 và trị tuyệt đối của G2 Rồi, và vì đây là cái phép chia trên phép áp dụng trên từng phần tử do đó thì cái này nó sẽ là bằng một cái vector trong đó alpha chia cho trị tuyệt đối của G1 và α chia cho trị tuyệt đối của G2 như vậy thì chúng ta nhìn lại nếu như G1 của chúng ta mà lớn nếu G1 mà lớn thì khi đó α chia cho G1 đó chính là tương ứng cái α1 của mình đề cập trong slide trước thì α1 là bằng α chia cho trị tuyệt đối G1 G1 lớn thì trị tuyệt đối của G1 sẽ lớn và 1 phần trị tuyệt đối của G1 sẽ nhỏ do đó thằng này sẽ là nhỏ Ngược lại, nếu như G2 mà nhỏ thì khi đó là 1 phần trị tuyệt đối của G2 sẽ lớn do đó thành phần này sẽ lớn như vậy là nó đáp ứng được yêu cầu mà chúng ta đã thiết kế ban đầu thành phần gradient nào mà lớn thì learning rate sẽ nhỏ và ngược lại Thì khi đó, đây chính là thành phần chấp chơi cho chúng ta chuẩn hóa Thì khi đó cái công thức V này của mình sẽ biến thành là V là bằng alpha 1, tức là alpha chia cho trị tuyệt đối của G1 nhân với lại G1 Thành phần thứ 2 sẽ là alpha chia cho trị tuyệt đối của G2 Ngoài việc chia chuẩn hóa này sẽ khiến cho 2 thành phần gradient cân bằng hơn Đây là ý tưởng để giúp chúng ta thoát ra khỏi vấn đề thiên lệch thì chúng ta xét trong hình ở bên tay phải ở đây chúng ta thấy là tại vị trí A thì nó bị thiên lệch về hướng theta 1 nhưng mà nhờ có cái thành phần alpha 1 và alpha 2 được chuẩn hóa ở đây đây là alpha 1, đây là alpha 2 thì khi đó Khi đó, vector tổng hợp của mình thay vì nó bị lệch về phía này thì nó sẽ đi đều hơn. Và khi đó thì chúng ta sẽ vẽ lại.'] | Mạng Perceptron chỉ có khả năng giải quyết các bài toán tuyến tính. Một ví dụ về bài toán phức tạp mà Perceptron không thể giải quyết là phân loại hai tập điểm nằm trong và nằm ngoài một vòng tròn, vì điều này đòi hỏi một sự phân chia phi tuyến tính. Để giải quyết các bài toán phi tuyến tính, cần có sự kết hợp của nhiều đường thẳng hoặc sử dụng các kiến trúc mạng neural phức tạp hơn với các lớp ẩn.                  | Chúng ta lấy một cái tình huống ví dụ đó là hai cái tập điểm nằm trong và nằm ngoài vòng tròn.                                                                                             |       1        |           0.965013 |                 nan |                1 |\n",
      "| Mục tiêu của việc phát triển mô hình là gì?                                   | ['Các môn trước đây, nếu chúng ta tìm cách để liên kết giữa hình ảnh và văn bản, thì Visual Programming đi theo một phương cách hoàn toàn khác. Vì Visual Programming là gì? Chúng ta sẽ cùng tìm hiểu trong phần tiếp theo. Đầu tiên là phát triển bài toán. Mục tiêu của chúng ta là hướng đến để phát triển một mô hình có khả năng thực hiện được nhiều task khác nhau, hay gọi là General Purpose AI. Cách tiếp cận thông thường của chúng ta là 1.', 'Chúng ta sẽ cùng đến với một mô hình tạo sinh đầu tiên, đó là mô hình Autoencoder hay còn gọi là bộ tự mã hóa. Nền tảng của mô hình này là dựa trên hướng tiếp cận là học, không giám sát. Mục tiêu đó là làm sao chúng ta sẽ biểu diễn được đặc trưng của dữ liệu gốc ban đầu. Ví dụ như đầu vào của chúng ta là ảnh của một con số viết tay. Chúng ta sẽ tìm cách biểu diễn ảnh này thành một vector đặc trưng, trong đó nó có chiều thấp hơn. Giả sử như ảnh của chữ số viết tay có kích thước 28 x 28, đây là kích thước chuẩn trong tập dữ liệu MNIST.', 'Trên đây là bài giảng về quá trình tiến hóa của các mô hình học sâu.', 'Ở đây là công thức của sinh ảnh không có điều kiện. Đối với sinh ảnh mà có điều kiện, chúng ta sẽ thêm vô một biến nữa là biến y. Đây chính là conditional signal. Đây là conditional signal. Sau này khi tổng quát lên, y này không nhất thiết phải là văn bản. nó có thể là một cái mask, nó có thể là một cái điểm v.v. thì công thức của chúng ta thay vì là S theta của Xt, t thì chúng ta sẽ thêm cái thành phần là y vào đây và khi đó thì cái St này sẽ xấp xỉ với lại cái gradient của log p Xt cho trước y Đây là conditional score Công thức trước là unconditional score Bây giờ chúng ta sẽ chuyển sang conditional score chúng ta sẽ đưa vô một xác suất có điều kiện là i Chứ cho trước i, thì xác suất để tìm ra xt khi cho trước i là bao nhiêu? Chúng ta sẽ triển khai Và dựa trên định lý Bayes thì công thức này xuất phát từ triển khai như sau đó là cái log của Px t cho trước y thì nó sẽ là bằng log của Pxt cho trước y thì nó sẽ là bằng Pxt nhân với lại Pi cho trước xt tất cả chia cho Pi Với công thức này, chúng ta sẽ triển khai ra và có được là bằng đạo hàm của log của PxT Nhân thì chúng ta sẽ đưa về dấu cộng, đó là cộng cho log của Py cho trước xT Chia thì chúng ta sẽ chuyển thành là dấu trừ cho log của Pi Với công thức này, chúng ta thấy là vì chúng ta đang muốn tính đạo hàm theo XT chúng ta đang tính đạo hàm theo XT Đây là đạo hàm theo XT Trong con mắt của XT, thì y của mình là hằng số Do đó chúng ta sẽ loại bỏ đi thành phần này đi Tại vì đạo hàm của một cái hằng số đối với xt thì nó sẽ là bằng 0 Do đó thì công thức này sẽ đưa về công thức ở trên Đó là log của pxt cộng cho log của pi cho trước xt Và với cái công thức này thì chúng ta sẽ thấy là cái xt của mình Khi chúng ta khôi phục, chúng ta decode Bình thường nó sẽ đi theo con đường này là Unconditioned là màu xanh lá Màu xanh lá tương ứng cho Unconditioned Bình thường nó sẽ đi theo đường màu xanh dương Và qua màu xanh lá thì chúng ta sẽ điều hướng đi qua mũi tên màu xanh và cộng 2 cái đó lại thì nó sẽ ra cái mũi tên màu cam. Thế thì bình thường là chúng ta sẽ đi theo cái con đường này. Nhờ có cái vector gradient của log y cho trước xt, nó bẻ lái để biến thành cái vector màu cam này. Chúng ta lưu ý ở đây nó sẽ có thêm một cái hệ số nữa, nó gọi là classifier guidance. Nếu như trong công thức chúng ta biến đổi ở phía trước là chúng ta không có cái gamma ở đây thì hàm ý đó là một cái Unconditional Score nó sẽ kết hợp với một cái Adversarial Gradient tức là cái vector điều hướng theo tỷ lệ đó là 1,1 nhưng mà chúng ta muốn nó nhanh điều hướng thì chúng ta sẽ tăng cái hệ số tỷ lệ đó lên hoặc là chúng ta muốn chậm lại thì chúng ta sẽ giảm cái hệ số tỷ lệ đó xuống Như vậy trong công thức này, gamma sẽ là hệ số để giảm tốc độ điều hướng của mình Vector màu cam sẽ là tổng hợp của vector màu đỏ trong điều kiện là Unconditional Kết hợp với adversarial thì nó sẽ đưa ra, bẻ cái hướng, thay vì chúng ta đi theo hướng này để mà tìm được đến đây thì bây giờ nó bẻ hướng lại, nó sẽ đi theo cái hướng này để đến cái ảnh mà có cái điều kiện giống với lại cái Y của mình thì đó chính là cái Classifier Guidance thế thì cái mô hình này sẽ được thực hiện như thế nào Trước tiên chúng ta sẽ nói về vai trò của Classifier Guidance, tức là gamma hồi nãy của mình Nếu chúng ta chọn gamma là bằng một, tức là dùng công thức gốc ban đầu Thì kết quả của mình sẽ không được điều hướng đủ tốt và đủ nhanh Dẫn đến là nó sẽ tạo ra những hình thù không có thật Tại sao không có thật? Tại vì nó vừa pha trộn của một cái ảnh, của một đối tượng có một đối tượng thật mà lẽ ra với vector Z tạo ra tạo ra cái x0 khi có sự tham gia của gamma vào thì gamma này nó bẻ lái nhưng nó bẻ chưa đủ nhanh dẫn đến đó là kết quả của mình nó tạo ra đối tượng lai lai ở giữa đây là cái x0 còn đây là cái x0 mới thì lẽ ra là chúng ta hướng đến chỗ này nhưng mà cái gamma của chúng ta chưa đủ nên thay vì là nó bẻ lái bình thường là đến đây đúng không thì nó sẽ bẻ lái đến giữa chừng và ở cái khúc giữa chừng này thì nó tạo ra những tấm ảnh như thế này trong khi đó nếu chúng ta cho classifier guidance tức là cái gamma lớn hơn ví dụ như gamma trong trường hợp này bằng 10 thì nó sẽ bẻ lái mạnh hơn để mà nó đến được đến cái xnew giống với lại cái nội dung mà chúng ta mong muốn đó là Pembroke Welsh Corgi Đây là một cái giống chó rất là hiếm Vậy thì quá trình sinh ở trên là quá trình sinh có điều kiện và nó có một cái Classifier Guidance Vậy thì chúng ta sẽ huấn luyện cái mô hình này như thế nào Thì cái cách thức huấn luyện đó là chúng ta sẽ có thêm một cái module chúng ta sẽ có thêm một cái mạng nữa, nó gọi là một cái Classifier hay còn gọi là Off-the-shelf Classifier Và cứ với mỗi cái i mà chúng ta đưa vào thì chúng ta sẽ đi huấn luyện cho một cái classifier như vậy là một cái i sẽ có một cái classifier riêng Và như vậy thì nó sẽ khiến cho cái mô hình của mình nó không có tính linh động Nó không có tính linh động vì khi chúng ta muốn tạo ra một cái đối tượng mới Bình thường chúng ta tạo ra 2 con mèo đeo kính, bây giờ chúng ta muốn tạo ra 1 con chó Welsh Corgi đeo kính chẳng hạn thì lúc đó chúng ta sẽ phải train 1 cái classifier mới cho cái y đó thì nó sẽ khiến cho cái mô hình của mình nó chạy không có tính thực tiễn cao do đó thì chúng ta sẽ chuyển sang 1 cái mô hình, nó gọi là cái mô hình mà sinh có điều kiện nhưng mà với Classifier Free Guidance, tức là không có classifier Vậy thì công thức của mình sẽ được sửa lại đó là bằng 1 trừ gamma nhân cho log của PXT thì đây là cái Unconditional Score kết hợp với Conditional Score và ở đây chúng ta sẽ huấn luyện trên chính mô hình Diffusion của mình luôn Đây chính là U-Net trong diffusion. U-Net trong diffusion này chúng ta sẽ huấn luyện bằng cách đưa 2 tình huống. Tình huống thứ nhất là chúng ta sẽ đưa một vector rỗng vào. Mục tiêu của mình tương đương như một mô hình sinh ảnh nhưng mà không có điều hướng. và chúng ta sẽ đưa y vào, thì y này sẽ là mẫu dữ liệu huấn luyện của chúng ta và y này sẽ cho trước một số mẫu condition mà chúng ta muốn huấn luyện để từ đó nó sẽ estimate ra cái x, xt, t, y Thứ nhất là chúng ta sẽ không có thêm, không có classifier mà chúng ta sẽ huấn luyện trên chính cái mô hình của diffusion của mình luôn trên chính cái decoder của mình luôn và khi chúng ta huấn luyện trên cái decoder này thì chúng ta sẽ có hai tình huống một đó là chúng ta sẽ truyền vô một cái condition là rỗng đây là một cái condition rỗng Mục tiêu của nó là tạo ra tấm ảnh không có cần điều hướng và đưa vào 1 condition trong data set của mình để chuẩn bị trước, đó chính là y. Mục tiêu của mình là điều hướng đến cái này là không điều hướng, còn cái này là có điều hướng. sau khi chúng ta huấn luyện xong, chúng ta cứ sử dụng decoder này để đưa y vào và nó sẽ tạo sinh ra mô hình của mình thì cái sơ đồ này sẽ tương tự như nó sẽ lấy từ mô hình mà chúng ta đã học trong những slide trước bình thường là chúng ta chỉ đưa vào xt và t, bây giờ chúng ta sẽ đưa vào thêm y nữa để làm được việc này thì chúng ta có thể sử dụng các mô hình của Transformer với attention sử dụng key-value của attention để điều hướng thì cái i này có thể là query', 'Chúng ta sẽ cùng đến với một chủ đề rất là hot trong thời gian gần đây, đó là mô hình ngôn ngữ thị giác. Xuất phát điểm ý tưởng của mô hình ngôn ngữ thị giác đó là các bài toán của chúng ta hiện nay đòi hỏi có sự tham gia của nhiều thể thức dữ liệu hay còn gọi là multimodality model. Mô hình ngôn ngữ thị giác có thể gồm các modalities là văn bản, hình ảnh, âm thanh và video. Thế thì tại sao các mô hình của mình có sự tham gia của các loại thể thức dữ liệu khác nhau, đó là do nhu cầu ứng dụng của mình. Ví dụ như chúng ta hiện nay chúng ta thấy các ứng dụng của AI hiện giờ là cho phép chúng ta có thể điều khiển hoặc là giao tiếp bằng giọng nói. Nhưng mà ứng với cái giọng nói đó thì chúng ta có thể tạo ra các hình ảnh hoặc là chúng ta có thể trò chuyện với hình ảnh.', 'Nhưng cái đó chưa phải là một cái tiêu chí duy nhất mà chúng ta sẽ còn rất nhiều những cái tiêu chí khác. Mình có thể kể một vài cái tiêu chí ví dụ như là nó có thể hoạt động tốt khi chúng ta làm việc hoạt động tốt. Với dữ liệu mà mất cân bằng. Tức là cái y này của mình nó sẽ có nhiều class ví dụ vậy và có những class thì xuất hiện rất nhiều nhưng có những cái class rất ít. Thì cái hàm lỗi này nó phải làm sao để cho hướng cái mô hình đến cái việc là kể cả những mẫu dữ liệu mà ít thì vẫn có thể được cho cái vai trò ngang bằng với lại những cái mẫu như nhiều. Rồi ngoài ra thì chúng ta sẽ có những cái tiêu chí nữa ví dụ như hàm lỗi như thế nào để cho cái việc huấn luyện nhanh, hội tụ, huấn luyện nhanh.', 'Và bây giờ chúng ta sẽ quay trở lại đến với cái chủ đề của chúng ta. Đó là mô hình tạo sinh hay còn gọi là generative model. Thì mục tiêu của cái mô hình tạo sinh đó là chúng ta sẽ lấy mẫu dữ liệu huấn luyện. Lấy mẫu dữ liệu huấn luyện đầu vào của một số cái phân bố, của một số cái phân phối. Và từ đó chúng ta có thể tái tạo lại các cái phân phối đó.', 'Thì đó chính là cái ý tưởng của thuật toán Visual Programming. Và kỹ thuật chính mà nó sử dụng ở đây chính là Prompt Engineering và In-context Learning, để cung cấp ngữ cảnh, cộng với cái ví dụ minh họa. Và cái mô hình sử dụng ở đây là GPT-3. Một cách tổng quát thì chúng ta có thể sử dụng các cái mô hình mà dạng decoder, các cái mô hình dạng decoder, bất kỳ, chứ không phải là GPT-3. Rồi, thì cái In-context Example, In-context Example nó sẽ là một cái ví dụ như đây, là chúng ta sẽ truyền vào một cái cặp Instruction Program. Thì đây giống như là những cái mẫu ví dụ để cho máy tính nó sẽ tự biết được là các cái thao tác cần phải thực hiện.', 'Chúng ta có thể dùng trong lĩnh vực về phân loại một cái đối tượng nào đó, bài toán hồi quy, dự đoán một cái giá trị có tính thứ tự nào đó. Rồi phát hiện đối tượng, phân đoạn ngữ nghĩa đối tượng v.v. thì học có giám sát nó đã đạt được những thành tựu hiện nay và có thể ứng dụng được rất là rộng rãi. Thế thì còn một cái mảng nữa đó chính là học không có giám sát. Thì học không có giám sát đó là dữ liệu đầu vào chúng ta sẽ không có y mà chúng ta chỉ có duy nhất một biến x đầu vào. Chúng ta không có nhãn, thì đây chính là sự khác biệt lớn nhất giữa học không giám sát và học có giám sát. Mục tiêu của học không giám sát đó là chúng ta sẽ học từ cái cấu trúc ẩn của dữ liệu, hay là chúng ta sẽ đi học cái phân bố của dữ liệu. Phân bố của dữ liệu. Rồi, thì mình có thể lấy một cái ví dụ như sau để chúng ta hiểu thế nào là chúng ta đi học một cái cấu trúc ẩn và học một cái phân bố dữ liệu. Bằng cách đó là chúng ta sẽ trả lời cho cái câu hỏi sau. Một bạn học sinh có điểm trung bình là ví dụ như là 8,8 điểm. Thì theo các bạn đó là bạn này sẽ có cái học lực là giỏi, khá xuất sắc hay là dưới trung bình. Thì đa số đó là chúng ta sẽ không biết được cái điểm này là cao hay thấp khi chúng ta không đặt nó ở trong cái phân bố của những cái bạn còn lại trong lớp. Thì nếu như cái điểm của lớp mình mà có cái phân bố như sau, điểm 8,8 thì nằm ở cái khu vực này. Ví dụ như điểm 8,8 là nằm ở khu vực này. Thì bạn này là một bạn có học lực giỏi tại vì nhìn trong cái phân bố này bạn nằm ở cái top mà những người có điểm cao. Nhưng ngược lại nếu trong một cái phân bố khác, điểm 8,8 của bạn nó lại nằm ở đây. 8,8 thì khi đó là với cái phân bố này thì điểm của bạn là có học lực dưới trung bình. Như vậy để kết luận được tính chất của dữ liệu x thì chúng ta phải học được cái phân bố. Vì vậy, trong cái phân bố chúng ta sẽ xác định được cái phân bố của dữ liệu và từ đó chúng ta hình thành được cái cấu trúc ẩn của dữ liệu. Ví dụ chúng ta chia cái không gian của mình ra làm 3 phần. Ví dụ vậy thì đây là những cái bạn mà có học lực kém. Đây là những bạn có học lực trung bình và đây là những bạn có học lực giỏi. Ví dụ vậy thì đây là chúng ta đang cấu trúc hóa cái không gian ẩn của mình. Và những cái bài toán mà kinh điển liên quan đến cái học không giám sát đó chính là bài toán phân cụm, bài toán giảm chiều dữ liệu. Thì đó là chúng ta đã cùng ôn lại một vài cái khái niệm về học có giám sát và học không có giám sát.', 'Nó đã tận dụng được rất nhiều thành tựu của các kiến trúc trước đó. Ví dụ như là Skip Connection, Ví dụ như là LayerNorm, Ví dụ như là cái optimizer là AdamW, Ví dụ như là StackLayer. Ví dụ như là Ví dụ như là TransGPT, Ví dụ như là Transformer. Và việc huấn luyện các mô hình mà Transformer hiện nay thì đã có rất nhiều những doanh nghiệp công ty, hoặc là tổ chức nghiên cứu lớn mà thường là tổ chức nghiên cứu ở bên trong doanh nghiệp lớn để tạo ra các mô hình cho cộng đồng có thể sử dụng, ví dụ như là DeepSix, Ví dụ như là Llama, v.v. Các mô hình này đã góp phần cho việc nghiên cứu các mô hình học sâu hiện đại ngày càng trở nên thuận tiện hơn.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Mục tiêu chính của việc phát triển mô hình là hướng đến tạo ra một Trí tuệ nhân tạo đa năng (General Purpose AI), có khả năng thực hiện nhiều tác vụ khác nhau. Điều này khác biệt so với các phương pháp truyền thống thường tìm cách liên kết giữa hình ảnh và văn bản. Visual Programming được giới thiệu như một phương pháp tiếp cận hoàn toàn mới để đạt được mục tiêu phát triển AI đa năng này.                            | Mục tiêu của chúng ta là hướng đến để phát triển một mô hình có khả năng thực hiện được nhiều task khác nhau, hay gọi là General Purpose AI.                                               |       0.666667 |           0.884336 |                 nan |                1 |\n",
      "| Tại sao việc tự huấn luyện mô hình CLIP lại không khả thi?                    | ['Chúng ta sẽ cùng tìm hiểu về cách sử dụng một cái mô hình clip đã được tiền huấn luyện trên một bộ dữ liệu vô cùng lớn của OpenAI. Vì vậy, tự huấn luyện được môn clip là khá là không khả thi, vì nó cần lượng data cực kỳ lớn, tài nguyên tính toán, xử lý song song, GPU cũng cực kỳ mắc tiền. Vì vậy, khả duy nhất của chúng ta lúc này là chúng ta sẽ sử dụng một cái môn pre-drain để đi giải quyết những cái tác vụ đã có. Thế thì, đầu tiên chúng ta sẽ cài đặt một số cái thư viện cũng như là đưa cái môn clip, cái thư viện của clip về.', 'Thì đó là những cái yếu tố tác động đến cái mạng CNN đầu đời, mà khiến cho nó không có thể phát triển được. Thì cũng vì cái giai đoạn mà đầu đời, tức là trước những năm 2000, CPU là một cái tài nguyên không quá phổ biến và người ta cũng chưa có sử dụng nó, cũng như là chưa có nhiều thư viện để hỗ trợ lập trình với GPU. Nên giai đoạn này thì GPU chỉ dùng để chơi game chứ không có dùng để nghiên cứu. Thì đó chính là cái bối cảnh lịch sử trước khi mà AlexNet ra đời.', 'Và nó không có thực hiện cái phép nhân nhiều lần. Nhân đạo hàm nhiều lần.', 'Và nó sẽ dễ gây ra cái hiện tượng đó là lan truyền lỗi. Ví dụ điều gì xảy ra nếu như cái ảnh 64 x 64 này nó có những cái artifact, tức là những cái dấu hiệu để mà không có được đẹp và có những cái lỗi trong hình ảnh. Vì vậy thì nó sẽ lan truyền cái lỗi đó đến những cái ảnh sau mà không có cái cơ chế, nó không có cơ chế để sửa lỗi. Thế thì cái mô hình này cascade diffusion này thì nó sẽ không có phù hợp để mà có thể ứng dụng được. Lý do đó là vì thứ nhất là nó sẽ lan truyền lỗi.', 'Thay vì chúng ta làm một bước lớn thì nó sẽ khó để huấn luyện và bài toán của chúng ta phức tạp hơn. Thay vì chúng ta có một biến Z thì bây giờ nó sẽ là T biến là X1 cho đến XT, và do đó thì thành phần Z này sẽ biến thành từ X1 cho đến XT. Còn đối với biến X này của mình thì nó sẽ là X0, tức là cái giá trị ký hiệu ở đây.', 'Bình thường là chúng ta chỉ có tập các cái ảnh. Nhưng mà chúng ta sẽ không có cái ảnh đích, cái ảnh mà chúng ta muốn tạo thành. Còn kiến trúc của Pix2Pix tức là nó biến một cái picture thành một cái picture. Vâng, thì nó đòi hỏi chúng ta sẽ phải có một cặp ảnh để huấn luyện. Vì vậy, chúng ta sẽ có một cái cặp ảnh đó là ảnh thật và một cái ảnh mà có cái phân đoạn, semantic map. Thì đây là một cái cặp ảnh và nó tham gia vào quá trình huấn luyện cũng tương tự như GAN. Nó có generator và discriminator.', 'đó là những cái từ ít gặp Thì thậm chí là những cái từ mà có tính trừu tượng cao ví dụ như là the view, là khoanh vùng nguyên cái này là the view Rồi beautiful caribbean, caribe sea, thì ở đây chúng ta thấy là nó biết đây là một cái biển ở caribbean để mà nó khoanh vùng Thì đây chính là những cái khái niệm rất là trừu tượng và ít gặp trong thực tế mà clip nó vẫn có thể phát hiện bằng định vị được Vậy thì cách thức hoạt động và các cái module chính của clip là thực hiện như thế nào Thì đầu tiên đó là chúng ta sẽ tạo ra một cái code prompt tổng quát là tên của 80 vật thể trong tập dữ liệu coco được phân cách bởi dấu chấm Tức là mỗi một cái vật thể thì sẽ cách nhau với các vật thể khác, ví dụ chữ person, cách chữ bicycle là dấu chấm như thế này Và kèm theo là một cái câu mô tả, một cái cặp câu mô tả giữa hình ảnh và chúng ta sẽ đưa các cái từ này, cái code prompt Và cái câu mô tả này qua textencoder thì chúng ta sẽ tạo ra được là P0, P1, P2 v.v. Và tương tự như vậy thì cái ảnh chúng ta cũng sẽ khoanh vùng các cái đối tượng này và qua cái visualencoder để tạo ra cái O0, O1, O2 Lưu ý đó là trong cái mô hình clip thì chúng ta sẽ kết hợp hai cái loại dữ liệu là hình ảnh và văn bản ở bước trung gian G-clip thì là ở bước trung gian, trong khi đó với clip thì chúng ta chỉ kết hợp nó ở cái bước cuối cùng thôi Còn ở đây chúng ta sẽ thực hiện ở bước trung gian Thì tại sao lại có những cái việc như vậy? Đó là khi chúng ta tổng hợp ra cái đặc trưng thì ở phía trên là chỉ thuần nội dung cái đặc trưng về văn bản Còn ở bên dưới là các cái đặc trưng mà chúng ta thuần về hình ảnh và qua cái Fusion này thì chúng ta sẽ kết hợp được với nhau Đó là lấy cái đặc trưng của hình ảnh để bỏ vào văn bản và lấy nội dung của văn bản đưa vào hình ảnh để cho nó có thể tương tác để giúp cho hình ảnh nó có thể thực sự được thấy ở trong văn bản này Và cái sự khác biệt lớn nhất đó chính là cái module thứ 2, đó là chúng ta sẽ đo cái độ tương đồng giữa mỗi vùng và từ mô tả thay thế cho cái module phân lớp truyền thống Và ở trên đây chúng ta sẽ có m từ khóa là P1, P2, m token là P1, P2 và Pm Thì chúng ta có một cái lưu ý ở đây là có những cái từ mà dài và có hai, gọi là giống như tiếng Việt của mình là từ F là hair dryer thì nó sẽ tách ra làm hai, làm hai token hoặc có những cái từ hoặc cụm từ nó sẽ đi một cái combo với nhau, ví dụ như là blue dot, nó là một cái cụm từ thì nó sẽ tách ra làm hai token Thì khi đó chúng ta thấy là tính cái độ tương đồng nó sẽ là hai cái phần tử trên cái ma trận mà có cái giá trị lớn, ví dụ như đây là chữ tính từ và đây là danh từ thì chẳng hạn Hoặc trong cái ví dụ trên thì chúng ta thấy là hair dryer thì đây chính là hair và đây là dryer, hair và dryer này thì nó sẽ đi chung với nhau một cái combo khi chúng ta so sánh cái độ tương đồng với cái feature của cái hình ảnh là của cái máy sấy tóc Thì cái ý tưởng của nó cũng tương tự như clip nhưng mà clip thì sẽ tách nó ra thành các cái khu vực, các cái mảnh hình ảnh nhỏ rồi sau đó nó sẽ đi tính độ tương đồng với những cái từ ở bên trong cái chuỗi prompt của mình Cái token được tạo ra bởi cái prompt của mình Sau khi chúng ta đã tính được cái ma trận này rồi thì chúng ta sẽ đi tính cái alignment loss giữa cái ground truth, đây là cái ma trận ground truth Và ở trên đó là cái ma trận mà chúng ta được tính từ cái độ tương đồng giữa cái vùng ảnh, cục bộ với lại các cái token ở bên trong cái prompt của mình Và alignment loss này thì mục đích là để xác định xem cái đối tượng đó là gì, bên cạnh đó thì chúng ta sẽ có cái region feature để tính cái localization loss Mục tiêu đó là để cho chúng ta xác định xem cái vị trí, cái sai số khi dự đoán vị trí Thế thì quá trình huấn luyện của clip thì nó sẽ bao gồm đầu tiên đó là cái phrase routing Với mỗi một cái tấm ảnh ở đây, O1, O2, ON chúng ta sẽ truyền vào, truyền vào đây và chúng ta sẽ ra được O O chính là cái feature hoặc là cái embedding của cái vùng ảnh Và sau đó thì chúng ta sẽ lấy cái prompt, prompt của mình thì nó sẽ được hình thành từ cái câu là detect person bicycle car third brush v.v. Rồi, và cái ở đây thêm một cái ý nữa đó là cái feature mà biểu diễn cho cái đặc trưng hình ảnh thì đó là một cái đặc trưng có kích thước đó là D chiều Còn cái ảnh của mình thì nó sẽ có N cái vùng, N vùng Rồi tương tự như vậy thì prompt thì đặc trưng của mỗi từ hoặc là token thì chúng ta sẽ biểu diễn bởi các cái vector và đại diện nó là ma trận p Ma trận p này thì cũng tương tự đó là nó sẽ có chiều của cái đặc trưng văn bản sẽ là D chiều, giống như bên đây để mà sau này chúng ta có thể nhân tích vô hướng được Và số token của chúng ta thì sẽ có m token, và m này thì thường lớn hơn N rất là nhiều Rồi sau khi chúng ta lấy cái O và P chúng ta nhân với nhau thì chúng ta sẽ ra được cái S routing Thì cái S routing này nó sẽ có kích thước đó là N nhân m, trong đó N là số vật thể hoặc số vùng, m là số token Và cuối cùng là chúng ta sẽ dựa trên cái S routing này để chúng ta đi tính cái loss của mình, trong đó loss của mình thì nó sẽ có cái T phải là được mở rộng ra từ T bao gồm là N đối tượng Rồi, thế thì clip đó là cho phép chúng ta có thể tạo ra một cái câu prompt thủ công Ở trên ví dụ trên thì chúng ta có thể thấy những cái đối tượng hiếm và lạ thì ta có thể mô tả đối tượng đó bằng một cái nguồn tự nhiên Bình thường thì chúng ta mô tả đó là Car, Bus, Car, Dog, đây là những cái đối tượng tương đối là phổ biến Thì chúng ta sẽ không cần phải mô tả nhiều hơn, nhưng đối với cái từ lạ, ví dụ như là cá đuối, là stingray, thì nếu chúng ta đưa vào cái mô hình clip để mà phát hiện đối tượng thì chúng ta thấy là cái khả năng phát hiện của nó khá là thấp, nó chỉ phát hiện được một con và với cái Confidence là khoảng 0.21 Nhưng khi chúng ta mô tả nó dài dòng hơn, nhiều thông tin hơn, ví dụ như là stingray with a flat and round, thì ở đây chúng ta sẽ, mô hình của mình nó sẽ hiểu và nó sẽ phát hiện ra cái đối tượng nhiều hơn và dày đặc hơn.', 'Ở đây là công thức của sinh ảnh không có điều kiện. Đối với sinh ảnh mà có điều kiện, chúng ta sẽ thêm vô một biến nữa là biến y. Đây chính là conditional signal. Đây là conditional signal. Sau này khi tổng quát lên, y này không nhất thiết phải là văn bản. nó có thể là một cái mask, nó có thể là một cái điểm v.v. thì công thức của chúng ta thay vì là S theta của Xt, t thì chúng ta sẽ thêm cái thành phần là y vào đây và khi đó thì cái St này sẽ xấp xỉ với lại cái gradient của log p Xt cho trước y Đây là conditional score Công thức trước là unconditional score Bây giờ chúng ta sẽ chuyển sang conditional score chúng ta sẽ đưa vô một xác suất có điều kiện là i Chứ cho trước i, thì xác suất để tìm ra xt khi cho trước i là bao nhiêu? Chúng ta sẽ triển khai Và dựa trên định lý Bayes thì công thức này xuất phát từ triển khai như sau đó là cái log của Px t cho trước y thì nó sẽ là bằng log của Pxt cho trước y thì nó sẽ là bằng Pxt nhân với lại Pi cho trước xt tất cả chia cho Pi Với công thức này, chúng ta sẽ triển khai ra và có được là bằng đạo hàm của log của PxT Nhân thì chúng ta sẽ đưa về dấu cộng, đó là cộng cho log của Py cho trước xT Chia thì chúng ta sẽ chuyển thành là dấu trừ cho log của Pi Với công thức này, chúng ta thấy là vì chúng ta đang muốn tính đạo hàm theo XT chúng ta đang tính đạo hàm theo XT Đây là đạo hàm theo XT Trong con mắt của XT, thì y của mình là hằng số Do đó chúng ta sẽ loại bỏ đi thành phần này đi Tại vì đạo hàm của một cái hằng số đối với xt thì nó sẽ là bằng 0 Do đó thì công thức này sẽ đưa về công thức ở trên Đó là log của pxt cộng cho log của pi cho trước xt Và với cái công thức này thì chúng ta sẽ thấy là cái xt của mình Khi chúng ta khôi phục, chúng ta decode Bình thường nó sẽ đi theo con đường này là Unconditioned là màu xanh lá Màu xanh lá tương ứng cho Unconditioned Bình thường nó sẽ đi theo đường màu xanh dương Và qua màu xanh lá thì chúng ta sẽ điều hướng đi qua mũi tên màu xanh và cộng 2 cái đó lại thì nó sẽ ra cái mũi tên màu cam. Thế thì bình thường là chúng ta sẽ đi theo cái con đường này. Nhờ có cái vector gradient của log y cho trước xt, nó bẻ lái để biến thành cái vector màu cam này. Chúng ta lưu ý ở đây nó sẽ có thêm một cái hệ số nữa, nó gọi là classifier guidance. Nếu như trong công thức chúng ta biến đổi ở phía trước là chúng ta không có cái gamma ở đây thì hàm ý đó là một cái Unconditional Score nó sẽ kết hợp với một cái Adversarial Gradient tức là cái vector điều hướng theo tỷ lệ đó là 1,1 nhưng mà chúng ta muốn nó nhanh điều hướng thì chúng ta sẽ tăng cái hệ số tỷ lệ đó lên hoặc là chúng ta muốn chậm lại thì chúng ta sẽ giảm cái hệ số tỷ lệ đó xuống Như vậy trong công thức này, gamma sẽ là hệ số để giảm tốc độ điều hướng của mình Vector màu cam sẽ là tổng hợp của vector màu đỏ trong điều kiện là Unconditional Kết hợp với adversarial thì nó sẽ đưa ra, bẻ cái hướng, thay vì chúng ta đi theo hướng này để mà tìm được đến đây thì bây giờ nó bẻ hướng lại, nó sẽ đi theo cái hướng này để đến cái ảnh mà có cái điều kiện giống với lại cái Y của mình thì đó chính là cái Classifier Guidance thế thì cái mô hình này sẽ được thực hiện như thế nào Trước tiên chúng ta sẽ nói về vai trò của Classifier Guidance, tức là gamma hồi nãy của mình Nếu chúng ta chọn gamma là bằng một, tức là dùng công thức gốc ban đầu Thì kết quả của mình sẽ không được điều hướng đủ tốt và đủ nhanh Dẫn đến là nó sẽ tạo ra những hình thù không có thật Tại sao không có thật? Tại vì nó vừa pha trộn của một cái ảnh, của một đối tượng có một đối tượng thật mà lẽ ra với vector Z tạo ra tạo ra cái x0 khi có sự tham gia của gamma vào thì gamma này nó bẻ lái nhưng nó bẻ chưa đủ nhanh dẫn đến đó là kết quả của mình nó tạo ra đối tượng lai lai ở giữa đây là cái x0 còn đây là cái x0 mới thì lẽ ra là chúng ta hướng đến chỗ này nhưng mà cái gamma của chúng ta chưa đủ nên thay vì là nó bẻ lái bình thường là đến đây đúng không thì nó sẽ bẻ lái đến giữa chừng và ở cái khúc giữa chừng này thì nó tạo ra những tấm ảnh như thế này trong khi đó nếu chúng ta cho classifier guidance tức là cái gamma lớn hơn ví dụ như gamma trong trường hợp này bằng 10 thì nó sẽ bẻ lái mạnh hơn để mà nó đến được đến cái xnew giống với lại cái nội dung mà chúng ta mong muốn đó là Pembroke Welsh Corgi Đây là một cái giống chó rất là hiếm Vậy thì quá trình sinh ở trên là quá trình sinh có điều kiện và nó có một cái Classifier Guidance Vậy thì chúng ta sẽ huấn luyện cái mô hình này như thế nào Thì cái cách thức huấn luyện đó là chúng ta sẽ có thêm một cái module chúng ta sẽ có thêm một cái mạng nữa, nó gọi là một cái Classifier hay còn gọi là Off-the-shelf Classifier Và cứ với mỗi cái i mà chúng ta đưa vào thì chúng ta sẽ đi huấn luyện cho một cái classifier như vậy là một cái i sẽ có một cái classifier riêng Và như vậy thì nó sẽ khiến cho cái mô hình của mình nó không có tính linh động Nó không có tính linh động vì khi chúng ta muốn tạo ra một cái đối tượng mới Bình thường chúng ta tạo ra 2 con mèo đeo kính, bây giờ chúng ta muốn tạo ra 1 con chó Welsh Corgi đeo kính chẳng hạn thì lúc đó chúng ta sẽ phải train 1 cái classifier mới cho cái y đó thì nó sẽ khiến cho cái mô hình của mình nó chạy không có tính thực tiễn cao do đó thì chúng ta sẽ chuyển sang 1 cái mô hình, nó gọi là cái mô hình mà sinh có điều kiện nhưng mà với Classifier Free Guidance, tức là không có classifier Vậy thì công thức của mình sẽ được sửa lại đó là bằng 1 trừ gamma nhân cho log của PXT thì đây là cái Unconditional Score kết hợp với Conditional Score và ở đây chúng ta sẽ huấn luyện trên chính mô hình Diffusion của mình luôn Đây chính là U-Net trong diffusion. U-Net trong diffusion này chúng ta sẽ huấn luyện bằng cách đưa 2 tình huống. Tình huống thứ nhất là chúng ta sẽ đưa một vector rỗng vào. Mục tiêu của mình tương đương như một mô hình sinh ảnh nhưng mà không có điều hướng. và chúng ta sẽ đưa y vào, thì y này sẽ là mẫu dữ liệu huấn luyện của chúng ta và y này sẽ cho trước một số mẫu condition mà chúng ta muốn huấn luyện để từ đó nó sẽ estimate ra cái x, xt, t, y Thứ nhất là chúng ta sẽ không có thêm, không có classifier mà chúng ta sẽ huấn luyện trên chính cái mô hình của diffusion của mình luôn trên chính cái decoder của mình luôn và khi chúng ta huấn luyện trên cái decoder này thì chúng ta sẽ có hai tình huống một đó là chúng ta sẽ truyền vô một cái condition là rỗng đây là một cái condition rỗng Mục tiêu của nó là tạo ra tấm ảnh không có cần điều hướng và đưa vào 1 condition trong data set của mình để chuẩn bị trước, đó chính là y. Mục tiêu của mình là điều hướng đến cái này là không điều hướng, còn cái này là có điều hướng. sau khi chúng ta huấn luyện xong, chúng ta cứ sử dụng decoder này để đưa y vào và nó sẽ tạo sinh ra mô hình của mình thì cái sơ đồ này sẽ tương tự như nó sẽ lấy từ mô hình mà chúng ta đã học trong những slide trước bình thường là chúng ta chỉ đưa vào xt và t, bây giờ chúng ta sẽ đưa vào thêm y nữa để làm được việc này thì chúng ta có thể sử dụng các mô hình của Transformer với attention sử dụng key-value của attention để điều hướng thì cái i này có thể là query', 'Chúng ta có thể học không giám sát trên tập dữ liệu rất lớn hay gọi là pre-training. Và cái pre-training này sẽ giúp chúng ta tạo ra những cái pre-trained model để có thể tổng quát hóa được các task, thì nó có thể tạo ra được các embeddings và dùng các embeddings đó để giải quyết các tác vụ của các bài toán khác nhau. Cách tiếp cận thứ 2 đó là học giám sát. Thì chúng ta sẽ fine-tune mô hình cho từng task cụ thể. Thế thì sẽ có bước pre-training trước và sau đó sẽ là fine-tuning sau.', 'Thì ở đây chúng ta sẽ dẫn nhập, giải thích cái ý này. Các cái mô hình của mình khi được huấn luyện thì lấy dữ liệu ở trong thực tế mà dữ liệu chúng ta sampling trong thực tế thì 95% Chúng ta lấy một cái ví dụ đó là dữ liệu mà lái xe trên đường. 95% dữ liệu mà chúng ta lái xe, tức là nó nằm ở trong cái khu vực này. Là trong cái khu vực này.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Việc tự huấn luyện mô hình CLIP không khả thi vì nó đòi hỏi một lượng dữ liệu cực kỳ lớn. Đồng thời, quá trình này cần tài nguyên tính toán và khả năng xử lý song song đáng kể. Ngoài ra, chi phí cho các thiết bị GPU cũng rất cao, khiến việc tự huấn luyện trở nên không thực tế.                                                                                                                                              | Tự huấn luyện được môn clip là khá là không khả thi, vì nó cần lượng data cực kỳ lớn, tài nguyên tính toán, xử lý song song, GPU cũng cực kỳ mắc tiền.                                     |       1        |           0.997339 |                 nan |                1 |\n",
      "| Mô hình tạo sinh giúp ích gì trong việc huấn luyện mô hình?                   | ['Thu thập dữ liệu rất là nhiều. Thế thì nhờ có các cái mô hình tạo sinh tạo ra các cái ảnh tự động. Chúng ta chỉ cần đi lấy mẫu một cái điểm trong cái phân phối này. Xong rồi chúng ta tái tạo lại thì chúng ta đã có một cái ảnh mới. Thì cái mô hình tạo sinh nó đã giúp cho chúng ta tự động tăng cường dữ liệu lên. Giúp cho cái việc huấn luyện mô hình gọi là đỡ bị hiện tượng overfitting hơn. Thì đó chính là cái động cơ của mô hình tạo sinh. Và giả sử như chúng ta có một cái mẫu dữ liệu. Chúng ta lấy mẫu dữ liệu để huấn luyện. Chúng ta lấy được cái mẫu này. Sau đó chúng ta xác định được cái phân phối của nó. Đây là ước lượng một cái hàm mật độ.', 'Và bây giờ chúng ta sẽ quay trở lại đến với cái chủ đề của chúng ta. Đó là mô hình tạo sinh hay còn gọi là generative model. Thì mục tiêu của cái mô hình tạo sinh đó là chúng ta sẽ lấy mẫu dữ liệu huấn luyện. Lấy mẫu dữ liệu huấn luyện đầu vào của một số cái phân bố, của một số cái phân phối. Và từ đó chúng ta có thể tái tạo lại các cái phân phối đó.', 'Trong cái quá trình mà huấn luyện để tránh được những cái tình huống không thể đoán được. Tại vì khi chúng ta muốn xây dựng cái dữ liệu cho cái hệ thống xe tự lái, chúng ta phải lường trước những cái tình huống mà xe sẽ gặp những cái tình huống mà hiếm xuất hiện. Ví dụ như có một người băng qua trước mặt, hoặc là đường thì gập ghềnh, đường bị quanh co, hoặc là thời tiết xấu. Thế thì cái mà chúng ta mong muốn có cái dữ liệu để cho mô hình của mình, để cải thiện cái mô hình của mình, đó là những cái tình huống là phân bố ở bên ngoại vi, tức là outlier. Đây là cái outlier mà chúng ta mong muốn có dữ liệu để cho mô hình nó học. Ví dụ đó là có cái giải phân cách, hoặc là có cái tình huống là máy bay lớn đi trên đầu, hoặc là thời tiết xấu, thời tiết cực đoan, ví dụ như là mưa to, bão tuyết, hoặc là có tình huống người đi bộ băng qua đột ngột trước mặt mình, hoặc là đùa giỡn, v.v. Thì đó chính là những cái tình huống ngoại vi mà chúng ta mong muốn có cái dữ liệu này để cho mô hình của mình nó học được. Thì đó chính là cái lý do tại sao chúng ta cần có mô hình tạo sinh, để khi chúng ta sampling với những cái tình huống ngoại lệ này, thì chúng ta sẽ có được những cái dữ liệu này, nó sẽ giúp cho cái bộ dữ liệu huấn luyện của chúng ta nó cân bằng hơn. Nó giúp cân bằng hơn và dẫn đến là mô hình của mình nó sẽ không bị bias vào 95% những cái dữ liệu mà đẹp, dữ liệu bình thường ở đây. Và một trong những cái hướng tiếp cận để mà tạo ra các cái mô hình tạo sinh, đó là chúng ta sẽ sử dụng mô hình là Latent Variable, tức là mô hình dựa trên biến tiềm ẩn và có hai cái mô hình chúng ta sẽ cùng tìm hiểu trong cái buổi ngày hôm nay, đó là mô hình về Autoencoder, đó là Autoencoder phiên bản gốc và Variational Autoencoder hay viết tắt là VAE và Generative Adversarial Network, tức là mô hình tạo sinh đối kháng GAN. Thì đây là hai cái mô hình dựa trên cái biến tiềm ẩn.', 'Vấn đề đó là làm thế nào để khi gặp những cái đối tượng mới hoặc là hiếm trong dữ liệu. Rồi chiến lược đó là chúng ta sẽ tận dụng được các cái mô hình tạo sinh để phát hiện ra các điểm dữ liệu lạ trong cái phân bố. Rồi sau đó sử dụng các cái dữ liệu Outlier này để mà cho cái quá trình huấn luyện mô hình, nó sẽ cải thiện được cái mô hình tốt hơn.', 'Ở đây là công thức của sinh ảnh không có điều kiện. Đối với sinh ảnh mà có điều kiện, chúng ta sẽ thêm vô một biến nữa là biến y. Đây chính là conditional signal. Đây là conditional signal. Sau này khi tổng quát lên, y này không nhất thiết phải là văn bản. nó có thể là một cái mask, nó có thể là một cái điểm v.v. thì công thức của chúng ta thay vì là S theta của Xt, t thì chúng ta sẽ thêm cái thành phần là y vào đây và khi đó thì cái St này sẽ xấp xỉ với lại cái gradient của log p Xt cho trước y Đây là conditional score Công thức trước là unconditional score Bây giờ chúng ta sẽ chuyển sang conditional score chúng ta sẽ đưa vô một xác suất có điều kiện là i Chứ cho trước i, thì xác suất để tìm ra xt khi cho trước i là bao nhiêu? Chúng ta sẽ triển khai Và dựa trên định lý Bayes thì công thức này xuất phát từ triển khai như sau đó là cái log của Px t cho trước y thì nó sẽ là bằng log của Pxt cho trước y thì nó sẽ là bằng Pxt nhân với lại Pi cho trước xt tất cả chia cho Pi Với công thức này, chúng ta sẽ triển khai ra và có được là bằng đạo hàm của log của PxT Nhân thì chúng ta sẽ đưa về dấu cộng, đó là cộng cho log của Py cho trước xT Chia thì chúng ta sẽ chuyển thành là dấu trừ cho log của Pi Với công thức này, chúng ta thấy là vì chúng ta đang muốn tính đạo hàm theo XT chúng ta đang tính đạo hàm theo XT Đây là đạo hàm theo XT Trong con mắt của XT, thì y của mình là hằng số Do đó chúng ta sẽ loại bỏ đi thành phần này đi Tại vì đạo hàm của một cái hằng số đối với xt thì nó sẽ là bằng 0 Do đó thì công thức này sẽ đưa về công thức ở trên Đó là log của pxt cộng cho log của pi cho trước xt Và với cái công thức này thì chúng ta sẽ thấy là cái xt của mình Khi chúng ta khôi phục, chúng ta decode Bình thường nó sẽ đi theo con đường này là Unconditioned là màu xanh lá Màu xanh lá tương ứng cho Unconditioned Bình thường nó sẽ đi theo đường màu xanh dương Và qua màu xanh lá thì chúng ta sẽ điều hướng đi qua mũi tên màu xanh và cộng 2 cái đó lại thì nó sẽ ra cái mũi tên màu cam. Thế thì bình thường là chúng ta sẽ đi theo cái con đường này. Nhờ có cái vector gradient của log y cho trước xt, nó bẻ lái để biến thành cái vector màu cam này. Chúng ta lưu ý ở đây nó sẽ có thêm một cái hệ số nữa, nó gọi là classifier guidance. Nếu như trong công thức chúng ta biến đổi ở phía trước là chúng ta không có cái gamma ở đây thì hàm ý đó là một cái Unconditional Score nó sẽ kết hợp với một cái Adversarial Gradient tức là cái vector điều hướng theo tỷ lệ đó là 1,1 nhưng mà chúng ta muốn nó nhanh điều hướng thì chúng ta sẽ tăng cái hệ số tỷ lệ đó lên hoặc là chúng ta muốn chậm lại thì chúng ta sẽ giảm cái hệ số tỷ lệ đó xuống Như vậy trong công thức này, gamma sẽ là hệ số để giảm tốc độ điều hướng của mình Vector màu cam sẽ là tổng hợp của vector màu đỏ trong điều kiện là Unconditional Kết hợp với adversarial thì nó sẽ đưa ra, bẻ cái hướng, thay vì chúng ta đi theo hướng này để mà tìm được đến đây thì bây giờ nó bẻ hướng lại, nó sẽ đi theo cái hướng này để đến cái ảnh mà có cái điều kiện giống với lại cái Y của mình thì đó chính là cái Classifier Guidance thế thì cái mô hình này sẽ được thực hiện như thế nào Trước tiên chúng ta sẽ nói về vai trò của Classifier Guidance, tức là gamma hồi nãy của mình Nếu chúng ta chọn gamma là bằng một, tức là dùng công thức gốc ban đầu Thì kết quả của mình sẽ không được điều hướng đủ tốt và đủ nhanh Dẫn đến là nó sẽ tạo ra những hình thù không có thật Tại sao không có thật? Tại vì nó vừa pha trộn của một cái ảnh, của một đối tượng có một đối tượng thật mà lẽ ra với vector Z tạo ra tạo ra cái x0 khi có sự tham gia của gamma vào thì gamma này nó bẻ lái nhưng nó bẻ chưa đủ nhanh dẫn đến đó là kết quả của mình nó tạo ra đối tượng lai lai ở giữa đây là cái x0 còn đây là cái x0 mới thì lẽ ra là chúng ta hướng đến chỗ này nhưng mà cái gamma của chúng ta chưa đủ nên thay vì là nó bẻ lái bình thường là đến đây đúng không thì nó sẽ bẻ lái đến giữa chừng và ở cái khúc giữa chừng này thì nó tạo ra những tấm ảnh như thế này trong khi đó nếu chúng ta cho classifier guidance tức là cái gamma lớn hơn ví dụ như gamma trong trường hợp này bằng 10 thì nó sẽ bẻ lái mạnh hơn để mà nó đến được đến cái xnew giống với lại cái nội dung mà chúng ta mong muốn đó là Pembroke Welsh Corgi Đây là một cái giống chó rất là hiếm Vậy thì quá trình sinh ở trên là quá trình sinh có điều kiện và nó có một cái Classifier Guidance Vậy thì chúng ta sẽ huấn luyện cái mô hình này như thế nào Thì cái cách thức huấn luyện đó là chúng ta sẽ có thêm một cái module chúng ta sẽ có thêm một cái mạng nữa, nó gọi là một cái Classifier hay còn gọi là Off-the-shelf Classifier Và cứ với mỗi cái i mà chúng ta đưa vào thì chúng ta sẽ đi huấn luyện cho một cái classifier như vậy là một cái i sẽ có một cái classifier riêng Và như vậy thì nó sẽ khiến cho cái mô hình của mình nó không có tính linh động Nó không có tính linh động vì khi chúng ta muốn tạo ra một cái đối tượng mới Bình thường chúng ta tạo ra 2 con mèo đeo kính, bây giờ chúng ta muốn tạo ra 1 con chó Welsh Corgi đeo kính chẳng hạn thì lúc đó chúng ta sẽ phải train 1 cái classifier mới cho cái y đó thì nó sẽ khiến cho cái mô hình của mình nó chạy không có tính thực tiễn cao do đó thì chúng ta sẽ chuyển sang 1 cái mô hình, nó gọi là cái mô hình mà sinh có điều kiện nhưng mà với Classifier Free Guidance, tức là không có classifier Vậy thì công thức của mình sẽ được sửa lại đó là bằng 1 trừ gamma nhân cho log của PXT thì đây là cái Unconditional Score kết hợp với Conditional Score và ở đây chúng ta sẽ huấn luyện trên chính mô hình Diffusion của mình luôn Đây chính là U-Net trong diffusion. U-Net trong diffusion này chúng ta sẽ huấn luyện bằng cách đưa 2 tình huống. Tình huống thứ nhất là chúng ta sẽ đưa một vector rỗng vào. Mục tiêu của mình tương đương như một mô hình sinh ảnh nhưng mà không có điều hướng. và chúng ta sẽ đưa y vào, thì y này sẽ là mẫu dữ liệu huấn luyện của chúng ta và y này sẽ cho trước một số mẫu condition mà chúng ta muốn huấn luyện để từ đó nó sẽ estimate ra cái x, xt, t, y Thứ nhất là chúng ta sẽ không có thêm, không có classifier mà chúng ta sẽ huấn luyện trên chính cái mô hình của diffusion của mình luôn trên chính cái decoder của mình luôn và khi chúng ta huấn luyện trên cái decoder này thì chúng ta sẽ có hai tình huống một đó là chúng ta sẽ truyền vô một cái condition là rỗng đây là một cái condition rỗng Mục tiêu của nó là tạo ra tấm ảnh không có cần điều hướng và đưa vào 1 condition trong data set của mình để chuẩn bị trước, đó chính là y. Mục tiêu của mình là điều hướng đến cái này là không điều hướng, còn cái này là có điều hướng. sau khi chúng ta huấn luyện xong, chúng ta cứ sử dụng decoder này để đưa y vào và nó sẽ tạo sinh ra mô hình của mình thì cái sơ đồ này sẽ tương tự như nó sẽ lấy từ mô hình mà chúng ta đã học trong những slide trước bình thường là chúng ta chỉ đưa vào xt và t, bây giờ chúng ta sẽ đưa vào thêm y nữa để làm được việc này thì chúng ta có thể sử dụng các mô hình của Transformer với attention sử dụng key-value của attention để điều hướng thì cái i này có thể là query', 'Vân vân. Và sau đó thì chúng ta sẽ đi học để tái tạo lại phân phối đó. Từ đó có thể lấy mẫu một cái mẫu mới. Rồi sau đó chúng ta tạo ra một cái dữ liệu. Và cái dữ liệu này vì chúng ta đã học ra được cái phân phối của các cái không gian mà có chứa cái ảnh gương mặt. Nên khi chúng ta lấy mẫu trong cái phân phối này thì khi chúng ta khôi phục, chúng ta tái tạo lại thì nó cũng sẽ ra ảnh một cái gương mặt. Và đó chính là cái ý nghĩa của cái mô hình tạo sinh. Tức là chúng ta sẽ đi lấy mẫu dữ liệu, huấn luyện nó vào để huấn luyện cho một cái phân phối. Và sau đó để học cái cách để mà chúng ta học để mà tái tạo lại. Đây là tái tạo. Chúng ta sẽ tái tạo lại cái tấm ảnh mới. Thì cái quá trình tái tạo này chính là cái quá trình tạo sinh ảnh. Thế thì cái mô hình tạo sinh ở giai đoạn đầu nó được sử dụng để phục vụ cho cái công việc đó là tăng cường dữ liệu. Tại vì các cái mô hình học máy chúng ta biết rằng là các cái mô hình học máy thì nó sẽ bị cái hiện tượng gọi là hiện tượng overfitting.', 'Và huấn luyện nó cũng sẽ ổn định hơn. Thì đó chính là cái điều khiến cho latent diffusion model là một trong những cái mô hình tạo sinh hình ảnh mà được rất nhiều cái trích dẫn và được rất nhiều các cái bài báo cũng như là các cái nghiên cứu gần đây họ sử dụng để phát triển.', 'Thì đây là mẫu tạo sinh. Thì đối với cái mẫu đầu vào thì chúng ta sẽ ký hiệu đó là dữ liệu huấn luyện. Chúng ta sẽ sampling trong cái Pdata. Trong cái Pdata, tức là cái dữ liệu thế giới thực. Mẫu tạo sinh thì chúng ta sẽ đi sampling trong cái Pmodel. Tức là giả sử như chúng ta đã có cái model này rồi. Đây là cái model. Rồi thì chúng ta sẽ sampling trong cái dữ liệu trong cái không gian của cái mô hình mà mình ước lượng được. Đây là cái mô hình ước lượng được. Rồi từ đó chúng ta tái tạo lại. Và cái việc mà học một cái mô hình tạo sinh là chúng ta tìm cách nào đó để cho cái mô hình PmodelX nó sẽ có cái sự tương tự về mặt phân phối giống như là Pdata. Thì đây chính là cái mục tiêu của các cái mô hình tạo sinh. Pmodel phải xấp xỉ, phải tương tự với lại cái P của data. Vậy thì tại sao chúng ta cần phải có cái mô hình tạo sinh thì nó có khả năng là khám phá ra các đặc trưng cơ bản của dữ liệu. Ví dụ các đặc trưng về mặt màu da, các đặc trưng về tư thế đồng nhất.', 'Thì chúng ta thấy cái khu vực này là xuất hiện dày đặc. Nhưng mà nó hơi ít hơn so với cái khu vực bên tay phải. Khu vực này sẽ xuất hiện dày hơn. Còn ở cái khu vực ở giữa ở đây hoặc là ở ngoài rìa ở đây thì chúng ta thấy đó là khi lấy mẫu nó thưa hơn. Do đó khi chúng ta ước lượng ra cái hàm mật độ thì nó sẽ có cái dạng như thế này. Đó là hai đỉnh. Và khi chúng ta tạo sinh mẫu thì từ chúng ta sẽ tạo ra được những cái ảnh mới mà có cái tính chất giống như là cái tính chất của cái ảnh mà chúng ta đã lấy mẫu trước đó. Thì đây là, trong cái ví dụ này thì đây chính là cái mẫu đầu vào để huấn luyện. Đó là cái ảnh trong thế giới thực.', 'Như vậy thì chúng ta đã cùng tìm hiểu về những phương pháp để tạo sinh hình ảnh tuy nhiên những phương pháp trên bao gồm VAE, Diffusion thậm chí là GAN đó là chúng ta sẽ khởi tạo ngẫu nhiên một vector Z và từ đó nó sẽ tạo ra một tấm hình của mình qua hàm decoder nhưng mà quá trình decoder này thì chúng ta không kiểm soát được đầu ra của mình thì trong thực tế chúng ta sẽ có những nhu cầu đó là làm sao để kiểm soát được ảnh đầu ra tạo ra những tấm ảnh mà chúng ta muốn với nội dung mà chúng ta muốn Vậy thì, cái phần điều hướng ảnh tạo sinh là một cái phần để giúp chúng ta trả lời được câu hỏi đó là Làm sao để sinh ảnh được từ văn bản? Văn bản chỉ là một trong những cách để giúp chúng ta điều hướng cái ảnh của mình Trên hình đó là quá trình sinh ảnh mà không có điều kiện Tức là với một vector Z ngẫu nhiên qua hàm decoder với tham số theta mà chúng ta đã huấn luyện thì nó sẽ giúp chúng ta tạo ra các hình ảnh, ví dụ như là chó, mèo, gấu và bò nằm trong phân bố P theta X như thế này và quá trình sinh ảnh mà có điều kiện thì chúng ta sẽ đưa vào conditional signal, tức là một tín hiệu có điều kiện là I Ví dụ như trong ngữ cảnh này sẽ là a cat wearing sunglasses thì cái y này sẽ được đưa vào quá trình decoder tại mỗi step và khi đưa vào thì chúng ta sẽ điều hướng hoặc là bẻ lái thì đây là một cái từ mang tính hình tượng thôi đó là bẻ lái cái hướng Bình thường nếu như một cái vector z bất kỳ thì nó sẽ đưa đến cái khu vực ảnh mà ví dụ như có cái đối tượng không liên quan đến cái nội dung mình đang muốn Nhưng mà nhờ có conditional signal tham gia qua quá trình decode thì nó sẽ bẻ hướng để chúng ta đến vào khu vực ảnh mà có những con mèo đeo kính cool như thế này. Ở đây chúng ta sẽ có một mô hình để giúp chúng ta sinh ảnh có điều kiện.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Mô hình tạo sinh giúp tự động tăng cường dữ liệu, từ đó giảm thiểu hiện tượng overfitting trong quá trình huấn luyện mô hình. Đặc biệt, chúng còn hỗ trợ phát hiện và tạo ra dữ liệu cho các tình huống hiếm gặp hoặc ngoại lệ, như các điều kiện đường xá bất thường hay thời tiết khắc nghiệt. Việc này giúp cân bằng bộ dữ liệu huấn luyện, ngăn chặn mô hình bị thiên vị bởi dữ liệu phổ biến và cải thiện hiệu suất tổng thể. | Mô hình tạo sinh giúp chúng ta tự động tăng cường dữ liệu lên, giúp cho việc huấn luyện mô hình đỡ bị hiện tượng overfitting hơn.                                                          |       1        |           0.951516 |                 nan |                1 |\n",
      "Hoàn tất đánh giá.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import List, Dict\n",
    "from datasets import Dataset\n",
    "\n",
    "# --- Ragas & Datasets ---\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "from datasets import Dataset\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- HÀM MỚI: Tạo bộ test tổng hợp từ Vector DB ---\n",
    "async def generate_synthetic_test_set_from_db(llm: ChatGoogleGenerativeAI, db: Chroma, num_samples: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Lấy các chunk từ Chroma DB, chọn ngẫu nhiên, và dùng LLM tạo câu hỏi + câu trả lời mẫu.\n",
    "    \"\"\"\n",
    "    print(f\"Đang lấy chunk từ Vector DB để tạo bộ test...\")\n",
    "    try:\n",
    "        # Lấy TẤT CẢ các chunk từ DB\n",
    "        raw_data = db.get(include=[\"documents\", \"metadatas\"])\n",
    "        all_chunks_data = [\n",
    "            {\"page_content\": doc, \"metadata\": meta}\n",
    "            for doc, meta in zip(raw_data[\"documents\"], raw_data[\"metadatas\"])\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"LỖI: Không thể lấy dữ liệu từ Chroma DB: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Lọc các chunk quá ngắn hoặc có nội dung không phù hợp\n",
    "    valid_chunks = [\n",
    "        chunk for chunk in all_chunks_data\n",
    "        if len(chunk[\"page_content\"]) > 200 and \"subscribe\" not in chunk[\"page_content\"].lower()\n",
    "    ]\n",
    "\n",
    "    if len(valid_chunks) < num_samples:\n",
    "        print(f\"Cảnh báo: Chỉ tìm thấy {len(valid_chunks)} chunk hợp lệ. Sẽ dùng tất cả.\")\n",
    "        num_samples = len(valid_chunks)\n",
    "        if num_samples == 0:\n",
    "            print(\"LỖI: Không có chunk hợp lệ để tạo bộ test.\")\n",
    "            return []\n",
    "\n",
    "    sampled_chunks = random.sample(valid_chunks, num_samples)\n",
    "\n",
    "    generation_prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Bạn là một chuyên gia tạo dữ liệu. Dựa vào NGỮ CẢNH (context) sau đây, hãy tạo ra 1 cặp (câu hỏi, câu trả lời) mà NGỮ CẢNH này có thể trả lời trực tiếp.\n",
    "        - Câu trả lời (answer) phải được rút ra TRỰC TIẾP từ NGỮ CẢNH.\n",
    "        - Câu hỏi (question) phải là câu hỏi mà một người xem video sẽ hỏi.\n",
    "        - Trả lời bằng tiếng Việt.\n",
    "        - Chỉ trả về 1 JSON object với 2 key: \"question\" và \"ground_truth\".\n",
    "\n",
    "        NGỮ CẢNH:\n",
    "        {context}\n",
    "\n",
    "        JSON:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    generation_chain = generation_prompt_template | llm\n",
    "\n",
    "    test_set = []\n",
    "    print(f\"Đang dùng LLM để tạo {num_samples} mẫu test...\")\n",
    "    for chunk_data in sampled_chunks:\n",
    "        context = chunk_data[\"page_content\"]\n",
    "        try:\n",
    "            response = await generation_chain.ainvoke({\"context\": context})\n",
    "            # LLM có thể trả về ```json ... ```, cần làm sạch\n",
    "            json_str = response.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            data = json.loads(json_str)\n",
    "\n",
    "            test_set.append({\n",
    "                \"question\": data[\"question\"],\n",
    "                \"ground_truth\": data[\"ground_truth\"], # Đây là câu trả lời mẫu\n",
    "                # Ragas cần 'ground_truth_context' là một list\n",
    "                \"ground_truth_context\": [context]\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi tạo câu hỏi cho chunk: {e}\")\n",
    "            print(f\"Chunk lỗi: {context[:100]}...\")\n",
    "\n",
    "    print(f\"Đã tạo xong {len(test_set)} mẫu test.\")\n",
    "    return test_set\n",
    "\n",
    "# --- HÀM M MAIN ĐỂ CHẠY ĐÁNH GIÁ ---\n",
    "async def main_evaluation():\n",
    "    print(\"Bắt đầu quá trình đánh giá RAG...\")\n",
    "\n",
    "    # --- 1. Lấy các biến đã khởi tạo từ cell trước ---\n",
    "    try:\n",
    "        # SỬA ĐỔI: Thêm 'embedding' vào danh sách kiểm tra\n",
    "        if 'llm' not in globals() or 'vector_retriever' not in globals() or 'bm25_runnable' not in globals() or 'embedding' not in globals():\n",
    "            print(\"LỖI: 'llm', 'vector_retriever', 'bm25_runnable', hoặc 'embedding' chưa được định nghĩa.\")\n",
    "            print(\"Hãy chạy các cell ở trên trước khi chạy cell này.\")\n",
    "            return\n",
    "        \n",
    "        # Tạo bản sao (hoặc tham chiếu) để code dễ đọc hơn\n",
    "        current_llm = llm\n",
    "        current_vector_retriever = vector_retriever\n",
    "        current_bm25_runnable = bm25_runnable\n",
    "        current_vector_db = vector_db\n",
    "        current_embedding = embedding # SỬA ĐỔI: Lấy embedding đã được định nghĩa\n",
    "\n",
    "    except NameError as e:\n",
    "        print(f\"LỖI: Thiếu biến. Hãy chạy các cell ở trên trước. Lỗi: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Định nghĩa 2 chain RỜI RẠC để đánh giá ---\n",
    "\n",
    "    # Hàm rerank (đã có ở cell trên)\n",
    "    def rerank_with_query(docs_and_query) -> List[Document]:\n",
    "        docs, query = docs_and_query\n",
    "        reranked = crossencoder_rerank(docs, query, top_k=10) # Dùng hàm 'crossencoder_rerank' đã định nghĩa\n",
    "        return reranked\n",
    "\n",
    "    # Chain 2a: RETRIEVER CHAIN (Hybrid + Rerank)\n",
    "    hybrid_retriever = EnsembleRetriever(\n",
    "        retrievers=[current_bm25_runnable, current_vector_retriever],\n",
    "        weights=[0.5, 0.5]\n",
    "    )\n",
    "\n",
    "    retriever_chain = (\n",
    "        RunnableLambda(lambda query: (hybrid_retriever.get_relevant_documents(query), query))\n",
    "        | RunnableLambda(rerank_with_query)\n",
    "    )\n",
    "\n",
    "    # Chain 2b: GENERATION CHAIN (Prompt + LLM + Parser)\n",
    "    # Dùng 'prompt' và 'parser' đã định nghĩa ở cell trên\n",
    "    parser = JsonOutputParser(pydantic_object=VideoAnswer) # Đảm bảo VideoAnswer đã được định nghĩa\n",
    "    \n",
    "    generation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Dựa vào transcript sau, trả lời câu hỏi của người dùng bằng tiếng Việt.Phần tóm tắt nội dung thì nên tóm tắt trong 3 câu, \n",
    "    dựa vào các đoạn transcript được cung cấp và chỉ ra đoạn video chứa thông tin đó (video url, thời điểm bắt đầu và kết thúc).\n",
    "    Đồng thời làm mượt lại nội dung tóm tắt đó\n",
    "    Khi trích dẫn thông tin, **luôn sử dụng đúng [Video URL] và [Start] từ doc chứa nội dung đó**.\n",
    "    Nếu không biết câu trả lời thì cứ trả lời là tôi không biết và độ tin cậy là zero\n",
    "    Nếu câu hỏi không liên quan đến nội dung video thì trả lời tôi chỉ được huấn luyện trả lời các câu hỏi liên quan đến nội dung video và độ tin cậy là zero\n",
    "    Không bịa ra thông tin không có căn cứ, không trả lời sai format\n",
    "    Nếu bạn cực kỳ chắc chắn về câu trả lời, hãy đặt độ tin cậy là high. Nếu bạn khá chắc chắn, hãy đặt độ tin cậy là medium. Nếu bạn không chắc chắn về câu trả lời, hãy đặt độ tin cậy là low.\n",
    "    Định dạng đầu ra phải tuân theo JSON schema sau:\n",
    "    {format_instructions}\n",
    "    Transcript:\n",
    "    {context}\n",
    "\n",
    "    Câu hỏi: {question}\n",
    "    \\nAnswer:\n",
    "    \"\"\") # Dùng prompt đã định nghĩa ở cell trên\n",
    "\n",
    "    generation_chain = (\n",
    "        generation_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "        | current_llm\n",
    "    )\n",
    "\n",
    "    # --- 3. Tạo bộ Test Set ---\n",
    "    # Dùng LLM của RAG (Gemini) để tạo test set từ Chroma\n",
    "    test_set = await generate_synthetic_test_set_from_db(current_llm, current_vector_db, num_samples=5) # Tăng num_samples (vd: 20) để kết quả tin cậy hơn\n",
    "\n",
    "    if not test_set:\n",
    "        print(\"Không thể tạo test set. Dừng đánh giá.\")\n",
    "        return\n",
    "\n",
    "    # --- 4. Chạy pipeline và thu thập dữ liệu ---\n",
    "    print(\"Đang chạy pipeline trên bộ test set...\")\n",
    "    evaluation_data = []\n",
    "\n",
    "    for i, item in enumerate(test_set):\n",
    "        print(f\"Đang xử lý mẫu {i+1}/{len(test_set)}: {item['question'][:50]}...\")\n",
    "        question = item['question']\n",
    "\n",
    "        # 4a. Lấy contexts\n",
    "        retrieved_docs = await retriever_chain.ainvoke(question)\n",
    "        contexts_list = [d.page_content for d in retrieved_docs]\n",
    "\n",
    "        # 4b. Lấy answer\n",
    "        formatted_context_str = format_doc(retrieved_docs) # Dùng hàm format_doc đã định nghĩa\n",
    "        response_msg = await generation_chain.ainvoke({\n",
    "            \"question\": question,\n",
    "            \"context\": formatted_context_str\n",
    "        })\n",
    "\n",
    "        try:\n",
    "            # Trích xuất câu trả lời text từ JSON\n",
    "            # LLM của bạn trả về AIMessage(content=\"```json\\n{...}\\n```\")\n",
    "            json_str = response_msg.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            answer_json = json.loads(json_str)\n",
    "            answer_text = answer_json.get(\"text\", \"\")\n",
    "        except Exception:\n",
    "            answer_text = response_msg.content # Fallback nếu JSON lỗi\n",
    "\n",
    "        evaluation_data.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": answer_text,\n",
    "            \"contexts\": contexts_list,\n",
    "            \"ground_truth\": item[\"ground_truth\"] # Câu trả lời mẫu\n",
    "        })\n",
    "\n",
    "    print(\"Đã thu thập xong dữ liệu. Chuẩn bị cho Ragas...\")\n",
    "\n",
    "    # --- 5. Chạy Ragas Evaluate ---\n",
    "    if not evaluation_data:\n",
    "        print(\"LỖI: Không có dữ liệu để đánh giá.\")\n",
    "        return\n",
    "\n",
    "    # Chuyển đổi list dictionary thành Hugging Face Dataset\n",
    "    dataset = Dataset.from_list(evaluation_data)\n",
    "\n",
    "\n",
    "    \n",
    "    metrics = [\n",
    "        faithfulness,     # Câu trả lời có bám sát context không? (Không bịa)\n",
    "        answer_relevancy, # Câu trả lời có liên quan đến câu hỏi không?\n",
    "        context_precision,# Context truy xuất có liên quan không?\n",
    "    ]\n",
    "    \n",
    "    # Thêm context_recall nếu bộ test có ground_truth_context\n",
    "    if \"ground_truth_context\" in test_set[0]:\n",
    "        print(\"Đã phát hiện ground_truth_context, sẽ đo context_recall.\")\n",
    "        # Thêm ground_truth_context vào evaluation_data cho Ragas\n",
    "        for i in range(len(evaluation_data)):\n",
    "            evaluation_data[i][\"ground_truth_context\"] = test_set[i][\"ground_truth_context\"]\n",
    "        \n",
    "        dataset = Dataset.from_list(evaluation_data) # Tạo lại dataset với key mới\n",
    "        metrics.append(context_recall)\n",
    "\n",
    "\n",
    "    print(\"Đang chạy Ragas evaluate... (Sử dụng Gemini làm Judge, việc này có thể mất vài phút)\")\n",
    "    \n",
    "    # SỬA ĐỔI: Cung cấp 'llm' và 'embeddings' của bạn cho Ragas\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=metrics,\n",
    "        llm=current_llm,        # Yêu cầu Ragas dùng Gemini (đã có API key)\n",
    "        embeddings=current_embedding # Yêu cầu Ragas dùng BAAI/bge-m3\n",
    "    )\n",
    "\n",
    "    print(\"--- KẾT QUẢ ĐÁNH GIÁ RAGAS ---\")\n",
    "    print(result)\n",
    "\n",
    "    # Chuyển sang dataframe để xem cho đẹp\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        df = result.to_pandas()\n",
    "        print(\"\\n--- Bảng kết quả chi tiết ---\")\n",
    "        print(df.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(\"\\nCài 'pandas' và 'tabulate' để xem bảng kết quả đẹp hơn.\")\n",
    "\n",
    "# --- Bắt đầu chạy đánh giá ---\n",
    "print(\"Chuẩn bị chạy đánh giá...\")\n",
    "# Bọc main() trong một hàm run để bắt lỗi\n",
    "def run_evaluation_notebook():\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(main_evaluation())\n",
    "    except RuntimeError as e:\n",
    "        if \"cannot be called from a running event loop\" in str(e):\n",
    "            print(\"\\nLỖI: Vẫn gặp lỗi asyncio.\")\n",
    "            print(\"Hãy thử khởi động lại kernel notebook và chạy lại cell này.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "run_evaluation_notebook()\n",
    "print(\"Hoàn tất đánh giá.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Phuc1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
